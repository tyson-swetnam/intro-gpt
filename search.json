{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Generative AI &amp; Prompt Engineering","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p></p> <p></p>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#welcome","level":2,"title":"Welcome","text":"<p>Welcome to this self-paced, asynchronous online workshop on generative AI and prompt engineering for academic research and education.</p> <p>Generative AI tools are now deeply integrated into how we work, conduct research, teach, and learn. This workshop will help you develop the skills to effectively utilize these powerful tools, focusing on the art of crafting \"prompts\" — the instructions that guide AI models — and exploring how to integrate AI into daily productivity.</p> <p>Learning Objectives</p> <p>After completing this workshop, you will be able to:</p> <ul> <li>Understand the current generative AI landscape and how it impacts the workplace and classroom</li> <li>Create effective prompts for leading AI platforms including Claude, ChatGPT, Gemini, and Copilot</li> <li>Apply AI tools to enhance teaching, research, and daily productivity</li> <li>Make informed decisions about when and how to integrate AI into your work</li> <li>Navigate ethical considerations and responsible AI use in academic contexts</li> </ul>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#workshop-agenda-learning-paths","level":2,"title":"Workshop Agenda &amp; Learning Paths","text":"<p>This workshop is organized into five main modules with an estimated 8-12 hours of content. You can complete them in order or skip to sections most relevant to your needs.</p> Module Topic Time 0 Getting Started - AI landscape and orientation 30-60 min 1 Platform Setup - Claude, ChatGPT, Gemini, Copilot 1-2 hours 2 Prompt Engineering &amp; Productivity - Core skills and daily use 2-3 hours 3 AI in Education - Teaching, tutoring, and academic administration 2-3 hours 4 AI for Research - Advanced tools and techniques 3-4 hours 5 Ethics &amp; Responsible AI - Ethical frameworks and considerations 1-2 hours <p> View the full agenda with detailed topics and learning paths</p>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#quick-start","level":2,"title":"Quick Start","text":"<p>Choose Your Path</p> BeginnersEducatorsResearchersDevelopers <p>New to AI? Start here:</p> <ol> <li> AI Landscape Overview - Understand the AI ecosystem</li> <li> Set up Claude or  ChatGPT - Get your first AI account</li> <li> Writing Effective Prompts - Learn core prompting techniques</li> <li> Ethics Overview - Understand responsible AI use</li> </ol> <p>Focus on teaching applications:</p> <ol> <li> Education Overview - AI's role in modern education</li> <li> Teaching with AI - Course design and content creation</li> <li> AI Tutoring - Personalized learning assistance</li> <li> Plagiarism &amp; Detection - Academic integrity</li> </ol> <p>Focus on research applications:</p> <ol> <li> Research Overview - AI in academic research</li> <li> Code Interpreters - Data analysis and visualization</li> <li> Agentic AI - Autonomous AI workflows</li> <li> RAG - Custom knowledge bases</li> </ol> <p>Focus on technical integration:</p> <ol> <li> GitHub Copilot - AI pair programming</li> <li> Vibe Coding - AI-assisted development</li> <li> Model Context Protocol - Tool integration</li> <li> OpenAI API - Programmatic access</li> </ol>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#prerequisites","level":2,"title":"Prerequisites","text":"<p> A computer with internet connection</p> <p> At least one AI platform account - Free tiers are available for all major platforms:</p> <ul> <li> Claude - Free or Pro ($20/month)</li> <li> ChatGPT - Free or Plus ($20/month)</li> <li> Google Gemini - Free or Advanced ($20/month)</li> <li> Microsoft Copilot - Free with Microsoft 365</li> </ul> <p> No prior AI experience required - This workshop starts with the basics and progresses to advanced topics</p> <p>Platform Recommendations</p> <p>Not sure which platform to choose? See our Platform Comparison Guide for detailed feature comparisons, pricing, and use-case recommendations.</p>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#workshop-sections","level":2,"title":"Workshop Sections","text":"","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#setup","level":3,"title":"Setup","text":"<p>Get started with major AI platforms. Each guide includes account setup, interface overview, and platform-specific tips.</p> Platform Description  Claude Anthropic's AI with Projects, Artifacts, and MCP support  ChatGPT OpenAI's ChatGPT with GPTs, Canvas, and Advanced Voice  Gemini Google's AI with workspace integration and multimodal capabilities  Microsoft Copilot AI integrated into Microsoft 365 applications  GitHub Copilot AI pair programming for developers","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#prompt-engineering","level":3,"title":"Prompt Engineering","text":"<p>Master the core skills for effective AI interaction.</p> Topic Description  Writing Prompts Core techniques: chain-of-thought, few-shot learning, role-based prompting  Daily Productivity AI for emails, writing, summarization, and workflow automation  Code Interpreters Data analysis, visualization, and computational tasks  Vibe Coding AI-assisted software development and prototyping  Choosing a Platform Compare features, pricing, and use cases","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#education","level":3,"title":"Education","text":"<p>Explore how AI can enhance teaching, learning, and academic administration.</p> Topic Description  Overview AI's transformative role in modern education  Teaching with AI Course design, content creation, and assessment  AI Tutoring Using AI as a personalized learning assistant  Admissions &amp; Recruiting AI for student recruitment and admissions  Plagiarism &amp; Detection AI detection tools and academic integrity","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#research","level":3,"title":"Research","text":"<p>Advanced topics for researchers using AI in their work.</p> Topic Description  Overview AI applications in academic research  Agentic AI Autonomous AI agents and workflows  AI Sandboxes Safe environments for AI experimentation  Jupyter AI AI integration in Jupyter notebooks  Model Context Protocol Claude's MCP for tool integration  NotebookLM Google's AI research assistant  Ollama Running LLMs locally  RAG Retrieval Augmented Generation for custom knowledge bases  OpenAI API Programming with OpenAI's API  HuggingFace Open-source models and datasets  Gradio Building AI interfaces  Posit (RStudio) AI tools for R users  VS Code &amp; AI Tools AI extensions for VS Code  Text Mining AI for text analysis and NLP","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#ethics","level":3,"title":"Ethics","text":"<p>Critical considerations for responsible AI use in academia.</p> Topic Description  Overview Ethical frameworks and principles for AI use  Bias Understanding and mitigating AI bias  Legal Copyright, privacy, and legal considerations  Transparency Disclosing AI use and maintaining integrity","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#hands-on-tutorials","level":3,"title":"Hands-On Tutorials","text":"<p>Apply your learning with practical case studies and tutorials.</p> Tutorial Description  Claude Code Workflow Complete workflow using Claude Code  Public Health Case Study AI for public health research  GIS &amp; Map Making Creating maps with AI assistance","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#about-this-workshop","level":2,"title":"About This Workshop","text":"<p>This workshop is developed and maintained by the University of Arizona BIO5 Institute, AI2S, &amp; College of Information Science.</p> <p>This website follows the FAIR and CARE data principles and hopes to help further open science.</p> <p>All materials are freely available and licensed under Creative Commons Attribution 4.0.</p> <p> Get started with the full agenda</p>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"admissions/","level":1,"title":"AI in Admissions and Job Recruiting","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#introduction","level":2,"title":"Introduction","text":"<p>AI has fundamentally transformed both sides of the admissions and recruiting process in 2026. Prospective students use AI to craft compelling application materials and prepare for entrance exams, while admissions officers and recruiters leverage AI to manage increasingly large applicant pools and identify promising candidates.</p> <p>Research indicates that over 33% of college applicants have used AI for essay assistance (EdWeek, 2024), and a significant majority of admissions offices now employ AI tools for application screening and evaluation (Forbes, 2024).</p> <p>This creates both opportunities and ethical challenges: How can applicants use AI authentically? How should institutions employ AI fairly? What constitutes appropriate vs. inappropriate AI use on both sides of the process?</p> <p>This guide addresses AI in admissions from multiple perspectives: admissions professionals, prospective undergraduate students, graduate program applicants, and job seekers.</p> <p>Key Audiences</p> <ul> <li>Admissions Professionals: How to use AI ethically and effectively in application review and recruitment</li> <li>Prospective Students: How to leverage AI for authentic, compelling applications</li> <li>Graduate Applicants: Specialized guidance for graduate and professional programs</li> <li>Job Seekers: AI strategies for career applications and recruiting</li> </ul> <p>For related guidance on AI's broader role in education, see:</p> <ul> <li>Education Overview - AI's impact on higher education</li> <li>Teaching with AI - Faculty perspectives on AI integration</li> <li>AI Tutoring - Student learning support</li> <li>Plagiarism &amp; AI Detection - Authenticity and academic integrity</li> </ul>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#for-admissions-professionals","level":2,"title":"For Admissions Professionals","text":"","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#application-review-assistance","level":3,"title":"Application Review Assistance","text":"<p>AI can help admissions staff manage high-volume application periods while maintaining holistic review standards:</p> <p>Initial Screening Applications:</p> <ul> <li>Flag incomplete applications or missing required materials</li> <li>Identify applications requiring special attention (first-generation, underrepresented groups, unique circumstances)</li> <li>Extract key data points for initial review (GPA, test scores, major requirements)</li> <li>Categorize applications by program, region, or other relevant factors</li> </ul> <p>Pattern Recognition:</p> <ul> <li>Identify common themes or strengths across applicant essays</li> <li>Detect potential plagiarism or AI-generated essays (with significant limitations—see Plagiarism &amp; AI Detection)</li> <li>Flag essays that may require additional human review for authenticity concerns</li> </ul> <p>Holistic Review Support:</p> <ul> <li>Summarize lengthy personal statements or supplemental essays for reviewer consideration</li> <li>Generate preliminary reader comments or notes for committee discussion</li> <li>Compare applicant qualifications against program requirements</li> </ul> <p>Critical Ethical Boundaries</p> <p>Never use AI to:</p> <ul> <li>Make final admissions decisions without human review</li> <li>Rank or score applications as sole determinant of admission</li> <li>Replace human judgment in evaluating applicant potential</li> <li>Process applications without transparency to applicants about AI use</li> <li>Use AI models that perpetuate demographic bias</li> </ul> <p>Always:</p> <ul> <li>Maintain human oversight of all AI-assisted decisions</li> <li>Audit AI tools regularly for bias and fairness</li> <li>Disclose AI use in admissions processes to applicants</li> <li>Ensure AI complements rather than replaces holistic human review</li> </ul>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#recruitment-and-outreach","level":3,"title":"Recruitment and Outreach","text":"<p>AI enhances enrollment management and outreach to prospective students:</p> <p>Personalized Outreach Emails:</p> <p>Generate tailored communication based on student interests, intended major, and engagement history:</p> <pre><code>Prompt: Draft a personalized outreach email for a prospective student interested\nin computer science who attended our virtual info session last month and lives in\n[region]. Highlight our new AI lab, undergraduate research opportunities, and career\noutcomes for CS majors. Keep tone warm and encouraging, 200-250 words.\n</code></pre> <p>Event Planning and Logistics:</p> <ul> <li>Generate schedules for campus visit days</li> <li>Create FAQ documents for prospective student events</li> <li>Draft talking points for admissions staff and student ambassadors</li> <li>Develop social media content promoting programs and events</li> </ul> <p>Multilingual Recruitment Materials:</p> <ul> <li>Translate recruitment materials into multiple languages for international recruitment</li> <li>Adapt messaging for cultural contexts and regional markets</li> <li>Create localized content for different geographic regions</li> </ul> <p>Personalization at Scale</p> <p>Use AI to create templates with personalization fields:</p> <pre><code>Dear [FirstName],\n\nThank you for your interest in [Program] at [University]. Based on your interest\nin [IntendedMajor], I wanted to share some exciting opportunities...\n\n[AI-generated personalized content based on major/interests]\n\n[Standard closing with contact information]\n</code></pre> <p>Review and customize AI-generated emails before sending, especially for high-priority recruits.</p>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#yield-management","level":3,"title":"Yield Management","text":"<p>AI supports data-driven enrollment predictions and targeted yield strategies:</p> <p>Predictive Modeling:</p> <ul> <li>Estimate likelihood of admitted students enrolling based on engagement data</li> <li>Identify students at risk of declining offers</li> <li>Predict financial aid sensitivity and enrollment likelihood</li> <li>Forecast enrollment numbers for capacity planning</li> </ul> <p>Personalized Retention Outreach:</p> <ul> <li>Generate targeted communication for admitted students showing low engagement</li> <li>Suggest interventions for students with questions or concerns</li> <li>Create personalized financial aid appeal responses</li> <li>Develop yield event invitation strategies</li> </ul> <p>Ethical Considerations:</p> <p>Ethical Yield Practices</p> <p>Acceptable:</p> <ul> <li>Using aggregate data to understand enrollment patterns</li> <li>Providing additional information to help students make informed decisions</li> <li>Offering support and answering questions for admitted students</li> </ul> <p>Problematic:</p> <ul> <li>Manipulative tactics pressuring students into enrollment decisions</li> <li>Differential treatment based on predicted ability to pay</li> <li>Withholding information to influence decisions</li> <li>Using AI to exploit student vulnerabilities or anxieties</li> </ul>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#international-student-recruitment","level":3,"title":"International Student Recruitment","text":"<p>AI facilitates global recruitment while respecting cultural differences:</p> <p>Translation and Cultural Adaptation:</p> <ul> <li>Translate recruitment materials accurately while preserving meaning</li> <li>Adapt messaging for cultural norms and expectations in target markets</li> <li>Generate multilingual social media content</li> <li>Create culturally appropriate communication strategies</li> </ul> <p>Virtual Tours and Presentations:</p> <ul> <li>AI-powered virtual tour narration in multiple languages</li> <li>Automated scheduling across time zones</li> <li>Real-time translation during virtual information sessions</li> <li>Personalized follow-up materials in students' native languages</li> </ul> <p>Document Translation Support:</p> <ul> <li>Assist with preliminary translation of international transcripts (human verification required)</li> <li>Generate English-language summaries of foreign credentials for initial review</li> <li>Create guides for document submission in multiple languages</li> </ul>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#graduate-program-recruiting","level":3,"title":"Graduate Program Recruiting","text":"<p>Graduate and professional program recruitment has unique considerations:</p> <p>Research Interest Matching:</p> <ul> <li>Identify faculty whose research aligns with applicant interests</li> <li>Suggest potential advisors for prospective PhD students</li> <li>Generate research summaries for faculty recruitment emails</li> <li>Create customized program descriptions highlighting relevant research areas</li> </ul> <p>Faculty-Student Pairing Suggestions:</p> <pre><code>Prompt: Based on this applicant's research statement focused on [topic], identify\n3-5 faculty members in our department whose work would be a strong fit. For each,\nprovide a 2-3 sentence summary of why their research aligns with the student's\ninterests.\n</code></pre> <p>Cohort Composition Optimization:</p> <ul> <li>Analyze admitted student research interests for cohort diversity</li> <li>Identify gaps in cohort composition (methodological, topical, demographic)</li> <li>Suggest targeted recruitment for underrepresented areas</li> <li>Generate funding allocation recommendations based on program goals</li> </ul> <p>Funding Communications:</p> <ul> <li>Draft personalized funding offer letters</li> <li>Generate fellowship application guidance</li> <li>Create TA/RA opportunity descriptions</li> <li>Develop funding comparison tools for admitted students</li> </ul>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#for-prospective-students","level":2,"title":"For Prospective Students","text":"","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#application-materials-with-ai","level":3,"title":"Application Materials with AI","text":"<p>AI can significantly support your application process when used authentically and ethically. The key is using AI as a brainstorming and editing partner, not as a ghostwriter.</p>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#acceptable-vs-unacceptable-ai-use","level":4,"title":"Acceptable vs. Unacceptable AI Use","text":"Task Acceptable AI Use Unacceptable AI Use Brainstorming ✓ Generate topic ideas for essays ✗ Have AI write entire essays Outlining ✓ Create essay structure and organization ✗ Submit AI-generated outlines as your own thinking Drafting ✓ Get suggestions for how to start paragraphs ✗ Copy AI-generated paragraphs verbatim Editing ✓ Check grammar, clarity, and flow ✗ Let AI completely rewrite your voice and ideas Resume Building ✓ Format suggestions and bullet point refinement ✗ Fabricate experiences or accomplishments Research ✓ Learn about programs and requirements ✗ Use AI-generated (often false) information without verification <p>Authenticity is Critical</p> <p>Admissions readers are trained to recognize authentic student voices. AI-generated essays often:</p> <ul> <li>Lack specific, personal details that make your story unique</li> <li>Use generic language and clichéd expressions</li> <li>Have perfect grammar but lack personality or distinctive voice</li> <li>Include suspiciously sophisticated vocabulary inconsistent with other materials</li> </ul> <p>Your application must reflect YOUR experiences, perspectives, and voice. Use AI as a tool, not a replacement for authentic self-expression.</p>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#personal-statement-development","level":3,"title":"Personal Statement Development","text":"<p>The personal statement is your opportunity to differentiate yourself. Here's an iterative AI-assisted workflow that maintains authenticity:</p> <p>Step 1: Brainstorming (AI-Assisted)</p> <pre><code>Prompt: I'm applying to [type of program] and need to write a personal statement.\nHelp me brainstorm by asking me questions about:\n- Formative experiences that shaped my interest in this field\n- Challenges I've overcome\n- What makes my perspective or background unique\n- Why this specific program/institution appeals to me\n\nAsk one question at a time and help me explore my answers deeply.\n</code></pre> <p>Step 2: Outlining (Your Work, AI Feedback)</p> <p>Create your outline based on your brainstorming, then:</p> <pre><code>Prompt: Here's my personal statement outline: [paste outline]\n\nProvide feedback on:\n- Does the structure flow logically?\n- Are any sections too brief or too detailed?\n- Does this effectively showcase my strengths and fit for the program?\n- What's missing that admissions readers would want to know?\n</code></pre> <p>Step 3: Drafting (Your Writing)</p> <p>Write your first draft yourself. This is critical. Your authentic voice must come through.</p> <p>Step 4: Revision (AI as Editor)</p> <pre><code>Prompt: I've written a draft of my personal statement. Help me improve it:\n\n[paste your draft]\n\nPlease provide feedback on:\n1. Clarity - Are any sentences confusing or unclear?\n2. Voice - Does this sound authentic and personal?\n3. Impact - Are there opportunities to be more specific or compelling?\n4. Grammar and mechanics\n\nDo NOT rewrite the essay. Give me suggestions I can implement myself.\n</code></pre> <p>Step 5: Final Polish (Your Work)</p> <p>Implement the suggestions that resonate with you, maintaining your voice and authenticity.</p> Good AI CollaborationBad AI Collaboration <p>Student's Draft: \"I've always been interested in environmental science because I care about climate change.\"</p> <p>AI Feedback: \"This is a good starting point, but it's quite general. Can you add a specific experience that sparked this interest? What made you care about climate change personally?\"</p> <p>Student's Revision: \"My interest in environmental science crystallized during the 2021 wildfires that forced my family to evacuate our home. Watching smoke obscure the sun for weeks made climate change viscerally real, not just an abstract concept.\"</p> <p>Student's Brief Note: \"I'm interested in environmental science because of climate change.\"</p> <p>AI Generated Essay: \"From a young age, I have been captivated by the intricate tapestry of our natural world. The pressing issue of climate change has ignited within me a profound passion for environmental science...\"</p> <p>Student: [Copies this verbatim into application]</p> <p>Problem: This is AI-generated content, not the student's authentic voice. It's generic, lacks personal specificity, and constitutes academic dishonesty.</p>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#program-research-and-selection","level":3,"title":"Program Research and Selection","text":"<p>AI can help you efficiently research and compare programs:</p> <p>Comparing Programs:</p> <pre><code>Prompt: I'm deciding between [University A's Program] and [University B's Program]\nfor graduate study in [field]. Based on publicly available information, help me\ncompare them across:\n\n- Faculty research strengths\n- Program structure and requirements\n- Career outcomes for graduates\n- Location and cost of living\n- Funding opportunities\n\nProvide a comparison table and highlight key differences.\n</code></pre> <p>Generating Campus Visit Questions:</p> <pre><code>Prompt: I'm visiting [University] to learn about their [Program]. Generate 10-15\nthoughtful questions I should ask during my visit about:\n- Academic experience and curriculum\n- Faculty mentorship and advising\n- Student life and community\n- Career preparation and outcomes\n- Unique opportunities or challenges\n\nPrioritize questions that will help me assess fit beyond what's on the website.\n</code></pre> <p>Financial Comparison:</p> <p>AI can help you create spreadsheets comparing total cost of attendance, funding packages, and long-term financial implications across multiple institutions.</p>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#test-preparation","level":3,"title":"Test Preparation","text":"<p>AI tutoring can supplement traditional test prep for standardized exams:</p> <p>GRE/GMAT/LSAT Study Support:</p> <pre><code>Prompt: I'm preparing for the [exam] and struggling with [specific section].\nCreate a 4-week study plan that:\n- Focuses on my weak areas in [specific content]\n- Includes practice problems with increasing difficulty\n- Incorporates spaced repetition for retention\n- Fits into 10-15 hours per week of study time\n</code></pre> <p>Practice Question Generation:</p> <pre><code>Prompt: Generate 10 [exam type] practice questions similar to those in [section].\nProvide answer explanations that teach the underlying concepts, not just the\nright answer.\n</code></pre> <p>Weak Area Identification:</p> <pre><code>Prompt: I completed this practice set: [describe your results]. Based on my\nerrors, what concepts should I review? What study strategies would help me\nimprove in these areas?\n</code></pre> <p>See AI Tutoring for comprehensive guidance on using AI for self-study.</p>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#interview-preparation","level":3,"title":"Interview Preparation","text":"<p>AI can simulate interviews and help you prepare compelling responses:</p> <p>Mock Interview Practice:</p> <pre><code>Prompt: Conduct a mock admissions interview for [program type]. Ask me common\nquestions one at a time. After I respond, provide constructive feedback on:\n- Content: Did I answer the question fully?\n- Structure: Was my response organized (STAR method if applicable)?\n- Delivery: Any suggestions for improvement?\n- Follow-up: What related questions might this response prompt?\n\nKeep feedback concise and actionable.\n</code></pre> <p>STAR Method Practice (Behavioral Questions):</p> <p>For questions about experiences, use the Situation-Task-Action-Result framework:</p> <pre><code>Prompt: I need to prepare a STAR response for this behavioral question:\n\"Tell me about a time you overcame a significant challenge.\"\n\nHere's my experience: [describe situation]\n\nHelp me structure this into a compelling STAR format response (2-3 minutes).\nHighlight what aspects are strongest and where I should add more detail.\n</code></pre> <p>Follow-Up Email Drafting:</p> <pre><code>Prompt: I just interviewed for [program] at [institution]. Draft a thank-you\nemail to [interviewer name/title] that:\n- Thanks them for their time\n- References a specific topic we discussed [mention topic]\n- Reaffirms my interest in the program\n- Keeps a professional yet warm tone\n- Stays under 200 words\n</code></pre>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#ethical-considerations","level":2,"title":"Ethical Considerations","text":"","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#disclosure-and-authenticity","level":3,"title":"Disclosure and Authenticity","text":"<p>When to Disclose AI Use:</p> <p>Different institutions have different expectations. Some general principles:</p> <ul> <li>Always disclose if asked directly on the application</li> <li>Consider disclosing in supplemental materials if AI played a significant role in brainstorming or editing (but not writing)</li> <li>Don't disclose minor uses like grammar checking, which is now standard practice</li> </ul> <p>Example Disclosure Language:</p> <p>\"I used AI tools for brainstorming essay topics and editing for clarity. All ideas, experiences, and perspectives are my own, and the essay reflects my authentic voice.\"</p>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#equity-and-access-concerns","level":3,"title":"Equity and Access Concerns","text":"<p>AI in admissions raises equity questions:</p> <p>For Applicants:</p> <ul> <li>Students with access to premium AI tools (ChatGPT Plus, Claude Pro) may have advantages over those using free versions</li> <li>Digital literacy and prompt engineering skills vary by background and privilege</li> <li>Some students may lack awareness of appropriate vs. inappropriate AI use</li> </ul> <p>For Institutions:</p> <ul> <li>AI screening tools may perpetuate existing biases in admissions</li> <li>Institutions serving underrepresented populations may have fewer resources for AI tools</li> <li>Small programs may lack technical capacity for responsible AI implementation</li> </ul> <p>Addressing Equity in AI-Assisted Admissions</p> <p>Recommendations for Institutions:</p> <ul> <li>Audit AI tools regularly for demographic bias</li> <li>Provide clear guidance to applicants about acceptable AI use</li> <li>Don't penalize applicants for AI use unless it constitutes plagiarism</li> <li>Ensure human review for all final admissions decisions</li> <li>Consider socioeconomic context when evaluating AI-polished applications</li> </ul> <p>Recommendations for Applicants:</p> <ul> <li>Use free AI tools (ChatGPT, Claude, Gemini) available to all students</li> <li>Focus on authenticity over polish</li> <li>Seek feedback from teachers, counselors, and mentors</li> <li>Remember that genuine experiences matter more than perfect writing</li> </ul>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#institutional-ai-policies","level":3,"title":"Institutional AI Policies","text":"<p>Many universities now have explicit policies about AI use in applications:</p> <p>Example Policy Spectrum:</p> <ul> <li>Disclosure Required: Some institutions require applicants to disclose any AI use</li> <li>Disclosure Optional: Most institutions don't specifically ask but expect authentic work</li> <li>AI-Generated Essays Prohibited: Some institutions explicitly prohibit AI-written application materials</li> <li>No Official Policy: Many institutions haven't yet established formal positions</li> </ul> <p>Checking Institutional Policies:</p> <ul> <li>Review application instructions carefully</li> <li>Check institution websites for AI guidance</li> <li>When in doubt, contact the admissions office directly</li> <li>Err on the side of caution and authenticity</li> </ul> <p>See Education Ethics for broader discussion of AI ethics in higher education.</p>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#best-practices-summary","level":2,"title":"Best Practices Summary","text":"","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#for-admissions-professionals_1","level":3,"title":"For Admissions Professionals","text":"<p>Do:</p> <ul> <li>Use AI to manage high-volume tasks and administrative work</li> <li>Maintain human oversight of all admissions decisions</li> <li>Audit AI tools regularly for bias and fairness</li> <li>Be transparent with applicants about AI use in admissions</li> <li>Provide clear guidance to applicants about acceptable AI use</li> </ul> <p>Don't:</p> <ul> <li>Rely on AI as sole decision-maker</li> <li>Use AI detection tools as primary authenticity check (high false positive rates)</li> <li>Implement AI without considering equity implications</li> <li>Use AI to replace holistic human review</li> </ul> <p>Sample Prompt Templates:</p> <pre><code>Application Summary: \"Summarize this personal statement in 3-4 bullet points\nhighlighting: applicant's primary motivation, key experiences, demonstrated fit\nfor program, and any unique factors for committee consideration.\"\n\nOutreach Email: \"Draft a 200-word email to admitted students in [program] who\nhaven't yet enrolled. Emphasize [program strengths], address common concerns\nabout [issue], and include a clear call to action to [next step].\"\n</code></pre>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#for-prospective-students_1","level":3,"title":"For Prospective Students","text":"<p>Do:</p> <ul> <li>Use AI for brainstorming and exploring ideas</li> <li>Edit and refine YOUR writing with AI feedback</li> <li>Verify all AI-provided information against authoritative sources</li> <li>Maintain your authentic voice and personal perspective</li> <li>Disclose AI use when asked or when significant</li> </ul> <p>Don't:</p> <ul> <li>Have AI write your essays or personal statements</li> <li>Copy AI-generated content verbatim into applications</li> <li>Fabricate experiences or accomplishments</li> <li>Trust AI-generated citations or sources without verification</li> <li>Use AI during interviews unless explicitly allowed</li> </ul> <p>Prompt Templates for Authentic Use:</p> <pre><code>Brainstorming: \"Help me explore this experience more deeply by asking me\nquestions: [describe experience]. Ask follow-up questions that help me\narticulate why this matters to me.\"\n\nEditing Feedback: \"I've written this paragraph for my personal statement:\n[paste paragraph]. Give me 3 specific suggestions for improvement that I\ncan implement myself. Don't rewrite it.\"\n\nResearch Verification: \"I found this information about [program]: [information].\nHelp me identify what I should verify against official sources and what\nquestions I should ask the admissions office.\"\n</code></pre>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"admissions/#additional-resources","level":2,"title":"Additional Resources","text":"<p>For Admissions Professionals:</p> <ul> <li>Common App AI Guidance</li> <li>NACAC Ethical Guidelines</li> <li>FERPA and AI in Admissions</li> </ul> <p>For Prospective Students:</p> <ul> <li>Harvard Graduate School of Education: Students Using AI</li> <li>College Application AI Ethics (The Nation)</li> <li>AI Tutoring Guide - Comprehensive student AI learning support</li> </ul> <p>Cross-References:</p> <ul> <li>Education Overview - Broader context on AI in higher ed</li> <li>Teaching with AI - Faculty perspectives and classroom AI use</li> <li>Plagiarism &amp; AI Detection - Understanding AI detection limitations and alternatives</li> </ul> <p>Last Updated: January 2026</p> <p>This guide reflects current best practices and will be updated as AI capabilities and institutional policies evolve.</p>","path":["Education","AI in Admissions and Job Recruiting"],"tags":[]},{"location":"agenda/","level":1,"title":"Self-Paced Online Workshop","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p></p>","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#format","level":3,"title":"Format","text":"<p>This is a self-paced, asynchronous online workshop designed to help academics, researchers, and educators learn to effectively use generative AI tools. All materials are freely available online and can be completed at your own pace.</p>","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#time-commitment","level":3,"title":"Time Commitment","text":"<p>We recommend dedicating 8-12 hours to complete the full workshop, though you can work through sections as needed based on your interests and experience level.</p>","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#creatorsinstructors","level":4,"title":"Creators/Instructors:","text":"<p>Greg Chism PhD </p> <p>Michele Cosi </p> <p>Jeffrey K. Gillan PhD </p> <p>Megh Krishnaswamy </p> <p>Carlos Lizárraga-Celaya PhD </p> <p>Enrique Noriega PhD </p> <p>Tyson Lee Swetnam PhD </p>","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#about","level":2,"title":"About","text":"<p>This website follows the FAIR and CARE data principles and hopes to help further open science. </p>","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#learning-path","level":2,"title":"Learning Path","text":"<p>This workshop is organized into five main modules. You can complete them in order or skip to sections most relevant to your needs.</p>","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#module-0-getting-started-30-60-minutes","level":3,"title":"Module 0: Getting Started (30-60 minutes)","text":"<p>If participating in an organized workshop, before you begin, please review our Code of Conduct.</p> <p>Start here to understand the AI landscape and set up your accounts.</p> Topic Description Link Welcome &amp; Overview Introduction to the workshop and learning objectives Welcome AI Landscape Understanding generative AI, LLMs, and the current ecosystem AI Landscape Code of Conduct Community guidelines and ethical AI use Code of Conduct","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#module-1-platform-setup-1-2-hours","level":3,"title":"Module 1: Platform Setup (1-2 hours)","text":"<p>Set up accounts and learn the basics of major AI platforms. Choose the platforms most relevant to your work.</p> Platform Description Link Claude Anthropic's Claude AI with MCP support Claude Setup ChatGPT OpenAI's ChatGPT Plus and API access ChatGPT Setup Gemini Google's Gemini AI with workspace integration Gemini Setup Microsoft Copilot Microsoft 365 Copilot integration Copilot Setup GitHub Copilot AI pair programming for developers GitHub Copilot Choosing a Platform Compare features, pricing, and use cases Comparison Guide","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#module-2-prompt-engineering-productivity-2-3-hours","level":3,"title":"Module 2: Prompt Engineering &amp; Productivity (2-3 hours)","text":"<p>Learn core skills for effective AI interaction and daily productivity.</p> Topic Description Link Writing Effective Prompts Core techniques for prompt engineering Prompt Engineering Daily Productivity AI for emails, writing, research, and workflow Daily Productivity Code Interpreters Using AI for data analysis and visualization Code Interpreters Vibe Coding AI-assisted software development Vibe Coding","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#module-3-ai-in-education-2-3-hours","level":3,"title":"Module 3: AI in Education (2-3 hours)","text":"<p>Explore how AI can enhance teaching, learning, and academic administration.</p> Topic Description Link Education Overview AI's role in modern education Education Overview Teaching with AI Course design, content creation, and assessment Teaching AI Tutoring Using AI as a personalized learning assistant Tutoring Admissions &amp; Recruiting AI for student recruitment and admissions Admissions Plagiarism &amp; Detection Understanding AI detection and academic integrity Plagiarism","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#module-4-ai-for-research-3-4-hours","level":3,"title":"Module 4: AI for Research (3-4 hours)","text":"<p>Advanced topics for researchers using AI in their work.</p> Topic Description Link Research Overview AI applications in academic research Research Overview Agentic AI Autonomous AI agents and workflows Agentic AI AI Sandboxes Safe environments for AI experimentation AI Sandboxes Jupyter AI AI integration in Jupyter notebooks Jupyter AI Model Context Protocol Claude's MCP for tool integration MCP NotebookLM Google's AI research assistant NotebookLM Ollama Running LLMs locally Ollama RAG (Retrieval Augmented Generation) Building AI with custom knowledge bases RAG OpenAI API Programming with OpenAI's API OpenAI API HuggingFace Open-source models and datasets HuggingFace Gradio Building AI interfaces Gradio Posit (RStudio) AI tools for R users Posit VS Code &amp; AI Tools AI extensions for VS Code VS Code Text Mining AI for text analysis and NLP Text Mining","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#module-5-ethics-responsible-ai-1-2-hours","level":3,"title":"Module 5: Ethics &amp; Responsible AI (1-2 hours)","text":"<p>Critical considerations for responsible AI use in academia.</p> Topic Description Link Ethics Overview Ethical frameworks for AI use Ethics Overview Bias Understanding and mitigating AI bias Bias Legal Considerations Copyright, privacy, and legal issues Legal Transparency Disclosing AI use and maintaining integrity Transparency","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#hands-on-tutorials","level":3,"title":"Hands-On Tutorials","text":"<p>Apply your learning with practical case studies and tutorials.</p> Tutorial Description Link Claude Code Workflow Complete workflow using Claude Code Claude Code Tutorial Public Health Case Study AI for public health research Public Health GIS &amp; Map Making Creating maps with AI assistance Map Making","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#recommended-learning-paths","level":3,"title":"Recommended Learning Paths","text":"<p>For Beginners:</p> <ol> <li>Module 0: Getting Started</li> <li>Module 1: Set up 1-2 platforms</li> <li>Module 2: Focus on Writing Prompts and Daily Productivity</li> <li>Module 5: Ethics Overview</li> </ol> <p>For Educators:</p> <ol> <li>Module 0: Getting Started</li> <li>Module 1: Platform Setup</li> <li>Module 2: Prompt Engineering</li> <li>Module 3: Complete Education section</li> <li>Module 5: Ethics &amp; Responsible AI</li> </ol> <p>For Researchers:</p> <ol> <li>Module 0: Getting Started</li> <li>Module 1: Platform Setup</li> <li>Module 2: Prompt Engineering &amp; Code Interpreters</li> <li>Module 4: Select relevant research topics</li> <li>Module 5: Ethics &amp; Responsible AI</li> <li>Hands-On Tutorials</li> </ol>","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#prerequisites","level":2,"title":"Prerequisites","text":"<p>To get the most out of this workshop, you'll need:</p> <p> A computer with internet connection</p> <p> At least one AI platform account - We recommend starting with:</p> <ul> <li>ChatGPT (Free or Plus)</li> <li>Claude (Free or Pro)</li> <li>Google Gemini (Free or Advanced)</li> <li>Microsoft Copilot (with Microsoft 365)</li> </ul> <p> Optional for developers: GitHub account with GitHub Copilot access</p> <p> No prior AI experience required - This workshop starts with the basics and progresses to advanced topics  </p>","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agenda/#code-of-conduct","level":2,"title":"Code of Conduct","text":"<p>This Code of Conduct applies to all Event participants, instructors, and activities during the workshop.</p> <p>Data Science Institute (DSI) is dedicated to providing professional computational research and educational experiences for all of our users, regardless of domain focus, academic status, educational level, gender/gender identity/expression, age, sexual orientation, mental or physical ability, physical appearance, body size, race, ethnicity, religion (or lack thereof), technology choices, dietary preferences, or any other personal characteristic.</p> <p>While participating at an Event, we expect you to:</p> <ul> <li>Interact with others and use GPTs professionally and ethically by     complying with our Policies.</li> <li>Constructively criticize ideas and processes, not people.</li> <li>Follow the Golden Rule (treat others as you want to be treated) when     interacting online or in-person with collaborators, trainers, and     support staff.</li> <li>Comply with this Code in spirit as much as the letter, as it is     neither exhaustive nor complete in identifying any and all possible     unacceptable conduct.</li> </ul> <p>We do not tolerate harassment of other users or staff in any form (including, but not limited to, violent threats or language, derogatory language or jokes, doxing, insults, advocating for or encouraging any of these behaviors). Sexual language and imagery are not appropriate at any time (excludes Protected Health Information in compliance with HIPAA). Any user violating this Code may be expelled from the platform and the workshop at DSI's sole discretion without warning.</p> <p>To report a violation of this Code, directly speak to a trainer. If you are not comfortable speaking to a trainer, or the trainer is who you are reporting, email info@cyverse.org with the following information:</p> <ul> <li>Your contact information</li> <li>Names (real, username, pseudonyms) of any individuals involved, and     or witness(es) if any.</li> <li>Your account of what occurred and if the incident is ongoing. If     there is a publicly available record (a tweet, public chat log,     etc.), please include a link or attachment.</li> <li>Any additional information that may be helpful in resolving the     issue.</li> </ul>","path":["Home","Self-Paced Online Workshop"],"tags":[]},{"location":"agentic/","level":1,"title":"Agentic AI","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#what-is-agentic-ai","level":2,"title":"What is Agentic AI?","text":"<p>\"Agents\" or \"Agentic\" AI systems are LLM-powered assistants that can take multiple autonomous actions when given prompts or tasks. Unlike traditional conversational AI that simply responds to queries, agentic AI can:</p> <ul> <li>Execute specific tasks independently with minimal supervision</li> <li>Reflect and reason about problems through multi-step thinking processes</li> <li>Make decisions based on context, predictions, and classifications</li> <li>Interact with tools and systems to accomplish complex workflows</li> <li>Adapt their approach based on feedback and results</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#key-characteristics-of-agentic-ai","level":2,"title":"Key Characteristics of Agentic AI","text":"","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#autonomy","level":3,"title":"Autonomy","text":"<p>Agentic AI can break down complex requests into subtasks and execute them without requiring step-by-step human guidance. For example, when asked to \"fix the bug in the checkout flow,\" an agentic system might:</p> <ol> <li>Search the codebase for checkout-related files</li> <li>Identify potential issues by analyzing error patterns</li> <li>Propose and implement fixes</li> <li>Run tests to verify the solution</li> <li>Document the changes made</li> </ol>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#tool-use-and-integration","level":3,"title":"Tool Use and Integration","text":"<p>Modern agentic AI systems can interact with external tools, APIs, and systems. This is where Model Context Protocol (MCP) becomes crucial. MCP allows AI agents to:</p> <ul> <li>Access file systems and databases</li> <li>Execute code and terminal commands</li> <li>Interact with version control systems like Git</li> <li>Connect to web services and APIs</li> <li>Read and modify application state</li> </ul> <p>See our MCP documentation for detailed information on how this protocol enables sophisticated agentic behaviors.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#iterative-problem-solving","level":3,"title":"Iterative Problem-Solving","text":"<p>Rather than providing a single response, agentic AI can iterate on solutions. It may:</p> <ul> <li>Try an approach, evaluate the results, and adjust</li> <li>Request additional context when needed</li> <li>Backtrack and try alternative strategies</li> <li>Learn from errors within a session</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#multi-step-reasoning","level":3,"title":"Multi-Step Reasoning","text":"<p>Agentic systems often employ chain-of-thought reasoning, breaking problems into logical steps and maintaining context across a sequence of operations. This is particularly evident in modern coding assistants during vibe coding workflows.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#agentic-ai-in-practice-vibe-coding","level":2,"title":"Agentic AI in Practice: Vibe Coding","text":"<p>The term \"vibe coding\" describes one of the most prominent applications of agentic AI today—where developers collaborate with AI agents directly in their development environment. Modern agentic coding tools include:</p> <ul> <li> Claude Code - VS Code extension with autonomous coding capabilities</li> <li> Cursor - Standalone editor with powerful agentic features</li> <li> Cline - Open-source VS Code extension pioneering \"bring your own model\" approach</li> <li> GitHub Copilot - Integrated agentic coding with GitHub workflows</li> <li> Windsurf - Standalone editor with agentic inline features</li> </ul> <p>These tools demonstrate agentic behavior by:</p> <ul> <li>Reading multiple files to understand project context</li> <li>Making coordinated changes across multiple files</li> <li>Running commands in the terminal to test changes</li> <li>Debugging errors and iterating on solutions</li> <li>Suggesting architectural improvements based on codebase analysis</li> </ul> <p>Learn more about these tools in our Vibe Coding guide.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#how-agentic-ai-works-the-agent-loop","level":2,"title":"How Agentic AI Works: The Agent Loop","text":"<p>Agentic AI typically operates using a perception-decision-action loop:</p> <pre><code>flowchart TD\n    A[User Request] --&gt; B[Perceive Context]\n    B --&gt; C[Plan Actions]\n    C --&gt; D[Execute Action]\n    D --&gt; E[Observe Results]\n    E --&gt; F{Goal Achieved?}\n    F --&gt;|No| B\n    F --&gt;|Yes| G[Report Completion]\n\n    style A fill:#e1f5ff\n    style G fill:#c8e6c9</code></pre> <ol> <li>Perceive: Gather context from the environment (code, files, system state)</li> <li>Plan: Determine what actions are needed to accomplish the goal</li> <li>Execute: Perform the action using available tools</li> <li>Observe: Evaluate the results and any errors</li> <li>Iterate: Continue until the goal is met or help is needed</li> </ol>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#enabling-technologies","level":2,"title":"Enabling Technologies","text":"","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#model-context-protocol-mcp","level":3,"title":"Model Context Protocol (MCP)","text":"<p>MCP is foundational for modern agentic AI systems. It provides:</p> <ul> <li>Standardized context access across different applications</li> <li>Tool invocation capabilities for executing actions</li> <li>Real-time application state awareness</li> <li>Cross-application coordination potential</li> </ul> <p>Without MCP or similar protocols, AI agents would be limited to conversational assistance. MCP enables them to \"see\" your work environment and \"act\" within it. Read our comprehensive MCP guide to understand how this works.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#function-calling-tool-use","level":3,"title":"Function Calling / Tool Use","text":"<p>Most modern LLMs support structured function calling, allowing them to:</p> <ul> <li>Invoke APIs with specific parameters</li> <li>Execute predefined workflows</li> <li>Query databases or search engines</li> <li>Interact with external services</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#extended-context-windows","level":3,"title":"Extended Context Windows","text":"<p>Larger context windows (200K+ tokens) enable agents to:</p> <ul> <li>Maintain awareness of entire projects</li> <li>Reference extensive documentation</li> <li>Track long conversation histories</li> <li>Analyze multiple files simultaneously</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#use-cases-for-agentic-ai","level":2,"title":"Use Cases for Agentic AI","text":"","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#software-development","level":3,"title":"Software Development","text":"<ul> <li>Automated code refactoring across multiple files</li> <li>Bug diagnosis and fixing with minimal guidance</li> <li>Test generation and execution</li> <li>Documentation creation from code analysis</li> <li>Code review and suggestions based on best practices</li> </ul> <p>Related: See Vibe Coding for development-focused tools.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#research-and-data-analysis","level":3,"title":"Research and Data Analysis","text":"<ul> <li>Data scraping and preprocessing from multiple sources</li> <li>Automated literature reviews with source synthesis</li> <li>Statistical analysis with iterative refinement</li> <li>Visualization generation and iteration</li> <li>Report generation from raw data</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#content-creation","level":3,"title":"Content Creation","text":"<ul> <li>Multi-format content generation (blog posts, social media, scripts)</li> <li>Iterative editing based on style guidelines</li> <li>Research and fact-checking during writing</li> <li>SEO optimization with keyword analysis</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#system-administration","level":3,"title":"System Administration","text":"<ul> <li>Log analysis and troubleshooting</li> <li>Automated deployment workflows</li> <li>Configuration management</li> <li>Security auditing and remediation</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#creative-work","level":3,"title":"Creative Work","text":"<ul> <li>Iterative design exploration in design tools</li> <li>3D modeling assistance with context awareness</li> <li>Music and art generation with style consistency</li> <li>Creative brainstorming with research integration</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#the-future-of-agentic-ai","level":2,"title":"The Future of Agentic AI","text":"<p>As agentic AI systems become more sophisticated, we're seeing:</p> <ul> <li>Multi-agent systems where specialized agents collaborate</li> <li>Longer-running agents that work on tasks over hours or days</li> <li>Cross-application coordination via protocols like MCP</li> <li>Improved safety mechanisms for autonomous operations</li> <li>Better user control over agent autonomy levels</li> </ul> <p>The combination of vibe coding tools, MCP integration, and increasingly capable LLMs is creating a new paradigm where AI agents become true collaborators in complex workflows.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#getting-started-with-agentic-ai","level":2,"title":"Getting Started with Agentic AI","text":"<p>To experience agentic AI firsthand:</p> <ol> <li>Try vibe coding: Install Claude Code or Cursor and experience agentic coding assistance</li> <li>Explore MCP: Set up Claude Desktop with MCP servers to see context-aware assistance</li> <li>Experiment with prompting: Practice breaking down complex tasks and letting the AI agent iterate on solutions</li> <li>Learn the tools: Explore the various vibe coding platforms to find the best fit for your workflow</li> </ol>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#best-practices-for-working-with-agentic-ai","level":2,"title":"Best Practices for Working with Agentic AI","text":"<ul> <li>Start with clear goals: Give agents well-defined objectives</li> <li>Monitor progress: Check in on agent actions, especially when learning</li> <li>Provide feedback: Correct course when the agent goes astray</li> <li>Understand limitations: Know when to take manual control</li> <li>Security awareness: Be cautious with agents that can execute code or access sensitive systems</li> <li>Iterate on prompts: Refine your instructions based on agent behavior</li> </ul> <p>Security Considerations</p> <p>Agentic AI systems that can execute code, access files, or interact with systems require careful security consideration. Always:</p> <ul> <li>Review code before execution in sensitive environments</li> <li>Use appropriate sandboxing and permissions</li> <li>Follow your institution's security policies</li> <li>Be aware of what tools and systems your AI agent can access</li> </ul> <p>Learn more in our Vibe Coding security warnings.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#further-resources","level":2,"title":"Further Resources","text":"<ul> <li>Vibe Coding Guide - Comprehensive overview of agentic coding tools</li> <li>Model Context Protocol (MCP) - Deep dive into the protocol enabling agentic behaviors</li> <li>AI Landscape - Broader context on AI capabilities and models</li> <li>Anthropic's Claude - Documentation for one of the leading agentic AI systems</li> <li>LangChain Agents - Framework for building custom agentic systems  </li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"ai_landscape/","level":1,"title":"The Landscape","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#the-generative-ai-landscape-in-2026","level":2,"title":"The Generative AI Landscape in 2026","text":"<p>The generative AI landscape has transformed dramatically since the release of ChatGPT in November 2022. What began as text-generation models has exploded into a diverse ecosystem of platforms capable of creating text, images, video, code, and music—while also evolving from simple chatbots into sophisticated agentic systems that can autonomously complete complex tasks.</p> <p>This page provides an overview of the generative AI landscape as of January 2026, focusing on three key perspectives:</p> <ol> <li>The Evolution of Foundation Models - How we arrived at today's capable AI systems</li> <li>Platform Comparison - Choosing the right tool for your needs</li> <li>The Age of Agentic AI - How AI has evolved from conversation to autonomous action</li> </ol>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#evolution-of-foundation-models","level":2,"title":"Evolution of Foundation Models","text":"","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#the-llm-family-tree-2018-2023","level":3,"title":"The LLM Family Tree (2018-2023)","text":"<p>Image Credit: Yang et al. 2023 </p> <p>This diagram traces the lineage of large language models from 2018-2023, showing how modern models like GPT-4, Claude, and Gemini descended from earlier architectures. Key milestones include:</p> <ul> <li>2017: Transformer architecture introduced (\"Attention is All You Need\")</li> <li>2018-2019: BERT, GPT-2 demonstrate transfer learning potential</li> <li>2020: GPT-3 shows few-shot learning at scale (175B parameters)</li> <li>2021-2022: Model scaling continues (PaLM, GPT-3.5, ChatGPT)</li> <li>2023: Multimodal models emerge (GPT-4 with vision, Gemini)</li> <li>2024-2026: Agent capabilities, reasoning models, and specialized tools</li> </ul>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#from-text-generation-to-world-simulation","level":3,"title":"From Text Generation to World Simulation","text":"<p>The evolution of generative AI has progressed through distinct phases:</p> <p>Phase 1: Text Generation (2018-2022)</p> <ul> <li>Models like GPT-3, BERT, and T5 focused on understanding and generating text</li> <li>Primary use cases: chatbots, summarization, translation</li> <li>Interaction model: single-turn question-and-answer</li> </ul> <p>Phase 2: Multimodal Integration (2022-2024)</p> <ul> <li>Models gained ability to process images, audio, and eventually video</li> <li>GPT-4 Vision, Gemini, and Claude 3 could analyze charts, diagrams, and photos</li> <li>Enabled new use cases: visual analysis, document understanding, accessibility</li> </ul> <p>Phase 3: Agentic Systems (2024-Present)</p> <ul> <li>AI evolved from responding to acting</li> <li>Systems can now plan, use tools, and complete multi-step tasks autonomously</li> <li>Examples: Claude Code, GitHub Copilot Workspace, ChatGPT with Canvas</li> </ul> <p>Phase 4: Interactive World Models (Emerging)</p> <p>The frontier of generative AI research focuses on systems that not only generate content but simulate interactive environments:</p> <p>Self-Evolving AI Agents</p> <p></p> <p>Image: Self-Evolving Agent Taxonomy from Fang et al. 2025 </p> <p>Research is exploring agents that improve their own capabilities through experience, optimizing:</p> <ul> <li>Behavior: Learning better action strategies through reinforcement learning</li> <li>Prompts: Refining self-instructions iteratively</li> <li>Memory: Improving information storage and retrieval</li> <li>Tool Use: Learning when and how to leverage external capabilities</li> <li>Collaboration: Optimizing workflows across multiple specialized agents</li> </ul> <p>For more on agentic AI systems, see our dedicated Agentic AI documentation.</p> <p>Interactive Generative Video (IGV)</p> <p></p> <p>Image: IGV System Architecture from Yu et al. 2025 </p> <p>Unlike traditional video generation (Sora, Runway), Interactive Generative Video systems generate video content that responds to user input in real-time—essentially creating playable worlds from text descriptions.</p> <p>IGV systems combine five key modules:</p> Module Function Challenge Generation Creates high-quality video frames Real-time performance Control Handles user input (keyboard, mouse, natural language) Open-domain control Memory Maintains temporal consistency Long-term coherence Dynamics Simulates realistic physics Accurate simulation Intelligence Makes autonomous decisions Causal reasoning <p>Applications include:</p> <ul> <li>Gaming: Procedurally generated worlds that respond to player actions</li> <li>Embodied AI: Robots training in safe, scalable simulated environments</li> <li>Autonomous Driving: Testing edge cases in synthetic scenarios</li> <li>Education: Interactive science simulations</li> <li>Entertainment: Choose-your-own-adventure video content</li> </ul> <p>Example: Genie 3 (Google DeepMind)</p> <p>Genie 3 represents a breakthrough in interactive world models—capable of generating playable 3D environments from a single image or text description. Unlike traditional video generation that creates fixed sequences, Genie 3 produces controllable, interactive worlds where users can navigate and interact in real-time.</p> <p>Key capabilities:</p> <ul> <li>Image-to-World: Upload a single image → explore it as a playable 3D environment</li> <li>Text-to-World: Describe a scene → generate an interactive world from scratch</li> <li>Real-time Control: WASD navigation, camera control, physics simulation</li> <li>Temporal Consistency: Maintains coherent world state across extended interactions</li> </ul> <p>Mote: Interactive Ecosystem Simulation</p> <p>Mote is an interactive ecosystem simulation that combines elements from games and research, creating a sandbox for computational biology, machine learning, and physics. It uses a custom GPU-based physics engine (1:07) to model many simple behaviors at a massive scale, leading to emergent phenomena.</p> <p></p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#ai-platform-comparison","level":2,"title":"AI Platform Comparison","text":"<p>The AI landscape now includes dozens of platforms, each optimized for different use cases. Rather than duplicate extensive comparison tables here, we've consolidated all platform comparisons into a single comprehensive guide:</p> <p>📊 Choosing the Right AI Platform includes:</p> <ul> <li>Platform Comparison Tables by use case (Chat, Research, Code, Image/Video)</li> <li>Agentic Browsers - AI-powered web browsers (Perplexity Comet, Dia, Fellou, etc.)</li> <li>API Pricing for Developers - Token-level costs for Claude, Gemini, OpenAI, Mistral, etc.</li> <li>Educational Platforms - IXL, Khan Academy, Codecademy, Duolingo, and more</li> <li>Student Discounts - Special pricing for students and educators</li> <li>Federal Restrictions - Important compliance information for US-based researchers</li> </ul> <p>All pricing verified January 2026.</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#quick-recommendations","level":3,"title":"Quick Recommendations","text":"<p>For Academic Research:</p> <ul> <li>Literature Review: Perplexity, Claude, ScholarAI, Consensus</li> <li>Data Analysis: Claude (200K context), ChatGPT (Advanced Data Analysis)</li> <li>Writing Assistance: Claude (strong reasoning), ChatGPT Plus (plugins)</li> <li>Citation Management: NotebookLM (RAG capabilities)</li> </ul> <p>For Education:</p> <ul> <li>Students (Budget): Free options - HuggingFace Chat, Google AI Pro (1 yr free for students), Perplexity Education ($4.99/mo)</li> <li>Teachers: GitHub Copilot (free for educators), Claude (strong pedagogy), ChatGPT</li> <li>Tutoring: Khan Academy (free AI tutor Khanmigo), Claude, ChatGPT</li> </ul> <p>For Coding:</p> <ul> <li>IDE Integration: Claude Code, GitHub Copilot, Continue.dev</li> <li>Learning to Code: ChatGPT (interactive execution), Replit AI</li> <li>Code Review: Claude (strong analysis), GitHub Copilot</li> <li>See also: Our Vibe Coding guide for detailed agentic coding workflows</li> </ul> <p>For Creative Work:</p> <ul> <li>Images: Midjourney (quality), ChatGPT Image (convenience), Stable Diffusion (control)</li> <li>Video: Sora (OpenAI), Veo (Google), Runway Gen-4.5</li> <li>Music: Suno, Udio</li> <li>Writing: Claude (creative writing), ChatGPT, Jasper (marketing)</li> </ul>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#the-age-of-agentic-ai","level":2,"title":"The Age of Agentic AI","text":"<p>The most significant shift in the AI landscape over the past two years has been the evolution from conversational AI to agentic AI—systems that don't just respond to questions but take autonomous actions to accomplish goals.</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#what-makes-ai-agentic","level":3,"title":"What Makes AI \"Agentic\"?","text":"Traditional Chatbot Agentic AI System Responds to questions Pursues goals Single-turn interactions Multi-step planning Text-only output Uses tools (search, code, APIs) Stateless Maintains memory across sessions Reactive Proactive Requires explicit instructions for each step Breaks down complex tasks autonomously <p>Example Comparison:</p> <ul> <li>Chatbot: \"How do I fix a bug in my Python code?\" → Explains debugging steps</li> <li>Agent: \"Fix the bug in checkout.py\" → Searches codebase, identifies issue, implements fix, runs tests, commits changes</li> </ul>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#the-agent-capability-spectrum","level":3,"title":"The Agent Capability Spectrum","text":"<p>Agentic AI systems operate across five levels of autonomy:</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#level-1-conversational-ai","level":4,"title":"Level 1: Conversational AI","text":"<p>Basic question-answering chatbots like early ChatGPT, Gemini web interface, or Claude without tools.</p> <p>Capabilities: Answer questions, summarize text, explain concepts</p> <p>Limitations: Cannot take actions or use external tools</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#level-2-tool-using-llms","level":4,"title":"Level 2: Tool-Using LLMs","text":"<p>AI assistants that can search the web, execute code, or access plugins when prompted.</p> <p>Capabilities: Web search, calculations, code execution (sandboxed), API calls</p> <p>Examples: ChatGPT with plugins, Claude with MCP, Gemini with search</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#level-3-autonomous-task-completion","level":4,"title":"Level 3: Autonomous Task Completion","text":"<p>Single agents that can complete multi-step tasks independently.</p> <p>Capabilities: Break down goals, iterate on solutions, use multiple tools in sequence</p> <p>Examples: Claude Code (with agentic coding), GitHub Copilot Workspace, Devin</p> <p>Use Cases: - Writing and deploying a feature from a description - Conducting research and compiling a report - Debugging an application end-to-end</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#level-4-multi-agent-collaboration","level":4,"title":"Level 4: Multi-Agent Collaboration","text":"<p>Multiple specialized agents working together on complex tasks.</p> <p>Capabilities: Task decomposition, specialization, inter-agent communication</p> <p>Frameworks: CrewAI, AutoGen, LangGraph</p> <p>Examples: - Software team simulation (product manager + engineers + QA) - Research team (literature review + data analysis + writing) - Business workflow automation</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#level-5-self-evolving-systems","level":4,"title":"Level 5: Self-Evolving Systems","text":"<p>Agents that improve their own capabilities through experience.</p> <p>Capabilities: Self-optimization, lifelong learning, capability expansion</p> <p>Status: Research frontier (2025-present)</p> <p>Examples: Experimental systems from EvoAgentX, academic research</p> <p>Where are we today? Most commercial AI platforms (ChatGPT, Claude, Gemini) operate at Levels 2-3. Developer frameworks enable Level 4. Level 5 remains primarily in research labs.</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#agentic-platforms-in-2026","level":3,"title":"Agentic Platforms in 2026","text":"<p>Several platforms now offer agentic capabilities beyond simple chat:</p> <p>Claude Code (Anthropic)</p> <ul> <li>CLI and IDE integration for autonomous coding</li> <li>Can read files, execute commands, make multi-file edits</li> <li>Integrated with Model Context Protocol (MCP) for tool extensibility</li> <li>Best for: Complex refactoring, feature implementation, debugging</li> </ul> <p>GitHub Copilot Workspace</p> <ul> <li>Agentic coding environment in GitHub</li> <li>Plans implementation, edits multiple files, creates PRs</li> <li>Best for: Issue resolution, feature development</li> </ul> <p>ChatGPT with Canvas / Projects</p> <ul> <li>Artifact-based interaction for iterative creation</li> <li>Can maintain context across sessions with Projects</li> <li>Best for: Writing, planning, iterative document creation</li> </ul> <p>Perplexity Comet / Dia / Fellou (Agentic Browsers)</p> <ul> <li>Browsers with AI agents that can navigate, extract data, complete forms</li> <li>See Agentic Browsers comparison</li> </ul> <p>CrewAI / AutoGen (Multi-Agent Frameworks)</p> <ul> <li>Developer tools for building multi-agent systems</li> <li>Best for: Custom workflows, specialized automation</li> </ul> <p>For detailed guidance on using agentic coding tools, see our Vibe Coding documentation.</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#the-model-context-protocol-mcp","level":3,"title":"The Model Context Protocol (MCP)","text":"<p>A key enabler of agentic AI is the Model Context Protocol (MCP)—an open standard developed by Anthropic that allows AI assistants to securely connect to external tools and data sources.</p> <p>MCP enables agents to:</p> <ul> <li>Access local file systems and databases</li> <li>Execute terminal commands</li> <li>Interact with Git repositories</li> <li>Connect to web APIs and services</li> <li>Query cloud services (GitHub, Slack, Google Drive, etc.)</li> </ul> <p>Security Note: MCP runs locally with explicit user permission for each connection. See our MCP documentation for setup instructions.</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#industry-landscape-resources","level":2,"title":"Industry Landscape Resources","text":"<p>Matt Turck's MAD (ML/AI/Data) Landscape</p> <p> </p> <p>An annually updated overview of the machine learning, AI, and data ecosystem—covering infrastructure, tools, applications, and industry trends.</p> <p>HuggingFace Arena LLM Leaderboard</p> <p>A community-driven leaderboard ranking AI models based on blind human evaluations (users vote on responses without knowing which model generated them).</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#glossary","level":2,"title":"Glossary","text":"<p>External Glossaries</p> <p> Google's Machine Learning Glossary</p> <p> NVIDIA's Data Science Glossary</p> <p>Agentic AI: AI systems that use reasoning and iterative planning to autonomously solve complex, multi-step problems. Agentic systems can break down tasks, use tools, and make decisions to achieve goals with minimal human intervention. See: Agentic AI documentation.</p> <p>AI Agent: An AI system that can perceive its environment, make decisions, and take actions to achieve specified goals. Unlike chatbots, agents use tools, maintain memory across interactions, and execute multi-step plans autonomously.</p> <p>Attention Mechanism: A neural network technique that allows models to focus on relevant parts of input data when processing information. The foundation of transformer architectures used in modern LLMs.</p> <p>Chain-of-Thought (CoT): A prompting technique that encourages AI models to break down complex problems into intermediate reasoning steps, improving accuracy on tasks requiring logic and multi-step reasoning.</p> <p>Context Window: The maximum amount of text (measured in tokens) that an LLM can process at once, including both input and output. Modern models range from 8K to over 1M tokens (Claude's context window).</p> <p>Diffusion Models: A class of generative models that create images by iteratively denoising random noise. Used in Stable Diffusion, DALL-E, and Midjourney for text-to-image generation.</p> <p>Embeddings: Numerical vector representations of data (text, images, audio) that capture semantic meaning and relationships. Used for search, clustering, recommendations, and RAG systems.</p> <p>Few-Shot Learning: The ability of an AI model to learn new tasks from just a few examples in the prompt, without additional training or fine-tuning.</p> <p>Fine-Tuning: The process of further training a pre-trained model on a specific dataset or task to specialize its capabilities for particular domains or use cases.</p> <p>Foundation Models: Large-scale AI models (LLMs, vision models, multimodal models) trained on massive datasets. They serve as a base for many downstream tasks via transfer learning and rapid adaptation. Examples: GPT-4, Claude, Gemini, Llama.</p> <p>Hallucination: When an AI model generates false, nonsensical, or unfaithful information presented as fact. A key challenge in LLM reliability, especially for factual domains.</p> <p>Interactive Generative Video (IGV): AI systems that generate video content in real-time based on user input, combining video generation with interactive control. Unlike passive video generation (Sora, Runway), IGV systems respond to user actions in real-time, enabling gaming, simulation, and embodied AI applications.</p> <p>Large Language Models (LLMs): A subset of foundation models trained on extensive text corpora, enabling them to generate human-like text, summarize information, reason about topics, and perform various NLP tasks. Examples: GPT-4, Claude, Gemini, Llama.</p> <p>Lifelong Learning: The capability of an AI system to continuously learn and adapt from new experiences after initial training, accumulating knowledge over time. Enables agents to improve through environmental feedback and adapt to changing contexts without catastrophic forgetting.</p> <p>LoRA (Low-Rank Adaptation): An efficient fine-tuning technique that modifies only a small subset of model parameters, reducing computational costs while maintaining performance for specialized tasks.</p> <p>MCP (Model Context Protocol): An open standard protocol developed by Anthropic for connecting AI assistants to external data sources and tools. Enables LLMs to access databases, APIs, and live information while maintaining security and privacy. See: MCP documentation.</p> <p>Mixture of Experts (MoE): A neural network architecture that uses multiple specialized sub-models (experts) and activates only relevant ones for each input, improving efficiency and scalability in large models.</p> <p>Multimodal Models: AI systems that can process and generate multiple types of data (text, images, audio, video) in combination. Examples: GPT-4 with vision, Gemini, Claude 3.5.</p> <p>Multi-Agent System: An AI architecture where multiple specialized agents collaborate to complete complex tasks, with each agent handling specific subtasks and coordinating with others. Examples: CrewAI, AutoGen frameworks.</p> <p>Parameters: The trainable values within a neural network that determine the model's learned behavior. Model size is often described by parameter count (e.g., 7B, 70B, 405B parameters).</p> <p>Prompt Engineering: The practice of crafting, refining, and optimizing instructions (prompts) given to AI models to guide their outputs toward desired results.</p> <p>Quantization: A technique that reduces the precision of model weights (e.g., from 16-bit to 4-bit) to decrease memory usage and computational requirements, enabling deployment on resource-constrained devices.</p> <p>RAG (Retrieval-Augmented Generation): A technique that enhances LLM responses by retrieving relevant information from external knowledge bases or documents before generating answers, reducing hallucinations and improving factual accuracy. See: RAG documentation.</p> <p>RLHF (Reinforcement Learning from Human Feedback): A training method that uses human preferences to fine-tune AI models, improving their alignment with human values and desired behaviors. Used extensively in ChatGPT and Claude development.</p> <p>Self-Evolving Agent: An AI agent capable of improving its own performance through experience, optimizing aspects like behavior strategies, prompts, memory systems, or tool usage without explicit human retraining. Represents the frontier of agentic AI research.</p> <p>System Prompt: Initial instructions given to an AI model that define its role, behavior, constraints, and capabilities for a conversation or task. Often invisible to end users but shapes all responses.</p> <p>Temperature: A parameter controlling randomness in AI-generated outputs. Lower temperatures (0.0-0.3) produce deterministic responses; higher temperatures (0.7-1.0) increase creativity and variability.</p> <p>Token: A fundamental unit of text—often a word, subword, or character—that LLMs process. Pricing and context limits are typically measured in tokens.</p> <p>Transformer: The neural network architecture that powers modern LLMs, introduced in \"Attention is All You Need\" (2017). Uses attention mechanisms to process sequences efficiently.</p> <p>Vector Database: A specialized database optimized for storing and querying high-dimensional embedding vectors, enabling fast semantic search and similarity matching for RAG applications.</p> <p>Zero-shot Learning: The capability of an AI model to perform tasks it has never been explicitly trained on, often made possible by large-scale pretraining on diverse datasets.</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#further-reading","level":2,"title":"Further Reading","text":"<p>Foundation Model Evolution:</p> <ul> <li>Yang et al. 2023: Harnessing the Power of LLMs in Practice</li> <li>Attention is All You Need (Transformer paper)</li> </ul> <p>Agentic AI Research:</p> <ul> <li>Fang et al. 2025: A Comprehensive Survey of Self-Evolving AI Agents</li> <li>Awesome Self-Evolving Agents - Collection of 100+ papers</li> </ul> <p>Interactive Generative Video:</p> <ul> <li>Yu et al. 2025: A Survey of Interactive Generative Video</li> </ul> <p>Agentic Frameworks:</p> <ul> <li>EvoAgentX - Framework for automated evolving agentic workflows</li> <li>MASLab - Unified codebase for LLM-based multi-agent systems</li> <li>CrewAI - Framework for orchestrating role-playing autonomous AI agents</li> <li>AutoGen - Microsoft's multi-agent conversation framework</li> </ul>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_sandboxes/","level":1,"title":"AI Sandboxes","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#what-is-an-ai-sandbox","level":2,"title":"What is an AI Sandbox?","text":"<p>An AI sandbox is a controlled, isolated environment where AI tools can operate safely without risking your personal data, system files, or computer stability. The term \"sandbox\" comes from the idea of a child's sandbox: a contained play area where activities cannot affect the world outside.</p> <p>There are two distinct types of AI sandboxes:</p> <ol> <li>Traditional Sandboxes - Virtual machines and containers that isolate entire computing environments</li> <li>Agentic AI Sandboxes - Built-in safety features within AI coding assistants that restrict what the AI can do on your computer</li> </ol> <p>Understanding the difference is essential for safely working with modern AI tools, especially those that can execute code or modify files.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#traditional-sandboxes","level":2,"title":"Traditional Sandboxes","text":"<p>Traditional sandboxes have been used in computing for decades to isolate software and protect systems. These create a separate computing environment where programs run in isolation from your main system.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#what-are-traditional-sandboxes","level":3,"title":"What Are Traditional Sandboxes?","text":"<p>Traditional sandboxes use virtualization or containerization to create isolated environments:</p> Technology Description Isolation Level Virtual Machines (VMs) Complete simulated computers with their own operating system High - full hardware isolation Containers Lightweight isolated environments sharing the host OS kernel Medium - process isolation Development Containers Containerized development environments (e.g., VS Code Dev Containers) Medium - with IDE integration","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#key-characteristics","level":3,"title":"Key Characteristics","text":"<p>Traditional sandboxes provide protection through:</p> <ul> <li>File system isolation - The sandbox cannot access files outside its designated area</li> <li>Network isolation - Control over what network resources the sandbox can reach</li> <li>Resource constraints - Limits on CPU, memory, and disk usage prevent system crashes</li> <li>Process isolation - Programs inside cannot interact with programs outside</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#when-to-use-traditional-sandboxes","level":3,"title":"When to Use Traditional Sandboxes","text":"<p>Traditional sandboxes are ideal for:</p> <ul> <li>Running untrusted software or code</li> <li>Testing potentially risky AI-generated code before deploying it</li> <li>Working with sensitive data that should not leave a controlled environment</li> <li>Experimenting with new AI tools without risking your main system</li> </ul> <p>Recommendation for AI Experimentation</p> <p>If you are experimenting with AI tools that execute code, consider running them inside a virtual machine or container first. This provides an extra layer of protection while you learn how the tools behave.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#ua-resources-for-traditional-sandboxes","level":3,"title":"UA Resources for Traditional Sandboxes","text":"<p>The University of Arizona provides managed cloud services that support traditional sandbox environments:</p> <ul> <li>Managed Cloud Services - AWS-based virtual machines and development environments</li> <li>CyVerse Discovery Environment - Container-based computing platform (see below)</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#agentic-ai-sandboxes","level":2,"title":"Agentic AI Sandboxes","text":"<p>Agentic AI sandboxes are a newer concept that emerged with the rise of AI coding assistants like Claude Code, OpenAI Codex, and Gemini CLI. These tools can read files, write code, and execute commands on your computer, which creates significant security considerations.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#what-are-agentic-ai-sandboxes","level":3,"title":"What Are Agentic AI Sandboxes?","text":"<p>Unlike traditional sandboxes that isolate entire environments, agentic AI sandboxes are built-in safety features within the AI application itself. They restrict what the AI agent can do when running on your computer.</p> <p>Key Difference</p> <p>Traditional sandbox: Isolates the entire computing environment from your system</p> <p>Agentic AI sandbox: Restricts specific AI capabilities while the AI runs on your normal system</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#how-agentic-ai-sandboxes-work","level":3,"title":"How Agentic AI Sandboxes Work","text":"<p>When you enable sandbox mode in an agentic AI tool, it typically enforces:</p> Protection What It Does Restricted system calls Limits permissions so the AI cannot perform dangerous operations (like deleting your hard drive) Limited file system access Restricts the AI to only access specific folders you designate Network isolation controls Controls whether the AI can access the internet or other programs Resource constraints Limits CPU, RAM, and disk usage to prevent system crashes Security boundaries Contains potentially malicious code to prevent it from escaping to your broader system","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#commercial-agentic-ai-tools-with-sandbox-features","level":3,"title":"Commercial Agentic AI Tools with Sandbox Features","text":"<p>Several major AI coding assistants now include sandbox modes:</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#claude-code","level":4,"title":"Claude Code","text":"<p> Claude Code includes built-in sandboxing capabilities.</p> <ul> <li>Documentation: Claude Code Sandboxing Guide</li> <li>Features: Configurable file access, command restrictions, and approval workflows</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#openai-codex","level":4,"title":"OpenAI Codex","text":"<p> OpenAI Codex provides sandbox execution environments.</p> <ul> <li>Runs code in isolated containers</li> <li>Limited network access by default</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#gemini-cli","level":4,"title":"Gemini CLI","text":"<p> Gemini CLI offers sandbox modes for safer execution.</p> <ul> <li>UA credentials work for authentication</li> <li>Configurable permission levels</li> </ul> <p>Critical Security Consideration</p> <p>Even with sandbox features enabled, you should understand what capabilities you are granting to AI tools. Sandboxes reduce risk but do not eliminate it entirely.</p> <p>Always review AI-generated code before executing it in production environments.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#running-ai-safely-understanding-the-risks","level":2,"title":"Running AI Safely: Understanding the Risks","text":"<p>Before using any AI tool that can execute code or modify files, you need to understand the potential risks.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#what-can-go-wrong","level":3,"title":"What Can Go Wrong?","text":"<p>When you give an AI tool permission to execute code on your computer, several things can happen:</p> <p>Potential Risks of Unrestricted AI Execution</p> <ul> <li>Data Loss - The AI could accidentally delete important files</li> <li>Privacy Exposure - Sensitive data could be sent to external servers</li> <li>System Instability - Poorly written code could crash your system</li> <li>Security Vulnerabilities - The AI might install malicious packages or create security holes</li> <li>Compliance Violations - Actions might violate institutional policies (FERPA, HIPAA, etc.)</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#levels-of-ai-tool-risk","level":3,"title":"Levels of AI Tool Risk","text":"Risk Level Description Examples Low AI provides suggestions only; you execute manually ChatGPT web chat, Claude web interface Medium AI can execute code in isolated browser environment ChatGPT Code Interpreter, Google Colab High AI can execute code on your local machine Claude Code, Cursor, Codex CLI Very High AI has unrestricted access to your system Any tool with sandbox disabled","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#best-practices-for-safe-ai-usage","level":3,"title":"Best Practices for Safe AI Usage","text":"<ol> <li>Start with restricted permissions - Enable sandbox mode whenever available</li> <li>Review before executing - Always read AI-generated code before running it</li> <li>Use dedicated environments - Run risky operations in VMs or containers</li> <li>Limit file access - Only grant access to project-specific folders</li> <li>Monitor activity - Pay attention to what the AI is doing</li> <li>Keep backups - Maintain backups of important data before AI experimentation</li> </ol>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#the-discovery-environment-a-layered-security-approach","level":2,"title":"The Discovery Environment: A Layered Security Approach","text":"<p>The University of Arizona's Discovery Environment (DE) provides a secure platform that combines traditional container isolation with the ability to run agentic AI tools. This creates a layered security model that offers stronger protection than running AI tools directly on your personal computer.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#what-is-the-discovery-environment","level":3,"title":"What is the Discovery Environment?","text":"<p>The Discovery Environment is a Kubernetes-based platform that provides:</p> <ul> <li>Secure, authenticated access via KeyCloak identity management</li> <li>Container isolation - Each user session runs in its own Kubernetes pod</li> <li>Network restrictions - Limited to port 443 (HTTPS) only</li> <li>TLS encryption - All traffic encrypted via NGINX</li> <li>GPU capabilities - Access to GPU resources for AI workloads</li> </ul> <p>Important Clarification</p> <p>The Discovery Environment is not a true AI sandbox by itself. However, it provides many sandbox-like features and serves as an excellent platform for running agentic AI sandboxes safely.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#the-layered-security-model","level":3,"title":"The Layered Security Model","text":"<p>When you run a commercial AI application (like Claude Code or Codex) inside the Discovery Environment, you benefit from two layers of protection:</p> <pre><code>flowchart TB\n    subgraph outer[\"Outer Layer: Discovery Environment (Kubernetes)\"]\n        direction TB\n        A[KeyCloak Authentication] --&gt; B[Container Isolation]\n        B --&gt; C[Network Restrictions]\n        C --&gt; D[TLS Encryption]\n\n        subgraph inner[\"Inner Layer: AI Application Sandbox\"]\n            E[File Access Controls]\n            F[Command Restrictions]\n            G[Resource Limits]\n            H[Code Execution Sandbox]\n        end\n    end\n\n    U[User] --&gt; outer\n\n    style outer fill:#e3f2fd\n    style inner fill:#fff3e0</code></pre> <p>Outer Layer (Discovery Environment):</p> <ul> <li>Container isolation via Kubernetes pods</li> <li>KeyCloak authentication controls who can access</li> <li>Network restrictions limit exposure</li> <li>Process isolation between users</li> </ul> <p>Inner Layer (AI Application Sandbox):</p> <ul> <li>The AI tool's own sandbox features</li> <li>File access restrictions</li> <li>Command execution controls</li> <li>Code isolation mechanisms</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#why-this-matters","level":3,"title":"Why This Matters","text":"<p>This layered approach provides significant advantages:</p> Benefit Description Defense in depth If one layer fails, the other still provides protection Data protection Sensitive data on your personal laptop is not exposed Institutional compliance Easier to meet security and privacy requirements Recovery Container can be reset without affecting your personal system Audit capability Platform-level logging of activities","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#using-ai-sandboxes-in-the-discovery-environment","level":2,"title":"Using AI Sandboxes in the Discovery Environment","text":"<p>The Discovery Environment offers pre-configured applications for running agentic AI tools safely.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#claude-code-in-discovery-environment","level":3,"title":"Claude Code in Discovery Environment","text":"<p> Claude Code is available in the featured CloudShell application.</p> <p>Setup:</p> <ol> <li>Launch the CloudShell application in the Discovery Environment</li> <li>Install Claude Code with a single command:    <pre><code>npm install -g @anthropic-ai/claude-code\n</code></pre></li> <li>Authenticate with your Anthropic account or API key:    <pre><code>claude login\n</code></pre></li> </ol> <p>Documentation:</p> <ul> <li>Claude Code Sandboxing</li> <li>Claude Code Documentation</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#openai-codex-in-discovery-environment","level":3,"title":"OpenAI Codex in Discovery Environment","text":"<p> OpenAI Codex is also available in the CloudShell application.</p> <p>Setup:</p> <ol> <li>Launch the CloudShell application in the Discovery Environment</li> <li>Install the OpenAI CLI:    <pre><code>pip install openai\n</code></pre></li> <li>Authenticate with your OpenAI account or API key:    <pre><code>export OPENAI_API_KEY=\"your-api-key\"\n</code></pre></li> </ol>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#gemini-cli-in-discovery-environment","level":3,"title":"Gemini CLI in Discovery Environment","text":"<p> Gemini CLI works with UA credentials.</p> <p>Setup:</p> <ol> <li>Launch the CloudShell application in the Discovery Environment</li> <li>Authenticate using your UA Google account</li> <li>Configure Gemini CLI for your project</li> </ol> <p>UA Credential Integration</p> <p>University of Arizona personnel can use their UA credentials to authenticate with Gemini CLI, simplifying access management.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#ai-sandbox-landscape-in-higher-education","level":2,"title":"AI Sandbox Landscape in Higher Education","text":"<p>Universities and major technology companies have recognized the importance of providing safe AI experimentation environments for students. This section explores the broader landscape of AI sandbox offerings beyond the University of Arizona, demonstrating how institutions worldwide are addressing the need for secure, accessible AI learning platforms.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#university-hosted-ai-sandbox-platforms","level":3,"title":"University-Hosted AI Sandbox Platforms","text":"<p>Many leading universities have developed their own AI sandbox environments to give students secure, ready-to-use platforms for AI exploration. These campus-hosted solutions range from web interfaces for generative AI tools to full computing clusters for coursework.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#harvard-university-ai-sandbox","level":4,"title":"Harvard University - AI Sandbox","text":"<p>What it is: A secure web platform launched in 2023 that provides access to multiple large language models (including ChatGPT) within Harvard's network.</p> <p>Access: Free for all Harvard undergraduates and faculty with Harvard login credentials. Harvard AI Sandbox</p> <p>Key Features:</p> <ul> <li>Multiple LLM interfaces for experimentation</li> <li>Chat interface for code generation and text analysis</li> <li>Data protection (approved for up to \"Level 3\" confidential data per Harvard policies)</li> <li>Ensures moderate-sensitivity data stays protected within Harvard's network</li> </ul> <p>Why it matters: Harvard's approach demonstrates how institutions can provide secure AI access while maintaining data governance standards.</p> <p>Learn more: Harvard AI Sandbox</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#stanford-university-ai-playground","level":4,"title":"Stanford University - AI Playground","text":"<p>What it is: Stanford's \"safer AI platform\" launched in 2024-2025, providing free access to multiple AI models in a Stanford-controlled environment.</p> <p>Access: Free for any Stanford affiliate (students, faculty, or staff) via Stanford login at aiplayground.stanford.edu.</p> <p>Key Features:</p> <ul> <li>Multiple generative AI models (ChatGPT and others)</li> <li>Custom Stanford plugins for searching institutional resources</li> <li>Cleared for low- and moderate-risk Stanford data</li> <li>Slack community integration for collaboration</li> <li>Continuously evolving with new features</li> </ul> <p>Why it matters: Stanford emphasizes security compliance, allowing students to experiment with AI while meeting data privacy requirements.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#princeton-university-ai-sandbox","level":4,"title":"Princeton University - A.I. Sandbox","text":"<p>What it is: A secure service enabling researchers and students to use large language models via both web chat UI and API, with integration to Princeton's HPC cluster.</p> <p>Access: Controlled access - faculty must sponsor and request accounts for students or research staff.</p> <p>Key Features:</p> <ul> <li>Web chat interface and API access</li> <li>Integration with Princeton's HPC cluster for large-scale tasks</li> <li>Faculty oversight ensures academic use</li> <li>Can call AI models from cluster nodes for computation-intensive work</li> </ul> <p>Why it matters: Princeton's faculty-sponsored model provides oversight while offering powerful computational integration for advanced research projects.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#georgia-tech-ai-makerspace","level":4,"title":"Georgia Tech - AI Makerspace","text":"<p>What it is: A \"digital sandbox\" unveiled in 2024 in collaboration with NVIDIA - essentially a supercomputing cluster dedicated to undergraduate AI instruction.</p> <p>Access: Available to Georgia Tech engineering students as part of their curriculum at no cost.</p> <p>Key Features:</p> <ul> <li>Enterprise-grade AI hardware: 20 NVIDIA HGX H100 servers (160 total H100 GPUs)</li> <li>High-speed InfiniBand networking</li> <li>NVIDIA AI Enterprise software stack</li> <li>Support from NVIDIA's Deep Learning Institute (workshops, certifications)</li> <li>Enables realistic AI projects previously infeasible in normal computer labs</li> </ul> <p>Why it matters: Represents a major investment in giving undergraduates access to cutting-edge hardware, preparing them for industry-scale AI development.</p> <p>Learn more: Georgia Tech AI Makerspace</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#uc-berkeley-datahub-jupyterhub","level":4,"title":"UC Berkeley - DataHub (JupyterHub)","text":"<p>What it is: Campus-wide JupyterHub cloud service developed for the \"Data 8\" course (Foundations of Data Science), now serving dozens of courses across disciplines.</p> <p>Access: Free for Berkeley students enrolled in participating courses.</p> <p>Key Features:</p> <ul> <li>Cloud-hosted Jupyter notebook environment (runs on Google Cloud Kubernetes)</li> <li>Standard computing environment with Python/R and ML libraries pre-configured</li> <li>Supports Jupyter notebooks, JupyterLab, R Studio, and VS Code interfaces</li> <li>Persistent storage for student work</li> <li>Highly scalable (handles 400+ concurrent users)</li> <li>Instructors can distribute assignments via Git links that auto-launch notebooks</li> </ul> <p>Why it matters: An established platform (mid-2010s) that has inspired other universities to adopt similar JupyterHub setups. Demonstrates how traditional sandbox technology (containers) effectively supports AI and data science education.</p> <p>JupyterHub Adoption Across Universities</p> <p>Many universities have adopted similar Jupyter-based sandboxes, including University of Toronto, Brown, University of Washington, and Purdue. These provide standardized computing environments with Python/R and ML libraries for undergraduate AI and data science instruction.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#other-notable-university-platforms","level":4,"title":"Other Notable University Platforms","text":"<p>Florida Atlantic University - Gruber AI Sandbox</p> <ul> <li>Physical makerspace in campus library (established 2019)</li> <li>Open-door access for all FAU students, faculty, and staff</li> <li>High-performance desktops with GPU power for deep learning</li> <li>Grad student mentors provide office hours support</li> <li>Interdisciplinary focus (biology, arts, business, etc.)</li> </ul> <p>Clemson University - Launchpad AI Sandbox</p> <ul> <li>Dedicated to student startup teams developing AI models</li> <li>Competitive admission (4 active teams at a time)</li> <li>Each team gets equivalent of 1 NVIDIA A100 GPU</li> <li>Includes expert coaching, mentors, and networking opportunities</li> <li>Incubator model combining computing resources with business support</li> </ul> <p>UW Tacoma - AI Sandbox (Center for Business Analytics)</p> <ul> <li>Apple Silicon workstation with AI software tools</li> <li>Reservation-based access for students and faculty</li> <li>Guided learning paths for beginners and advanced users</li> <li>Focus on business analytics applications</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#corporate-sponsored-ai-sandbox-programs","level":3,"title":"Corporate-Sponsored AI Sandbox Programs","text":"<p>Major technology companies provide educational cloud sandbox programs to universities and students, ranging from free cloud credits to full curricula and managed class environments.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#amazon-web-services-aws","level":4,"title":"Amazon Web Services (AWS)","text":"<p>AWS Educate</p> <ul> <li>Access: Free for individual students (age 13+) with no credit card required</li> <li>Delivery: Cloud-based learning portal with self-paced courses and hands-on labs</li> <li>Features: No-cost \"starter accounts\" for experimenting with AWS services, curated learning paths on cloud/AI/ML, job board for students 18+</li> <li>Target: Undergraduate students worldwide beginning in cloud and AI</li> <li>Longevity: Established 2015, well-established program</li> </ul> <p>AWS Academy</p> <ul> <li>Access: Universities apply to join (free); approved schools get ready-to-teach curricula</li> <li>Delivery: AWS provides course materials and AWS Academy Learner Lab environment</li> <li>Features: Full curriculum pathways aligned to AWS certifications, hands-on labs/projects, assessment tools, student credits for cloud work</li> <li>Target: Institutions offering cloud computing or AI courses (often MIS, IT, CS departments)</li> <li>Longevity: Growing since ~2018, includes Generative AI Foundations course (2023)</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#google-cloud","level":4,"title":"Google Cloud","text":"<p>Google Cloud for Students &amp; Teaching Credits</p> <ul> <li>Access: Free $300 trial for students; faculty can request $50/student + $100/faculty for courses</li> <li>Delivery: Full Google Cloud Platform access</li> <li>Features: GCP services (AI APIs, BigQuery, Compute Engine), Google Cloud Skills Boost labs with free credits</li> <li>Target: Students in computing, data science, or courses introducing cloud/AI</li> <li>Longevity: Active since ~2018-2019, expanding with generative AI training (2023-2024)</li> </ul> <p>Google Cloud Skills Boost (formerly Qwiklabs)</p> <ul> <li>Online lab platform with catalog of cloud and AI labs</li> <li>Students get 200 free lab credits for hands-on exercises</li> <li>Labs run in temporary sandbox accounts</li> <li>Earn skill badges upon completion</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#microsoft-azure","level":4,"title":"Microsoft Azure","text":"<p>Azure for Students</p> <ul> <li>Access: Any full-time student 18+ at verified institution; no credit card required</li> <li>Delivery: Standard Azure cloud portal with \"Azure for Students\" subscription</li> <li>Features: $100 in Azure credit (renewable annually), 25+ free Azure products for 12 months, access to Azure OpenAI Service, GitHub Student benefits</li> <li>Target: Individual student developers and learners doing class projects</li> <li>Longevity: Established ~2017, widely used in university CS/IT programs</li> </ul> <p>Azure Lab Services</p> <ul> <li>Access: Institution/faculty needs Azure subscription (often uses educational grants/credits)</li> <li>Delivery: Managed cloud VMs for classroom use</li> <li>Features: Pre-configured VMs with custom software (e.g., TensorFlow, GPU-enabled), auto-shutdown, quota setting, LMS integration (Canvas)</li> <li>Target: Courses needing custom environments (CS, data science, engineering)</li> <li>Longevity: Active since ~2018, major revamp in 2022</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#ibm","level":4,"title":"IBM","text":"<p>IBM Academic Initiative &amp; SkillsBuild</p> <ul> <li>Access: Faculty and students register with institutional email</li> <li>Delivery: IBM Cloud credits (enhanced trial accounts), software downloads, IBM SkillsBuild online courses</li> <li>Features: IBM Cloud services (Watson AI APIs, Watson Studio, SPSS), courseware and tutorials, free IBM badges and certifications</li> <li>Target: Universities globally, especially business analytics and CS programs</li> <li>Longevity: Over 10 years, modernized through SkillsBuild platform</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#oracle","level":4,"title":"Oracle","text":"<p>Oracle Academy Cloud Program</p> <ul> <li>Access: Institutions become Oracle Academy members (free); educators request student accounts</li> <li>Delivery: Oracle Cloud Infrastructure with Always Free services + $300 credits/year per student</li> <li>Features: Oracle Data Science notebooks (Jupyter), Autonomous Database with ML algorithms, AI services for language/vision</li> <li>Target: Students in institutions teaching Oracle technologies (database, Java, information systems)</li> <li>Longevity: Started ~2019, actively used worldwide</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#databricks","level":4,"title":"Databricks","text":"<p>Databricks Free Edition &amp; University Alliance</p> <ul> <li>Access: Anyone can sign up for Free Edition; University Alliance for educators with teaching materials</li> <li>Delivery: Cloud-hosted Databricks workspace</li> <li>Features: Full Databricks experience (not demo version), data analytics and AI workflows, Spark and GenAI capabilities (MosaicML), collaborative notebooks, Databricks Academy training content</li> <li>Target: Students learning data science and AI; courses teaching Spark, ML, big data</li> <li>Longevity: University Alliance active for several years; Free Edition brand new (2025) with $100M education investment</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#comparison-of-ai-sandbox-offerings","level":3,"title":"Comparison of AI Sandbox Offerings","text":"<p>The following table summarizes key characteristics of major AI sandbox programs for undergraduate education:</p> Provider Program Access Model Delivery Core Features Target Users Status Harvard AI Sandbox Free (Harvard login) Cloud web app Multiple LLMs, secure data handling All undergrads &amp; faculty New (2023) Stanford AI Playground Free (Stanford SSO) Cloud web app Open-source &amp; ChatGPT models, moderate-risk data Students, staff, faculty New (2024) Georgia Tech AI Makerspace Course-integrated (free) On-prem HPC (160 H100 GPUs) Supercomputer-grade GPU computing Undergrad engineering New (2024) UC Berkeley DataHub Free for enrollees Cloud (Kubernetes/GCP) Jupyter/R notebooks, ML libs preloaded Students in many courses Established (~2015+) AWS AWS Educate Free individual signup AWS Cloud (managed labs) Self-paced courses, no-CC sandbox Global students &amp; educators Established (2015) AWS AWS Academy Institution joins (free) AWS Cloud (Academy portal) Cloud curriculum + lab environment College CS/IT courses Established (~2018) Google Student &amp; Teaching Credits Free credits ($300 trial, $50/student) Google Cloud Platform Full GCP access, Skills Boost labs Students (cloud/AI projects) Established (~2018) Microsoft Azure for Students Free signup (no CC, $100/yr) Azure Cloud portal Full Azure services, includes OpenAI Individual student developers Established (~2017) Microsoft Azure Lab Services Instructor setup Azure Cloud (managed VMs) Class VM labs, pre-configured environments Classes needing custom software Established (~2018) IBM Academic Initiative Free (verify .edu) IBM Cloud + software IBM Cloud trials, Watson AI APIs, SPSS Universities (various disciplines) Established (10+ years) Oracle Oracle Academy Cloud Member institutions Oracle Cloud (OCI) Always Free + $300 credit/year, DB &amp; ML tools Educators &amp; students (DB/AI) New (~2019) Databricks Free Edition &amp; Alliance Free signup (all users) Databricks Cloud Unified data &amp; AI platform, Spark, GenAI Students (data science/AI) New (2025)","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#key-takeaways-from-the-landscape","level":3,"title":"Key Takeaways from the Landscape","text":"<p>University-hosted platforms focus on:</p> <ul> <li>Local institutional needs (security, specific curricula, equal campus access)</li> <li>Data governance aligned with institutional policies</li> <li>Integration with existing courses and programs</li> <li>Often free for the entire campus community</li> </ul> <p>Corporate-sponsored programs offer:</p> <ul> <li>Cutting-edge cloud platforms and tools</li> <li>Broader reach to students worldwide</li> <li>Industry-relevant skills and certifications</li> <li>Significant free credits and resources</li> </ul> <p>Common goals across all offerings:</p> <ul> <li>Lower barriers to AI learning by reducing cost and infrastructure challenges</li> <li>Provide hands-on experience with production-grade tools</li> <li>Ensure students gain practical skills relevant to industry</li> <li>Address security and data privacy concerns</li> </ul> <p>The Growing Ecosystem</p> <p>The landscape of AI sandbox offerings is rapidly expanding. Both universities and companies recognize that providing safe, accessible AI experimentation environments is essential for preparing students for an AI-driven future. Many of these programs have become integral to undergraduate AI education.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#choosing-the-right-approach","level":2,"title":"Choosing the Right Approach","text":"<p>The best sandbox approach depends on your use case and risk tolerance:</p> Scenario Recommended Approach Learning/Experimenting Discovery Environment with AI sandbox enabled Personal projects (low sensitivity) Local AI tool with sandbox mode enabled Research with sensitive data Discovery Environment or dedicated VM Production code development Local AI tool with sandbox + version control + code review Compliance-regulated work (HIPAA, FERPA) Consult IT Security; likely requires isolated environment","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#decision-flowchart","level":3,"title":"Decision Flowchart","text":"<pre><code>flowchart TD\n    A[Do you need to run AI coding tools?] --&gt;|Yes| B{Does the tool execute code?}\n    A --&gt;|No| C[Standard web-based AI is likely sufficient]\n\n    B --&gt;|No| C\n    B --&gt;|Yes| D{Is your data sensitive?}\n\n    D --&gt;|No| E{Are you comfortable with the tool's risks?}\n    D --&gt;|Yes| F[Use Discovery Environment or isolated VM]\n\n    E --&gt;|Yes| G[Enable sandbox mode on local machine]\n    E --&gt;|No| F\n\n    style F fill:#c8e6c9\n    style G fill:#fff3e0\n    style C fill:#e3f2fd</code></pre>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#summary","level":2,"title":"Summary","text":"Concept Key Points Traditional Sandboxes VMs and containers that isolate entire environments; proven technology for decades Agentic AI Sandboxes Built-in safety features in AI coding tools; restrict AI capabilities Layered Security Combining both approaches provides defense in depth Discovery Environment UA platform providing container isolation ideal for running AI tools Best Practice Enable sandbox features, review code before execution, use isolated environments for sensitive work <p>Key Takeaway</p> <p>Running AI tools that can execute code always carries some risk. By understanding the difference between traditional and agentic sandboxes, and by using layered security approaches like the Discovery Environment, you can significantly reduce that risk while still benefiting from powerful AI assistance.</p>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"ai_sandboxes/#further-resources","level":2,"title":"Further Resources","text":"<ul> <li>Managed Cloud Services (UA IT) - AWS resources for VMs and development environments</li> <li>Claude Code Sandboxing Documentation - Official Anthropic sandboxing guide</li> <li>Claude Code Documentation - Complete Claude Code reference</li> <li>Agentic AI Overview - Understanding agentic AI concepts</li> <li>Vibe Coding Guide - AI coding assistants and their capabilities</li> <li>Model Context Protocol (MCP) - How AI tools connect to your system</li> </ul>","path":["Research","AI Sandboxes"],"tags":[]},{"location":"bias/","level":1,"title":"Bias and Discrimination","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>This lesson addresses the critical challenges of bias in AI. We will briefly explore their origins, impacts, and strategies for recognizing, mitigating, and preventing them.</p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#understanding-ai-bias-its-origins","level":2,"title":"Understanding AI bias &amp; its origins","text":"<p>Definitions</p> <p>AI Bias - occurs when an AI system produces systematically prejudiced or unfair results (outputs). Erroneous assumptions made during the development of the model, or biases in the data upon which it was trained are both potential sources.</p> <p>Algorithmic Discrimination occurs when an the use of an AI results in the unfair or illegal treatment of individuals or groups based on a protected characteristic (age, disability, race, religion, sex, or socioeconomic status).</p> <p>Fairness includes metrics around equalized error rates across groups and parity of outcomes across groups. </p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#sources-of-bias","level":2,"title":"Sources of Bias","text":"<p>Algorithmic - when the algorithm used to process the information prioritizes certain features over others, e.g. optimization techniques that favor majority over minority groups</p> <p>Data - the most common source of AI bias is when the data used to train a model are flawed, unrepresentative, lack global diversity, and do not reflect the ground truth of the real-world </p> <ul> <li> <p>Selection Bias when training data are not representative of the whole population </p> </li> <li> <p>Measurement Bias when the data systematically differs from the true values, or when proxies are used</p> </li> <li> <p>Exclusion Bias when certain types or groups are omitted from data collection</p> </li> <li> <p>Experience or Expertise Bias when subjective judgements among the collectors, labellers, or data input are introduced</p> </li> <li> <p>Environment Bias when data collected in one context are not generalizable to other contexts</p> </li> </ul> <p>Human Decision - when biases held by humans influence the decisions around data labeling, model development, engineering or outputs</p> <ul> <li> <p>Confirmation Bias - over reliance on pre-existing beliefs or patterns in data</p> </li> <li> <p>Stereotyping Bias - perpetuation of a labeling bias that is harmful to specific groups</p> </li> <li> <p>Out-Group Bias - generalizing underrepresented groups as being more similar to one another than they actually are</p> </li> <li> <p>Empathy Bias - inability to incorporate nuanced human experiences, emotions, or subjective elements into a quantitative model</p> </li> </ul> <p>Synthetic Bias - when models based on biased training data are used to generate synthetic datasets, they perpetuate their bias into the new trained model</p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#bias-prevention-strategies","level":2,"title":"Bias prevention strategies","text":"","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#data-centric-approaches","level":3,"title":"Data-centric approaches","text":"<p>Can help to ensure data are representative, high quality, and contain the diversity of the study system:</p> <p>Collection - curate datasets accurately to represent all relevant groups and populations.</p> <p>Quality - identify and address issues within data sets, including compatibility problems, gaps within populations, and underrepresentation in historical data. </p> <p>Balancing - under-sample majority and over-sample minority groups, use synthetic data generation to capture under-represented samples</p> <p>Labeling - consistent, annotated, with masks for irrelevant factors, sensitive and secure</p> <p>Continuous - data are updated throughout the entire lifecycle of their use, not just a single collection phase.</p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#algorithmic-techniques","level":3,"title":"Algorithmic Techniques","text":"<p>Technical tools can help to identify bias in models:</p> <p>Bias Detection - specialized software tools designed to flag, measure, and analyze biases.</p> <p>Fairness Metrics - equalized odds, demographic parity, counterfactual fairness</p> <p>Algorithmic Adjustments - pre-processing (adjusting training data), in-process (modifying algorithm), or post-processing (adjust outputs)</p> <p>Explainable AI (XAI) - understand which inputs are driving model decisions, reveal hidden biases or reliance on spurious factors</p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#assessment","level":2,"title":"Assessment","text":"True or False: AI bias only originates from the data used to train the model. <p>False</p> <p>AI bias can originate from the data, the algorithm, and human decisions during the development process.</p> Which of the following is an example of 'Selection Bias'? <p>A. An algorithm that prioritizes majority groups over minority groups.</p> <p>B. A dataset for a skin cancer detection model that predominantly features images of light-skinned individuals.</p> <p>C. Subjective judgments from data labelers influencing the data.</p> <p>D. Using a model trained on data from one hospital in a different country.</p> Answer <p>B. A dataset for a skin cancer detection model that predominantly features images of light-skinned individuals.</p> <p>Selection bias occurs when the training data are not representative of the whole population.</p> What is the primary purpose of 'Explainable AI (XAI)' in bias mitigation? <p>A. To generate synthetic data for underrepresented groups.</p> <p>B. To understand which inputs are driving model decisions, potentially revealing hidden biases.</p> <p>C. To ensure the model's predictions are always 100% accurate.</p> <p>D. To make the model run faster on new hardware.</p> Answer <p>B: To understand which inputs are driving model decisions, potentially revealing hidden biases.</p> <p>XAI helps to make the model's decision-making process transparent, which is crucial for identifying and addressing bias.</p> True or False: 'Algorithmic Discrimination' is when an AI model makes a simple mistake. <p>False</p> <p>Algorithmic Discrimination is when the use of an AI results in the unfair or illegal treatment of individuals or groups based on a protected characteristic.</p> Which of these is NOT a data-centric approach to bias prevention? <p>A. Curating datasets to accurately represent all relevant groups.</p> <p>B. Over-sampling minority groups.</p> <p>C. Modifying the algorithm during the training process.</p> <p>D. Ensuring data labels are consistent and annotated.</p> Answer <p>C: Modifying the algorithm during the training process.</p> <p>This is an algorithmic technique, not a data-centric approach.</p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"chatgpt/","level":1,"title":"OpenAI ChatGPT","text":"<p> This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#about-openai-and-chatgpt","level":2,"title":"About OpenAI and ChatGPT","text":"<p>OpenAI is an artificial intelligence research company founded in 2015, known for developing some of the most influential AI models in recent years. Their flagship product, ChatGPT, launched in November 2022 and quickly became the fastest-growing consumer application in history.</p> <p>ChatGPT is powered by a family of large language models (LLMs) including GPT-4, GPT-4o, and the reasoning-focused o1 and o3 models. These models can understand and generate human-like text, analyze images, write code, and assist with a wide range of tasks.</p>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#creating-a-chatgpt-account","level":2,"title":"Creating a ChatGPT Account","text":"<p>Log In to Your Account</p> <ul> <li>Visit chatgpt.com and log in using your existing credentials or create a new account.</li> </ul> <p>Access Account Settings:</p> <ul> <li>Once logged in, look for the sidebar (usually on the left).</li> <li>Click on the \"Upgrade to Plus\" or \"Manage my plan\" button.<ul> <li>If you do not see this option, try refreshing the page or updating your browser.</li> </ul> </li> </ul> <p>Initiate Upgrade:</p> <ul> <li>Click \"Upgrade to Plus\" (\\(20/mo), or **\"Upgrade to Pro\"** (\\)200/mo).</li> <li>A pricing page will appear with current subscription options.</li> </ul> <p>Compare ChatGPT with Other AI Platforms</p> <p>For comprehensive pricing comparisons and to see how ChatGPT stacks up against Claude, Gemini, and other AI platforms, visit:</p> <p>Choosing the Right AI Platform - Compare features, pricing, and use cases</p> <p>Enter Payment Information:</p> <ul> <li>Provide the required billing details.</li> <li>Review the payment terms and confirm your subscription.</li> </ul> <p>Confirmation and Billing Cycle:</p> <ul> <li>After completing the payment process, you will receive a confirmation email.</li> <li>Your Plus account should be active immediately.</li> <li>You can now enjoy features like priority access, faster response times, and the latest model updates.</li> </ul>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#chatgpt-subscription-plans","level":2,"title":"ChatGPT Subscription Plans","text":"<p>Pricing (as of January 2025)</p> <p>Free Tier</p> <ul> <li>Access to GPT-4o with usage limits</li> <li>Standard response speed</li> <li>Limited access to advanced features</li> <li>Good for casual users exploring AI capabilities</li> </ul> <p>ChatGPT Plus ($20/month)</p> <ul> <li>Priority access during peak hours</li> <li>Faster response speeds</li> <li>Access to GPT-4, GPT-4o, and o1 reasoning models</li> <li>Image generation with DALL-E 3</li> <li>File uploads, voice mode, and data analysis</li> <li>Custom GPTs and GPT Store access</li> <li>Advanced Voice mode with natural conversation</li> </ul> <p>ChatGPT Pro ($200/month)</p> <ul> <li>Everything in Plus</li> <li>Unlimited access to o1 and o1 pro mode (enhanced reasoning)</li> <li>Unlimited access to GPT-4o</li> <li>Higher limits on advanced features</li> <li>Access to Sora video generation</li> <li>Deep Research tool for comprehensive analysis</li> <li>Priority access to newest features</li> </ul> <p>ChatGPT Team ($25-30/user/month)</p> <ul> <li>Everything in Plus</li> <li>Admin controls and workspace management</li> <li>Higher usage limits per user</li> <li>Data excluded from training by default</li> <li>Minimum 2 users required</li> </ul> <p>ChatGPT Enterprise (Custom pricing)</p> <ul> <li>Unlimited high-speed GPT-4 access</li> <li>Enterprise-grade security and compliance</li> <li>Admin console with SSO and domain verification</li> <li>Custom data retention policies</li> <li>Priority support</li> </ul>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#using-chatgpt","level":2,"title":"Using ChatGPT","text":"<p>Web Interface (chatgpt.com):</p> <ul> <li>Prompting: Type your requests or questions into the chat box. Be clear and specific in your prompts.</li> <li>Conversation History: ChatGPT remembers context within the current chat session.</li> <li>Model Selection: Plus and Pro users can switch between models (GPT-4o, o1, etc.) using the model selector.</li> <li>File Uploads: Upload images, PDFs, documents, and data files for analysis.</li> <li>Voice Mode: Use voice input and receive spoken responses (Plus feature).</li> <li>Canvas: Collaborative editing workspace for writing and coding projects.</li> </ul> <p>Custom GPTs:</p> <ul> <li>GPT Store: Browse and use specialized GPTs created by OpenAI and the community.</li> <li>Create Your Own: Build custom GPTs with specific instructions, knowledge, and capabilities.</li> <li>Use Cases: Research assistants, writing helpers, coding tutors, language learning, and more.</li> </ul> <p>Advanced Features:</p> <ul> <li>Web Browsing: Search the internet for current information (enabled by default for Plus users).</li> <li>Code Interpreter: Run Python code, analyze data, create visualizations, and process files.</li> <li>DALL-E 3: Generate and edit images from text descriptions.</li> <li>Advanced Voice: Natural, conversational voice interactions with low latency.</li> </ul>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#openai-platform-and-api","level":2,"title":"OpenAI Platform and API","text":"<p>Beyond ChatGPT, OpenAI provides a developer platform for programmatic access to their AI models.</p> <p>OpenAI Platform allows developers to access the API and integrate powerful AI models into custom applications or systems.</p>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#openai-api-access","level":3,"title":"OpenAI API Access","text":"<p>The OpenAI API provides programmatic access to models like GPT-4, GPT-4o, o1, DALL-E, and more, enabling integration into applications and research workflows.</p> <p>Signing up for the OpenAI API:</p> <ol> <li> <p>Open the OpenAI Platform: Go to platform.openai.com.</p> </li> <li> <p>Sign up or Log in:</p> <ul> <li>Sign up: If you don't have an OpenAI account, create one. You can reuse your ChatGPT account credentials.</li> <li>Log in: If you already have an account, log in.</li> </ul> </li> </ol> <p>Creating API Keys:</p> <ol> <li> <p>Navigate to the API Keys page: Click on your profile icon in the top-right corner and select \"API keys.\"</p> </li> <li> <p>Create a new API key: Click on \"Create new secret key.\"</p> </li> <li> <p>Name your key (optional): Give it a descriptive name for tracking purposes.</p> </li> <li> <p>Copy and securely store your API key: Important: You will not be able to view the full API key again. Store it in a password manager or a secure environment variable.</p> </li> </ol> <p>Treat your API key like a password</p> <p>Do not share it publicly or commit it to version control platforms (like GitHub).</p>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#using-the-openai-api","level":3,"title":"Using the OpenAI API","text":"<p>Quick Start (Python):</p> <pre><code>from openai import OpenAI\n\nclient = OpenAI(api_key=\"your-api-key\")\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello, GPT!\"}\n    ]\n)\nprint(response.choices[0].message.content)\n</code></pre> <p>Available SDKs: Python, Node.js/TypeScript, and community libraries for other languages.</p> <p>Developer Resources:</p> <ul> <li> <p>Documentation: Visit the OpenAI API Documentation for guidance, code examples, and model parameters.</p> </li> <li> <p>Pricing: Review the OpenAI API Pricing page for cost details, which are based on tokens processed.</p> </li> <li> <p>Rate Limits: Familiarize yourself with API rate limits to prevent disruptions.</p> </li> <li> <p>Playground:  OpenAI Playground allows you to experiment with models for Chat, Text Completion, Image generation, Embedding, Speech-to-Text, and Fine Tuning.</p> </li> </ul> <p>Context Windows and Costs</p> <p>Large context windows allow for more extensive prompt engineering and large-document analysis but can increase costs significantly. Plan your usage accordingly.</p>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#openai-cookbook","level":3,"title":"OpenAI Cookbook","text":"<p>Check out the  openai/openai-cookbook repository for Jupyter Notebook lessons and examples on using the OpenAI API.</p> <p></p> <p>The cookbook is also available at cookbook.openai.com.</p>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#tips-for-using-chatgpt","level":2,"title":"Tips for Using ChatGPT","text":"<ul> <li>Be Specific: Provide clear instructions and context in your prompts for better results.</li> <li>Iterate: Refine your prompts based on ChatGPT's responses to improve outcomes.</li> <li>Use System Instructions: For custom GPTs or API usage, system prompts guide the model's behavior.</li> <li>Leverage Context: Upload relevant documents or provide background information for complex tasks.</li> <li>Experiment with Models: Different models excel at different tasks - o1 for reasoning, GPT-4o for general use, DALL-E for images.</li> </ul>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#additional-resources","level":2,"title":"Additional Resources","text":"<p>OpenAI Official Resources:</p> <ul> <li>OpenAI Website: openai.com</li> <li>ChatGPT: chatgpt.com</li> <li>API Documentation: platform.openai.com/docs</li> <li>OpenAI Research: openai.com/research</li> <li>Developer Forum: community.openai.com</li> </ul> <p>Research and Technical Papers:</p> <ul> <li>GPT-4 Technical Report: arxiv.org/abs/2303.08774</li> <li>OpenAI Publications: openai.com/research/index/publication</li> </ul> <p>Privacy and Security:</p> <ul> <li>Review OpenAI's Privacy Policy and ensure compliance with your institution's guidelines.</li> <li>Teaching Resources: Some institutions have specific guidance on using AI tools in education. Check your local teaching center or ask your institution's IT or library services.</li> </ul> <p>Next Steps:</p> <ul> <li>After setting up your account, proceed to the Writing Prompts section for hands-on prompt engineering exercises and best practices.</li> <li>Explore Choosing the Right AI Platform to compare ChatGPT with Claude, Gemini, and other options.</li> </ul>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"choose/","level":1,"title":"Choosing the Right AI Platform","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>This comprehensive guide helps you choose the right AI platform for your needs. All pricing information has been verified as of January 2026.</p>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#platform-comparison-tables","level":2,"title":"Platform Comparison Tables","text":"<p>Below are tables that rank popular AI platforms by use case, organized by Chat, Research, Code, and Image/Video generation capabilities.</p>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#best-for-chat","level":3,"title":"Best for Chat","text":"Platform Strength Weakness Cost Interface Docs Claude (Anthropic) - Fast, coherent dialogue - Large context window - Strong reasoning - API can be expensive - Limited third-party integrations Free, $20/mo (Pro), $100-200/mo (Max), $30+/seat (Team) Claude Anthropic Docs Gemini (Google) - Multimodal (images + text + video) - Strong Google integration - Some features Beta/experimental - Pricing tiers complex Free, $19.99/mo (AI Pro), $249.99/mo (AI Ultra) Gemini Gemini Docs ChatGPT (OpenAI) - Strong reasoning (o-series) - Extensive plugin ecosystem - Multi-turn conversation - Subscription required for best models - Usage caps on free tier Free, $8/mo (Go with ads), $20/mo (Plus), $200/mo (Pro), Team/Enterprise ChatGPT OpenAI Docs DeepSeek (Open Source) - Extremely affordable API - Open source models - Smaller dev community - Data stored in China Free (Web Chat) / Free (Open Source) / API from $0.28 per 1M tokens DeepSeek Chat DeepSeek Docs Microsoft 365 Copilot - Deep MS Office integration - Enterprise features - Requires M365 license - Premium pricing Free (Chat), $21/mo (Business), $30/mo (Enterprise) Copilot Copilot Docs Grok (xAI) - Multimodal capabilities - X platform integration - Premium pricing - Content restrictions Free (limited), $40/mo (X Premium+), API from $0.20 per 1M tokens Grok xAI Docs HuggingFace Chat - 113+ open source models - Free access - Quality varies by model - Some features need Pro Free, $9/mo (Pro), $20/user/mo (Team), $50+/mo (Enterprise) HF Chat HF Docs Jasper - Marketing-focused - Content workflows - Expensive for individual use - Less technical depth $59/mo (Pro), $69/mo (monthly billing) Jasper Jasper Docs Perplexity - Research + search - Citation backing - Subscription for advanced features Free, $20/mo (Pro), $200/mo (Max), $4.99/mo (Education) Perplexity Perplexity Docs NotebookLM (Google) - RAG capabilities - Google Drive integration - Still evolving features Free, $19.99/mo (Plus via Google One AI Premium) NotebookLM NotebookLM Docs Vicuna - Open source - Free to use - Smaller than GPT-4 - Self-hosting required Free (self-host) or free demos Vicuna Demo Vicuna GitHub Pi (Inflection AI) - Empathetic conversation style - Personal AI - Rate limited - No coding support Free (personal use, rate limits) Pi N/A (Enterprise API only) Poe (Quora) - Access to multiple models - Single subscription - Usage caps on free tier $5/mo (10k points), $19.99/mo (1M points), $250/mo (12.5M points) Poe Poe Docs Mistral AI - European LLMs - Multilingual - Still evolving ecosystem Free + API from \\(0.02-\\)6 per 1M tokens, Le Chat Pro $14.99/mo Mistral Mistral Docs Latimer - Diversity-focused training - Inclusive perspective - Smaller user base Free (100 interactions), $9.99/mo (Individual) Latimer Email: support@latimer.ai Meta AI (Llama) - Open source - Llama 4 available - Self-hosting requires resources Free (self-host) or enterprise Llama Meta GitHub Apple Intelligence - iOS/macOS integration - Privacy-focused - Apple ecosystem only Included on Apple devices (iOS 18.1+, M1+ Macs) Apple Intelligence Apple Dev Docs Amazon Titan - AWS ecosystem - Bedrock integration - Enterprise-focused Pay-per-use on Bedrock Titan AWS Docs Amazon Bedrock - Multi-model platform - 100+ models - Requires AWS account Pay-per-use (varies by model) Bedrock Bedrock Docs Azure OpenAI Service - Enterprise security - Azure integration - Azure subscription required Pay-per-use (Azure pricing) Azure OpenAI Azure Docs Merlin AI - Multi-function tool - Browser extension - \"Unlimited\" has hidden caps Free (limited), $19/mo (Pro with $100/mo usage cap) Merlin Merlin Help","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#best-for-research","level":3,"title":"Best for Research","text":"Platform Strength Weakness Cost Interface Docs Perplexity - Citation-backed answers - Web search integration - Subscription for Pro searches Free, $20/mo (Pro), $200/mo (Max), $4.99/mo (Education) Perplexity Perplexity Docs Gemini (Google) - In-depth analysis - Chain-of-thought reasoning - Can be slow for complex queries Free, $19.99/mo (AI Pro), $249.99/mo (AI Ultra) Gemini Gemini Docs ChatGPT (OpenAI) - Advanced reasoning - Multi-step problems - Requires Plus/Pro subscription $20/mo (Plus), $200/mo (Pro) ChatGPT OpenAI Docs Claude (Anthropic) - Strong analysis - 200K context window - Higher API costs Free, $20/mo (Pro), $100-200/mo (Max) Claude Anthropic Docs ScholarAI - 200M+ papers - Academic focus - Requires ChatGPT Plus or standalone subscription Free (5 credits), $9.99/mo (Basic), $18.99/mo (Premium) Scholar AI GPT / Web App ScholarAI Docs Scholar GPT - Academic database access - ChatGPT integration - Requires ChatGPT Plus $20/mo (ChatGPT Plus required) Scholar GPT User Guide Semantic Scholar - 232M+ papers - Free API - Not a conversational AI - Search-focused Free Semantic Scholar API Docs Elicit - AI literature review - 138M+ papers - Premium features expensive Free (limited), $12/mo (Plus), $49/mo (Pro), $79/seat/mo (Team) Elicit Elicit Support Consensus - AI research summaries - 200M+ papers - Limited free tier Free (limited), $12-15/mo (Pro), $12.99/seat/mo (Teams) Consensus Consensus Help Scite - Smart Citations - 1.5B citations analyzed - Subscription required for full access Free (limited), $20/mo Scite Scite API Ai2 OpenScholar - 45M+ open-access papers - Citation accuracy - Open-access content only Free OpenScholar Demo GitHub Polymathic AI - Scientific research focus - 72 models on HuggingFace - Specialized for STEM Free (Open Source) Polymathic AI GitHub / HuggingFace You.com - Multi-model access - Customizable AI agents - Paid subscription for advanced Free, $20/mo (Pro), $200/mo (Max) You.com You.com Docs OpenResearcher - arXiv integration - Open source - arXiv-only corpus - Requires self-hosting Free (Open Source) arXiv Paper GitHub","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#best-for-code","level":3,"title":"Best for Code","text":"Platform Strength Weakness Cost Interface Docs Claude Code (Anthropic) - CLI/IDE integration - Strong code generation - Requires Pro+ subscription Included with Pro ($20/mo) or higher Claude Anthropic Docs Gemini (Google) - Code + text synergy - Fast responses - Less specialized than dedicated coding tools Free, $19.99/mo (AI Pro) Gemini Gemini Docs GitHub Copilot - Seamless IDE integration - Code completions - Subscription required for unlimited Free (students/OSS), $10/mo (Pro), $39/mo (Pro+), $19/user/mo (Business) GitHub Copilot Copilot Docs ChatGPT (OpenAI) - Interactive code execution - Good for learning - Requires Plus/Pro for best experience Free, $20/mo (Plus), $200/mo (Pro) ChatGPT OpenAI Docs Continue.dev - Open source - Multiple model support - Requires technical setup - Users pay LLM API costs Free (Open Source, users pay API costs) Continue.dev Continue Docs Codeium (Windsurf) - Free tier available - IDE integration - Rebranded to Windsurf - Credit-based limits Free (25 credits/mo), $15/mo (Pro), $30/mo (Teams), $60/mo (Enterprise) Windsurf Codeium Docs Phind - Code search + AI chat - Inconsistent pricing Free, Paid tiers $10-40/mo (verify on site) Phind Phind Help Replit AI - Cloud IDE + AI - Multi-language support - Subscription for full features Free tier, $20/mo (annual) or $25/mo (monthly) Replit AI Replit Docs StarCoder - Open source - Multiple model sizes - Self-hosting required Free (Open Source) StarCoder2 BigCode Code Llama (Meta) - Specialized for coding - Multiple variants ⚠️ Repository archived July 2025 - consider StarCoder2 instead Free (Open Source, archived) Code Llama Meta GitHub","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#best-for-imagevideo","level":3,"title":"Best for Image/Video","text":"Platform Strength Weakness Cost Interface Docs Veo (Google) - High-quality video - Up to 4K resolution - Limited daily generation $0.15-$0.60/second (API) or $19.99-$249.99/mo (subscription via AI Pro/Ultra) Veo Veo Docs Midjourney - Exceptional image quality - Web interface available - Subscription required $10/mo (Basic), $30/mo (Standard), $60/mo (Pro), $120/mo (Mega) Midjourney Midjourney Docs ChatGPT Image (OpenAI) - Native integration - Multi-turn refinement ⚠️ DALL-E 3 being sunset May 2026 - GPT-4o Image is replacement $20/mo (ChatGPT Plus) or API pricing ChatGPT OpenAI Image Docs Stable Diffusion - Open source - Highly customizable - Requires technical knowledge Free (Open Source) or API services Stability AI Stable Diffusion Adobe Firefly - Creative Cloud integration - Commercial-safe - Subscription required $9.99-$29.99/mo (standalone) or $70/mo (CC Pro) Firefly Firefly Docs Sora (OpenAI) - Text-to-video - Up to 1080p ⚠️ NOT available in EU/UK $20/mo (ChatGPT Plus), $200/mo (ChatGPT Pro) Sora Sora Research Runway ML - Advanced video tools - Gen-4.5 available - Higher-res requires paid plans $15/mo (monthly), $12/mo (annual) to $95/mo Runway Runway Docs Imagine with Meta - Free image generation - Meta AI integration - Quality less advanced Free, $30/mo (Meta AI+ optional) Meta AI Meta Help Craiyon - Simple free tier - Unlimited base quality - Lower quality on free tier Free (unlimited Base w/ ads), $5-12/mo (Supporter), $20-24/mo (Professional) Craiyon FAQ on site <p>Image and Video Generation Models</p>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#image-generation-models","level":2,"title":"Image Generation Models","text":"<p>The image generation landscape includes both commercial platforms and open-source options:</p> <p>Commercial Platforms:</p> <ul> <li>Midjourney: Known for exceptional artistic quality and aesthetics. Discord and web interface available.</li> <li>ChatGPT Image Generation (OpenAI): Native integration with ChatGPT, good text rendering, iterative refinement.</li> <li>Google Imagen: Strong photo-realism and text rendering. Available via Gemini API.</li> <li>Adobe Firefly: Commercial-safe training data, Creative Cloud integration.</li> <li>Ideogram: Strong text rendering and style references.</li> <li>Leonardo: Versatile with multiple style options.</li> <li>Recraft: Vector art generation and extended text capabilities.</li> </ul> <p>Open-Source Options:</p> <ul> <li>Stable Diffusion (Stability AI): Highly customizable, can run locally. Available on HuggingFace.</li> <li>FLUX (Black Forest Labs): Multiple variants for different use cases, Apache-licensed options available.</li> <li>HiDream: Open-source (MIT license).</li> </ul>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#video-generation-models","level":2,"title":"Video Generation Models","text":"<p>Video generation AI has advanced rapidly with several platforms offering text-to-video and image-to-video capabilities:</p> <p>Commercial Platforms:</p> <ul> <li>Sora (OpenAI): Text-to-video with native audio. Available to ChatGPT Plus/Pro subscribers. Not available in EU/UK.</li> <li>Veo (Google): High-quality video with native audio. Available via Gemini API and Google AI Studio.</li> <li>Runway: Professional video tools with world consistency features.</li> <li>Pika: Keyframe-based video creation.</li> <li>Kling AI: Strong motion handling.</li> <li>Luma: Fast generation with draft mode.</li> </ul> <p>Avatar and Presenter Platforms:</p> <ul> <li>HeyGen: AI avatars with multilingual support.</li> <li>Synthesia: AI avatars with dubbing capabilities.</li> <li>Hedra: Full-body animation with speech.</li> </ul> <p>Open-Source Options:</p> <ul> <li>Hunyuan Video (Tencent): Large open-source model on GitHub/HuggingFace.</li> <li>Stable Video (Stability AI): Open-source video generation.</li> <li>Mochi (Genmo): Apache 2.0 licensed.</li> </ul>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#related-capabilities","level":2,"title":"Related Capabilities","text":"<p>Image and Video Understanding:</p> <ul> <li>Segment Anything Model (SAM 2) (Meta): Image and video segmentation</li> <li>CLIP (OpenAI): Vision-language understanding</li> <li>LLaVA: Open-source visual instruction tuning</li> </ul> <p>3D Generation:</p> <ul> <li>DreamGaussian: Text/image to 3D</li> <li>Meshy: Text to 3D mesh generation</li> <li>Luma Genie: Text to 3D model generation</li> </ul>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#additional-platforms-resources","level":2,"title":"Additional Platforms &amp; Resources","text":"","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#open-source-self-hosted","level":3,"title":"Open Source &amp; Self-Hosted","text":"Platform Description Cost Link Amplify GenAI Open source multi-model platform from Vanderbilt AWS usage + model costs (~$3/user/mo) Amplify GenAI / GitHub Ollama Run LLMs locally Free Ollama LM Studio Desktop app for local LLMs Free LM Studio","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#educational-ai-platforms","level":2,"title":"Educational AI Platforms","text":"<p>These platforms provide AI-powered tutoring and learning support across various subjects:</p> Platform Subject Areas Target Audience Pricing Key Features IXL Math, Language Arts, Science, Social Studies, Spanish Pre-K to 12<sup>th</sup> Grade $9.95/mo (single subject), $19.95/mo (all subjects) Personalized learning, adaptive questions, real-time diagnostics, progress tracking Khan Academy Math, Science, Economics, Arts &amp; Humanities, Computing, Test Prep K-12, College, Adults Free Video lessons, practice exercises, personalized dashboard, progress tracking Duolingo Languages (40+ languages) All ages Free (Duolingo Plus for premium) Gamified learning, bite-sized lessons, spaced repetition, pronunciation practice Quizlet User-Generated Content (all subjects) All ages Free (Quizlet Plus for premium) Flashcards, study games, practice tests, AI-powered study sets EdX University-Level Courses Adults, Professionals Free to audit, paid certificates Courses from top universities, professional certificates, MicroMasters, online degrees Coursera University-Level Courses Adults, Professionals Free to audit, paid certificates Courses from leading universities, specializations, professional certificates, degrees Google Career Certificates Data Analytics, Cybersecurity, IT, Project Management, UX, Marketing, AI Adults, Career Changers $49/mo via Coursera, 7-day free trial Industry-recognized certificates, no degree required, 3-6 month completion, access to Employer Consortium (150+ companies) Udemy Skills-Based Courses (business, tech, personal development) Adults, Professionals Courses priced individually Wide range of topics, frequent discounts, lifetime access to purchased courses MasterClass Expert-Led Courses (creative, professional skills) Adults $120/year (individual), $180/year (duo), $240/year (family) Video lessons from renowned experts, downloadable workbooks, community access Codecademy Programming, Data Science, Web Development Teens, Adults Free (basic), Pro: $239.88/year or $39.99/mo Interactive coding lessons, projects, quizzes, skill paths, career paths Brilliant Math, Science, Computer Science Teens, Adults $149/year or $24.99/mo Interactive problem-solving, conceptual understanding, guided learning paths Google Classroom Platform for any subject K-12, Higher Education Free for schools using Google Workspace Assignment distribution, grading, integration with Google services Kahoot Gamified content for any subject K-12, Higher Education, Corporate Free (basic), paid plans for features Game-based learning, quizzes, trivia, real-time engagement Grammarly Writing improvement K-12, Higher Education, Professionals Free (basic), paid plans AI writing assistant, grammar checking, style suggestions, tone detection <p>For more information on using AI for tutoring and education, see AI Tutoring: Student's Guide.</p>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#important-notes","level":2,"title":"Important Notes","text":"<p>About This Guide</p> <ul> <li>Verification Date: All pricing verified January 2026</li> <li>Updates: AI platforms change rapidly. Check official websites for current pricing</li> <li>Free Tiers: Many services offer free tiers with usage limits</li> <li>Student Discounts: Check for education pricing (Perplexity, Google AI Pro, GitHub Copilot, etc.)</li> <li>API vs Subscription: Some platforms offer both subscription and pay-per-use API options</li> </ul> <p>⚠️ Deprecated/Archived Platforms</p> <ul> <li>SearchGPT - Merged into ChatGPT (no longer standalone)</li> <li>Code Llama - Repository archived July 2025 (consider StarCoder instead)</li> <li>DALL-E - Version 3 being sunset May 2026 (replaced by GPT-4o Image Generation)</li> </ul> <p>Best Options for Students &amp; Educators</p> <p>Free/Low-Cost:</p> <ul> <li>GitHub Copilot - Free for students, teachers, OSS maintainers</li> <li>Perplexity Education - $4.99/mo with verification</li> <li>Google AI Pro - Free for university students (1 year)</li> <li>Khan Academy - Completely free</li> </ul> <p>Best Value Paid:</p> <ul> <li>ChatGPT Plus - $20/mo (good all-rounder)</li> <li>Claude Pro - $20/mo (excellent for research and writing)</li> <li>Gemini AI Pro - $19.99/mo (great multimodal capabilities)</li> </ul> <p>Security &amp; Research Considerations: For research use, consult your institution's AI policies. Some platforms (DeepSeek, Qwen) have restrictions for US-based researchers. See Important Restrictions below for details.</p>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#agentic-browsers-ai-powered-web-browsers","level":2,"title":"Agentic Browsers (AI-Powered Web Browsers)","text":"<p>Agentic browsers integrate AI directly into your web browsing experience, enabling autonomous task execution, intelligent search, and productivity enhancements.</p> Browser Plan Price (per month) Details Perplexity Comet Free $0 AI-powered browser with sidecar assistant, Perplexity AI search, tab management, content summarization Perplexity Max $200 Background Assistant for multi-tasking, autonomous task execution (booking flights, sending emails), mission control dashboard Dia Browser Free Beta $0 (Invite-only) AI-first browser, URL bar = AI chat, tab conversations, Skills system, browsing history context (opt-in)  macOS 14+ M1+ only Dia Pro $20 Unlimited AI chat and Skills, multi-step reasoning, task automation  Acquired by Atlassian ($610M) Fellou Free $0 1,000 Sparks (~4 tasks), Deep Search, autonomous web actions, Shadow Workspace for background tasks Plus $19 2,000 Sparks (~8 tasks), 3 scheduled tasks, priority support Pro $39.90 5,000 Sparks (~20 tasks), 5 scheduled tasks, Image/Code/Music agents Ultra $199.90 Unlimited Sparks, unlimited scheduled/concurrent tasks, exclusive support Opera Neon Subscription $19.99 (Waitlist) Neon Do (autonomous browsing), Neon Make (AI creation), Cards system, Tasks workspaces, local processing Genspark AI Browser Free $0 100 credits daily, Super Agent Everywhere, Autopilot Mode, 700+ MCP tool integrations Plus $24.99 10,000 credits monthly, priority AI agent access, top-tier models, AI Slides/Sheets/Docs Pro $249.99 125,000 credits monthly, full Super Agent access, phone calls, video generation Microsoft Edge Copilot Mode Free (Experimental) $0 Cross-tab awareness, task automation, in-page assistance, browser history/credentials access  Windows/Mac, opt-in Opera One + Aria Free $0 Free AI assistant, real-time web access, page context mode, image generation, tab commands, local AI models  No account required Brave + Leo AI Free $0 Privacy-first AI, Llama 3.1 8B, Mixtral, Claude Haiku, Qwen, content awareness, zero data retention Leo Premium Varies Claude Sonnet 4, DeepSeek R1 reasoning models, Bring Your Own Model (BYOM) <p>Notes on Agentic Browsers:</p> <ul> <li>True Agentic Capabilities: Comet, Fellou, Opera Neon, Dia, and Genspark can autonomously perform multi-step tasks (booking, purchasing, form filling)</li> <li>AI-Enhanced: Microsoft Edge Copilot Mode, Opera One, and Brave Leo provide AI assistance but with less autonomous action</li> <li>Platform Availability: Most are Chromium-based; Dia is macOS only (M1+); Others support Windows/Mac/Linux</li> <li>Privacy Considerations: Check each browser's data policies - some use cloud AI, others offer local processing</li> <li>Coming Soon: OpenAI browser expected late 2025 with ChatGPT integration and Operator agent</li> </ul>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#api-pricing-for-developers","level":2,"title":"API Pricing for Developers","text":"<p>For developers building with AI APIs, here's detailed token-level pricing:</p> Service Plan Pricing Details Claude API Pay-As-You-Go Varies Claude 4.5 Sonnet: $3/1M input, $15/1M output  Claude 4.5 Opus: $15/1M input, $75/1M output  Claude 4.5 Haiku: $0.25/1M input, $1.25/1M output  Batch: 50% discount, Prompt caching: 75-90% savings Gemini API Pay-As-You-Go Varies Gemini 2.5 Flash: $0.30/1M input, $2.50/1M output  Gemini 2.5 Pro: $1.25/1M input, $10/1M output  Gemini 2.5 Flash-Lite: $0.10/1M input, $0.40/1M output  Batch: 50% discount OpenAI API Pay-As-You-Go Varies GPT-4o: $2.50/1M input, $10/1M output  GPT-4o mini: $0.15/1M input, $0.60/1M output  o1: $15/1M input, $60/1M output  o3-mini: $1.10/1M input, $4.40/1M output Mistral API Pay-As-You-Go Varies Medium 3: $0.40/1M in, $2/1M out  Nemo: $0.30/1M  Large 2: $3/1M in, $9/1M out  Codestral: $1/1M in, $3/1M out DeepSeek API Pay-As-You-Go ~200x cheaper DeepSeek Chat: $0.28/1M in, $1.12/1M out  Reasoner (R1): $0.28/1M in, $1.12/1M out  ⚠️ NOT ALLOWED for US researchers Cohere API Pay-As-You-Go Varies Command R: $0.50/1M in, $1.50/1M out  Command R+: $2.50/1M in, $10/1M out  Command-light: $0.30/1M in, $0.60/1M out Together AI Serverless Pay-As-You-Go Text/Vision: \\(0.02-\\)3.50/1M tokens  Images: \\(0.0027-\\)0.08/MP  GPU Clusters: \\(1.76-\\)5.50/GPU hr Groq Developer Pay-As-You-Go 10x rate limits vs free, 50% batch discount Replicate Pay-As-You-Go Varies CPU: $0.36/hr  T4 GPU: $0.81/hr  8x H100: $43.92/hr Amazon Bedrock On-Demand Varies Multi-model platform (Claude, Llama, etc.) - model-specific pricing Google Vertex AI On-Demand Varies 130+ models - refer to Gemini API pricing + model-specific costs Azure AI Studio On-Demand Varies GPT-4o, Claude, Llama, Mistral - refer to OpenAI API pricing + Azure markup","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#important-restrictions-for-us-based-researchers","level":2,"title":"⚠️ Important Restrictions for US-Based Researchers","text":"","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#deepseek-ai-federal-and-state-restrictions","level":3,"title":"DeepSeek AI - Federal and State Restrictions","text":"<p>PAID CLOUD SERVICE NOT ALLOWED:</p> <p>DeepSeek's paid API and cloud services are prohibited for US-based researchers at many institutions due to:</p> <p>Federal Restrictions:</p> <ul> <li> <p>H.R. 1121 - \"No DeepSeek on Government Devices Act\" (Introduced Feb 2025)</p> </li> <li> <p>House Select Committee Report - \"DeepSeek Unmasked: Exposing the CCP's Latest Tool For Spying, Stealing, and Subverting U.S. Export Control Restrictions\"</p> </li> <li> <p>Federal Agency Bans: NASA, U.S. Navy, Department of Defense (DOD), Department of Commerce have banned DeepSeek</p> </li> <li> <p>Owned by High-Flyer (Chinese company with CCP control)</p> </li> <li> <p>Data stored in China and accessible to Chinese government</p> </li> <li> <p>Content manipulation to align with CCP propaganda</p> </li> </ul> <p>State-Level Bans:</p> <ul> <li> <p>Texas (Jan 31, 2025), Virginia (Feb 11, 2025), New York (Feb 10, 2025)</p> </li> <li> <p>Additional states: Iowa, South Dakota, Kansas, Tennessee, North Carolina, Nebraska, Arkansas, North Dakota, Oklahoma, Alabama, Georgia</p> </li> </ul> <p>University Bans:</p> <ul> <li> <p>All Virginia public universities (George Mason, UVA, Virginia Tech, William &amp; Mary, JMU)</p> </li> <li> <p>North Dakota University System</p> </li> </ul> <p>SELF-HOSTED OPEN-SOURCE MAY BE PERMITTED:</p> <p>Open-source DeepSeek models can be downloaded and run on-premises, but researchers MUST:</p> <ul> <li> <p>✅ Check with institutional IT and security teams first</p> </li> <li> <p>✅ Ensure compliance with federal grant requirements (NSF, DOD, DOE)</p> </li> <li> <p>✅ Never upload sensitive, proprietary, or controlled data</p> </li> <li> <p>✅ Document usage for research security compliance</p> </li> </ul>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#qwen-alibaba-data-sovereignty-concerns","level":3,"title":"Qwen (Alibaba) - Data Sovereignty Concerns","text":"<p>NOT SPECIFICALLY BANNED, BUT NOT RECOMMENDED:</p> <p>Qwen is not subject to specific federal bans like DeepSeek, but has serious concerns for US researchers:</p> <p>Key Issues:</p> <ul> <li> <p>Owned by Alibaba (Chinese company subject to CCP control)</p> </li> <li> <p>Data stored in China under Chinese data sovereignty laws</p> </li> <li> <p>No GDPR compliance or EU data protection representative</p> </li> <li> <p>Potential surveillance under Chinese national security laws</p> </li> <li> <p>Congressional scrutiny (Senators urged sanctions in 2023, not yet implemented)</p> </li> </ul> <p>Regulatory Framework:</p> <ul> <li> <p>NSF Research Security - Requires disclosure of foreign support and affiliations</p> </li> <li> <p>Treasury Outbound Investment Restrictions - Limits US investments in Chinese AI companies (affects funding, not use)</p> </li> <li> <p>No Entity List designation (as of Oct 2025)</p> </li> </ul> <p>SELF-HOSTED OPEN-SOURCE MAY BE PERMITTED:</p> <p>Qwen's Apache 2.0 licensed models (40M+ downloads on HuggingFace) can be run on-premises, but researchers MUST:</p> <ul> <li> <p>✅ Check with institutional IT and security teams first</p> </li> <li> <p>✅ Verify compliance with federal grant terms</p> </li> <li> <p>✅ Avoid uploading to Chinese cloud services</p> </li> <li> <p>✅ Document AI tool usage in research security plans</p> </li> </ul>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"choose/#recommendations-for-researchers","level":3,"title":"Recommendations for Researchers","text":"<p>✅ SAFE FOR RESEARCH (US-based alternatives):</p> <ul> <li> <p>OpenAI (ChatGPT, GPT-5 API) - US company</p> </li> <li> <p>Anthropic (Claude) - US company</p> </li> <li> <p>Google (Gemini) - US company</p> </li> <li> <p>Microsoft (Copilot) - US company</p> </li> <li> <p>Mistral AI - French company (EU-based)</p> </li> <li> <p>Cohere - Canadian company</p> </li> </ul> <p>⚠️ USE WITH EXTREME CAUTION (Chinese companies):</p> <ul> <li> <p>DeepSeek - BANNED at many institutions</p> </li> <li> <p>Qwen - Not banned, but data sovereignty concerns</p> </li> <li> <p>Check institutional policies BEFORE use</p> </li> </ul> <p>✅ SELF-HOSTED OPEN-SOURCE (May be acceptable):</p> <ul> <li> <p>Meta Llama (US company, Apache 2.0)</p> </li> <li> <p>DeepSeek open-source (with institutional approval)</p> </li> <li> <p>Qwen open-source (with institutional approval)</p> </li> <li> <p>Mistral open-source (EU company, Apache 2.0)</p> </li> </ul> <p>ALWAYS:</p> <ol> <li> <p>Check your institution's AI usage policy</p> </li> <li> <p>Review federal grant terms (NSF, NIH, DOD, DOE)</p> </li> <li> <p>Consult with IT security and research compliance offices</p> </li> <li> <p>Never share sensitive, proprietary, or controlled data with foreign AI services</p> </li> <li> <p>Document all AI tool usage for research security requirements</p> </li> </ol>","path":["Prompt Engineering","Choosing the Right AI Platform"],"tags":[]},{"location":"claude-code/","level":1,"title":"Claude Code: Setup and Usage Tutorial","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#claude-code","level":2,"title":"Claude Code","text":"<p>This tutorial will guide you through setting up and using Claude Code, Anthropic's AI-powered development tool.</p> <p>Claude Code acts as a pair programmer that understands context, writes code, creates documentation, and helps you create software faster.</p> <p>What You'll Learn</p> <p>This tutorial covers both the Claude Code CLI (command-line interface), the VS Code Extension, and Claude Desktop Code feature. </p> <p>We'll highlight the differences and help you choose the right tool for your workflow.</p> <p>By the end of this tutorial, you'll be able to:</p> <ul> <li>Set up Claude Code in Terminal or VS Code Extension</li> <li>Create and manage GitHub repositories using the GitHub <code>gh</code> CLI</li> <li>Initialize Claude Code with existing codebases or start new projects</li> <li>Create custom agents for specialized development tasks</li> <li>Build slash commands to automate common workflows</li> <li>Integrate Claude Code with your Git workflow</li> <li>Apply best practices for secure, efficient AI-assisted development</li> <li>Understand AI Sandboxes and their importance for AI Safety</li> </ul> <p>Prerequisites</p> <p>Before starting this tutorial, you should have:</p> <p> Basic command-line/terminal experience</p> <p> Familiarity with Git and version control concepts</p> <p> A GitHub account</p> <p> A text editor or IDE (VS Code recommended)</p> <p> Willingness to experiment and learn!</p> Are there other CLI  Code Assistants? <p>Yes! Claude Code is not the only CLI tool for AI-assisted development. </p> <p>Other popular options include:</p> <p> Google Gemini CLI</p> <p> ChatGPT Codex</p> <p> OpenCode.ai</p> <p> aider.chat</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#1-what-is-claude-code","level":2,"title":"1. What is Claude Code?","text":"<p>Claude Code is an AI-powered development assistant built by Anthropic that integrates directly into your development workflow.</p> <p>Unlike simple code completion tools, Claude Code is an agentic AI system capable of:</p> <ul> <li>Understanding entire codebases through contextual analysis</li> <li>Writing and editing code across multiple files simultaneously</li> <li>Running commands in your terminal to test and verify changes</li> <li>Debugging errors by analyzing stack traces and suggesting fixes</li> <li>Generating documentation that stays in sync with your code</li> <li>Creating tests based on your implementation</li> <li>Refactoring code while maintaining functionality</li> </ul> <p>Claude Code represents the evolution of AI-assisted development—moving beyond autocomplete to truly collaborative coding experiences often called \"Vibe Coding\".</p> CLI vs VS Code Extension: Which Should You Use? <p>Claude Code comes in two primary forms, each suited to different workflows?</p> Feature Claude Code CLI Claude Code VS Code Extension Platform  Terminal/Command Line  VS Code Editor Installation <code>npm install -g @anthropic-ai/claude</code> VS Code Extensions Marketplace Interface Text-based conversations in terminal Integrated chat panel + inline edits File Editing Creates/modifies files via CLI commands Direct in-editor modifications Context Awareness Full project directory access VS Code workspace integration Terminal Integration Native terminal environment VS Code integrated terminal Best For Terminal-first developers, automation, CI/CD VS Code users, visual development, GUI preferences Keyboard Shortcuts Standard terminal shortcuts VS Code keybindings + custom shortcuts MCP Support Yes, via configuration Yes, via configuration Multi-Project Switch directories manually Workspace support <p>Recommendation: Start with Your Comfort Zone</p> <p>If you're primarily a terminal user who lives in vim, emacs, or tmux, start with the CLI. </p> <p>If you spend most of your time in VS Code, start with the Extension. You can always use both!</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#2-prerequisites-account-setup","level":2,"title":"2. Prerequisites &amp; Account Setup","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#21-account-options","level":3,"title":"2.1 Account Options","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#option-1-claudeai","level":4,"title":"Option 1: Claude.ai","text":"<p>Claude ($20/month), Claude Pro ($100/month), Claude Pro Max ($200/month) </p> <ul> <li>Access to Claude Code CLI and VS Code Extension</li> <li>Extended usage limits (5x more than free tier)</li> <li>Priority access during high-traffic periods</li> <li>Access to all Claude models (Sonnet, Opus, Haiku)</li> <li>Early access to new features</li> </ul> <p>Best for: Individual developers and frequent users</p> <p>Sign up: claude.ai</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#option-2-anthropic-api-key","level":4,"title":"Option 2: Anthropic API Key","text":"<p>For programmatic access and integration:</p> <ul> <li>Sign up: console.anthropic.com</li> <li>Pricing: Pay-per-use based on tokens (see pricing below)</li> <li>API key management: Generate keys in console dashboard</li> <li>Usage tracking: Monitor consumption in real-time</li> </ul> <p>Best for: Teams, developers who want fine-grained control, batch processing, or integration with other tools</p> <p>API Pricing (January 2026)</p> <p>Per million tokens:</p> <ul> <li>Claude 4.5 Sonnet: $3 input / $15 output</li> <li>Claude 4.5 Opus: $15 input / $75 output</li> <li>Claude 4.5 Haiku: $0.25 input / $1.25 output</li> </ul> <p>For most coding tasks, Claude 4.5 Sonnet provides the best balance of capability and cost.</p> <p>Treat Your API Key Like a Password</p> <p>Never commit API keys to version control!</p> <ul> <li>Store in environment variables</li> <li>Use <code>.env</code> files (and add to <code>.gitignore</code>)</li> <li>Rotate keys regularly</li> <li>Revoke compromised keys immediately</li> </ul> <p>See Security Best Practices for more details.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#22-system-requirements","level":3,"title":"2.2 System Requirements","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#operating-system","level":4,"title":"Operating System","text":"<ul> <li> macOS 10.15 (Catalina) or later</li> <li> Windows 10/11 (with WSL2 recommended for CLI)</li> <li> Linux (Ubuntu 20.04+, Fedora 35+, or equivalent)</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#required-software","level":4,"title":"Required Software","text":"<p>Node.js and npm (for CLI installation):</p> <ul> <li>Node.js v16.0.0 or later</li> <li>npm v7.0.0 or later</li> <li>Check versions: <code>node --version &amp;&amp; npm --version</code></li> <li>Install from nodejs.org</li> </ul> <p>Git:</p> <ul> <li>Git v2.20.0 or later</li> <li>Check version: <code>git --version</code></li> <li>Install from git-scm.com</li> </ul> <p>VS Code (or clone):</p> <ul> <li>Visual Studio Code v1.75.0 or later: code.visualstudio.com</li> <li>Posit Positron: posit.com</li> <li>Google Antigravity: antigravity.google</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#ai-sandbox-environments-optional","level":4,"title":"AI Sandbox Environments (Optional)","text":"<p>For isolated, secure, or team-based development environments, Claude Code works in:</p> <p>Docker Containers</p> <ul> <li>Run Claude Code in isolated containers</li> <li>Useful for reproducible environments</li> <li>See Docker Documentation for setup</li> </ul> <p>Virtual Machines</p> <ul> <li>Full OS isolation for security-sensitive work</li> <li>Supports all major VM platforms (VirtualBox, VMware, Hyper-V)</li> <li>Good for institutional policies requiring sandboxes</li> </ul> <p>Jupyter Lab</p> <ul> <li>Integrate Claude Code into notebook workflows</li> <li>See our Jupyter AI Guide for details</li> <li>Useful for data science and research contexts</li> </ul> <p>Cloud Development Environments</p> <ul> <li>CyVerse: cyverse.org</li> <li>Jetstream-2: jetstream-cloud.org</li> </ul> When to Use AISandboxes <p>Consider sandbox environments if you:</p> <ul> <li>Work with sensitive or proprietary code</li> <li>Need compliance with institutional security policies</li> <li>Want reproducible development environments</li> <li>Are teaching or conducting workshops</li> <li>Need to test code in isolated environments</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#3-installation-guide","level":2,"title":"3. Installation Guide","text":"<p>This section covers installing both the Claude Code CLI and the VS Code Extension. You can install one or both depending on your workflow preferences.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#31-claude-code-cli","level":3,"title":"3.1 Claude Code CLI","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#installation-on-macoslinux","level":4,"title":"Installation on macOS/Linux","text":"<p>Open your terminal and run:</p> <pre><code>curl -fsSL https://claude.ai/install.sh | bash\nclaude --version\n</code></pre> <p>Expected output:</p> <pre><code>2.1.9 (Claude Code)\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#installation-on-windows","level":4,"title":"Installation on Windows","text":"<p>Option 1: Using WSL2 (Recommended)</p> <p>Windows Subsystem for Linux provides the best experience:</p> <pre><code># In WSL2 terminal\ncurl -fsSL https://claude.ai/install.sh | bash\nclaude --version\n</code></pre> <p>Option 2: PowerShell/Command Prompt</p> <pre><code># In PowerShell or CMD\ncurl -fsSL https://claude.ai/install.cmd -o install.cmd &amp;&amp; install.cmd &amp;&amp; del install.cmd\nclaude --version\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#authentication-setup","level":4,"title":"Authentication Setup","text":"<p>After installation, authenticate with your Claude account:</p> <pre><code>claude\n</code></pre> <p>Claude will start with a welcome graphic and ask you to select a color palette</p> <pre><code>Welcome to Claude Code v2.1.9                                                                   \n…………………………………………………………………………………………………………………………………………………………                                      \n\n     *                                       █████▓▓░                                           \n                                 *         ███▓░     ░░                                         \n            ░░░░░░                        ███▓░                                                 \n    ░░░   ░░░░░░░░░░                      ███▓░                                                 \n   ░░░░░░░░░░░░░░░░░░░    *                ██▓░░      ▓                                         \n                                             ░▓▓███▓▓░                                          \n *                                 ░░░░                                                         \n                                 ░░░░░░░░                                                       \n                               ░░░░░░░░░░░░░░░░                                                 \n       █████████                                        *                                       \n      ██▄█████▄██                        *                                                      \n       █████████      *                                                                         \n…………………█ █   █ █………………………………………………………………………………………………………………                                      \n\n Let's get started.                                                                             \n\n Choose the text style that looks best with your terminal                                       \n To change this later, run /theme                                                               \n\n ❯ 1. Dark mode ✔                                                                               \n   2. Light mode                                                                                \n   3. Dark mode (colorblind-friendly)                                                           \n   4. Light mode (colorblind-friendly)                                                          \n   5. Dark mode (ANSI colors only)                                                              \n   6. Light mode (ANSI colors only)                                                             \n\n╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌\n 1  function greet() {                                                                          \n 2 -  console.log(\"Hello, World!\");                                                             \n 2 +  console.log(\"Hello, Claude!\");                                                            \n 3  }                                                                                           \n╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌\n</code></pre> <p>Next, you will need to authenticate in one of two ways:</p> <pre><code>Welcome to Claude Code v2.1.9                                                                   \n…………………………………………………………………………………………………………………………………………………………                                      \n\n     *                                       █████▓▓░                                           \n                                 *         ███▓░     ░░                                         \n            ░░░░░░                        ███▓░                                                 \n    ░░░   ░░░░░░░░░░                      ███▓░                                                 \n   ░░░░░░░░░░░░░░░░░░░    *                ██▓░░      ▓                                         \n                                             ░▓▓███▓▓░                                          \n *                                 ░░░░                                                         \n                                 ░░░░░░░░                                                       \n                               ░░░░░░░░░░░░░░░░                                                 \n       █████████                                        *                                       \n      ██▄█████▄██                        *                                                      \n       █████████      *                                                                         \n…………………█ █   █ █………………………………………………………………………………………………………………                                      \n\n\n Claude Code can be used with your Claude subscription or billed based on API usage through your\n  Console account.                                                                              \n\n Select login method:                                                                           \n\n ❯ 1. Claude account with subscription · Pro, Max, Team, or Enterprise                          \n\n   2. Anthropic Console account · API usage billing              \n</code></pre> <p>This will:</p> <ol> <li>Open your browser to authenticate</li> <li>Ask you to authorize Claude Code</li> <li>Save your credentials securely</li> </ol> <p>For API key users:</p> <pre><code># Set API key via environment variable\nexport ANTHROPIC_API_KEY=\"your-api-key-here\"\n</code></pre> <p>Environment Variables</p> <p>Add to your shell profile (<code>~/.bashrc</code>, <code>~/.zshrc</code>, etc.):</p> <pre><code>export ANTHROPIC_API_KEY=\"your-api-key-here\"\n</code></pre> <p>Then reload: <code>source ~/.zshrc</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#basic-configurations","level":4,"title":"Basic Configurations","text":"<p>Configure Claude Code preferences using slash commands</p> <p>In Claude, type the <code>/model</code> command:</p> <pre><code> ▐▛███▜▌   Claude Code v2.1.9                                                                   \n▝▜█████▛▘  Sonnet 4.5 (1M context) · Claude Max                                                 \n  ▘▘ ▝▝    ~/github/intro-gpt                                                                   \n\n────────────────────────────────────────────────────────────────────────────────────────────────\n❯ /model                                                                                        \n────────────────────────────────────────────────────────────────────────────────────────────────\n  /model                  Set the AI model for Claude Code                                      \n  /status                 Show Claude Code status including version, model, account, API conn…  \n  /vim                    Toggle between Vim and Normal editing modes                           \n  /plan                   Enable plan mode or view the current session plan           \n</code></pre> <p>Hit  <code>return</code> or  <code>enter</code> key on your keyboard to enter the new menu</p> <p>Select a model from the list:</p> <pre><code> ▐▛███▜▌   Claude Code v2.1.9                                                                   \n▝▜█████▛▘  Sonnet 4.5 (1M context) · Claude Max                                                 \n  ▘▘ ▝▝    ~/github/intro-gpt                                                                   \n────────────────────────────────────────────────────────────────────────────────────────────────\n Select model                                                                                   \n Switch between Claude models. Applies to this session and future Claude Code sessions. For     \n other/previous model names, specify with --model.                                              \n\n   1. Default (recommended)  Opus 4.5 · Most capable for complex work                           \n   2. Sonnet                 Sonnet 4.5 · Best for everyday tasks                               \n ❯ 3. Sonnet (1M context) ✔  Sonnet 4.5 with 1M context · Uses rate limits faster               \n   4. Haiku                  Haiku 4.5 · Fastest for quick answers    \n</code></pre> <p>In general, the default <code>Sonnet 4.5</code> model should be most useful (both efficient and accurate) for coding tasks.</p> <p>Use the <code>Opus 4.5</code> model when creating complex plans or for analysing a new codebase</p> <p>Use <code>Sonnet 4.5 1M</code> for large projects (this is actually the most expensive model)</p> <p>Use <code>Haiku 4.5</code> for faster outputs that don't require complexity (Haiku is still excellent for writing code, and is the least expensive model).</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#32-vs-code-extension","level":3,"title":"3.2 VS Code Extension","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#installing-from-marketplace","level":4,"title":"Installing from Marketplace","text":"<ol> <li> <p>Open VS Code</p> </li> <li> <p>Open Extensions View</p> </li> <li> <p>Click Extensions icon in sidebar (or <code>Ctrl/Cmd + Shift + X</code>)</p> </li> <li> <p>Search for \"Claude Code\"</p> </li> <li>Type \"Claude Code\" in search box</li> <li> <p>Look for official Anthropic extension</p> </li> <li> <p>Install</p> </li> <li>Click \"Install\" button</li> <li> <p>Wait for installation to complete</p> </li> <li> <p>Reload VS Code</p> </li> <li>Click \"Reload\" if prompted</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#alternative-command-line-installation","level":4,"title":"Alternative: Command Line Installation","text":"<pre><code>code --install-extension anthropic.claude\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#initial-setup-wizard","level":4,"title":"Initial Setup Wizard","text":"<p>After installation, the setup wizard will guide you through:</p> <ol> <li>Authentication</li> <li>Sign in with your Claude account</li> <li> <p>Or enter API key</p> </li> <li> <p>Model Selection</p> </li> <li>Choose default model (Sonnet recommended)</li> <li> <p>Can change per-conversation</p> </li> <li> <p>Permissions</p> </li> <li>File access permissions</li> <li>Terminal access permissions</li> <li> <p>Confirm security settings</p> </li> <li> <p>Workspace Configuration</p> </li> <li>Optional: configure per-workspace settings</li> <li>Set up <code>.claude</code> directory</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#authentication","level":4,"title":"Authentication","text":"<p>For Claude Pro/Team users:</p> <ol> <li>Click \"Sign in with Claude\" in extension</li> <li>Authorize in browser</li> <li>Return to VS Code</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#extension-settings-overview","level":4,"title":"Extension Settings Overview","text":"<p>Key settings to configure:</p> <ul> <li>Default Model: Which Claude model to use</li> <li>Auto-save: Whether to save files before running commands</li> <li>Context Window: How much code to include in context</li> <li>Terminal Integration: Enable/disable terminal access</li> <li>MCP Servers: Configure Model Context Protocol connections</li> </ul> <p>Access settings: <code>Preferences &gt; Settings &gt; Extensions &gt; Claude Code</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#verification","level":4,"title":"Verification","text":"<p>Verify the extension is working:</p> <ol> <li>Open Command Palette (<code>Cmd/Ctrl + Shift + P</code>)</li> <li>Type \"Claude Code: Chat\"</li> <li>Send a test message</li> <li>Confirm Claude responds</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#33-github-cli-setup","level":3,"title":"3.3 GitHub CLI Setup","text":"<p>The GitHub CLI (<code>gh</code>) simplifies repository management and integrates beautifully with Claude Code workflows.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#installing-gh-client","level":4,"title":"Installing gh Client","text":"<p>macOS:</p> <pre><code># Using Homebrew\nbrew install gh\n\n# Verify installation\ngh --version\n</code></pre> <p>Windows:</p> <pre><code># Using winget\nwinget install --id GitHub.cli\n\n# Or using Chocolatey\nchoco install gh\n\n# Verify\ngh --version\n</code></pre> <p>Linux (Ubuntu/Debian):</p> <pre><code># Add GitHub CLI repository\ntype -p curl &gt;/dev/null || sudo apt install curl -y\ncurl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \\\n&amp;&amp; sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \\\n&amp;&amp; echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | sudo tee /etc/apt/sources.list.d/github-cli.list &gt; /dev/null \\\n&amp;&amp; sudo apt update \\\n&amp;&amp; sudo apt install gh -y\n\n# Verify\ngh --version\n</code></pre> <p>Linux (Fedora/CentOS/RHEL):</p> <pre><code>sudo dnf install 'dnf-command(config-manager)'\nsudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo\nsudo dnf install gh\n\n# Verify\ngh --version\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#authentication-with-github","level":4,"title":"Authentication with GitHub","text":"<p>Authenticate the GitHub CLI:</p> <pre><code># Start authentication flow\ngh auth login\n</code></pre> <p>You'll be prompted to:</p> <ol> <li>Choose authentication method (browser recommended)</li> <li>Select protocol (HTTPS or SSH)</li> <li>Authenticate in browser</li> <li>Confirm successful authentication</li> </ol> <p>Verify authentication:</p> <pre><code>gh auth status\n</code></pre> <p>Expected output: <pre><code>✓ Logged in to github.com as your-username\n✓ Git operations for github.com configured to use https protocol\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#your-first-conversational-git-experience","level":4,"title":"Your First Conversational Git Experience","text":"<p>Now that you've installed <code>gh</code> CLI and authenticated with GitHub, here's the exciting part: you don't need to memorize Git commands anymore. </p> <p>Instead of typing manual commands, you can have natural conversations with Claude Code about what you want to accomplish, and Claude handles the Git operations for you.</p> <p>The Paradigm Shift:</p> <p>Traditional Git requires remembering specific commands, flags, and syntax. </p> <p>With Claude Code, you simply describe what you want in plain English, and Claude translates your intent into the appropriate Git operations.</p> <p>Traditional Git vs. Conversational Git:</p> Traditional Workflow Claude Code Conversation <code>git status</code><code>git add .</code><code>git commit -m \"message\"</code><code>git push</code> You: \"Commit and push my changes\"Claude: [Checks status, stages files, creates commit, pushes] <code>git status</code>(manually review changes)<code>git diff file.py</code> You: \"What's the current state of my repository?\"Claude: [Runs git status, summarizes changes clearly] <code>git add .</code><code>git commit -m \"fix: update config\"</code>(hope the message is good enough) You: \"Add all my files and commit with a good message\"Claude: [Analyzes changes, creates descriptive commit message] <code>gh pr create --title \"...\" --body \"...\"</code>(write PR description from scratch) You: \"Create a pull request\"Claude: [Analyzes commits, drafts PR with summary and test plan] <p>Essential Conversational Git Patterns:</p> <p>Here are realistic dialogues showing how Claude Code handles common Git workflows. Notice how you can ask in natural language, and Claude explains what it's doing:</p> <p>Example 1: Checking Repository Status</p> <p>You: What's the current state of my repository?</p> <p>Claude: Let me check...</p> <p>[Runs <code>git status</code>]</p> <p>Your repository is on branch <code>main</code> and it's up to date with <code>origin/main</code>.</p> <p>You have: - 3 untracked files: <code>src/app.py</code>, <code>requirements.txt</code>, and <code>README.md</code> - No staged or unstaged changes to tracked files</p> <p>Would you like to add these files and commit them?</p> <p>Alternative natural phrasings:</p> <ul> <li>\"Check my git status\"</li> <li>\"What files have I changed?\"</li> <li>\"Show me what's in my repo\"</li> <li>\"Did I modify anything?\"</li> </ul> <p>Example 2: Adding and Committing Files</p> <p>You: Add all my files and commit them with a good message</p> <p>Claude: I'll help you commit these changes. Let me check what we're committing...</p> <p>[Runs <code>git status</code>]</p> <p>I see 3 new files: - <code>src/app.py</code> - A Flask application setup - <code>requirements.txt</code> - Python dependencies - <code>README.md</code> - Project documentation</p> <p>[Runs <code>git add .</code>]</p> <p>[Runs `git commit -m \"feat: initial project setup with Flask app</p> <ul> <li>Add Flask application skeleton</li> <li>Add project dependencies</li> <li>Add initial documentation\"`]</li> </ul> <p>✓ Changes committed! Would you like to push to the remote repository?</p> <p>Alternative natural phrasings: - \"Commit my changes\" - \"Save all my work to git\" - \"Make a commit with a descriptive message\" - \"Stage and commit everything\"</p> <p>Claude Analyzes Before Acting</p> <p>Notice how Claude first checks what files are being committed and provides context. This helps you understand what's happening and catch any mistakes before they're committed.</p> <p>Example 3: Pushing to Remote</p> <p>You: Push my changes to GitHub</p> <p>Claude: I'll push your commits to the remote repository.</p> <p>[Runs <code>git push</code>]</p> <p>✓ Successfully pushed to origin/main!</p> <p>Your changes are now on GitHub at: https://github.com/username/repo</p> <p>Alternative natural phrasings:</p> <ul> <li>\"Push to remote\"</li> <li>\"Upload my commits to GitHub\"</li> <li>\"Send my changes to GitHub\"</li> <li>\"Sync with GitHub\"</li> </ul> <p>Example 4: Creating a Pull Request</p> <p>You: Create a pull request for my changes</p> <p>Claude: I'll create a PR for you. Let me analyze your changes...</p> <p>[Runs <code>git diff main</code>]</p> <p>[Runs `gh pr create --title \"feat: Add Flask application\" --body \"## Summary</p> <ul> <li>Initial Flask application setup</li> <li>Added project dependencies</li> <li>Created documentation</li> </ul> <p>Alternative natural phrasings:</p> <ul> <li>\"Make a PR\"</li> <li>\"Open a pull request\"</li> <li>\"Submit for review\"</li> <li>\"Create PR from my branch\"</li> </ul> <p>Try It Yourself</p> <p>The best way to learn is by doing. Once you've created your first project in Section 4, come back and try these conversations. You'll be amazed at how natural it feels!</p> <p>What You Just Experienced:</p> <p>With Claude Code, Git operations become conversational:</p> <p>✓ Natural language instead of command memorization ✓ Context awareness - Claude understands your project state ✓ Smart defaults - Claude writes good commit messages and PR descriptions ✓ Safety checks - Claude shows you what it's doing before making changes ✓ Flexibility - Ask in whatever way feels natural to you</p> <p>Advanced Git Workflows</p> <p>This section covered the essential Git workflow (status, add, commit, push, PR) that beginners need. For advanced operations like branching strategies, rebasing, stashing, handling merge conflicts, and collaborative workflows, see Section 8.2: Git Integration Patterns.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#quick-command-reference","level":4,"title":"Quick Command Reference","text":"<p>Claude Can Run These For You</p> <p>You don't need to memorize or manually type these commands! Claude Code can execute all of these through natural conversation (as shown above). This reference is useful for:</p> <ul> <li>Understanding what Claude does behind the scenes</li> <li>Manual use when Claude Code isn't running</li> <li>Scripts and automation that don't need AI assistance</li> </ul> <p>Common <code>gh</code> and <code>git</code> commands for reference:</p> <pre><code># Create a repository\ngh repo create my-project --public\n\n# Clone a repository\ngh repo clone username/repository\n\n# Create a pull request\ngh pr create --title \"Feature: Add new component\" --body \"Description here\"\n\n# View repository information\ngh repo view\n\n# List your repositories\ngh repo list\n\n# Open repository in browser\ngh repo view --web\n\n# Check issues\ngh issue list\n\n# Create an issue\ngh issue create --title \"Bug: Something broke\" --body \"Details\"\n</code></pre> <p>For more commands: <code>gh --help</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#verifying-installation","level":4,"title":"Verifying Installation","text":"<p>Test all components are working:</p> <pre><code># Check versions\necho \"Node: $(node --version)\"\necho \"npm: $(npm --version)\"\necho \"Git: $(git --version)\"\necho \"GitHub CLI: $(gh --version)\"\necho \"Claude Code: $(claude --version)\"\n</code></pre> <p>All commands should return version numbers without errors.</p> <p>Installation Complete!</p> <p>You've installed Claude Code, authenticated with GitHub, and learned how conversational Git works. In the next section, we'll create your first project and put these skills into practice!</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#4-creating-your-first-project","level":2,"title":"4. Creating Your First Project","text":"<p>Now that you have Claude Code set up and understand conversational Git, let's create your first project using natural conversation. No need to memorize <code>gh</code> commands—just tell Claude what you want to build!</p> <p>First, create a new folder in the CLI and change directory into it</p> <pre><code>mkdir review-paper\ncd review-paper\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#41-starting-claude-code","level":3,"title":"4.1 Starting Claude Code","text":"<p>Before activating the local folder as a git repository, let's start Claude Code inside the new empty directory.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#cli-starting-a-session","level":4,"title":"CLI: Starting a Session","text":"<p>Start Claude Code:</p> <pre><code># Start Claude Code from any directory\nclaude\n</code></pre> <p>You'll see Claude Code's interactive prompt:</p> <pre><code>(base) ➜  review-paper claude\n\n────────────────────────────────────────────────────────────────────────────────────────────────\n Do you trust the files in this folder?                                                         \n\n /Users/tswetnam/review-paper                                                                   \n\n Claude Code may read, write, or execute files contained in this directory. This can pose       \n security risks, so only use files from trusted sources.                                        \n\n Learn more                                                                                     \n\n ❯ 1. Yes, proceed                                                                              \n   2. No, exit                                                                                  \n\n Enter to confirm · Esc to cancel                    \n</code></pre> <p>Click  <code>1. Yes, proceed</code> at this point if you are in the correct folder. </p> <p>Pro Tip</p> <p>You can start Claude Code from any directory. </p> <p>Claude can navigate the file system, create directories, and set up projects wherever you need them!</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#42-creating-a-new-repository-conversational","level":3,"title":"4.2 Creating a New Repository (Conversational)","text":"<p>Now comes the exciting part: creating your first GitHub repository through conversation with Claude. </p> <p>No manual commands needed!</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#example-creating-a-brand-new-project","level":4,"title":"Example: Creating a Brand New Project","text":"<p>You: </p> <pre><code>❯ set up this folder as a git repository, include all of the common files for a data            \n  science project that uses Python  \n</code></pre> <p>Claude: </p> <pre><code>⏺ I'll help you set up this folder as a git repository with common files for a Python data      \n  science project. Let me plan this out.                                                        \n\n⏺ Bash(git init)                                                                                \n  ⎿  Running…                                                                                   \n\n  Todos · ctrl+t to hide todos                                                                  \n  ☐ Initialize git repository                                                                   \n  ☐ Create Python .gitignore file                                                               \n  ☐ Create README.md with project template                                                      \n  ☐ Create requirements.txt file                                                                \n  ☐ Create standard directory structure                                                         \n  ☐ Create initial git commit                                                                   \n\n────────────────────────────────────────────────────────────────────────────────────────────────\n Bash command                                                                                   \n\n   git init                                                                                     \n   Initialize git repository                                                                    \n\n Do you want to proceed?                                                                        \n ❯ 1. Yes                                                                                       \n   2. Yes, and don't ask again for git init commands in /Users/tswetnam/review-paper            \n   3. No                                                                                        \n\n Esc to cancel · Tab to add additional instructions   \n</code></pre> <p>Say <code>Yes</code></p> <pre><code>⏺ Bash(git init)                                                                                \n  ⎿  Initialized empty Git repository in /Users/tswetnam/review-paper/.git/                     \n     hint: Using 'master' as the name for the initial branch. This default branch name          \n     hint: is subject to change. To configure the initial branch name to use in all             \n     … +8 lines (ctrl+o to expand)                                                              \n\n⏺ Write(.gitignore)                                                                             \n  ⎿  Wrote 187 lines to .gitignore                                                              \n      1 # Byte-compiled / optimized / DLL files                                                 \n      2 __pycache__/                                                                            \n      3 *.py[cod]                                                                               \n      4 *$py.class                                                                              \n      5 # C extensions                                                                          \n      6 *.so                                                                                    \n      7 # Distribution / packaging                                                              \n      8 .Python                                                                                 \n     … +177 lines (ctrl+o to expand)                                                            \n\n⏺ Write(README.md)                                                                              \n\n  Todos · ctrl+t to hide todos                                                                  \n  ☒ Initialize git repository                                                                   \n  ☒ Create Python .gitignore file                                                               \n  ☐ Create README.md with project template                                                      \n  ☐ Create requirements.txt file                                                                \n  ☐ Create standard directory structure                                                         \n  ☐ Create initial git commit                                                                   \n\n────────────────────────────────────────────────────────────────────────────────────────────────\n Create file README.md                                                                          \n╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌\n   1 # Review Paper                                                                             \n   2                                                                                            \n   3 ## Project Description                                                                     \n   4                                                                                            \n   5 A brief description of your review paper project.                                          \n   6                                                                                            \n   7 ## Project Structure                                                                       \n   8                                                                                            \n   9 ```                                                                                        \n  10 review-paper/                                                                              \n  11 ├── data/                                                                                  \n  12 │   ├── raw/              # Original, immutable data                                       \n  13 │   ├── interim/          # Intermediate transformed data                                  \n  14 │   ├── processed/        # Final data sets for modeling                                   \n  15 │   └── external/         # Data from third party sources                                  \n  16 ├── notebooks/            # Jupyter notebooks for exploration                              \n  17 ├── src/                  # Source code for this project                                   \n  18 │   ├── __init__.py                                                                        \n  19 │   ├── data/            # Scripts to download or generate data                            \n  20 │   ├── features/        # Scripts to turn raw data into features                          \n  21 │   ├── models/          # Scripts to train models and make predictions                    \n  22 │   └── visualization/   # Scripts to create visualizations                                \n  23 ├── models/              # Trained and serialized models                                   \n  24 ├── reports/             # Generated analysis as HTML, PDF, LaTeX, etc.                    \n  25 │   └── figures/         # Generated graphics and figures                                  \n  26 ├── tests/               # Unit tests                                                      \n  27 ├── requirements.txt     # Python dependencies                                             \n  28 ├── .gitignore                                                                             \n  29 └── README.md                                                                              \n  30 ```                                                                                        \n  31                                                                                            \n  32 ## Setup                                                                                   \n  33                                                                                            \n  34 ### Prerequisites                                                                          \n  35                                                                                            \n  36 - Python 3.8 or higher                                                                     \n  37 - pip or conda                                                                             \n  38                                                                                            \n  39 ### Installation                                                                           \n  40                                                                                            \n  41 1. Clone this repository                                                                   \n  42 ```bash                                                                                    \n  43 git clone &lt;repository-url&gt;                                                                 \n  44 cd review-paper                                                                            \n  45 ```                                                                                        \n  46                                                                                            \n  47 2. Create a virtual environment                                                            \n  48 ```bash                                                                                    \n  49 python -m venv venv                                                                        \n  50 source venv/bin/activate  # On Windows: venv\\Scripts\\activate                              \n  51 ```                                                                                        \n  52                                                                                            \n  53 3. Install dependencies                                                                    \n  54 ```bash                                                                                    \n  55 pip install -r requirements.txt                                                            \n  56 ```                                                                                        \n  57                                                                                            \n  58 ## Usage                                                                                   \n  59                                                                                            \n  60 Describe how to use your project here.                                                     \n  61                                                                                            \n  62 ## Data                                                                                    \n  63                                                                                            \n  64 Describe your data sources and how to obtain them.                                         \n  65                                                                                            \n  66 ## Results                                                                                 \n  67                                                                                            \n  68 Summarize key findings and results.                                                        \n  69                                                                                            \n  70 ## Contributing                                                                            \n  71                                                                                            \n  72 If this is a collaborative project, describe how others can contribute.                    \n  73                                                                                            \n  74 ## License                                                                                 \n  75                                                                                            \n  76 Specify your license here.                                                                 \n  77                                                                                            \n  78 ## Contact                                                                                 \n  79                                                                                            \n  80 Your contact information or project maintainer details.                                    \n╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌\n Do you want to create README.md?                                                               \n ❯ 1. Yes                                                                                       \n   2. Yes, allow all edits during this session (shift+tab)                                      \n   3. No                                                                                        \n\n Esc to cancel · Tab to add additional instructions      \n</code></pre> <p>Continue to accept Claude's questions until the tasks are complete.</p> <p>Claude Understands Context</p> <p>Notice how Claude:</p> <ul> <li>Inferred you wanted a public repository (common for learning projects)</li> <li>Automatically added a Python .gitignore (you mentioned Python)</li> <li>Added a license (good practice for public repos)</li> <li>Cloned it locally and navigated into the directory</li> <li>Asked follow-up questions to understand next steps</li> </ul> <p>You can always be more specific: \"Create a private repo\" or \"Don't add a license yet\"</p> <p>Claude will continue to execute on the plan until it completes:</p> <pre><code>⏺ Write(.gitignore)                                                                             \n  ⎿  Wrote 187 lines to .gitignore                                                              \n      1 # Byte-compiled / optimized / DLL files                                                 \n      2 __pycache__/                                                                            \n      3 *.py[cod]                                                                               \n      4 *$py.class                                                                              \n      5 # C extensions                                                                          \n      6 *.so                                                                                    \n      7 # Distribution / packaging                                                              \n      8 .Python                                                                                 \n     … +177 lines (ctrl+o to expand)                                                            \n\n⏺ Write(README.md)                                                                              \n  ⎿  Wrote 81 lines to README.md                                                                \n      1 # Review Paper                                                                          \n      2 ## Project Description                                                                  \n      3 A brief description of your review paper project.                                       \n      4 ## Project Structure                                                                    \n      5 ```                                                                                     \n      6 review-paper/                                                                           \n     … +71 lines (ctrl+o to expand)                                                             \n\n⏺ Write(requirements.txt)                                                                       \n  ⎿  Wrote 35 lines to requirements.txt                                                         \n      1 # Core data science libraries                                                           \n      2 numpy&gt;=1.24.0                                                                           \n      3 pandas&gt;=2.0.0                                                                           \n      4 scipy&gt;=1.10.0                                                                           \n      5 # Visualization                                                                         \n      6 matplotlib&gt;=3.7.0                                                                       \n      7 seaborn&gt;=0.12.0                                                                         \n      8 plotly&gt;=5.14.0                                                                          \n     … +25 lines (ctrl+o to expand)                                                             \n\n⏺ Bash(mkdir -p data/raw data/interim data/processed data/external notebooks src/data           \n      src/features src/models src/visualization models reports/figures tests &amp;&amp; touch d…)       \n  ⎿  (No content)                                                                               \n\n⏺ Bash(git add . &amp;&amp; git commit -m \"Initial commit: Set up Python data science project           \n      structure…)                                                                               \n  ⎿ [master (root-commit) 0e41ecd] Initial commit: Set up Python data science project struc     \n    ture                                                                                        \n     14 files changed, 300 insertions(+)                                                        \n    … +14 lines (ctrl+o to expand)                                                              \n\n\n⏺ Done! I've successfully set up your folder as a git repository with a complete Python data    \n  science project structure. Here's what was created:                                           \n\n  Core Files:                                                                                   \n  - .gitignore - Comprehensive Python and data science exclusions                               \n  - README.md - Project template with structure documentation                                   \n  - requirements.txt - Common data science libraries (numpy, pandas, scikit-learn, jupyter,     \n  matplotlib, etc.)                                                                             \n\n  Directory Structure:                                                                          \n  review-paper/                                                                                 \n  ├── data/                                                                                     \n  │   ├── raw/              # For original data                                                 \n  │   ├── interim/          # For intermediate data                                             \n  │   ├── processed/        # For final datasets                                                \n  │   └── external/         # For third-party data                                              \n  ├── notebooks/            # For Jupyter notebooks                                             \n  ├── src/                  # Source code modules                                               \n  │   ├── data/                                                                                 \n  │   ├── features/                                                                             \n  │   ├── models/                                                                               \n  │   └── visualization/                                                                        \n  ├── models/               # For saved models                                                  \n  ├── reports/                                                                                  \n  │   └── figures/         # For generated visualizations                                       \n  └── tests/               # For unit tests                                                     \n\n  All changes have been committed to git. You can start working by:                             \n  1. Creating a virtual environment: python -m venv venv                                        \n  2. Activating it: source venv/bin/activate                                                    \n  3. Installing dependencies: pip install -r requirements.txt                                   \n\n✻ Baked for 1m 32s   \n</code></pre> <p>What You Just Experienced</p> <p>In this conversation, Claude:</p> <p>✓ Created a complete project structure from a simple request</p> <p>✓ Wrote actual code (Python project with folders)</p> <p>✓ Set up environment (virtual environment and dependencies)</p> <p>✓ Committed changes with a well-formatted message</p> <p>✓ Pushed to GitHub to save your work</p> <p>All through natural conversation—no manual commands needed!</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#5-initialization-two-paths","level":2,"title":"5. Initialization: Two Paths","text":"<p>When starting with Claude Code, you'll take one of two paths depending on whether you're working with existing code or starting fresh.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#51-path-a-existing-codebase","level":3,"title":"5.1 Path A: Existing Codebase","text":"<p>Use this approach when you have an established project with existing code.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#when-to-use-this-path","level":4,"title":"When to Use This Path","text":"<ul> <li>Joining an existing project</li> <li>Working with legacy code</li> <li>Analyzing unfamiliar codebases</li> <li>Adding features to established apps</li> <li>Debugging existing implementations</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#running-init-command","level":4,"title":"Running <code>/init</code> Command","text":"<p>The <code>/init</code> command tells Claude to comprehensively analyze your codebase:</p> <pre><code>You: /init\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#what-claude-analyzes","level":4,"title":"What Claude Analyzes","text":"<p>When you run <code>/init</code>, Claude Code:</p> <ol> <li>Traverses Directory Structure</li> <li>Maps out folders and files</li> <li>Identifies important directories (<code>src/</code>, <code>tests/</code>, <code>docs/</code>, etc.)</li> <li> <p>Notes configuration files</p> </li> <li> <p>Identifies Technologies</p> </li> <li>Programming languages used</li> <li>Frameworks and libraries (from package files)</li> <li>Build tools and task runners</li> <li> <p>Testing frameworks</p> </li> <li> <p>Analyzes Code Patterns</p> </li> <li>Architecture and design patterns</li> <li>Code organization conventions</li> <li>Naming conventions</li> <li> <p>Common patterns and idioms</p> </li> <li> <p>Reads Key Files</p> </li> <li>README and documentation</li> <li>Package manifests (<code>package.json</code>, <code>requirements.txt</code>, <code>Cargo.toml</code>, etc.)</li> <li>Configuration files (<code>.env.example</code>, config files)</li> <li> <p>Entry points (<code>main.py</code>, <code>index.js</code>, <code>app.py</code>, etc.)</p> </li> <li> <p>Understands Dependencies</p> </li> <li>External libraries and versions</li> <li>Internal module relationships</li> <li>Import/export patterns</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#example-output","level":4,"title":"Example Output","text":"<p>Here's what Claude might report after analyzing a Python web application:</p> <pre><code>⏺ I'll analyze the codebase and create a CLAUDE.md file with relevant guidance for future       \n  instances.                                                                                    \n\n⏺ Bash(find . -type f -name \"*.py\" -o -name \"*.ipynb\" -o -name \"*.md\" -o -name \"*.txt\" -o -name \n      \"*.yml\" -o -name \"*.yaml\" -o -name \"*.json\" | grep -v \".git\" | head -20)                  \n  ⎿  ./requirements.txt                                                                         \n     ./README.md                                                                                \n     ./src/visualization/__init__.py                                                            \n     … +4 lines (ctrl+o to expand)                                                              \n\n⏺ Bash(ls -la)                                                                                  \n  ⎿  total 24                                                                                   \n     drwxr-xr-x@  12 tswetnam  staff   384 Jan 16 15:45 .                                       \n     drwxr-xr-x+ 199 tswetnam  staff  6368 Jan 16 15:55 ..                                      \n     … +10 lines (ctrl+o to expand)                                                             \n\n⏺ Read(README.md)                                                                               \n  ⎿  Read 81 lines                                                                              \n\n⏺ Read(requirements.txt)                                                                        \n  ⎿  Read 35 lines                                                                              \n\n⏺ Bash(test -f .cursorrules &amp;&amp; cat .cursorrules || test -d .cursor/rules &amp;&amp; ls -la .cursor/rules\n       || echo \"No cursor rules found\")                                                         \n  ⎿  No cursor rules found                                                                      \n\n⏺ Bash(test -f .github/copilot-instructions.md &amp;&amp; cat .github/copilot-instructions.md || echo   \n      \"No copilot instructions found\")                                                          \n  ⎿  No copilot instructions found                                                              \n\n⏺ Now I'll create the CLAUDE.md file with relevant guidance for this Python data science        \n  project.                                                                                      \n\n⏺ Write(CLAUDE.md)                                                                              \n  ⎿  Wrote 103 lines to CLAUDE.md                                                               \n      1 # CLAUDE.md                                                                             \n      2 This file provides guidance to Claude Code (claude.ai/code) when working with cod       \n        e in this repository.                                                                   \n      3 ## Project Overview                                                                     \n      4 This is a Python data science project for a review paper, following a standard da       \n        ta science project structure with separation between raw data, processed data, so       \n        urce code, notebooks, and outputs.                                                      \n      5 ## Environment Setup                                                                    \n     … +93 lines (ctrl+o to expand)                                                             \n\n⏺ I've created a CLAUDE.md file for this repository. The file includes:                         \n\n  1. Environment setup commands - How to create a virtual environment and install dependencies  \n  2. Testing commands - How to run all tests, tests with coverage, single test files, and       \n  specific tests                                                                                \n  3. Code quality commands - How to use Black for formatting and flake8 for linting             \n  4. Architecture overview - The Cookiecutter Data Science structure pattern with explanations  \n  of each directory's purpose                                                                   \n  5. Data flow pattern - The intended workflow from raw data through processing to final outputs\n  6. Key dependencies - Categorized list of main libraries used                                 \n\n  The file focuses on the practical commands needed for development and the high-level          \n  architectural patterns that aren't immediately obvious from the directory structure alone.    \n  Future instances of Claude Code will be able to use this to understand how to work effectively\n   in this codebase.                                                                            \n\n✻ Baked for 55s     \n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#best-practices-for-large-projects","level":4,"title":"Best Practices for Large Projects","text":"<p>When working with large codebases:</p> <p>1. Start with High-Level Overview</p> <pre><code>You: /init --summary\n</code></pre> <p>Get a high-level summary before diving deep.</p> <p>2. Focus on Specific Areas</p> <pre><code>You: Can you analyze just the authentication system in src/auth/?\n</code></pre> <p>Narrow the scope to avoid overwhelming context.</p> <p>3. Ask About Specific Patterns</p> <pre><code>You: How is error handling implemented across the codebase?\n</code></pre> <p>Target specific architectural questions.</p> <p>4. Request Diagrams</p> <pre><code>You: Can you create a diagram showing how the main modules interact?\n</code></pre> <p>Visual representations help with complex systems.</p> <p>5. Incremental Exploration</p> <p>Don't try to understand everything at once. Start with:</p> <ul> <li>Entry points and main flows</li> <li>Core business logic</li> <li>Critical paths</li> <li>Then expand to utilities and helpers</li> </ul> Context Window Limits <p>Claude has a large context window (200K tokens ≈ 150,000 words), but extremely large codebases might exceed this. If you encounter limits:</p> <ul> <li>Focus on specific directories</li> <li>Use <code>.claudeignore</code> to exclude generated files, dependencies</li> <li>Ask Claude to analyze subsystems separately</li> <li>Provide context incrementally as needed</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#52-path-b-starting-from-scratch","level":3,"title":"5.2 Path B: Starting from Scratch","text":"<p>Use this approach when creating a new project from an empty or minimal repository.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#when-to-use-this-path_1","level":4,"title":"When to Use This Path","text":"<ul> <li>Starting a new project</li> <li>Building a proof of concept</li> <li>Learning a new framework</li> <li>Creating a tool or utility</li> <li>Prototyping an idea</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#planning-session-workflow","level":4,"title":"Planning Session Workflow","text":"<p>Instead of <code>/init</code>, start a planning conversation:</p> <pre><code>You: I want to create a new Python CLI tool that helps developers manage their dotfiles. Can you help me plan the structure?\n</code></pre> <p>Claude will engage in a conversation to understand:</p> <ol> <li> <p>Project Requirements</p> </li> <li> <p>What problem are you solving?</p> </li> <li>Who are the users?</li> <li> <p>What features are essential?</p> </li> <li> <p>Technical Decisions</p> </li> <li> <p>Programming language and version</p> </li> <li>Frameworks or libraries</li> <li>Architecture approach</li> <li> <p>Testing strategy</p> </li> <li> <p>Project Structure</p> </li> <li> <p>Directory organization</p> </li> <li>File naming conventions</li> <li>Module breakdown</li> <li>Configuration approach</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#example-planning-conversation","level":4,"title":"Example Planning Conversation","text":"<p>You:</p> <pre><code>I want to create a task management CLI app in Python that stores tasks in a local SQLite database. It should support adding, listing, completing, and deleting tasks.\n</code></pre> <p>Claude:</p> <pre><code>Great! Let's plan this project. Here's what I'm thinking:\n\n**Project Structure:**\n\ntask-manager/\n├── .gitignore\n├── README.md\n├── LICENSE\n├── requirements.txt\n├── setup.py\n├── src/\n│   ├── __init__.py\n│   ├── cli.py          # CLI interface (Click or argparse)\n│   ├── database.py     # SQLite operations\n│   ├── models.py       # Task data model\n│   └── commands/\n│       ├── __init__.py\n│       ├── add.py\n│       ├── list.py\n│       ├── complete.py\n│       └── delete.py\n└── tests/\n    ├── __init__.py\n    ├── test_database.py\n    ├── test_commands.py\n    └── fixtures/\n</code></pre> <p>Technology Stack:</p> <ul> <li>Python 3.9+</li> <li>Click for CLI framework (better than argparse for this use case)</li> <li>SQLite3 (built-in)</li> <li>pytest for testing</li> <li>Rich for beautiful terminal output (optional but nice)</li> </ul> <p>Features:</p> <ol> <li><code>task add \"Task description\"</code> - Add new task</li> <li><code>task list [--all|--completed|--pending]</code> - List tasks</li> <li><code>task complete &lt;id&gt;</code> - Mark task as done</li> <li><code>task delete &lt;id&gt;</code> - Delete task</li> <li><code>task init</code> - Initialize database</li> </ol> <p>Should I proceed with creating these files? Any changes you'd like? <pre><code>**You:**\n</code></pre> Yes, looks good! Let's also add a priority field to tasks. And use Rich for better output. <pre><code>**Claude:**\n</code></pre> Perfect! I'll update the plan to include: - Priority field (LOW, MEDIUM, HIGH) - Rich library for colored, formatted output - Priority sorting in list command</p> <p>Ready to create the project structure? <pre><code>#### Essential Files\n\nClaude will help you create these foundational files:\n\n**1. README.md**\n\nExplains what the project does, how to install, and how to use it:\n\n```bash\nYou: Create a comprehensive README.md\n</code></pre></p> <p>Claude generates: <pre><code># Task Manager CLI\n\nA simple, elegant command-line task manager built with Python.\n\n## Features\n\n- Add tasks with priorities\n- List tasks with filtering\n- Mark tasks complete\n- Beautiful terminal output\n\n## Installation\n\n```bash\npip install -e .\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#usage","level":2,"title":"Usage","text":"<pre><code># Add a task\ntask add \"Write documentation\" --priority high\n\n# List all tasks\ntask list\n\n# Complete a task\ntask complete 1\n\n# Delete a task\ntask delete 2\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#development","level":2,"title":"Development","text":"<pre><code># Install dependencies\npip install -r requirements.txt\n\n# Run tests\npytest\n</code></pre> <p>2. LICENSE</p> <pre><code>You: Add an MIT license\n</code></pre> <p>Claude creates <code>LICENSE</code> with proper MIT license text and your name/year.</p> <p>3. .gitignore</p> <pre><code>You: Create a Python .gitignore\n</code></pre> <p>Claude generates <code>.gitignore</code> with common Python exclusions:</p> <pre><code># Python\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n.Python\nenv/\nvenv/\nENV/\n*.egg-info/\ndist/\nbuild/\n\n# Database\n*.db\n*.sqlite\n*.sqlite3\n\n# IDE\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# Testing\n.pytest_cache/\n.coverage\nhtmlcov/\n\n# OS\n.DS_Store\nThumbs.db\n</code></pre> <p>4. requirements.txt</p> <pre><code>You: Create requirements.txt with our dependencies\n</code></pre> <pre><code>click&gt;=8.1.0\nrich&gt;=13.0.0\npytest&gt;=7.4.0\npytest-cov&gt;=4.1.0\n</code></pre> <p>5. CONTRIBUTING.md (Optional)</p> <p>For open-source projects:</p> <pre><code>You: Add a CONTRIBUTING.md guide\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#setting-up-for-different-languages","level":4,"title":"Setting Up for Different Languages","text":"<p>Claude can help you structure projects in any language:</p> <p>Python: <pre><code>You: Create a Python package structure with setuptools\n</code></pre></p> <p>JavaScript/Node: <pre><code>You: Create a Node.js project with Express and TypeScript\n</code></pre></p> <p>Rust: <pre><code>You: Initialize a Rust project with Cargo\n</code></pre></p> <p>Go: <pre><code>You: Create a Go module with a standard project layout\n</code></pre></p> <p>Claude will generate appropriate: - Directory structures - Configuration files (<code>Cargo.toml</code>, <code>package.json</code>, <code>go.mod</code>, etc.) - Build scripts - Testing setup - CI/CD templates</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#integration-with-mcp","level":4,"title":"Integration with MCP","text":"<p>For advanced projects, integrate Model Context Protocol (MCP) servers:</p> <pre><code>You: Set up MCP to connect to my PostgreSQL database\n</code></pre> <p>Claude will: 1. Create <code>.claude/mcp.json</code> configuration 2. Set up database connection settings 3. Create example queries 4. Configure environment variables</p> <p>Example MCP configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"postgres\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-postgres\"],\n      \"env\": {\n        \"POSTGRES_CONNECTION_STRING\": \"postgresql://localhost/mydb\"\n      }\n    }\n  }\n}\n</code></pre> <p>See our MCP Documentation for comprehensive setup guides.</p> <p>Start Simple, Iterate</p> <p>Don't try to plan every detail upfront. Start with a basic structure and let it evolve as you build. Claude can help refactor and reorganize as the project grows.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#6-working-with-custom-agents","level":2,"title":"6. Working with Custom Agents","text":"<p>One of Claude Code's most powerful features is the ability to create specialized agents for repeated tasks.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#61-what-are-agents","level":3,"title":"6.1 What are Agents?","text":"<p>In Claude Code, an agent is a specialized AI assistant configured for specific tasks with custom instructions, knowledge, and behaviors.</p> <p>How Agents Differ from Regular Prompts:</p> Aspect Regular Conversation Custom Agent Instructions General Claude behavior Specialized, task-specific instructions Context Current conversation Pre-loaded domain knowledge Consistency Varies by prompt Consistent behavior across uses Reusability Manual copy-paste Invoked by name or command Specialization General assistance Expert in specific domain <p>Benefits of Specialized Agents:</p> <ol> <li>Consistency: Same approach every time</li> <li>Efficiency: No need to repeat instructions</li> <li>Quality: Optimized prompts and workflows</li> <li>Team Alignment: Shared standards across team</li> <li>Expertise: Deep knowledge in specific areas</li> </ol> <p>For deeper understanding of agentic AI concepts, see Agentic AI.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#62-built-in-specialized-agents","level":3,"title":"6.2 Built-in Specialized Agents","text":"<p>Claude Code includes several built-in specialized agents that handle common development tasks. These agents are always available and can be invoked using the Task tool or through natural conversation.</p> <p>Available Built-in Agents:</p> Agent Purpose When to Use Key Capabilities Explore Codebase exploration specialist Finding files, searching code, understanding project structure Fast pattern matching, keyword search, architectural analysis. Supports thoroughness levels: \"quick\", \"medium\", \"very thorough\" Plan Software architecture and planning Designing implementation strategies before coding Creates step-by-step plans, identifies critical files, considers architectural trade-offs Bash Command execution specialist Git operations, terminal tasks, system commands Specialized for bash command execution and terminal operations general-purpose Multi-step task automation Complex research, iterative searching, multi-step workflows Access to all tools, autonomous task handling, ideal when multiple search attempts needed claude-code-guide Claude documentation expert Questions about Claude Code, API, or Agent SDK Specialized knowledge of Claude features, tools, commands, and best practices webcrawler Web content extraction Documentation research, gathering information from websites Web fetching, search, content extraction and analysis statusline-setup Configuration assistant Setting up Claude Code status line Reads and edits status line configuration <p>How to Invoke Built-in Agents:</p> <p>Built-in agents are automatically invoked by Claude when appropriate for your task, but you can also request them explicitly:</p> <pre><code># Examples of natural requests that invoke specific agents:\n\"Explore the authentication system in this codebase\"  # → Explore agent\n\"Plan out how to implement dark mode\"                 # → Plan agent\n\"How do I configure Claude Code hooks?\"               # → claude-code-guide agent\n\"Search for information about Zensical features\"      # → webcrawler agent\n</code></pre> <p>Thoroughness Levels for Explore Agent:</p> <p>When using the Explore agent, you can specify how thorough the search should be:</p> <ul> <li>\"quick\": Basic searches, fastest response</li> <li>\"medium\": Moderate exploration, balanced approach</li> <li>\"very thorough\": Comprehensive analysis across multiple locations and naming conventions</li> </ul> <p>Choosing the Right Agent</p> <p>Claude automatically selects the most appropriate built-in agent for your task. For codebase exploration, the Explore agent is much faster than running search commands directly. For implementation planning, the Plan agent helps you design before you code.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#63-creating-a-documentation-writer-agent","level":3,"title":"6.3 Creating a Documentation Writer Agent","text":"<p>Let's create a practical example: a documentation writer agent that maintains your project's documentation.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#conceptual-explanation","level":4,"title":"Conceptual Explanation","text":"<p>A documentation agent should:</p> <ul> <li>Understand your documentation style and standards</li> <li>Know what type of documentation you need (API docs, tutorials, README updates)</li> <li>Follow consistent formatting and tone</li> <li>Keep documentation in sync with code changes</li> <li>Generate examples and usage instructions</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#step-by-step-creation-using-agents","level":4,"title":"Step-by-Step Creation Using <code>/agents</code>","text":"<p>Claude Code provides the <code>/agents</code> slash command to create custom agents interactively. This is the recommended approach as it guides you through the process and generates the configuration file automatically.</p> <p>Step 1: Run the <code>/agents</code> Command</p> <p>In Claude Code chat:</p> <pre><code>/agents\n</code></pre> <p>This launches the agent creation wizard that will:</p> <ol> <li>Ask you to describe the agent's purpose and responsibilities</li> <li>Help you define the agent's instructions and behavior</li> <li>Set up any domain-specific knowledge</li> <li>Create the agent configuration file in <code>.claude/agents/</code></li> <li>Automatically register the agent for use</li> </ol> <p>Step 2: Describe Your Agent</p> <p>When prompted, provide a clear description. For a documentation writer agent:</p> <pre><code>I need a documentation writer agent that:\n- Writes clear, concise technical documentation\n- Follows Markdown formatting standards\n- Includes code examples for all features\n- Creates API docs, README updates, and tutorials\n- Uses active voice and present tense\n- Keeps documentation in sync with code changes\n</code></pre> <p>Step 3: Refine Agent Instructions</p> <p>The wizard will generate initial instructions and allow you to refine them. You can specify:</p> <ul> <li>Documentation standards: Formatting, style, structure</li> <li>Style guide: Voice, tense, sentence length</li> <li>Documentation types: README, API docs, changelogs, etc.</li> <li>Code style preferences: Language-specific conventions</li> <li>Domain knowledge: Project-specific information</li> </ul> <p>The wizard creates a configuration file like <code>.claude/agents/docs-writer.yaml</code> with content similar to:</p> <pre><code>name: Documentation Writer\ndescription: Technical documentation specialist for this project\nversion: 1.0.0\n\ninstructions: |\n  You are a technical documentation expert specializing in clear, concise, and\n  comprehensive documentation for software projects.\n\n  DOCUMENTATION STANDARDS:\n  - Write in clear, active voice\n  - Use consistent formatting (Markdown)\n  - Include code examples for all features\n  - Provide usage examples with realistic scenarios\n  - Keep README.md up-to-date with project changes\n  - Document all public APIs, functions, and classes\n\n  STYLE GUIDE:\n  - Use second person (\"you\") for instructions\n  - Use present tense for descriptions\n  - Keep sentences concise (&lt; 20 words)\n  - Use bullet points for lists\n  - Include code blocks with syntax highlighting\n\n# Additional configuration generated by the wizard...\n</code></pre> <p>Manual Creation Alternative</p> <p>While <code>/agents</code> is recommended, you can also manually create agent files in <code>.claude/agents/</code> if you prefer full control. See the Claude Code documentation for the complete YAML schema.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#how-to-invoke-the-agent","level":4,"title":"How to Invoke the Agent","text":"<p>CLI:</p> <pre><code>You: @docs-writer Please document the new authentication module in src/auth.py\n</code></pre> <p>VS Code:</p> <p>In chat panel: <pre><code>@docs-writer Please document the new authentication module in src/auth.py\n</code></pre></p> <p>Or via command palette: <pre><code>Cmd/Ctrl + Shift + P → \"Claude Code: Use Agent\" → Select \"Documentation Writer\"\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#example-interaction","level":4,"title":"Example Interaction","text":"<p>You: <pre><code>@docs-writer I just added a new function called calculate_fibonacci(n) in src/math_utils.py.\nPlease add a comprehensive docstring.\n</code></pre></p> <p>Documentation Writer Agent: <pre><code>def calculate_fibonacci(n: int) -&gt; int:\n    \"\"\"\n    Calculate the nth Fibonacci number using iterative approach.\n\n    The Fibonacci sequence is defined as:\n    F(0) = 0, F(1) = 1\n    F(n) = F(n-1) + F(n-2) for n &gt; 1\n\n    Args:\n        n (int): The position in the Fibonacci sequence (0-indexed).\n                 Must be a non-negative integer.\n\n    Returns:\n        int: The Fibonacci number at position n.\n\n    Raises:\n        ValueError: If n is negative.\n\n    Examples:\n        &gt;&gt;&gt; calculate_fibonacci(0)\n        0\n        &gt;&gt;&gt; calculate_fibonacci(1)\n        1\n        &gt;&gt;&gt; calculate_fibonacci(10)\n        55\n        &gt;&gt;&gt; calculate_fibonacci(20)\n        6765\n\n    Time Complexity:\n        O(n) - Linear time complexity\n\n    Space Complexity:\n        O(1) - Constant space complexity\n\n    Note:\n        For very large values of n (&gt; 1000), consider using\n        memoization or matrix exponentiation for better performance.\n    \"\"\"\n    if n &lt; 0:\n        raise ValueError(\"n must be non-negative\")\n\n    if n &lt;= 1:\n        return n\n\n    prev, curr = 0, 1\n    for _ in range(2, n + 1):\n        prev, curr = curr, prev + curr\n\n    return curr\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#when-to-use-documentation-agent","level":4,"title":"When to Use Documentation Agent","text":"<p>Invoke the documentation agent when:</p> <ul> <li>Adding new features or functions</li> <li>Refactoring existing code</li> <li>Creating release notes</li> <li>Writing tutorials or guides</li> <li>Updating API documentation</li> <li>Generating changelogs</li> <li>Writing contribution guidelines</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#64-other-useful-agent-ideas","level":3,"title":"6.4 Other Useful Agent Ideas","text":"<p>Here are other specialized agents you might create (conceptual descriptions):</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#testing-agent","level":4,"title":"Testing Agent","text":"<p>Purpose: Generate comprehensive test suites</p> <p>Key Instructions: - Write tests for all public functions - Include edge cases and error conditions - Use appropriate testing framework (pytest, Jest, etc.) - Aim for 80%+ code coverage - Write descriptive test names - Use fixtures and mocks appropriately</p> <p>Invocation: <code>@test-writer Generate tests for the UserService class</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#code-review-agent","level":4,"title":"Code Review Agent","text":"<p>Purpose: Provide thorough code reviews with constructive feedback</p> <p>Key Instructions: - Check for bugs and edge cases - Identify performance issues - Suggest best practices - Point out security vulnerabilities - Review naming and code style - Suggest refactoring opportunities - Be constructive and specific</p> <p>Invocation: <code>@code-reviewer Please review the changes in src/api/users.py</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#refactoring-agent","level":4,"title":"Refactoring Agent","text":"<p>Purpose: Improve code structure without changing behavior</p> <p>Key Instructions: - Extract functions for repeated code - Simplify complex conditionals - Apply SOLID principles - Improve naming and clarity - Reduce coupling and increase cohesion - Preserve existing tests and behavior - Make incremental, testable changes</p> <p>Invocation: <code>@refactor-agent Improve the structure of the DataProcessor class</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#security-auditor-agent","level":4,"title":"Security Auditor Agent","text":"<p>Purpose: Identify security vulnerabilities</p> <p>Key Instructions: - Check for SQL injection vulnerabilities - Identify XSS and CSRF risks - Review authentication and authorization - Check for insecure dependencies - Verify proper input validation - Review secrets management - Check for information disclosure</p> <p>Invocation: <code>@security-auditor Audit the login endpoint for vulnerabilities</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#performance-optimizer-agent","level":4,"title":"Performance Optimizer Agent","text":"<p>Purpose: Identify and fix performance bottlenecks</p> <p>Key Instructions: - Profile code for bottlenecks - Suggest algorithmic improvements - Identify unnecessary computations - Recommend caching strategies - Optimize database queries - Reduce memory allocations - Improve concurrency</p> <p>Invocation: <code>@performance-optimizer Analyze the data processing pipeline</code></p> <p>Creating Your Own Agents</p> <p>Think about tasks you repeat frequently and create specialized agents for them. The more specific the instructions, the better the results!</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#7-custom-slash-commands","level":2,"title":"7. Custom Slash Commands","text":"<p>Slash commands provide shortcuts for common workflows, turning multi-step processes into single commands.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#71-understanding-slash-commands","level":3,"title":"7.1 Understanding Slash Commands","text":"<p>What are Slash Commands?</p> <p>Slash commands are custom shortcuts that trigger predefined workflows in Claude Code. They're like macros or aliases that encapsulate common development tasks.</p> <p>Why They're Useful:</p> <ul> <li>Efficiency: Execute complex workflows with one command</li> <li>Consistency: Same process every time</li> <li>Team Alignment: Share common workflows across team</li> <li>Automation: Reduce manual, repetitive tasks</li> <li>Error Reduction: Less chance of forgetting steps</li> </ul> <p>Built-in Commands:</p> <p>Claude Code includes several built-in commands:</p> Command Purpose <code>/init</code> Analyze codebase structure <code>/help</code> Show available commands <code>/clear</code> Clear conversation history <code>/context</code> Show current context size <code>/files</code> List files in current context <code>/model</code> Change AI model <code>/save</code> Save conversation to file","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#72-example-creating-commit-command","level":3,"title":"7.2 Example: Creating <code>/commit</code> Command","text":"<p>Let's create a powerful <code>/commit</code> command that automates the git commit workflow.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#purpose-and-workflow","level":4,"title":"Purpose and Workflow","text":"<p>The <code>/commit</code> command should:</p> <ol> <li>Show <code>git status</code> to review changes</li> <li>Stage all changes (or prompt for selective staging)</li> <li>Generate a descriptive commit message based on changes</li> <li>Create the commit</li> <li>Optionally push to remote</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#configuration-syntax","level":4,"title":"Configuration Syntax","text":"<p>Create <code>.claude/commands/commit.yaml</code>:</p> <pre><code>name: commit\ndescription: Intelligent git commit with AI-generated message\nversion: 1.0.0\n\n# Command behavior\nworkflow:\n  - name: check_git_status\n    action: run_command\n    command: \"git status --short\"\n    description: \"Show current changes\"\n\n  - name: confirm_changes\n    action: prompt_user\n    message: \"Proceed with committing these changes?\"\n    options:\n      - value: \"all\"\n        label: \"Commit all changes\"\n      - value: \"selective\"\n        label: \"Let me choose files\"\n      - value: \"cancel\"\n        label: \"Cancel\"\n\n  - name: stage_changes\n    action: conditional\n    condition: \"confirm_changes != 'cancel'\"\n    then:\n      - action: run_command\n        command: \"git add -A\"\n        when: \"confirm_changes == 'all'\"\n      - action: prompt_for_files\n        when: \"confirm_changes == 'selective'\"\n\n  - name: analyze_diff\n    action: run_command\n    command: \"git diff --cached\"\n    store_output: \"diff_content\"\n\n  - name: generate_message\n    action: ai_task\n    prompt: |\n      Based on this git diff, generate a commit message following conventional commits format:\n\n      &lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n      &lt;body&gt;\n\n      &lt;footer&gt;\n\n      Types: feat, fix, docs, style, refactor, test, chore\n\n      Git diff:\n      ```\n      {{diff_content}}\n      ```\n\n      Generate a clear, concise commit message that explains what changed and why.\n    store_output: \"commit_message\"\n\n  - name: show_message\n    action: display\n    content: |\n      Proposed commit message:\n\n      {{commit_message}}\n\n      Approve this message?\n\n  - name: confirm_message\n    action: prompt_user\n    message: \"Use this commit message?\"\n    options:\n      - value: \"yes\"\n        label: \"Yes, commit with this message\"\n      - value: \"edit\"\n        label: \"Let me edit it\"\n      - value: \"cancel\"\n        label: \"Cancel\"\n\n  - name: edit_message\n    action: conditional\n    condition: \"confirm_message == 'edit'\"\n    then:\n      - action: prompt_for_text\n        multiline: true\n        default: \"{{commit_message}}\"\n        store_output: \"commit_message\"\n\n  - name: create_commit\n    action: conditional\n    condition: \"confirm_message != 'cancel'\"\n    then:\n      - action: run_command\n        command: \"git commit -m '{{commit_message}}'\"\n\n  - name: ask_push\n    action: prompt_user\n    message: \"Push to remote?\"\n    options:\n      - value: \"yes\"\n        label: \"Yes, push now\"\n      - value: \"no\"\n        label: \"No, I'll push later\"\n\n  - name: push_changes\n    action: conditional\n    condition: \"ask_push == 'yes'\"\n    then:\n      - action: run_command\n        command: \"git push\"\n\n# Safety settings\nsafety:\n  confirm_before_execute: true\n  allow_destructive_ops: false\n\n# Permissions needed\npermissions:\n  - git\n  - filesystem.read\n  - filesystem.write\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#simpler-version","level":4,"title":"Simpler Version","text":"<p>If the full workflow is too complex, here's a simpler version:</p> <p><code>.claude/commands/commit-simple.yaml</code>:</p> <pre><code>name: commit\ndescription: Quick commit with AI-generated message\n\nworkflow:\n  - action: run_command\n    command: \"git add -A\"\n\n  - action: ai_task\n    prompt: \"Analyze the git diff and generate a conventional commit message\"\n    command: \"git diff --cached\"\n\n  - action: git_commit\n    message: \"{{ai_output}}\"\n\npermissions:\n  - git\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#usage-demonstration","level":4,"title":"Usage Demonstration","text":"<p>Basic Usage:</p> <pre><code>You: /commit\n</code></pre> <p>With Options:</p> <pre><code>You: /commit --no-push\nYou: /commit --message \"fix: resolve login bug\"\nYou: /commit --amend\n</code></pre> <p>Example Flow:</p> <pre><code>You: /commit\n\nClaude Code: Analyzing changes...\n\nModified files:\n  M src/auth.py\n  M tests/test_auth.py\n  A docs/authentication.md\n\nProposed commit message:\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nfeat(auth): add support for OAuth 2.0 authentication\n\n- Implement OAuth2 authentication flow\n- Add token validation and refresh logic\n- Update authentication tests for new flow\n- Add documentation for OAuth setup\n\nCloses #42\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nUse this commit message? [Yes/Edit/Cancel]: Yes\n\nCreating commit... Done!\nPush to remote? [Yes/No]: Yes\nPushing to origin/main... Done!\n\n✓ Committed and pushed successfully!\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#73-other-slash-command-ideas","level":3,"title":"7.3 Other Slash Command Ideas","text":"<p>Here are more useful custom commands (conceptual descriptions):</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#test-run-test-suite","level":4,"title":"<code>/test</code> - Run Test Suite","text":"<pre><code>name: test\ndescription: Run tests with coverage and report results\n\nworkflow:\n  - Run pytest with coverage\n  - Generate coverage report\n  - Show failed tests with context\n  - Suggest fixes for failures\n</code></pre> <p>Usage: <code>/test</code> or <code>/test --file tests/test_api.py</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#review-code-review-workflow","level":4,"title":"<code>/review</code> - Code Review Workflow","text":"<pre><code>name: review\ndescription: Request code review before merging\n\nworkflow:\n  - Show uncommitted changes\n  - Run linters and formatters\n  - Check for common issues\n  - Generate review checklist\n  - Create pull request (optional)\n</code></pre> <p>Usage: <code>/review</code> or <code>/review --create-pr</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#deploy-deployment-workflow","level":4,"title":"<code>/deploy</code> - Deployment Workflow","text":"<pre><code>name: deploy\ndescription: Deploy to specified environment\n\nworkflow:\n  - Verify tests pass\n  - Check environment variables\n  - Build application\n  - Run deployment script\n  - Verify deployment\n  - Tag release\n</code></pre> <p>Usage: <code>/deploy production</code> or <code>/deploy staging --skip-tests</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#docs-documentation-generation","level":4,"title":"<code>/docs</code> - Documentation Generation","text":"<pre><code>name: docs\ndescription: Generate or update documentation\n\nworkflow:\n  - Scan for undocumented functions\n  - Generate missing docstrings\n  - Update README if needed\n  - Build documentation site\n  - Show coverage report\n</code></pre> <p>Usage: <code>/docs</code> or <code>/docs --module auth</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#refactor-smart-refactoring","level":4,"title":"<code>/refactor</code> - Smart Refactoring","text":"<pre><code>name: refactor\ndescription: Refactor code with specific pattern\n\nworkflow:\n  - Analyze current structure\n  - Suggest refactoring approach\n  - Apply changes incrementally\n  - Run tests after each change\n  - Create commit if successful\n</code></pre> <p>Usage: <code>/refactor extract-method</code> or <code>/refactor simplify-conditionals</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#fix-automated-bug-fixing","level":4,"title":"<code>/fix</code> - Automated Bug Fixing","text":"<pre><code>name: fix\ndescription: Analyze and fix errors\n\nworkflow:\n  - Run application/tests\n  - Capture error messages\n  - Analyze stack traces\n  - Suggest fixes\n  - Apply fix with approval\n  - Verify fix works\n</code></pre> <p>Usage: <code>/fix</code> or <code>/fix --error \"IndexError on line 42\"</code></p> <p>Command Best Practices</p> <ul> <li>Keep commands focused on single workflows</li> <li>Always include confirmation steps for destructive operations</li> <li>Provide clear output at each step</li> <li>Allow customization through parameters</li> <li>Include safety checks and validation</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#8-development-workflow-best-practices","level":2,"title":"8. Development Workflow Best Practices","text":"<p>Now that you understand the tools, let's explore effective workflows for daily development with Claude Code.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#81-typical-development-session","level":3,"title":"8.1 Typical Development Session","text":"<p>Here's how a productive Claude Code session typically flows:</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#starting-your-work","level":4,"title":"Starting Your Work","text":"<p>1. Navigate to Project:</p> <pre><code>cd /path/to/your-project\n</code></pre> <p>2. Start Claude Code:</p> <pre><code># CLI\nclaude\n\n# VS Code\ncode . # Opens VS Code, then open Claude panel\n</code></pre> <p>3. Review Context:</p> <pre><code>You: What was I working on last time?\n</code></pre> <p>Claude can reference conversation history (if saved) or analyze recent git commits.</p> <p>4. Set Today's Goal:</p> <pre><code>You: Today I need to implement user authentication. Let's start by planning the approach.\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#iterative-development-flow","level":4,"title":"Iterative Development Flow","text":"<p>Development Loop:</p> <pre><code>flowchart TD\n    A[Describe Feature/Fix] --&gt; B[Claude Generates Code]\n    B --&gt; C[Review &amp; Discuss]\n    C --&gt; D{Satisfactory?}\n    D --&gt;|No| E[Request Changes]\n    E --&gt; B\n    D --&gt;|Yes| F[Apply Changes]\n    F --&gt; G[Run Tests]\n    G --&gt; H{Tests Pass?}\n    H --&gt;|No| I[Debug with Claude]\n    I --&gt; B\n    H --&gt;|Yes| J[Commit Changes]\n    J --&gt; K{More Work?}\n    K --&gt;|Yes| A\n    K --&gt;|No| L[End Session]\n\n    style F fill:#c8e6c9\n    style J fill:#c8e6c9\n    style L fill:#e1f5ff</code></pre> <p>Example Development Flow:</p> <pre><code># Step 1: Plan the feature\nYou: I need to add a password reset feature. What's the best approach?\n\nClaude: [Suggests approach with email tokens, expiration, security considerations]\n\n# Step 2: Implement backend\nYou: Let's start with the backend. Create the password reset endpoint.\n\nClaude: [Generates Flask/Express/etc. endpoint code]\n\n# Step 3: Review and refine\nYou: Looks good, but let's add rate limiting to prevent abuse.\n\nClaude: [Updates code with rate limiting]\n\n# Step 4: Write tests\nYou: @test-writer Create tests for the password reset endpoint\n\nTest Agent: [Generates comprehensive test suite]\n\n# Step 5: Run tests\nYou: /test\n\nClaude: [Runs tests, reports results]\n\n# Step 6: Update documentation\nYou: @docs-writer Document the new password reset flow\n\nDocs Agent: [Updates API documentation and README]\n\n# Step 7: Commit\nYou: /commit\n\nClaude: [Creates commit with descriptive message]\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#managing-context","level":4,"title":"Managing Context","text":"<p>Keep Context Relevant:</p> <pre><code># Clear context if conversation gets too long\nYou: /clear\n\n# Focus on specific files\nYou: Let's focus on just src/auth.py and tests/test_auth.py\n\n# Remove files from context\nYou: You can forget about the migration files, we don't need those\n</code></pre> <p>Loading Additional Context:</p> <pre><code># Add files to context\nYou: Can you also look at config/auth_config.py?\n\n# Load related code\nYou: Show me other places where we handle authentication\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#conversation-organization","level":4,"title":"Conversation Organization","text":"<p>Use Clear, Specific Requests:</p> <p>✅ Good: <pre><code>Refactor the authenticate_user function in src/auth.py to use the Strategy pattern,\nmaking it easier to add new authentication methods.\n</code></pre></p> <p>❌ Unclear: <pre><code>Make auth better\n</code></pre></p> <p>Break Down Complex Tasks:</p> <p>Instead of: <pre><code>Build a complete user authentication system\n</code></pre></p> <p>Do: <pre><code>1. Let's start with the database models for User and Session\n2. Next, create the login endpoint\n3. Then, implement JWT token generation\n[etc.]\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#82-git-integration-patterns","level":3,"title":"8.2 Git Integration Patterns","text":"<p>Claude Code can be a powerful Git assistant.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#commit-message-generation","level":4,"title":"Commit Message Generation","text":"<p>Let Claude analyze your changes:</p> <pre><code>You: /commit\n\n# Or manually:\nYou: Generate a commit message for my changes\n</code></pre> <p>Claude will: - Analyze the diff - Identify the type of change (feat, fix, refactor, etc.) - Write a clear, conventional commit message - Include relevant details and context</p> <p>Example Generated Commit:</p> <pre><code>feat(auth): implement OAuth2 authentication flow\n\n- Add OAuth2 client configuration\n- Implement authorization code flow\n- Add token refresh mechanism\n- Update user model to store OAuth tokens\n- Add middleware for OAuth protected routes\n\nThis enables users to authenticate using Google, GitHub, and other\nOAuth providers instead of just username/password.\n\nCloses #42\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#branch-management-strategies","level":4,"title":"Branch Management Strategies","text":"<p>Feature Branch Workflow:</p> <pre><code># Create feature branch\nYou: Can you help me create a branch for the password reset feature?\n\nClaude: Sure! Run: git checkout -b feature/password-reset\n\n# Work on feature...\n\n# Before merging\nYou: /review\nYou: /test\nYou: /commit\n</code></pre> <p>Reviewing Before Merge:</p> <pre><code>You: Compare my feature branch with main and identify any conflicts\n\nClaude: [Analyzes differences, identifies conflicts, suggests resolution]\n</code></pre> <p>Rebasing:</p> <pre><code>You: I need to rebase my feature branch on the latest main. Walk me through it safely.\n\nClaude: [Provides step-by-step rebase instructions with safety checks]\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#pull-request-descriptions","level":4,"title":"Pull Request Descriptions","text":"<p>Generate comprehensive PR descriptions:</p> <pre><code>You: Generate a pull request description for my authentication feature\n</code></pre> <p>Claude will generate:</p> <pre><code>## Pull Request: Add OAuth2 Authentication\n\n### Summary\nImplements OAuth2 authentication flow allowing users to sign in with Google, GitHub, and Microsoft accounts.\n\n### Changes\n- ✨ Add OAuth2 client configuration (`src/auth/oauth.py`)\n- ✨ Implement authorization code flow\n- ✨ Add token management and refresh logic\n- 🗃️ Update User model to store OAuth provider info\n- 🔒 Add middleware for OAuth-protected routes\n- ✅ Add comprehensive test coverage (95%)\n- 📝 Update API documentation\n\n### Testing\n- [x] Unit tests pass\n- [x] Integration tests pass\n- [x] Manual testing with Google OAuth\n- [x] Manual testing with GitHub OAuth\n- [x] Security review completed\n\n### Security Considerations\n- OAuth tokens stored encrypted in database\n- State parameter used to prevent CSRF\n- Strict redirect URI validation\n- Token refresh handled automatically\n\n### Breaking Changes\nNone. Existing username/password authentication continues to work.\n\n### Related Issues\nCloses #42\nRelates to #38, #45\n\n### Screenshots\n[Add screenshots of OAuth login flow]\n\n### Deployment Notes\nRequires new environment variables:\n- `OAUTH_GOOGLE_CLIENT_ID`\n- `OAUTH_GOOGLE_CLIENT_SECRET`\n- `OAUTH_GITHUB_CLIENT_ID`\n- `OAUTH_GITHUB_CLIENT_SECRET`\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#code-review-with-claude","level":4,"title":"Code Review with Claude","text":"<p>Before submitting PR:</p> <pre><code>You: @code-reviewer Review my changes and check for issues\n\nCode Reviewer: [Provides detailed feedback on:]\n- Potential bugs\n- Security concerns\n- Performance issues\n- Style inconsistencies\n- Missing tests\n- Documentation gaps\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#83-security-privacy","level":3,"title":"8.3 Security &amp; Privacy","text":"<p>Developing securely with AI assistance requires careful attention.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#api-key-management","level":4,"title":"API Key Management","text":"<p>Environment Variables:</p> <p>Never hardcode API keys:</p> <pre><code># ❌ BAD - Hardcoded\napi_key = \"sk-ant-1234567890\"\n\n# ✅ GOOD - Environment variable\nimport os\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n</code></pre> <p>Setting Environment Variables:</p> <pre><code># .env file (add to .gitignore!)\nANTHROPIC_API_KEY=your-key-here\nDATABASE_URL=postgresql://...\nSECRET_KEY=your-secret-key\n</code></pre> <p>Load in code:</p> <pre><code>from dotenv import load_dotenv\nload_dotenv()\n</code></pre> <p>Claude Can Help:</p> <pre><code>You: Review my code for hardcoded secrets\n\nClaude: [Identifies hardcoded credentials and suggests fixes]\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#gitignore-best-practices","level":4,"title":".gitignore Best Practices","text":"<p>Ensure sensitive files are never committed:</p> <pre><code>You: Create a comprehensive .gitignore for Python/Node/etc.\n\nClaude: [Generates .gitignore including:]\n</code></pre> <pre><code># Environment variables\n.env\n.env.local\n.env.*.local\n\n# Secrets and credentials\n*.key\n*.pem\n*.p12\nsecrets.yaml\ncredentials.json\n\n# Database\n*.db\n*.sqlite\n*.sqlite3\n\n# API keys and tokens\n.anthropic\n.openai\n*_key.txt\n*_token.txt\n\n# IDE and editors\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# OS files\n.DS_Store\nThumbs.db\n</code></pre> <p>Verify Nothing Sensitive is Tracked:</p> <pre><code># Check what's tracked by git\ngit ls-files\n\n# Check for accidental secrets\nYou: Scan my repository for potential secrets or API keys\n\nClaude: [Uses regex patterns to identify potential secrets]\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#sensitive-data-handling","level":4,"title":"Sensitive Data Handling","text":"<p>Sanitize Before Sharing with Claude:</p> <pre><code># ❌ Don't paste\nYou: Debug this: DATABASE_URL=postgresql://admin:MyPassword123@prod.example.com/db\n\n# ✅ Do paste\nYou: Debug this: DATABASE_URL=postgresql://user:password@host/db\n</code></pre> <p>Use Placeholders:</p> <pre><code>You: Here's my config (I've replaced sensitive values with placeholders):\n\nAPI_KEY=&lt;redacted&gt;\nSECRET=&lt;redacted&gt;\nDATABASE_URL=postgresql://USER:PASSWORD@HOST/DATABASE\n\nThe issue is...\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#institutional-compliance","level":4,"title":"Institutional Compliance","text":"<p>Follow Your Organization's Policies</p> <p>Many universities and companies have strict policies about AI tools:</p> <ul> <li>Data Classification: Don't share classified or sensitive data</li> <li>Approved Tools: Use only approved AI services</li> <li>Code Review: Additional review may be required for AI-generated code</li> <li>Logging: Be aware of what's logged and where</li> <li>Intellectual Property: Understand IP implications</li> </ul> <p>Check with your IT security team before using Claude Code with: - Proprietary code - Sensitive research data - Personal information (PII) - Protected health information (PHI) - Financial data - Any classified information</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#security-checklist","level":4,"title":"Security Checklist","text":"<p>Before deploying AI-assisted code:</p> <ul> <li> No hardcoded credentials</li> <li> Environment variables used properly</li> <li> <code>.gitignore</code> includes sensitive files</li> <li> No secrets in git history</li> <li> Input validation on all user input</li> <li> SQL injection prevention</li> <li> XSS prevention</li> <li> CSRF protection implemented</li> <li> Authentication tested thoroughly</li> <li> Authorization checks in place</li> <li> Encryption for sensitive data</li> <li> Secure communication (HTTPS)</li> <li> Security review completed</li> <li> Compliance requirements met</li> </ul> <p>Ask Claude to Help:</p> <pre><code>You: @security-auditor Review my authentication system for vulnerabilities\n\nSecurity Auditor: [Comprehensive security analysis]\n</code></pre> <p>AI-Generated Code Requires Review</p> <p>Always review AI-generated code for security issues. AI can make mistakes or suggest insecure patterns. Your judgment is essential.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#9-ai-sandbox-environments","level":2,"title":"9. AI Sandbox Environments","text":"<p>For certain use cases, you may want to run Claude Code in an isolated sandbox environment.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#91-why-use-sandboxes","level":3,"title":"9.1 Why Use Sandboxes?","text":"<p>Isolation Benefits: - Separate development from production environment - Prevent accidental changes to main system - Test destructive operations safely - Maintain clean, reproducible environments</p> <p>Testing Environments: - Test installations and configurations - Experiment with different setups - Verify cross-platform compatibility - CI/CD integration</p> <p>Team Collaboration: - Consistent environment across team - Share exact development setup - Onboard new developers quickly - Document infrastructure as code</p> <p>Security &amp; Compliance: - Meet institutional security requirements - Isolate sensitive data processing - Audit and monitor activity - Enforce security policies</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#92-options-overview","level":3,"title":"9.2 Options Overview","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#docker-containers","level":4,"title":"Docker Containers","text":"<p>What: Lightweight, isolated containers that package applications with their dependencies.</p> <p>Pros: - Fast startup - Minimal resource usage - Easy to share (Dockerfile) - Perfect for CI/CD - Version controlled environments</p> <p>Cons: - Requires Docker knowledge - Linux-only containers (mostly) - Networking can be complex</p> <p>Learn More: Docker Documentation</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#virtual-machines","level":4,"title":"Virtual Machines","text":"<p>What: Complete OS instances running on your hardware.</p> <p>Pros: - Complete isolation - Run different OS (Windows on Mac, etc.) - Snapshots and restore - Better for GUI applications</p> <p>Cons: - Resource-intensive - Slower startup - Large disk usage - More complex setup</p> <p>Popular Options: - VirtualBox (Free, open-source) - VMware Workstation/Fusion - Parallels (Mac) - Hyper-V (Windows)</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#jupyter-lab-integration","level":4,"title":"Jupyter Lab Integration","text":"<p>What: Run Claude Code within Jupyter Lab for notebook-based development.</p> <p>Pros: - Interactive development - Great for data science - Inline documentation - Shareable notebooks</p> <p>Cons: - Different workflow than traditional coding - Less suitable for large applications</p> <p>Learn More: See our Jupyter AI Guide for detailed setup.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#cloud-development-environments","level":4,"title":"Cloud Development Environments","text":"<p>GitHub Codespaces - Cloud-based VS Code - Integrated with GitHub repos - Automatic environment setup - Learn more</p> <p>GitPod - Open-source alternative to Codespaces - Works with GitHub, GitLab, Bitbucket - Free tier available - Learn more</p> <p>AWS Cloud9 - AWS-integrated IDE - Serverless friendly - Pre-configured for AWS services - Learn more</p> <p>Replit - Browser-based IDE - Instant setup - Collaborative coding - Learn more</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#93-quick-docker-setup-example","level":3,"title":"9.3 Quick Docker Setup Example","text":"<p>Here's a basic Docker setup for Claude Code development:</p> <p>Dockerfile:</p> <pre><code>FROM python:3.11-slim\n\n# Install Node.js for Claude Code CLI\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    nodejs \\\n    npm \\\n    git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install Claude Code\nRUN npm install -g @anthropic-ai/claude\n\n# Install GitHub CLI\nRUN curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | \\\n    dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg &amp;&amp; \\\n    echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | \\\n    tee /etc/apt/sources.list.d/github-cli.list &gt; /dev/null &amp;&amp; \\\n    apt-get update &amp;&amp; \\\n    apt-get install gh -y\n\n# Set up workspace\nWORKDIR /workspace\n\n# Default command\nCMD [\"/bin/bash\"]\n</code></pre> <p>Usage:</p> <pre><code># Build the image\ndocker build -t claude-dev .\n\n# Run container with volume mount\ndocker run -it \\\n  -v $(pwd):/workspace \\\n  -e ANTHROPIC_API_KEY=$ANTHROPIC_API_KEY \\\n  claude-dev\n\n# Inside container\nclaude --version\ngh auth login\ncd /workspace\nclaude\n</code></pre> <p>For comprehensive Docker guides, see the official Docker documentation.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#10-troubleshooting","level":2,"title":"10. Troubleshooting","text":"<p>Common issues and their solutions.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#installation-problems","level":3,"title":"Installation Problems","text":"<p>Issue: <code>npm install -g @anthropic-ai/claude</code> fails</p> <p>Solutions:</p> <ol> <li> <p>Check Node/npm versions: <pre><code>node --version  # Should be v16+\nnpm --version   # Should be v7+\n</code></pre></p> </li> <li> <p>Update Node: <pre><code># macOS\nbrew upgrade node\n\n# Or use nvm\nnvm install --lts\n</code></pre></p> </li> <li> <p>Try without global: <pre><code>npx @anthropic-ai/claude --version\n</code></pre></p> </li> <li> <p>Permissions issue: <pre><code># Use correct npm permissions (don't use sudo!)\nmkdir ~/.npm-global\nnpm config set prefix '~/.npm-global'\necho 'export PATH=~/.npm-global/bin:$PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre></p> </li> </ol> <p>Issue: VS Code extension not appearing</p> <p>Solutions:</p> <ol> <li>Reload VS Code:</li> <li> <p><code>Cmd/Ctrl + Shift + P</code> → \"Developer: Reload Window\"</p> </li> <li> <p>Check VS Code version:</p> </li> <li>Must be v1.75.0 or later</li> <li> <p>Help → About</p> </li> <li> <p>Reinstall extension: <pre><code>code --uninstall-extension anthropic.claude\ncode --install-extension anthropic.claude\n</code></pre></p> </li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#authentication-errors","level":3,"title":"Authentication Errors","text":"<p>Issue: \"Authentication failed\" or \"Invalid API key\"</p> <p>Solutions:</p> <ol> <li> <p>Verify API key: <pre><code>echo $ANTHROPIC_API_KEY  # Should output your key\n</code></pre></p> </li> <li> <p>Re-authenticate: <pre><code># CLI\nclaude auth logout\nclaude auth login\n\n# Check status\nclaude auth status\n</code></pre></p> </li> <li> <p>Check API key format:</p> </li> <li>Should start with <code>sk-ant-</code></li> <li>No extra spaces or quotes</li> <li> <p>Not expired or revoked</p> </li> <li> <p>Environment variable: <pre><code># Add to ~/.bashrc or ~/.zshrc\nexport ANTHROPIC_API_KEY=\"your-key-here\"\nsource ~/.bashrc\n</code></pre></p> </li> </ol> <p>Issue: \"Rate limit exceeded\"</p> <p>Solution: - You've hit usage limits - Wait and try again - Upgrade to Pro plan for higher limits - Check console.anthropic.com for usage</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#extension-not-loading","level":3,"title":"Extension Not Loading","text":"<p>Issue: VS Code extension installed but not working</p> <p>Solutions:</p> <ol> <li>Check extension status:</li> <li>View → Extensions</li> <li>Search \"Claude Code\"</li> <li> <p>Should show \"Enabled\"</p> </li> <li> <p>Check for conflicts:</p> </li> <li>Disable other AI coding extensions</li> <li> <p>Restart VS Code</p> </li> <li> <p>View logs:</p> </li> <li>Help → Toggle Developer Tools</li> <li>Console tab → filter for \"claude\"</li> <li> <p>Look for error messages</p> </li> <li> <p>Reinstall clean: <pre><code># Remove extension completely\nrm -rf ~/.vscode/extensions/anthropic.claude-*\n\n# Reinstall\ncode --install-extension anthropic.claude\n</code></pre></p> </li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#performance-issues","level":3,"title":"Performance Issues","text":"<p>Issue: Claude Code is slow or unresponsive</p> <p>Solutions:</p> <ol> <li> <p>Reduce context: <pre><code>You: /clear\nYou: Let's focus only on the files we need\n</code></pre></p> </li> <li> <p>Use faster model: <pre><code>You: /model claude-4-5-haiku-20260115\n</code></pre></p> </li> <li> <p>Close unnecessary files (VS Code):</p> </li> <li>Close tabs you're not editing</li> <li> <p>Use <code>.claudeignore</code> to exclude files</p> </li> <li> <p>Check network: <pre><code>ping console.anthropic.com\n</code></pre></p> </li> <li> <p>System resources:</p> </li> <li>Close other applications</li> <li>Check RAM and CPU usage</li> <li>Restart VS Code/terminal</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#context-window-limits","level":3,"title":"Context Window Limits","text":"<p>Issue: \"Context window exceeded\" error</p> <p>Solutions:</p> <ol> <li> <p>Clear conversation: <pre><code>You: /clear\n</code></pre></p> </li> <li> <p>Focus on specific files: <pre><code>You: Let's work only with src/auth.py for now\n</code></pre></p> </li> <li> <p>Create <code>.claudeignore</code>: <pre><code># .claudeignore (like .gitignore)\nnode_modules/\ndist/\nbuild/\n*.log\n*.min.js\nvendor/\n.git/\n</code></pre></p> </li> <li> <p>Split large files:</p> </li> <li>Refactor large files into smaller modules</li> <li> <p>Use more focused conversations</p> </li> <li> <p>Use summaries: <pre><code>You: Give me a summary of the auth module instead of showing all the code\n</code></pre></p> </li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#common-error-messages","level":3,"title":"Common Error Messages","text":"<p>\"Cannot read properties of undefined\" - Usually a configuration issue - Check <code>.claude/config.json</code> syntax - Reset config: <code>rm -rf .claude/</code> and reinitialize</p> <p>\"EACCES: permission denied\" - File permission issue - Check file ownership: <code>ls -la</code> - Fix permissions: <code>chmod +x script.sh</code></p> <p>\"Git not found\" - Git not installed or not in PATH - Install Git: git-scm.com - Check PATH: <code>echo $PATH</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#getting-help","level":3,"title":"Getting Help","text":"<p>If you're still stuck:</p> <ol> <li>Check official documentation:</li> <li> <p>docs.anthropic.com/claude</p> </li> <li> <p>Search GitHub issues:</p> </li> <li>Known issues and solutions</li> <li> <p>Report new bugs</p> </li> <li> <p>Community resources:</p> </li> <li>Anthropic Discord</li> <li>Stack Overflow (tag: claude)</li> <li> <p>Reddit r/ClaudeAI</p> </li> <li> <p>Contact support:</p> </li> <li>Pro/Team subscribers: support@anthropic.com</li> <li>Include: Claude Code version, OS, error messages, steps to reproduce</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#11-tips-advanced-techniques","level":2,"title":"11. Tips &amp; Advanced Techniques","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#productivity-tips","level":3,"title":"Productivity Tips","text":"<p>Keyboard Shortcuts (VS Code Extension)</p> Shortcut Action <code>Cmd/Ctrl + Shift + C</code> Open Claude Code panel <code>Cmd/Ctrl + K</code> Quick ask Claude <code>Cmd/Ctrl + Shift + P</code> → \"Claude\" All Claude commands <code>Esc</code> Cancel current request <code>Tab</code> Accept inline suggestion <p>Efficient Prompting</p> <p>✅ Be Specific: <pre><code>Refactor the authenticate_user function in src/auth.py to handle OAuth2 tokens\n</code></pre></p> <p>❌ Too Vague: <pre><code>Make auth better\n</code></pre></p> <p>✅ Provide Context: <pre><code>This is a Flask app using SQLAlchemy. I need to add a user profile endpoint\nthat returns user info as JSON. It should require authentication and handle\nmissing users gracefully.\n</code></pre></p> <p>❌ Lacking Context: <pre><code>Add a user profile endpoint\n</code></pre></p> <p>✅ Iterative Refinement: <pre><code>1. Create the basic endpoint\n2. [After review] Add pagination support\n3. [After review] Add filtering by date\n</code></pre></p> <p>❌ Everything at Once: <pre><code>Create a user profile endpoint with pagination, filtering, sorting, search,\nexport to CSV, and admin overrides\n</code></pre></p> <p>Project Organization</p> <p>Create a <code>.claude/</code> directory for Claude-specific files:</p> <pre><code>.claude/\n├── agents/              # Custom agents\n│   ├── docs-writer.yaml\n│   ├── test-writer.yaml\n│   └── reviewer.yaml\n├── commands/            # Slash commands\n│   ├── commit.yaml\n│   ├── test.yaml\n│   └── deploy.yaml\n├── config.json          # Claude Code settings\n├── context/             # Pre-loaded context\n│   └── architecture.md\n└── prompts/             # Saved prompts\n    └── code-review.md\n</code></pre> <p>Using the Projects Feature</p> <p>Organize work by project:</p> <pre><code># CLI\nclaude project create my-app\nclaude project switch my-app\n\n# Each project maintains separate:\n# - Conversation history\n# - Context\n# - Agent configurations\n# - Settings\n</code></pre> <p>In VS Code: Use workspaces to separate projects.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#advanced-workflows","level":3,"title":"Advanced Workflows","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#multi-file-editing","level":4,"title":"Multi-File Editing","text":"<p>Ask Claude to make coordinated changes:</p> <pre><code>You: Rename the User class to Account across the entire codebase,\nincluding imports, tests, and documentation. Make sure everything\nstill works.\n</code></pre> <p>Claude will:</p> <ol> <li>Find all occurrences</li> <li>Show proposed changes</li> <li>Apply consistently</li> <li>Update related code</li> <li>Fix broken imports</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#refactoring-large-codebases","level":4,"title":"Refactoring Large Codebases","text":"<p>For major refactors:</p> <pre><code>You: I want to refactor our monolithic app into microservices.\nLet's start by analyzing the current structure and identifying\nservice boundaries.\n</code></pre> <p>Then iteratively:</p> <pre><code>1. Identify services\n2. Define interfaces\n3. Extract first service\n4. Test integration\n5. Repeat for each service\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#integration-with-cicd","level":4,"title":"Integration with CI/CD","text":"<p>Add Claude Code to your CI pipeline:</p> <p>.github/workflows/claude-review.yml:</p> <pre><code>name: Claude Code Review\n\non: [pull_request]\n\njobs:\n  review:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Node\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Install Claude Code\n        run: npm install -g @anthropic-ai/claude\n\n      - name: Run Code Review\n        env:\n          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}\n        run: |\n          claude review \\\n            --files $(git diff --name-only origin/main) \\\n            --output review.md\n\n      - name: Comment on PR\n        uses: actions/github-script@v6\n        with:\n          script: |\n            const fs = require('fs');\n            const review = fs.readFileSync('review.md', 'utf8');\n            github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: review\n            });\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#team-collaboration-patterns","level":4,"title":"Team Collaboration Patterns","text":"<p>Shared Agent Library:</p> <p>Create team-wide agents in a shared repository:</p> <pre><code>company-claude-agents/\n├── agents/\n│   ├── python-tester.yaml\n│   ├── api-docs.yaml\n│   └── security-audit.yaml\n└── commands/\n    ├── deploy-staging.yaml\n    └── create-release.yaml\n</code></pre> <p>Team members clone and symlink:</p> <pre><code>git clone git@github.com:company/claude-agents.git ~/.claude-agents\nln -s ~/.claude-agents/agents .claude/agents\nln -s ~/.claude-agents/commands .claude/commands\n</code></pre> <p>Code Review Guidelines:</p> <p>Establish team standards for AI-assisted development:</p> <pre><code>## Team Guidelines for Claude Code\n\n### Required Reviews\n\n- All AI-generated code must be reviewed by a human\n- Security-sensitive code requires additional security review\n- Database migrations require team lead approval\n\n### Documentation\n\n- Add \"Generated with Claude Code\" to commit messages for AI-generated code\n- Document significant AI assistance in PR descriptions\n- Explain any non-obvious AI suggestions\n\n### Testing\n\n- All AI-generated code must have tests\n- Tests should be human-written or thoroughly reviewed\n- Aim for 80%+ coverage on new code\n\n### Security\n\n- Never commit API keys or secrets\n- Run security scanners on AI-generated code\n- Review authentication/authorization logic manually\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#12-next-steps-resources","level":2,"title":"12. Next Steps &amp; Resources","text":"<p>Congratulations! You now have a comprehensive understanding of Claude Code and how to use it effectively in your development workflow.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#related-documentation","level":3,"title":"Related Documentation","text":"<p>Explore these related topics to deepen your understanding:</p> <p> Vibe Coding</p> <ul> <li>Compare Claude Code with other AI coding tools</li> <li>Understand the vibe coding landscape</li> <li>Choose the right tool for different scenarios</li> <li>Security considerations for AI-assisted development</li> </ul> <p> Model Context Protocol (MCP)</p> <ul> <li>Connect Claude Code to databases, APIs, and external services</li> <li>Set up MCP servers for enhanced capabilities</li> <li>Build custom integrations</li> <li>Leverage context-aware assistance</li> </ul> <p> Agentic AI</p> <ul> <li>Understand the principles behind agentic systems</li> <li>Learn about autonomous AI behaviors</li> <li>Explore advanced agent patterns</li> <li>See how agents transform software development</li> </ul> <p> Code Interpreters</p> <ul> <li>Understand code execution fundamentals</li> <li>Compare sandboxed vs local execution</li> <li>Security and privacy considerations</li> <li>Best practices for AI-generated code</li> </ul> <p> Jupyter AI</p> <ul> <li>Integrate Claude with Jupyter notebooks</li> <li>Data science workflows with AI assistance</li> <li>Interactive development patterns</li> <li>Research and analysis use cases</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#official-resources","level":3,"title":"Official Resources","text":"<p>Documentation:</p> <ul> <li>Anthropic Documentation</li> <li>Claude Code Official Docs</li> <li>API Reference</li> <li>Model Context Protocol</li> </ul> <p>Community:</p> <ul> <li>Anthropic Discord - Active community, get help, share projects</li> <li>GitHub Discussions - Technical discussions</li> <li>Anthropic Cookbook - Code examples and tutorials</li> </ul> <p>Social Media:</p> <ul> <li>Anthropic Blog</li> <li>Research Papers</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#example-projects","level":3,"title":"Example Projects","text":"<p>Check out these example projects to see Claude Code in action:</p> <ul> <li>Claude Code Starter Templates</li> <li>Anthropic Cookbook Examples</li> <li>Community Projects Showcase (Discord #showcase channel)</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#continuing-your-learning-journey","level":3,"title":"Continuing Your Learning Journey","text":"<p>Week 1-2: Foundation</p> <ul> <li>Complete this tutorial's exercises</li> <li>Create a simple project with Claude Code</li> <li>Practice using agents and slash commands</li> <li>Join the Discord community</li> </ul> <p>Week 3-4: Intermediate</p> <ul> <li>Contribute to an open-source project using Claude Code</li> <li>Create custom agents for your workflow</li> <li>Set up MCP servers for your tools</li> <li>Explore integration with CI/CD</li> </ul> <p>Month 2: Advanced</p> <ul> <li>Build a complex multi-service application</li> <li>Create team-shared agent libraries</li> <li>Develop custom MCP servers</li> <li>Contribute back to the community</li> </ul> <p>Ongoing:</p> <ul> <li>Follow Anthropic's blog for updates</li> <li>Experiment with new Claude models</li> <li>Share your experiences and learnings</li> <li>Help others in the community</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#stay-updated","level":3,"title":"Stay Updated","text":"<p>Claude Code and AI development tools evolve rapidly:</p> <ul> <li>Subscribe to Anthropic Newsletter</li> <li>Watch for Claude Code release notes</li> <li>Follow the #claude channel on Discord</li> <li>Check this documentation for updates</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#getting-involved","level":3,"title":"Getting Involved","text":"<p>Share Your Experience:</p> <ul> <li>Write blog posts about your Claude Code workflow</li> <li>Create video tutorials</li> <li>Share agents and commands on GitHub</li> <li>Help others on Discord</li> </ul> <p>Provide Feedback:</p> <ul> <li>Report bugs and issues</li> <li>Suggest new features</li> <li>Share use cases and success stories</li> <li>Contribute to documentation</li> </ul> <p>Build Extensions:</p> <ul> <li>Create MCP servers for popular tools</li> <li>Develop Claude Code plugins</li> <li>Share agent configurations</li> <li>Build integrations with other tools</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#thank-you","level":3,"title":"Thank You!","text":"<p>Thank you for completing this comprehensive Claude Code tutorial. We hope this guide helps you unlock the full potential of AI-assisted development. Happy coding! 🚀</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#13-assessment","level":2,"title":"13. Assessment","text":"<p>Test your understanding of Claude Code concepts with these questions:</p> What's the primary difference between Claude Code CLI and the VS Code Extension? Answer <p>Claude Code CLI is a terminal-based tool accessed via command line, best for terminal-first developers and automation workflows. The VS Code Extension integrates directly into VS Code with a visual interface, inline editing, and GUI features, making it better for developers who prefer visual development environments. Both have access to the same Claude models and capabilities, just different interfaces.</p> When should you use <code>/init</code> vs starting a planning session? Answer <p>Use <code>/init</code> when you have an existing codebase and want Claude to analyze and understand the current structure, technologies, patterns, and architecture.</p> <p>Use a planning session when starting from scratch or with a minimal repository, where you want Claude to help design the project structure, choose technologies, and plan the implementation.</p> What is a custom agent in Claude Code? Answer <p>A custom agent is a specialized AI assistant configured with specific instructions, knowledge, and behaviors for particular tasks. Agents differ from regular conversations by having: - Pre-defined domain expertise - Consistent behavior patterns - Reusable configurations - Specialized skills and instructions</p> <p>Examples include documentation writers, code reviewers, test generators, and security auditors.</p> True or False: You should commit your <code>.env</code> file containing API keys to git for your team to access. False <p>Never commit API keys or secrets to version control! API keys should be: - Stored in <code>.env</code> files that are added to <code>.gitignore</code> - Passed via environment variables - Stored securely using secret management tools - Shared with team members through secure channels (not git)</p> <p>Committing secrets to git exposes them to anyone with repository access and makes them nearly impossible to fully remove from git history.</p> Which slash command would you use to stage changes and create a commit with an AI-generated message? <ol> <li><code>/init</code></li> <li><code>/commit</code></li> <li><code>/review</code></li> <li><code>/deploy</code></li> </ol> Correct Answer: 2 <p><code>/commit</code> is the slash command that stages changes, generates an intelligent commit message based on the diff, and creates the commit. The <code>/init</code> command analyzes codebases, <code>/review</code> performs code reviews, and <code>/deploy</code> handles deployment workflows.</p> What is the Model Context Protocol (MCP) used for in Claude Code? Answer <p>Model Context Protocol (MCP) is a standardized communication framework that allows Claude Code to: - Access local file systems and databases - Interact with external APIs and services - Connect to tools like GitHub, PostgreSQL, Slack, etc. - Provide real-time application state awareness - Enable deep integration with development tools</p> <p>MCP enables Claude Code to go beyond conversation and actually interact with your development environment. See our MCP Documentation for more details.</p> True or False: All code generated by Claude Code is guaranteed to be secure and bug-free. False <p>AI-generated code requires careful human review. While Claude Code is sophisticated, it can: - Make mistakes or misunderstand requirements - Suggest outdated or insecure patterns - Miss edge cases or error conditions - Replicate biases from training data</p> <p>Always: - Review all AI-generated code - Run comprehensive tests - Check for security vulnerabilities - Verify against best practices - Use your judgment and expertise</p> Which of the following is a best practice when working with Claude Code? <ol> <li>Share all your production database credentials in prompts for better debugging</li> <li>Commit all generated code immediately without review</li> <li>Use specific, contextual prompts and iterate on solutions</li> <li>Try to include your entire codebase in every conversation</li> </ol> Correct Answer: 3 <p>Using specific, contextual prompts and iterating on solutions is the correct best practice. The other options are problematic: - Never share sensitive credentials in prompts (security risk) - Always review AI-generated code before committing - Focus conversations on relevant files to avoid context limits</p> <p>Effective Claude Code usage involves clear communication, incremental development, and maintaining security awareness.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude/","level":1,"title":"Anthropic Claude","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#ways-to-access-claude","level":2,"title":"Ways to Access Claude","text":"<p>There are multiple ways to access Claude:</p> <p>1. Claude Chat Interface (claude.ai):</p> <ul> <li>Go to: https://claude.ai/</li> <li>Sign up: Create an account using your email address or with a Google account</li> <li>Log in: If you already have an account, log in with your credentials</li> </ul> <p>2. Claude Code (VS Code Extension):</p> <ul> <li>Install: Search for \"Claude Code\" in VS Code Extensions marketplace or visit claude.ai/code</li> <li>Features: AI pair programming, code generation, debugging, and refactoring directly in VS Code</li> <li>Authentication: Requires Anthropic API key or Claude Pro subscription</li> </ul> <p>3. Claude Desktop App:</p> <ul> <li>Download: Available for macOS and Windows at claude.ai/download</li> <li>Features: Native desktop experience with keyboard shortcuts, file handling, and system integration</li> <li>Model Context Protocol: Built-in MCP support for connecting to local tools and services</li> </ul> <p>4. Anthropic API (for Developers):</p> <ul> <li>Sign Up: Go to https://console.anthropic.com/ to create an account</li> <li>API Key: Generate an API key from your console dashboard</li> <li>Documentation: https://docs.anthropic.com/</li> </ul> <p>Treat your API key like a password</p> <p>Do not share it publicly or commit it to version control platforms (like GitHub).</p>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#model-context-protocol-mcp","level":2,"title":"Model Context Protocol (MCP)","text":"<p>The Model Context Protocol is an open standard that enables Claude to interact with external tools and data sources:</p> <p>What is MCP?</p> <ul> <li>Purpose: Allows Claude to connect to databases, APIs, files, and other tools on your computer</li> <li>Security: Runs locally with your explicit permission for each connection</li> <li>Open Standard: Developed by Anthropic and available as open-source</li> </ul> <p>Installing MCP:</p> <ol> <li> <p>For Claude Desktop:</p> </li> <li> <p>MCP support is built into Claude Desktop</p> </li> <li>Configure servers in Settings → Developer → Model Context Protocol</li> <li> <p>Add server configurations in JSON format</p> </li> <li> <p>Example MCP Configuration:</p> </li> </ol> <pre><code>{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/allowed/directory\"]\n    },\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"your-token-here\"\n      }\n    }\n  }\n}\n</code></pre> <ol> <li>Popular MCP Servers:</li> <li>Filesystem: Access local files and directories</li> <li>GitHub: Interact with GitHub repositories</li> <li>PostgreSQL: Query databases</li> <li>Slack: Read Slack messages</li> <li>Google Drive: Access Google Drive files</li> </ol> <p>Learn More: modelcontextprotocol.io</p> <p>Subscription Plans and Pricing</p> <ul> <li>Claude Free: Access to Claude 4.5 Sonnet with usage limits</li> <li>Claude Pro ($20/month):<ul> <li>5x more usage vs free tier</li> <li>Access to Claude 4.5 Opus and Claude 4.5 Haiku</li> <li>Priority access during high-traffic periods</li> <li>Early access to new features</li> </ul> </li> <li>Claude Max ($100-200/month):<ul> <li>Extended usage limits</li> <li>Priority access to newest models</li> </ul> </li> <li>Claude Team ($25-30/user/month, min 5 users):<ul> <li>Everything in Pro</li> <li>Central billing and administration</li> <li>Team collaboration features</li> </ul> </li> <li>API Pricing (per million tokens, as of January 2026):<ul> <li>Claude 4.5 Sonnet: $3 input / $15 output</li> <li>Claude 4.5 Opus: $15 input / $75 output</li> <li>Claude 4.5 Haiku: $0.25 input / $1.25 output</li> </ul> </li> </ul> <p>Compare with other AI platforms: See Choosing the Right AI Platform for detailed comparisons with ChatGPT, Gemini, and more.</p>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#using-claude","level":2,"title":"Using Claude","text":"<p>Web Chat Interface (claude.ai):</p> <ul> <li>Prompting: Type your requests or questions into the chat box. Be clear and specific in your prompts</li> <li>Conversation History: Claude remembers the context of your conversation within the current chat</li> <li>Projects: Organize chats into projects with custom instructions and shared knowledge</li> <li>Artifacts: Claude can create and edit code, documents, and diagrams in a dedicated panel</li> <li>File Uploads: Upload images, PDFs, and text files (up to 5 files, 10MB each)</li> </ul> <p>Claude Code (VS Code Extension):</p> <ul> <li>Installation: <ol> <li>Open VS Code</li> <li>Go to Extensions (Ctrl/Cmd + Shift + X)</li> <li>Search for \"Claude Code\"</li> <li>Click Install</li> </ol> </li> <li>Features:<ul> <li>Inline code completion</li> <li>Chat interface within VS Code</li> <li>Code explanation and refactoring</li> <li>Multi-file context awareness</li> <li>Terminal command suggestions</li> </ul> </li> </ul> <p>Claude Desktop App:</p> <ul> <li>Installation:<ul> <li>macOS: Download from claude.ai/download and drag to Applications</li> <li>Windows: Download installer and follow setup wizard</li> </ul> </li> <li>Features:<ul> <li>Native OS integration</li> <li>Global keyboard shortcuts</li> <li>MCP server connections</li> <li>Local file access (with permission)</li> <li>Offline viewing of past conversations</li> </ul> </li> </ul> <p>Anthropic API:</p> <ul> <li>Quick Start (Python): <pre><code>from anthropic import Anthropic\n\nclient = Anthropic(api_key=\"your-api-key\")\n\nresponse = client.messages.create(\n    model=\"claude-4-5-sonnet-20260115\",\n    max_tokens=1000,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello, Claude!\"}\n    ]\n)\nprint(response.content[0].text)\n</code></pre></li> <li>SDKs Available: Python, TypeScript/JavaScript, Go, and community SDKs</li> <li>Use Cases: Chatbots, content generation, code assistance, data analysis</li> </ul>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#tips-for-using-claude","level":2,"title":"Tips for Using Claude","text":"<ul> <li>Be Specific: Provide clear instructions and context in your prompts.</li> <li>Iterate: Refine your prompts based on Claude's responses to improve the results.</li> <li>Use System Prompts: For complex or multi-step tasks, consider using system prompts to provide overall instructions to guide Claude's behavior.</li> <li>Experiment: Try different prompting techniques and model settings to find what works best for your use case.</li> </ul>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#about-claude","level":2,"title":"About Claude","text":"<p>Claude is a family of large language models (LLMs) developed by Anthropic, a company focused on AI safety and research. Claude is known for:</p> <ul> <li>Helpful and Honest Responses: Designed with Constitutional AI for safer, more aligned outputs</li> <li>Advanced Reasoning: Excels at complex analysis, math, and multi-step problem-solving</li> <li>Strong Coding Abilities: Excellent for software development, debugging, and code review</li> <li>Large Context Window: Up to 200,000 tokens (approximately 150,000 words or 500 pages)</li> <li>Vision Capabilities: Can analyze images, charts, diagrams, and screenshots</li> </ul>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#claude-model-family","level":2,"title":"Claude Model Family","text":"<p>Latest Models (January 2026):</p> <ul> <li> <p>Claude 4.5 Sonnet:</p> <ul> <li>Most capable balanced model</li> <li>Best for coding, analysis, and creative tasks</li> <li>Excellent performance-to-cost ratio</li> <li>Model ID: <code>claude-4-5-sonnet-20260115</code></li> </ul> </li> <li> <p>Claude 4.5 Opus:</p> <ul> <li>Most capable flagship model</li> <li>Best for complex reasoning and advanced tasks</li> <li>Highest intelligence and capability</li> <li>Model ID: <code>claude-4-5-opus-20251101</code></li> </ul> </li> <li> <p>Claude 4.5 Haiku:</p> <ul> <li>Fast and cost-effective</li> <li>Great for simple tasks and high-volume applications</li> <li>Optimized for speed and efficiency</li> <li>Model ID: <code>claude-4-5-haiku-20260115</code></li> </ul> </li> </ul> <p>Model Selection</p> <p>Claude 4.5 Sonnet is recommended for most use cases as it offers the best combination of capability, speed, and cost. Use Opus for tasks requiring maximum intelligence and reasoning, and Haiku for high-volume, simple tasks.</p>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#further-resources","level":2,"title":"Further Resources","text":"<ul> <li>Anthropic Website: https://www.anthropic.com/</li> <li>Claude Documentation: https://docs.anthropic.com/</li> <li>API Reference: https://docs.anthropic.com/en/api/</li> <li>Prompt Engineering Guide: https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering</li> <li>Claude Code Documentation: https://docs.anthropic.com/en/docs/claude-code</li> <li>Model Context Protocol: https://modelcontextprotocol.io</li> <li>Anthropic Cookbook: https://github.com/anthropics/anthropic-cookbook</li> <li>Community Discord: https://discord.gg/anthropic</li> </ul> <p>Getting Started Recommendations</p> <ol> <li>Start with the free tier at claude.ai to explore Claude's capabilities</li> <li>For developers, try Claude Code in VS Code for an enhanced coding experience</li> <li>Install Claude Desktop if you want MCP integration and native OS features</li> <li>Experiment with different models to find the right balance of capability and cost for your needs</li> </ol>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"code/","level":1,"title":"Understanding Code Generation with LLMs","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#introduction-from-generation-to-execution","level":2,"title":"Introduction: From Generation to Execution","text":"<p>Large Language Models (LLMs) have fundamentally changed how we write and interact with code. Beyond simply generating code snippets, modern AI tools can now execute code, analyze data, and produce results in real-time. This capability manifests in multiple forms:</p> <ul> <li>Code Interpreters that operate in secure, sandboxed environments</li> <li>Code Execution Frameworks that integrate directly into your local development environment</li> <li>Agentic AI Systems that can autonomously plan, code, test, and iterate on complex software projects</li> </ul> <p>This evolution from simple code completion to autonomous coding agents represents a paradigm shift in software development. This lesson explores the spectrum of code generation and execution tools, from sandboxed interpreters to sophisticated agentic AI systems that leverage Model Context Protocol (MCP) for deep integration with your development environment.</p> <p>This sets the foundation for understanding \"Vibe Coding\"—the emerging practice of collaborative, conversational development where AI acts as an autonomous pair programmer within your IDE.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#1-code-interpreters-your-sandboxed-ai-analyst","level":2,"title":"1. Code Interpreters: Your Sandboxed AI Analyst","text":"<p>A Code Interpreter is a tool, typically within a chat-based interface, that can write and execute code in a secure, isolated environment. You provide instructions and data in natural language, and the AI handles the coding, execution, and interpretation of results.</p> <p>Key Characteristics:</p> <ul> <li>Sandboxed Execution: Code runs in an isolated environment with no access to your local files or network</li> <li>Data Upload: Upload datasets, documents, or files for analysis</li> <li>Instant Results: See code execution output, visualizations, and analyses in real-time</li> <li>No Setup Required: No need to install programming languages or libraries locally</li> <li>Session-Based: Work is temporary; files and state typically reset between sessions</li> </ul> <p>Ideal Use Cases:</p> <ul> <li>Data Analysis &amp; Visualization: Process datasets and create charts without writing code</li> <li>File Conversions: Transform file formats (CSV to JSON, image format conversions)</li> <li>Mathematical Computations: Solve complex equations and perform statistical analyses</li> <li>Prototyping: Quickly test algorithms or data processing workflows</li> <li>Learning: Experiment with programming concepts in a safe environment</li> </ul> <p>Code Interpreters are perfect for exploratory data analysis, one-off computations, and tasks where you want AI assistance without giving it access to your local system. For deeper integration with your development workflow, see Code Execution Frameworks and Vibe Coding.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#recommended-platforms","level":3,"title":"Recommended Platforms","text":"","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#google-gemini","level":4,"title":"Google Gemini","text":"<p>Platform: gemini.google.com</p> <p>Google's Gemini integrates powerful code interpretation capabilities directly within its chat interface. With its multimodal capabilities, you can:</p> <ul> <li>Upload files (PDFs, spreadsheets, images) and ask for analysis</li> <li>Perform complex data analysis and generate visualizations</li> <li>Solve programming problems with step-by-step explanations</li> <li>Leverage integration with Google Workspace and Google Cloud Platform</li> </ul> <p>Best for: Users in the Google ecosystem, multimodal data analysis, and document processing.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#anthropics-claude","level":4,"title":"Anthropic's Claude","text":"<p>Platform: claude.ai</p> <p>Claude offers robust Code Interpreter functionality through its Artifacts feature, which provides a live preview panel for code execution. Key features include:</p> <ul> <li>Upload documents, spreadsheets, and code files (up to 5 files, 10MB each)</li> <li>Write and execute Python code in a secure sandbox</li> <li>Create interactive data visualizations and charts</li> <li>Generate and iterate on code with real-time execution feedback</li> <li>Extended context window (200K tokens) for analyzing large codebases</li> </ul> <p>Best for: Statistical analysis, data cleaning, document processing, and iterative code development.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#openai-chatgpt-plusteam","level":4,"title":"OpenAI ChatGPT Plus/Team","text":"<p>Platform: chat.openai.com</p> <p>ChatGPT's Advanced Data Analysis (formerly Code Interpreter) is available to Plus and Team subscribers:</p> <ul> <li>Upload and analyze data files in various formats</li> <li>Generate sophisticated visualizations using matplotlib and seaborn</li> <li>Perform file conversions and data transformations</li> <li>Solve mathematical problems with symbolic computation</li> <li>Create animated visualizations and GIFs</li> </ul> <p>Best for: Data science workflows, exploratory data analysis, and creating publication-ready visualizations.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#perplexity-pro","level":4,"title":"Perplexity Pro","text":"<p>Platform: perplexity.ai</p> <p>Perplexity Pro includes code execution capabilities alongside its powerful search features:</p> <ul> <li>Execute Python code in a sandboxed environment</li> <li>Combine web search results with data analysis</li> <li>Generate visualizations based on real-time data</li> <li>Verify calculations and computations with source citations</li> </ul> <p>Best for: Research tasks requiring both web search and data analysis.</p> <p>Data Analysis with a Code Interpreter</p> <p>Imagine you are a researcher with a dataset of student performance metrics. You could upload a CSV to Gemini or Claude and prompt:</p> <pre><code>Analyze the CSV https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv\n\n1.  Load the dataset into a Pandas DataFrame.\n2.  Clean the data by handling any missing values.\n3.  Generate a scatter plot to visualize the relationship between key variables.\n4.  Calculate the Pearson correlation coefficient between these two variables.\n5.  Interpret the results and provide a brief summary.\n</code></pre> <p>The Code Interpreter would then write and run Python code to perform these steps, showing you the code, the output, and the final analysis.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#2-code-execution-frameworks-your-ai-pair-programmer","level":2,"title":"2. Code Execution Frameworks: Your AI Pair Programmer","text":"<p>While sandboxed interpreters are powerful for isolated tasks, the real transformation in software development comes from Code Execution Frameworks—tools that integrate AI assistance directly into your Integrated Development Environment (IDE). These frameworks bridge the gap between simple autocomplete and full agentic AI systems capable of autonomous development.</p> <p>Key Characteristics:</p> <ul> <li>IDE Integration: Work directly within VS Code, JetBrains IDEs, or standalone editors</li> <li>Local Execution: Run code on your machine with access to your file system</li> <li>Multi-File Awareness: Understand context across your entire project</li> <li>Tool Use: Execute terminal commands, run tests, interact with Git</li> <li>Iterative Development: Debug, fix errors, and refine code autonomously</li> <li>Context Protocol Support: Leverage MCP for deep integration with local tools and services</li> </ul> <p>Evolution of Capabilities:</p> <ol> <li>Code Completion (2021-2022): Simple autocomplete and snippet generation</li> <li>Code Generation (2022-2023): Generate functions and classes from descriptions</li> <li>Conversational Coding (2023-2024): Chat-based assistance with code editing</li> <li>Agentic Coding (2024-present): Autonomous multi-file editing, testing, and debugging</li> </ol> <p>These tools form the foundation of Vibe Coding—a fluid, conversational approach to development where AI acts as an autonomous pair programmer, not just a suggestion engine.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#recommended-platforms-tools","level":3,"title":"Recommended Platforms &amp; Tools","text":"<p>The landscape of AI-assisted development tools has exploded, ranging from simple completion tools to sophisticated agentic systems. Below is a categorized overview; see our comprehensive Vibe Coding guide for detailed comparisons and setup instructions.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#desktop-ides-standalone-editors","level":4,"title":"Desktop IDEs &amp; Standalone Editors","text":"<p> Cursor </p> <p>A popular standalone fork of VS Code with powerful agentic features. Cursor excels at multi-file editing, codebase understanding, and autonomous debugging. Uses a flat-fee pricing model with support for multiple LLM providers.</p> <p>Best for: Developers wanting a turnkey solution with stable, production-ready features.</p> <p> Windsurf </p> <p>Standalone editor focused on \"just works\" usability with agentic and inline features. Similar capabilities to Cursor with a different UX philosophy.</p> <p>Best for: Developers who prefer Windsurf's interaction model over Cursor's approach.</p> <p> Claude Desktop </p> <p>Native desktop application with built-in Model Context Protocol (MCP) support. Connect to local filesystem servers, GitHub repositories, databases, and custom tools for context-aware assistance.</p> <p>Best for: Users wanting MCP integration and native OS features without IDE lock-in.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#vs-code-extensions","level":4,"title":"VS Code Extensions","text":"<p> Claude Code </p> <p>Official Anthropic VS Code extension featuring multi-file editing, debugging, and terminal integration. Provides agentic coding capabilities directly in VS Code.</p> <p>Best for: VS Code users wanting official Claude integration with strong agentic features.</p> <p> Cline </p> <p>Open-source, model-agnostic VS Code extension pioneering \"bring your own model\" (BYOM). Supports multiple LLM providers including local models via Ollama.</p> <p>Best for: Users wanting flexibility, open-source transparency, and control over model selection.</p> <p> Roo Code </p> <p>Fork of Cline focused on rapid feature development and customization. Serves users interested in experimental capabilities.</p> <p>Best for: Early adopters wanting cutting-edge features and customization options.</p> <p> GitHub Copilot </p> <p>Microsoft's AI pair programmer with deep GitHub integration. Provides inline completion, chat assistance, and agentic features through Copilot Workspace.</p> <p>Best for: GitHub-centric workflows and organizations with enterprise GitHub licenses.</p> <p> Gemini Code Assist </p> <p>Google's VS Code extension powered by Gemini models, offering code completion, generation, and chat assistance with Google Cloud integration.</p> <p>Best for: Google Cloud Platform users and those in the Google ecosystem.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#command-line-interface-cli-tools","level":4,"title":"Command Line Interface (CLI) Tools","text":"<p> Claude Code CLI </p> <p>Official Anthropic command-line interface enabling AI-assisted development from the terminal with MCP server support.</p> <p>Best for: Terminal-first developers and automation workflows.</p> <p> Aider </p> <p>Popular open-source command-line tool for AI-driven coding. Works with local or remote LLMs and integrates well with Git workflows.</p> <p>Best for: Developers who prefer command-line workflows and want model flexibility.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#browser-based-development","level":4,"title":"Browser-Based Development","text":"<p> Claude Code for Web </p> <p>Browser-based version providing AI pair programming through the web with multi-file editing and debugging capabilities.</p> <p>Best for: Quick coding sessions without local installation or Chromebook users.</p> <p> Firebase IDX </p> <p>Google's cloud-based IDE with built-in Gemini assistance, providing VS Code-like editing experience in the browser.</p> <p>Best for: Cloud-based development with Google Cloud Platform integration.</p> <p> OpenWebUI </p> <p>Self-hostable web interface supporting multiple LLM providers with built-in code execution and function calling.</p> <p>Best for: Self-hosting enthusiasts and teams wanting full control over their AI infrastructure.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#api-console-environments","level":4,"title":"API &amp; Console Environments","text":"<p> Google AI Studio </p> <p>Browser-based environment for experimenting with Gemini models, prototyping prompts, and generating code snippets.</p> <p>Best for: Prototyping with Gemini models and testing prompt strategies.</p> <p> OpenAI Playground </p> <p>Console environment for experimenting with OpenAI models, fine-tuning prompts, and developing code functions.</p> <p>Best for: API developers prototyping with OpenAI models.</p> <p>From Console to IDE: The Vibe Coding Evolution</p> <p>While console-based tools are excellent for prototyping, the real power of AI-assisted development comes from direct IDE integration. Modern tools leverage Model Context Protocol (MCP) to access your local environment, enabling agentic behaviors like:</p> <ul> <li>Autonomous multi-file refactoring</li> <li>Running tests and fixing failures iteratively</li> <li>Executing terminal commands and analyzing output</li> <li>Interacting with Git for version control</li> <li>Accessing databases and external APIs</li> </ul> <p>Explore our Vibe Coding guide to discover how these tools transform your editor into a collaborative coding environment where AI agents work alongside you.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#3-best-practices-ethical-considerations","level":2,"title":"3. Best Practices &amp; Ethical Considerations","text":"<p>Whether using a sandboxed interpreter, a code execution framework, or an agentic AI system, following best practices ensures effective, secure, and responsible use of AI coding tools.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#effective-prompting-strategies","level":3,"title":"Effective Prompting Strategies","text":"<p>Start with Clear Intent - Describe what you want to accomplish, not just how to do it - Provide context about your project, language, and frameworks - Specify constraints (performance, security, compatibility)</p> <p>Break Down Complex Tasks - Don't ask AI to build an entire application in one go - Decompose problems into smaller, testable steps - Let the AI iterate on solutions rather than attempting everything at once - This is especially important for agentic systems that benefit from clear subtask boundaries</p> <p>Provide Rich Context - Share relevant code snippets, error messages, and documentation - Use MCP-enabled tools to automatically provide file and project context - Explain your reasoning and decision-making process - Include examples of desired output or style</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#code-review-verification","level":3,"title":"Code Review &amp; Verification","text":"<p>Never Trust Generated Code Blindly - Always review for correctness, efficiency, and maintainability - Test thoroughly with unit tests, integration tests, and edge cases - Check for security vulnerabilities (SQL injection, XSS, authentication issues) - Verify adherence to your project's coding standards and best practices</p> <p>Understand Before Using - If you don't understand the generated code, ask the AI to explain it - Research unfamiliar libraries or patterns before adopting them - Consider maintainability—will you be able to debug this code in 6 months?</p> <p>Iterative Refinement - Start with a basic implementation and refine iteratively - Test at each stage before adding complexity - Use the AI to help debug and improve, not just generate initially</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#security-considerations","level":3,"title":"Security Considerations","text":"<p>Local Execution Risks</p> <p>Agentic AI systems and vibe coding tools that execute on your machine have significant access:</p> <ul> <li>File System Access: Can read, modify, and delete files</li> <li>Network Access: Can make API calls and external connections</li> <li>Terminal Access: Can execute arbitrary shell commands</li> <li>Environment Variables: May access sensitive credentials</li> </ul> <p>Security Best Practices:</p> <ul> <li>Review commands before AI executes them (most tools prompt for approval)</li> <li>Use project-specific virtual environments</li> <li>Never store secrets in code—use environment variables and secret managers</li> <li>Be cautious with <code>sudo</code> or administrator privileges</li> <li>Monitor AI actions, especially when learning a new tool</li> <li>Follow your institution's security and privacy policies</li> <li>Consider using sandboxed development environments for sensitive work</li> </ul> <p>Institutional Policies Many universities and organizations have policies about AI code execution. Check with your IT security team about:</p> <ul> <li>Approved AI tools and services</li> <li>Data classification restrictions</li> <li>Code review requirements for AI-generated code</li> <li>Network access policies for AI services</li> </ul> <p>See our Vibe Coding security warnings for more detailed guidance.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#bias-licensing-and-intellectual-property","level":3,"title":"Bias, Licensing, and Intellectual Property","text":"<p>Training Data Considerations</p> <p>AI models are trained on public code repositories, which may contain:</p> <ul> <li>Biased implementations (non-inclusive variable names, accessibility issues)</li> <li>Licensed code that may not be suitable for your use case</li> <li>Outdated patterns or deprecated approaches</li> <li>Security vulnerabilities from historical code</li> </ul> <p>Best Practices:</p> <ul> <li>Review generated code for inclusive language and accessibility</li> <li>Check license compatibility for suggested libraries</li> <li>Validate that patterns are current and recommended</li> <li>Don't assume AI-generated code is \"best practice\"</li> </ul> <p>Intellectual Property</p> <ul> <li>Most AI providers claim no copyright on generated output</li> <li>However, generated code might inadvertently replicate existing licensed code</li> <li>Your organization may have policies about AI-generated code ownership</li> <li>Document when and how AI tools were used in development</li> </ul>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#privacy-and-data-handling","level":3,"title":"Privacy and Data Handling","text":"<p>What Data Gets Sent to AI Services?</p> <ul> <li>Your prompts and code snippets</li> <li>File contents (with MCP or when explicitly shared)</li> <li>Error messages and terminal output</li> <li>Project structure and metadata</li> </ul> <p>Privacy Best Practices:</p> <ul> <li>Don't share sensitive data, credentials, or personal information in prompts</li> <li>Review your organization's data classification policies</li> <li>Use local/self-hosted models for sensitive code when possible</li> <li>Be aware of data retention policies for AI services you use</li> <li>Consider anonymizing data before sharing with AI tools</li> </ul> <p>Tools with Enhanced Privacy:</p> <ul> <li>Cline and Roo Code: Can use local models via Ollama</li> <li>Aider and OpenCode.ai: Supports local LLMs</li> <li>Claude Desktop with MCP: Data processing happens locally before being sent to API</li> </ul>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#accessibility-and-inclusive-development","level":3,"title":"Accessibility and Inclusive Development","text":"<p>Use AI to Improve Accessibility</p> <ul> <li>Ask AI to review code for WCAG compliance</li> <li>Generate accessible alternatives for visual content</li> <li>Check color contrast and screen reader compatibility</li> <li>Implement keyboard navigation</li> </ul> <p>Avoid Perpetuating Bias</p> <ul> <li>Review generated variable names and comments for inclusive language</li> <li>Ask AI to suggest alternatives if you spot problematic patterns</li> <li>Consider diverse user needs when prompting for UI/UX implementations</li> </ul>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#environmental-considerations","level":3,"title":"Environmental Considerations","text":"<p>AI Compute Costs</p> <ul> <li>LLM inference requires significant energy</li> <li>Be mindful of unnecessary requests</li> <li>Use appropriate model sizes (don't use GPT-4 for simple autocomplete)</li> <li>Cache results when possible</li> <li>Consider carbon-aware computing practices</li> </ul>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#continuous-learning","level":3,"title":"Continuous Learning","text":"<p>Stay Updated</p> <ul> <li>AI coding tools evolve rapidly</li> <li>Follow release notes and changelogs</li> <li>Experiment with new features in safe environments</li> <li>Join communities and share learnings</li> <li>Read our Vibe Coding guide regularly for updates</li> </ul> <p>Develop AI Literacy</p> <ul> <li>Understand how LLMs work and their limitations</li> <li>Learn about prompt engineering techniques</li> <li>Recognize when AI is appropriate vs. when human expertise is needed</li> <li>Share knowledge with your team</li> </ul> <p>The Human-AI Partnership</p> <p>The goal isn't to replace developers with AI—it's to augment human capabilities. The best results come from combining AI's pattern recognition and code generation with human creativity, domain expertise, and critical thinking. Use AI as a powerful tool, but keep your judgment and expertise at the center of development decisions.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#4-choosing-the-right-tool-for-your-workflow","level":2,"title":"4. Choosing the Right Tool for Your Workflow","text":"<p>With dozens of AI coding tools available, selecting the right one depends on your needs, environment, and workflow preferences.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#decision-framework","level":3,"title":"Decision Framework","text":"<p>Exploratory Data Analysis → Code Interpreters: Claude, Gemini, ChatGPT Plus</p> <p>Learning to Code → Code Interpreters or Browser-Based Tools</p> <p>Professional Software Development → Agentic IDE Tools: Cursor, Windsurf, Claude Code, Cline</p> <p>Need MCP Integration → Claude Desktop or Claude Code CLI</p> <p>Enterprise/Team Development → GitHub Copilot or Cursor Team</p> <p>Privacy-Sensitive Projects → Cline or Aider with local models</p> <p>Multi-Language Projects → Claude Code or Cursor (excellent multi-language support)</p> <p>Terminal-First Workflow → Aider or Claude Code CLI</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#integration-with-your-workflow","level":3,"title":"Integration with Your Workflow","text":"<p>For Researchers:</p> <ul> <li>Start with Code Interpreters for data analysis</li> <li>Progress to Claude Desktop with MCP for accessing research databases</li> <li>Use Vibe Coding tools for reproducible research code</li> </ul> <p>For Students:</p> <ul> <li>Begin with sandboxed interpreters to learn safely</li> <li>Experiment with browser-based tools for homework</li> <li>Transition to IDE extensions as skills develop</li> </ul> <p>For Professional Developers:</p> <ul> <li>Choose agentic tools based on your IDE preference</li> <li>Leverage MCP for project-specific integrations</li> <li>Follow security best practices rigorously</li> </ul> <p>For Teams:</p> <ul> <li>Standardize on enterprise tools with centralized billing</li> <li>Establish code review processes for AI-generated code</li> <li>Document policies on AI tool usage and data sharing</li> </ul>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#5-the-path-forward-vibe-coding-and-beyond","level":2,"title":"5. The Path Forward: Vibe Coding and Beyond","text":"<p>This lesson introduced the landscape of AI-powered code generation and execution. You've learned about:</p> <ul> <li>Code Interpreters for safe, sandboxed analysis</li> <li>Code Execution Frameworks for IDE integration</li> <li>Best practices for security, privacy, and responsible use</li> <li>Tool selection based on your needs</li> </ul>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#next-steps","level":3,"title":"Next Steps","text":"<p>Ready to Start Vibe Coding?</p> <p>Now that you understand the foundations, dive deeper into hands-on AI-assisted development:</p> <p> Explore Vibe Coding Learn how to set up and use modern agentic coding tools in your preferred development environment.</p> <p> Understand Model Context Protocol (MCP) Discover how MCP enables deep integration between AI and your development tools, enabling sophisticated agentic behaviors.</p> <p> Learn About Agentic AI Understand the principles behind autonomous AI systems and how they're transforming software development.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#recommended-learning-path","level":3,"title":"Recommended Learning Path","text":"<ol> <li>Experiment with Code Interpreters (30 minutes)</li> <li>Try Claude, Gemini, or ChatGPT Plus</li> <li>Upload a dataset and perform analysis</li> <li> <p>Get comfortable with natural language coding</p> </li> <li> <p>Install a Vibe Coding Tool (1 hour)</p> </li> <li>Follow our Vibe Coding setup guide</li> <li>Start with Claude Code or Cursor</li> <li> <p>Try basic code generation and editing</p> </li> <li> <p>Explore MCP Integration (1-2 hours)</p> </li> <li>Set up Claude Desktop with MCP</li> <li>Connect to filesystem and GitHub servers</li> <li> <p>Experience context-aware assistance</p> </li> <li> <p>Practice Best Practices (Ongoing)</p> </li> <li>Review all AI-generated code</li> <li>Develop your prompting skills</li> <li> <p>Learn from successes and failures</p> </li> <li> <p>Build Real Projects (Weeks to months)</p> </li> <li>Apply AI assistance to actual work</li> <li>Develop your AI collaboration style</li> <li>Share learnings with your community</li> </ol>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#staying-current","level":3,"title":"Staying Current","text":"<p>The AI coding landscape evolves rapidly. Stay informed:</p> <ul> <li>Follow tool announcements and changelogs</li> <li>Join developer communities (Discord, Reddit, forums)</li> <li>Experiment with new features in safe environments</li> <li>Read our Vibe Coding guide for regular updates</li> <li>Check MCP documentation for new server integrations</li> </ul>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#assessment","level":2,"title":"Assessment","text":"What is the primary difference between a sandboxed Code Interpreter (like in ChatGPT) and a Code Execution Framework (like GitHub Copilot in VS Code)? Answer <p>A sandboxed Code Interpreter runs code in a secure, isolated environment provided by the service, disconnected from your local machine. A Code Execution Framework integrates into your local IDE and can read, modify, and execute files directly on your computer.</p> True or False: Code generated by an AI assistant is guaranteed to be secure and free of errors. False <p>AI-generated code can contain bugs, security vulnerabilities, and biases from its training data. It is crucial to always review, test, and validate any code before using it in a production environment.</p> Which of the following tasks is best suited for a sandboxed Code Interpreter? <ol> <li>Refactoring a large, existing codebase in your project.</li> <li>Quickly analyzing a CSV file you upload to generate a plot.</li> <li>Building and running a web server on your local machine.</li> <li>Continuously providing autocompletions as you type in your IDE.</li> </ol> Correct Answer: 2 <p>Sandboxed interpreters excel at self-contained tasks involving data you can upload, like analyzing a file. The other tasks are better suited for AI tools integrated directly into a local IDE.</p> True or False: Using an open-source Code Execution Framework like Cline or Aider allows you to use locally-run LLMs (e.g., via Ollama) instead of relying on cloud-based APIs. True <p>One of the key advantages of many open-source tools is flexibility. They often allow you to connect to various LLM backends, including models running on your own hardware, giving you more control over privacy and cost.</p> Which technology enables AI agents to access your local file system, run terminal commands, and interact with external tools? <ol> <li>Code Interpreters</li> <li>Model Context Protocol (MCP)</li> <li>Function calling</li> <li>Extended context windows</li> </ol> Correct Answer: 2 <p>Model Context Protocol (MCP) is the standardized communication framework that allows AI agents to interact with local tools, file systems, databases, and external services. While function calling is related, MCP provides the comprehensive protocol for deep integration.</p> What is the main security concern when using agentic AI systems that execute code locally? Answer <p>Agentic AI systems with local execution have access to your file system, network, terminal, and environment variables. They can read, modify, or delete files, execute arbitrary commands, and potentially access sensitive credentials. Always review commands before execution, follow your organization's security policies, and avoid storing secrets in code.</p> Which workflow would be BEST suited for a sandboxed Code Interpreter rather than an agentic IDE tool? <ol> <li>Refactoring a large codebase with coordinated changes across multiple files</li> <li>Analyzing a CSV dataset you upload to generate statistical plots</li> <li>Setting up automated testing and CI/CD for a project</li> <li>Debugging a complex application with multiple service dependencies</li> </ol> Correct Answer: 2 <p>Sandboxed Code Interpreters excel at self-contained tasks with uploaded data, like analyzing a dataset. The other tasks require multi-file awareness, local tool integration, and persistent development workflows—all better suited for agentic IDE tools.</p> True or False: AI-generated code should always be considered \"best practice\" since models are trained on vast amounts of code from expert developers. False <p>AI models are trained on public code repositories that may contain outdated patterns, security vulnerabilities, biased implementations, and code that violates best practices. Always review AI-generated code critically, test thoroughly, and verify it meets current standards and your specific requirements.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"copilot/","level":1,"title":"GitHub Copilot","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Setup","GitHub Copilot"],"tags":[]},{"location":"copilot/#create-a-github-account","level":2,"title":"Create a GitHub Account","text":"<ul> <li> <p>GitHub Account: You need a GitHub account to use GitHub Copilot. Sign up here</p> </li> <li> <p>GitHub Education As a university faculty or staff, you can enroll as an educator through GitHub's Education space. As a student, you can also get access to GitHub features, like Codespaces and Classroom.</p> </li> <li> <p>Supported IDE: You'll need a compatible IDE. Currently, the most popular supported IDEs are:</p> <ul> <li>Visual Studio Code (VS Code)</li> <li>Neovim</li> <li>JetBrains IDEs (IntelliJ IDEA, PyCharm, WebStorm, etc.)</li> <li>Visual Studio</li> </ul> </li> <li>GitHub Copilot Subscription: GitHub Copilot is a paid service. You'll need an active subscription to use it. There are plans for individuals and businesses. There is a limited free trial so you can try it out. GitHub Copilot is free for verified students and maintainers of popular open source projects on GitHub.</li> </ul>","path":["Setup","GitHub Copilot"],"tags":[]},{"location":"copilot/#installation-and-setup","level":2,"title":"Installation and Setup","text":"<p>The installation process varies slightly depending on your IDE. Here's a general overview:</p> <p>Visual Studio Code (VS Code):</p> <ul> <li> <p>Install the Extension:</p> <ol> <li> <p>Open VS Code on your local or virtual machine.</p> </li> <li> <p>Go to the Extensions Marketplace (click the Extensions icon in the Activity Bar on the side of the window or press <code>Ctrl+Shift+X</code> / <code>Cmd+Shift+X</code>).</p> </li> <li> <p>Search for \"GitHub Copilot\".</p> </li> <li> <p>Click \"Install\" on the official GitHub Copilot extension.</p> </li> </ol> </li> <li> <p>Sign in to GitHub:</p> <ul> <li>You'll be prompted to sign in to GitHub to authorize the extension. Follow the on-screen instructions.</li> </ul> </li> </ul> <p>Visual Studio:</p> <ul> <li> <p>Install the Extension:</p> <p>Open Visual Studio.</p> <p>Go to <code>Extensions</code> &gt; <code>Manage Extensions</code>.</p> <p>Search for \"GitHub Copilot\" in the online tab.</p> <p>Click \"Download\" and follow the prompts to install it. Restart Visual Studio when done.</p> </li> <li> <p>Sign in to GitHub: You will need to sign in to your GitHub account to authorize the extension.</p> </li> </ul>","path":["Setup","GitHub Copilot"],"tags":[]},{"location":"daily-productivity/","level":1,"title":"General Productivity","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p></p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#when-to-use-a-gpt","level":2,"title":"When to use a GPT","text":"<p>About AI Model Names and Capabilities</p> <p>Throughout this document, you'll see references to specific AI models and platforms (ChatGPT, Gemini, Copilot, Claude). Model names, versions, and capabilities evolve frequently as AI technology advances. The examples provided demonstrate general capabilities that may be available across multiple platforms, though specific features and integration options vary by provider and subscription level.</p> <p>Prompt engineering can significantly enhance your productivity. In particular when Enterprise GPTs are integrated into your Microsoft Office Suite or Google Drive, and have secure access to your documents and data, GPTs can be used to:</p> <ul> <li>Draft Emails and manage inboxes: Automate the creation of routine emails, summarize long email threads, and even prioritize your inbox based on sender and content.</li> <li>Meeting Summarization: Quickly get the gist of meeting transcripts, identify action items, and track decisions made.</li> <li>Task Prioritization and Planning: Organize tasks based on urgency and importance, create daily or weekly schedules, and set reminders.</li> <li>Content Creation and Brainstorming: Generate ideas for articles, blog posts, social media content, and marketing campaigns.</li> <li>Language Translation: Translate documents or conversations in real-time, facilitating communication with international colleagues or clients.</li> <li>Learning and Skill Development: Get quick explanations of complex topics, find learning resources, and even practice new skills through simulated scenarios.</li> </ul> <p>In our  Code Interpreter lesson we discuss how GPTs can be used for:</p> <ul> <li>Code Generation and Debugging: Write basic code snippets, find and fix bugs in existing code, and understand complex code segments.</li> <li>Data Analysis and Interpretation: Summarize datasets, identify trends, and generate reports from raw data.</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#meeting-summary","level":2,"title":"Meeting Summary","text":"<p> AI Companion, along with other AI-powered meeting summary tools, can significantly boost productivity by automating note-taking and extracting key information from meetings. To effectively use these tools, it's important to understand best practices and institutional policies.</p> <p>Getting Started and Optimizing Use</p> <p>Begin by ensuring that the AI Companion feature is enabled in your Zoom settings. You can customize settings, such as choosing between brief and detailed summaries or specifying keywords for emphasis. </p> <p>Before meetings, set clear agendas to provide context for the AI. </p> <p>During the meeting, speak clearly, emphasize important terms, and encourage active participation to enrich the AI's analysis. </p> <p>While in a meeting you can ask the AI Companion for a summary or specific details, for example, \"Has a decision been made about X?\". </p> <p>After a meeting ends, Zoom will send an email summary to the host, which can be edited and shared with participants. </p> <p>Zoom can also highlight key parts of the meeting recording, or break down the recording into smart chapters.</p> <p>Institutional Policies and Data Security</p> <p>It's crucial to adhere to institutional policies regarding the use of AI tools in official communications. </p> <p>Only use approved plug-ins such as Zoom AI Companion. </p> <p>Third-party software may not comply with the university's data security and privacy requirements. </p> <p>Using unapproved third-party AI tools can pose significant risks. </p> <p>Unofficial tools may Compromise Data Security -- they may store or process meeting data on external servers without adequate security measures, potentially exposing sensitive information to breaches. </p> <p>Violate Data Privacy -- they might not adhere to data privacy regulations or institutional policies regarding the handling of personal and confidential data, such as student FERPA.</p> <p>Lack of Accountability: The university may have limited recourse or control over third-party vendors in case of data breaches or misuse.</p> <p>Integration Issues: 3<sup>rd</sup> party plug-ins may not integrate seamlessly with existing university systems, leading to inefficiencies and compatibility problems.</p> <p>Therefore, to maintain data security, privacy, and compliance with institutional policies, it is essential to use only officially sanctioned AI tools and plug-ins provided or approved by the university for official communication. Always consult your institution's IT department or relevant policies for guidance on approved tools and their proper usage.</p> <p> ChatGPT integrations</p> <p>ChatGPT Plus and Pro versions offer multiple integrations to enhance productivity:</p> <ul> <li>Cloud Storage: Microsoft OneDrive and Google Drive integrations allow you to attach documents directly to prompts</li> <li>Canvas: A collaborative workspace for writing and coding projects with iterative editing</li> <li>Memory: Remembers preferences and context across conversations for personalized assistance</li> <li>Custom GPTs: Access specialized GPTs from the GPT Store or create your own for specific workflows</li> <li>Plugins: Extend functionality with third-party tools (calendar, web browsing, data analysis, etc.)</li> </ul> <p>Make certain these integrations meet University security requirements</p> <p>Never submit student information, private conversations (Zoom AI Summaries), or other sensitive information through ChatGPT unless using a University of Arizona Enterprise license.</p> <p> Microsoft Copilot integration in Microsoft Office 365</p> <p>University of Arizona officially uses Microsoft Office Online for office productivity. This includes integration with Microsoft Copilot into Office 365.</p> <p>Microsoft Copilot features are available through the https://m365.cloud.microsoft/ domain and directly within Microsoft 365 applications.</p> <p>Access to Copilot features may be controlled by your department or UITS. If you need access, contact your department's system administrator. </p> <p> Google Gemini integration in Google Workspaces</p> <p>University of Arizona continues to have access to Google Workspace, but may be limited by your department or UITS.</p> <p>Google for Education also has integration with Gemini, which needs to be authorized by a system administrator. </p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#chat-use-cases","level":2,"title":"Chat Use Cases","text":"","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#example-1-personal-planner","level":3,"title":"Example 1: Personal Planner","text":"<p>Suppose you're using an AI assistant as a personal planner. This prompt involves three tasks: retrieving calendar data, creating an itinerary, and arranging tasks based on priority.</p> Planning your day <p>Prompt:</p> <pre><code>I need your help planning my day tomorrow.\nFirst, please list all my scheduled meetings and deadlines from my calendar.\nThen, taking into account 2 hours of break time, could you suggest a time-managed itinerary for me?\nLastly, based on the priority of the tasks, can you create a task list in the order I should tackle them?\n</code></pre> <p>Response:</p> <p>I would be happy to help you plan your day, but I need to clarify something first: I do not currently have access to your calendar or scheduling system.</p> <p>To help you effectively, please share: - Your scheduled meetings and their times - Any deadlines you have tomorrow - Tasks you need to complete - Your preferred working hours (e.g., 8 AM - 6 PM)</p> <p>Once you provide this information, I will:</p> <ol> <li>Organize your schedule with meetings as fixed anchor points</li> <li>Create a time-blocked itinerary that includes your 2 hours of break time strategically placed (ideally after cognitively demanding tasks and around lunch)</li> <li>Prioritize your tasks using the Eisenhower Matrix approach (urgent/important, important/not urgent, etc.)</li> </ol> <p>Alternatively, if you are using a platform with calendar integration enabled (such as Microsoft Copilot with Outlook, Google Gemini with Google Calendar, or a ChatGPT calendar plugin), you can use this same prompt there for automatic calendar access.</p> <p>Would you like to share your schedule details so I can create a personalized plan?</p> <p>Calendar Integration Availability</p> <p>Modern AI assistants offer varying levels of calendar integration. Here's how to enable calendar access for each platform:</p> <p> Microsoft Copilot with Microsoft 365</p> <ul> <li>Requirements: Enterprise Microsoft 365 account with Copilot access</li> <li>Setup: Calendar integration is enabled by default for M365 Copilot users</li> <li>Access: Available through m365.cloud.microsoft or Copilot in Outlook</li> <li>Note: Access may be controlled by your department or UITS administrator</li> </ul> <p> ChatGPT Plus/Pro Calendar Plugins</p> <ul> <li>Requirements: ChatGPT Plus or Pro subscription</li> <li>Setup:<ol> <li>Open ChatGPT and start a new chat</li> <li>Click the GPT Store icon or search for calendar plugins</li> <li>Install \"Google Calendar\" or \"Outlook Calendar\" plugin</li> <li>Authorize the plugin to access your calendar</li> </ol> </li> <li>Limitations: Plugin availability may change; check the GPT Store for current options</li> </ul> <p> Google Gemini with Google Workspace</p> <ul> <li>Requirements: Google One AI Premium subscription or Google Workspace account</li> <li>Setup: Calendar integration is built-in when signed in with a Google account</li> <li>Access: Available at gemini.google.com</li> <li>Note: May require system administrator authorization for Google Workspace for Education accounts</li> </ul> <p> Claude Desktop with MCP Calendar Server</p> <ul> <li>Requirements: Claude Pro subscription and Claude Desktop app</li> <li>Setup:<ol> <li>Install Claude Desktop from claude.ai/download</li> <li>Configure MCP server in Settings → Developer → Model Context Protocol</li> <li>Add Google Calendar MCP server (requires API credentials)</li> <li>See modelcontextprotocol.io for configuration details</li> </ol> </li> <li>Note: Requires technical setup; consult MCP documentation</li> </ul> <p>University Data Security</p> <p>When integrating calendar access with AI assistants:</p> <ul> <li>Only use platforms approved by your institution for university-related calendars</li> <li>Never share calendars containing FERPA-protected student information through non-enterprise AI tools</li> <li>Review your institution's IT policies before enabling calendar integrations</li> <li>Use enterprise/education licenses rather than personal accounts when available</li> </ul> <p>For University of Arizona users, consult UITS policies and use officially sanctioned integrations (primarily Microsoft 365 Copilot).</p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#example-2-drafting-emails-with-ai","level":3,"title":"Example 2: Drafting Emails with AI","text":"<p>Modern email platforms include built-in AI assistants that can help you draft, refine, and improve your emails directly within your email client. This is especially useful for composing professional messages, summarizing information, or adjusting tone.</p> Drafting emails with AI assistance Microsoft Copilot (Outlook Online - UA Users)Google Gmail (Non-UA Users) <p>Accessing Copilot in Outlook:</p> <p>University of Arizona users have access to Microsoft Copilot through Office 365 Online.</p> <ol> <li>Go to outlook.office.com and sign in with your UA NetID</li> <li>Click \"New mail\" to start composing an email</li> <li>In the compose window, look for the Copilot icon (sparkle/star icon) in the toolbar</li> <li>Click the Copilot icon and select \"Draft with Copilot\"</li> </ol> <p>Example: Meeting Recap Email</p> <p>Copilot Prompt:</p> <pre><code>Draft an email to my team summarizing today's meeting. Include:\n- New project timeline with July 30th deadline\n- Weekly client status updates rotating among team members\n- Brainstorming session next Wednesday for marketing strategies\n- Reminder to submit expense reports by Friday\nUse a professional but friendly tone.\n</code></pre> <p>Copilot Generated Email:</p> <p>Subject: Meeting Recap - Action Items and Next Steps</p> <p>Hi Team,</p> <p>Thank you for your participation in today's productive meeting. Here's a summary of our key decisions and action items:</p> <p>Project Timeline We've finalized our project timeline with a deadline of July 30<sup>th</sup>. Please align your deliverables with this date and flag any potential conflicts early.</p> <p>Client Status Updates Our client has requested weekly status updates. We'll implement a rotating schedule—details on assignments will be shared shortly. Each team member will draft and send updates during their assigned week.</p> <p>Marketing Strategy Session We'll hold a brainstorming session next Wednesday to develop new marketing strategies. Please come prepared with ideas to share.</p> <p>Expense Reports Reminder: Submit all expense reports by end of day Friday.</p> <p>Please reach out if you have questions or need clarification.</p> <p>Best regards</p> <p>Refining with Copilot:</p> <p>After Copilot generates the draft, you can:</p> <ul> <li>Click \"Regenerate\" for a different version</li> <li>Click \"Adjust tone\" to make it more formal or casual</li> <li>Click \"Make it shorter\" or \"Make it longer\"</li> <li>Manually edit the text and ask Copilot to \"Improve selected text\"</li> </ul> <p>Copilot Features in Outlook</p> <ul> <li>Draft with Copilot: Generate emails from prompts</li> <li>Coaching by Copilot: Get suggestions for tone, clarity, and sentiment</li> <li>Summarize: Condense long email threads</li> <li>Available to: All UA students, faculty, and staff through Office 365</li> </ul> <p>Accessing \"Help me write\" in Gmail:</p> <p>Gmail's AI writing assistant is available to Google Workspace users and some personal Gmail accounts.</p> <ol> <li>Go to mail.google.com</li> <li>Click \"Compose\" to start a new email</li> <li>Look for the \"Help me write\" icon (sparkle icon with pen) in the compose window</li> <li>Click the icon to open the AI writing assistant</li> </ol> <p>Example: Meeting Recap Email</p> <p>Gmail Prompt:</p> <pre><code>Write a professional email to my team summarizing our meeting today:\n- New deadline: July 30th\n- Weekly client updates will rotate among team\n- Marketing brainstorming session next Wednesday\n- Expense reports due this Friday\n</code></pre> <p>Gmail Generated Email:</p> <p>Subject: Today's Meeting - Key Takeaways</p> <p>Hi team,</p> <p>Thanks for a great meeting today. Here are the key points we discussed:</p> <p>New Project Deadline: We've set a firm deadline of July 30<sup>th</sup> for project completion. Please ensure all your work aligns with this timeline.</p> <p>Client Updates: Going forward, we'll provide weekly status updates to the client. We'll rotate responsibility for these updates among the team. More details on the rotation schedule coming soon.</p> <p>Marketing Brainstorm: We'll meet next Wednesday for a brainstorming session focused on new marketing strategies. Come ready to share your ideas!</p> <p>Expense Reports: Please submit your expense reports by end of day Friday.</p> <p>Let me know if you have any questions.</p> <p>Thanks,</p> <p>Refining with Gmail AI:</p> <p>After Gmail generates the draft, you can:</p> <ul> <li>Click \"Recreate\" to generate a new version</li> <li>Click \"Formalize\" to make it more professional</li> <li>Click \"Elaborate\" to add more details</li> <li>Click \"Shorten\" to make it more concise</li> <li>Manually edit and highlight text to ask for specific improvements</li> </ul> <p>Gmail AI Writing Features</p> <ul> <li>Help me write: Generate full email drafts from prompts</li> <li>Refine my draft: Improve tone, length, or formality</li> <li>Available to: Google Workspace users and select Gmail accounts</li> <li>Mobile: Also available in the Gmail mobile app</li> </ul> <p>Best Practices for AI-Drafted Emails</p> <ul> <li>Always review and edit: AI-generated emails should be reviewed for accuracy and appropriateness</li> <li>Verify facts: Check that all details (dates, names, numbers) are correct</li> <li>Personalize: Add personal touches that reflect your voice and relationship with recipients</li> <li>Sensitive content: Avoid using AI for highly sensitive, confidential, or legally significant emails</li> <li>Privacy: Don't include confidential information in prompts sent to AI services</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#advanced-research-capabilities","level":2,"title":"Advanced Research Capabilities","text":"<p>Modern AI platforms offer sophisticated research capabilities that go far beyond simple web searches. Four notable approaches are Extended Thinking (available in Claude Opus 4.5), Deep Research (available in Google Gemini Pro 3.0 and ChatGPT), and Google Scholar Labs (an experimental AI-powered academic search tool). Understanding when and how to use these features can dramatically improve your research productivity.</p> <p>What Are Extended Thinking, Deep Research, and Scholar Labs?</p> <p>Extended Thinking (Claude Opus 4.5) allows the AI to engage in deeper, more deliberate reasoning before responding. Instead of generating an immediate answer, Claude \"thinks through\" complex problems step-by-step, similar to how a researcher might work through a difficult problem on a whiteboard before presenting conclusions.</p> <p>Deep Research (Google Gemini Pro 3.0 and ChatGPT) is an agentic research mode where the AI autonomously searches the web, reads multiple sources, synthesizes information, and produces comprehensive research reports. Both platforms can spend several minutes gathering and analyzing information before delivering results:</p> <ul> <li>Gemini Deep Research: Produces longer, more formal research reports (~3,500+ words) with extensive sources including news, policy, and academic literature</li> <li>ChatGPT Deep Research: Produces concise academic syntheses (~1,000 words) with focus on consensus findings and numerical data from peer-reviewed sources</li> </ul> <p>Google Scholar Labs is an experimental AI-powered search assistant specifically designed for academic research. Unlike traditional keyword-based search, it analyzes complex research questions, identifies key relationships, and surfaces papers based on how well they answer your overall question rather than simple keyword matches.</p> <p>All these approaches are designed for tasks that benefit from sustained, careful analysis rather than quick responses.</p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#extended-thinking-with-claude-opus-45","level":4,"title":"Extended Thinking with Claude Opus 4.5","text":"<p>Extended Thinking is particularly valuable when you need the AI to work through complex reasoning, analyze nuanced problems, or consider multiple perspectives before responding. When enabled, Claude shows you its \"thinking\" process, making its reasoning transparent and verifiable.</p> <p>When to use Extended Thinking:</p> <ul> <li>Complex analytical problems requiring multi-step reasoning</li> <li>Evaluating arguments with competing perspectives</li> <li>Technical problem-solving where you need to see the reasoning process</li> <li>Research design and methodology questions</li> <li>Ethical dilemmas with multiple stakeholder considerations</li> </ul> Using Extended Thinking for research methodology <p>Scenario: You are designing a mixed-methods study on faculty adoption of AI tools in teaching and want Claude to help you think through potential methodological challenges.</p> <p>Prompt:</p> <pre><code>I'm designing a mixed-methods study to investigate how faculty at research universities\nare integrating generative AI tools into their teaching practices. The study will combine\nsurveys with semi-structured interviews.\n\nPlease think carefully about the methodological challenges I might face and how to\naddress them. Consider issues of sampling, bias, validity, and the rapidly changing\nnature of AI technology.\n</code></pre> <p>Claude's Extended Thinking Process (visible to you):</p> <p>Let me think through this systematically...</p> <p>First, sampling challenges: Faculty who respond to surveys about AI might be those already interested in technology - this creates self-selection bias. Also, \"research universities\" varies widely - R1 vs R2, public vs private, STEM-heavy vs liberal arts...</p> <p>The temporal dimension is tricky. AI tools are evolving so rapidly that practices from even 6 months ago may be obsolete. Interview data collected in January might not reflect practices by the time the study is published...</p> <p>Validity concerns: Faculty might overreport AI use due to social desirability, or underreport due to institutional policies they're uncertain about...</p> <p>Claude's Response:</p> <p>Your study design faces several interconnected methodological challenges. Here is my analysis with recommendations:</p> <p>1. Sampling and Selection Bias</p> <ul> <li>Challenge: Faculty who volunteer for AI-related studies likely skew toward early adopters, creating non-representative samples</li> <li>Mitigation: Use stratified sampling across disciplines, rank, and known technology adoption patterns. Consider incentivizing participation from technology-hesitant faculty. Partner with faculty development offices who can facilitate broader recruitment</li> </ul> <p>2. Temporal Validity</p> <ul> <li>Challenge: The AI landscape evolves monthly. Data collected now may not reflect practices 6-12 months later when you publish</li> <li>Mitigation: Explicitly timestamp your data collection period. Frame findings as capturing a specific moment in a trajectory. Consider a longitudinal design with follow-up interviews. Focus on underlying adoption patterns rather than specific tool usage</li> </ul> <p>3. Social Desirability and Institutional Climate</p> <ul> <li>Challenge: Faculty may underreport AI use if uncertain about institutional policies, or overreport to appear innovative</li> <li>Mitigation: Ensure anonymity in surveys. In interviews, normalize both adoption and non-adoption. Include questions about institutional climate and policy clarity. Consider asking about colleague practices (indirect questioning)</li> </ul> <p>4. Defining Key Constructs</p> <ul> <li>Challenge: \"Integration into teaching\" could mean anything from using ChatGPT for lecture prep to teaching students prompt engineering</li> <li>Mitigation: Develop a clear taxonomy of AI use in teaching. Pilot your definitions with faculty before full deployment. Include behavioral anchors in survey questions</li> </ul> <p>5. Mixed-Methods Integration</p> <ul> <li>Recommendation: Use an explanatory sequential design - let quantitative findings guide interview protocol development. This allows you to probe unexpected survey results and achieve genuine triangulation</li> </ul> <p>Would you like me to elaborate on any of these areas or help develop specific survey items?</p> <p>Enabling Extended Thinking</p> <p>In Claude (claude.ai or Claude Desktop):</p> <ul> <li>Extended Thinking is available with Claude Opus 4.5 for Pro subscribers</li> <li>Click the model selector and choose \"Claude Opus 4.5\"</li> <li>For complex problems, Claude may automatically engage in extended thinking</li> <li>You can encourage deeper reasoning by asking Claude to \"think carefully\" or \"reason through this step-by-step\"</li> <li>The thinking process appears in a collapsible section above the response</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#deep-research-with-google-gemini-pro-30","level":4,"title":"Deep Research with Google Gemini Pro 3.0","text":"<p>Deep Research transforms Gemini into an autonomous research assistant that can spend several minutes (sometimes longer) exploring a topic across the web. Rather than providing an instant response, Gemini creates a research plan, searches multiple sources, reads and analyzes content, and synthesizes findings into a comprehensive report.</p> <p>When to use Deep Research:</p> <ul> <li>Literature reviews and background research</li> <li>Investigating unfamiliar topics where you need comprehensive coverage</li> <li>Comparing multiple products, policies, or approaches</li> <li>Fact-finding missions requiring multiple authoritative sources</li> <li>Preparing for grant proposals or comprehensive reports</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#google-scholar-labs","level":4,"title":"Google Scholar Labs","text":"<p>Google Scholar Labs represents a new approach to academic literature search by using AI to understand the multidimensional nature of research questions. Rather than treating your query as a simple keyword search, Scholar Labs analyzes your question, identifies key topics and relationships, and surfaces papers based on their relevance to your overall research question.</p> <p>When to use Scholar Labs:</p> <ul> <li>Literature reviews requiring nuanced understanding of research questions</li> <li>Exploring connections between different research areas or methodologies</li> <li>Finding papers that address specific aspects of complex research questions</li> <li>Discovering relevant work that might not use your exact keywords</li> <li>Getting contextual summaries explaining why each paper is relevant</li> </ul> Using Scholar Labs for a literature review <p>Scenario: You're preparing a literature review for your dissertation on the effectiveness of peer-led instruction in undergraduate STEM courses.</p> <p>Research Question:</p> <pre><code>What evidence exists about the effectiveness of peer-led instruction (also called\npeer-led team learning or PLTL) in improving learning outcomes for underrepresented\nstudents in undergraduate STEM courses, particularly in gateway courses like\nintroductory biology, chemistry, and physics?\n</code></pre> <p>What Scholar Labs Does:</p> <p>Instead of searching for papers that simply contain \"peer-led instruction\" and \"underrepresented students,\" Scholar Labs:</p> <ol> <li>Analyzes the question to identify multiple dimensions:</li> <li>Instructional method: peer-led instruction, PLTL, peer learning</li> <li>Population: underrepresented students, diversity in STEM</li> <li>Context: undergraduate, gateway courses, introductory science</li> <li> <p>Outcomes: learning effectiveness, academic performance, retention</p> </li> <li> <p>Searches comprehensively across these dimensions simultaneously</p> </li> <li> <p>Surfaces relevant papers even if they use different terminology (e.g., \"supplemental instruction,\" \"peer teaching,\" \"collaborative learning\")</p> </li> </ol> <p>Example Results:</p> <p>Scholar Labs might return papers with contextual descriptions like:</p> <ul> <li> <p>\"Peer-Led Team Learning in General Chemistry: Implementation and Evaluation\" (Wilson &amp; Varma-Nelson, 2016)   This paper reports on PLTL effectiveness in a gateway chemistry course and includes disaggregated data showing differential impacts for first-generation college students.</p> </li> <li> <p>\"Supplemental Instruction and the Performance of Hispanic Students in Developmental Mathematics\" (Peterfreund et al., 2007)   While using different terminology (\"supplemental instruction\"), this paper addresses peer-led learning with a specific focus on Hispanic students in a foundational STEM course.</p> </li> <li> <p>\"The Role of Near-Peer Mentoring in STEM Persistence for Underrepresented Students\" (Johnson &amp; Stage, 2018)   This study examines peer mentorship structures in biology courses, providing insights into mechanisms that make peer-led instruction effective for underrepresented students.</p> </li> </ul> <p>Follow-up Questions:</p> <p>Scholar Labs allows you to ask follow-up questions to narrow or expand your search:</p> <pre><code>Which of these studies include control groups and experimental designs rather than\nobservational studies?\n</code></pre> <pre><code>Are there any meta-analyses or systematic reviews synthesizing this evidence?\n</code></pre> <pre><code>What critiques or limitations have researchers identified about peer-led instruction\nfor diverse student populations?\n</code></pre> <p>Accessing Google Scholar Labs</p> <p>Google Scholar Labs is currently experimental (as of January 2026):</p> <ul> <li>Visit https://scholar.google.com/scholar_labs/search</li> <li>Requires logging in with a Google account</li> <li>Currently available to limited users; you may need to join a waitlist</li> <li>Currently supports English-language questions only</li> <li>Results retain all familiar Google Scholar features (citations, \"cited by,\" related articles)</li> <li>You can ask follow-up questions to refine your search</li> </ul> <p>Scholar Labs Limitations</p> <p>As an experimental tool, Scholar Labs has some important limitations:</p> <ul> <li>No citation ranking: Scholar Labs deliberately ignores citation counts and journal prestige, ranking papers solely by relevance to your question. This can surface valuable but less-cited work, but you'll need to evaluate quality yourself</li> <li>Limited availability: Not all Google Scholar users have access yet</li> <li>Experimental status: Features and behavior may change as Google refines the tool</li> <li>Verification needed: Always read the actual papers—AI-generated summaries may mischaracterize findings</li> <li>Transparency: Unlike Deep Research, Scholar Labs doesn't show you its search process or all sources considered</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#comparing-the-research-approaches","level":4,"title":"Comparing the Research Approaches","text":"<p>Deep Research Availability</p> <p>Deep Research is available in both ChatGPT and Gemini. Both produce comprehensive research reports but differ in length and scope:</p> <ul> <li>ChatGPT Deep Research: Concise synthesis (~1,000 words), strong consensus focus</li> <li>Gemini Deep Research: Longer formal reports (~3,500+ words), broader source diversity</li> </ul> Aspect Extended Thinking (Claude) Deep Research (ChatGPT/Gemini) Scholar Labs (Google) Primary Purpose Deep reasoning and analysis Comprehensive information gathering Academic literature discovery Time Investment Seconds to minutes 3-10 minutes Seconds (instant results) Information Source Claude's training knowledge Live web searches Google Scholar database Best For Analytical problems, methodology, logic Literature reviews, fact-finding, comparisons Finding peer-reviewed research papers Output Style Reasoned analysis with visible thinking Research report with citations Ranked paper list with contextual summaries Verification Check reasoning logic Check source links Read actual papers Word Count Varies 1,000-3,500+ words N/A (paper list) Real-world comparison: Researching polar ice melt rates <p>To illustrate the differences between these research tools, here's a side-by-side comparison using the same research question across four different platforms: Scholar Labs, ChatGPT Deep Research, Gemini Deep Research, and Claude.</p> <p>Research Question:</p> <pre><code>Find recent and highly cited peer-reviewed articles from top-ranked journals that\nreport the rate of polar ice melt.\n</code></pre> Choosing the right approach <p>Use Extended Thinking when:</p> <ul> <li>You have a complex analytical question: \"What are the trade-offs between different approaches to measuring student engagement in online courses?\"</li> <li>You need to work through methodology: \"Help me think through the validity threats to my proposed quasi-experimental design.\"</li> <li>You want transparent reasoning: \"Analyze the arguments for and against requiring AI literacy in general education.\"</li> </ul> <p>Use Deep Research when:</p> <ul> <li>You need current information: \"What are the latest developments in AI-assisted grading tools?\"</li> <li>You want comprehensive coverage: \"Survey the landscape of open educational resources for teaching data science.\"</li> <li>You need citations and sources: \"Find recent studies on the effectiveness of flipped classroom approaches in STEM education.\"</li> </ul> <p>Use Scholar Labs when:</p> <ul> <li>You need peer-reviewed academic literature: \"Find recent research on the rate of polar ice melt from top-ranked journals.\"</li> <li>Your research question has multiple dimensions: \"What evidence exists about peer-led instruction effectiveness for underrepresented students in STEM gateway courses?\"</li> <li>You want papers that address your specific question rather than just containing keywords: \"How do community colleges support adult learners returning to higher education after career changes?\"</li> <li>You need to explore connections across subfields: \"What interdisciplinary research exists on climate change communication in K-12 education?\"</li> </ul> <p>Combine all three when:</p> <ul> <li>Start with Scholar Labs to find relevant peer-reviewed literature on your topic</li> <li>Use Deep Research to gather broader context, including grey literature, policy documents, and recent developments not yet in academic journals</li> <li>Apply Extended Thinking to synthesize findings, identify gaps, and develop your research questions or methodology</li> <li>Example workflow: Use Scholar Labs to find studies on AI in peer review → Use Deep Research to survey publisher policies and recent news → Use Extended Thinking to analyze the ethical implications and design interview questions for journal editors</li> </ul> <p>Verification and Critical Evaluation</p> <p>All three research tools are powerful but require critical evaluation:</p> <ul> <li>Extended Thinking: The reasoning may be flawed even when it appears logical. Verify key claims and check that the reasoning applies to your specific context</li> <li>Deep Research: Sources may be misinterpreted or selectively presented. Always click through to original sources for important claims</li> <li>Scholar Labs: AI-generated paper summaries may mischaracterize findings. Always read the actual papers, especially methodology and conclusions sections</li> <li>None replaces expertise: These tools augment research but cannot substitute for domain knowledge and scholarly judgment</li> <li>Cite appropriately: If using AI-generated research in academic work, follow your institution's guidelines for AI disclosure and citation</li> <li>Verify recency: Check publication dates—Scholar Labs and Deep Research may surface older work alongside recent studies</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#google-scholar-labs-results","level":3,"title":"Google Scholar Labs Results","text":"<p>Processing time: Instant (seconds) Output: 10 highly cited papers with contextual summaries</p> <p>Scholar Labs returned highly relevant papers with citation metrics and contextual summaries explaining why each is relevant to the query:</p> <p>Key papers found:</p> <ul> <li> <p>Otosaka et al. (2023) - Mass balance of the Greenland and Antarctic ice sheets from 1992 to 2020   Earth System Science Data · Cited by 196   Mass loss accelerated from 105 Gt/yr (1992-1996) to 372 Gt/yr (2016-2020)</p> </li> <li> <p>Edwards et al. (2021) - Projected land ice contributions to twenty-first-century sea level rise   Nature · Cited by 441   Limiting warming to 1.5°C would halve land ice contribution from 25 to 13 cm by 2100</p> </li> <li> <p>Hanna et al. (2024) - Short-and long-term variability of the Antarctic and Greenland ice sheets   Nature Reviews Earth &amp; Environment · Cited by 68   Total polar ice loss: -382 ± 42 Gt/year (2002-2022) = 1.1 mm/year SLE</p> </li> <li> <p>Greene et al. (2024) - Ubiquitous acceleration in Greenland Ice Sheet calving from 1985 to 2022   Nature · Cited by 35   AI-powered terminus mapping reveals 20% underestimate of Greenland mass loss</p> </li> <li> <p>Millan et al. (2023) - Rapid disintegration and weakening of ice shelves in North Greenland   Nature Communications · Cited by 35   North Greenland ice shelves lost 35% of volume since 1978</p> </li> </ul> <p>Strengths:</p> <ul> <li>✓ Instant results (seconds)</li> <li>✓ Citation counts immediately visible (\"Cited by 441\")</li> <li>✓ Contextual summaries explain why each paper is relevant</li> <li>✓ Direct links to PDFs and institutional library access</li> <li>✓ 100% peer-reviewed academic sources</li> <li>✓ Clean interface for literature discovery</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#gemini-deep-research-results","level":3,"title":"Gemini Deep Research Results","text":"<p>Processing time: ~5-15 minutes</p> <p>Output: Comprehensive research report (~3,500 words)</p> <p>View Full Gemini Deep Research Report</p> <p>Report Structure:</p> <ul> <li>Executive Abstract: High-level synthesis of cryospheric state and committed changes</li> <li>Methodological Convergence: Detailed explanation of GRACE, altimetry, and input-output methods</li> <li>Greenland Analysis: Greene et al. 20% underestimate, 2023 vs 2024 atmospheric variability, firn degradation</li> <li>Antarctic Analysis: WAIS committed collapse (van den Akker et al.), Thwaites tipping point, sea ice regime shift</li> <li>Global Teleconnections: AMOC impacts, New Zealand climate effects, Southern Hemisphere circulation</li> <li>Comparative Tables: Greenland metrics (2023-2025), polar ice sheet dynamics comparison</li> <li>25+ Citations: Nature, Science, The Cryosphere, PNAS, plus news and policy sources</li> </ul> <p>Strengths:</p> <ul> <li>✓ Formal research report structure with executive abstract</li> <li>✓ 25+ sources including academic papers, government reports, and news</li> <li>✓ Mathematical equations and technical depth</li> <li>✓ Comparative tables and data synthesis</li> <li>✓ Broader context (AMOC impacts, teleconnections, New Zealand climate)</li> <li>✓ Methodological explanations (GRACE vs. altimetry)</li> <li>✓ Export-ready format for grant proposals</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#claude-results","level":3,"title":"Claude Results","text":"<p>Processing time: 5-10 minutes (this example took 6 minutes)</p> <p>Output: Annotated bibliography with 23 papers organized thematically</p> <p>View Full Claude Annotated Bibliography</p> <p>Content Organization:</p> <ul> <li>Greenland Ice Sheet Studies (7 papers): IMBIE 2020/2023, Greene et al. calving acceleration, Box et al. committed losses, Briner et al. Holocene context</li> <li>Antarctic Ice Sheet Studies (6 papers): Smith et al. 2020, Milillo et al. rapid retreat, Naughten et al. unavoidable warming, Schmidt et al. Thwaites robotic observations</li> <li>Sea Ice Studies (7 papers): Arctic ice-free projections (Jahn et al.), Antarctic regime shift (Purich &amp; Doddridge), 2023 record lows (Josey et al.)</li> <li>Sea Level Rise Studies (3 papers): Edwards et al. projections, Bamber et al. expert elicitation, IMBIE 2018</li> </ul> <p>Strengths:</p> <ul> <li>✓ Most papers found (23 comprehensive sources)</li> <li>✓ Excellent thematic organization (Greenland → Antarctica → Sea Ice → SLR)</li> <li>✓ Citation counts + DOIs + impact metrics included</li> <li>✓ Balanced technical detail with accessibility</li> <li>✓ 100% peer-reviewed academic sources</li> <li>✓ Fast comprehensive synthesis</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#chatgpt-deep-research-results","level":3,"title":"ChatGPT Deep Research Results","text":"<p>Processing time: ~3 minutes</p> <p>Output: Structured synthesis (~1,000 words) with in-text citations</p> <p>View ChatGPT Deep Research Results</p> <p>Key findings presented:</p> <ul> <li>Greenland: 3,900 ± 340 Gt lost (1992-2018), peaking at 345 ± 66 Gt/yr in 2011</li> <li>Antarctica: Loss grew six-fold from ~40 Gt/yr (1979-1990) to 252 Gt/yr (2009-2017)</li> <li>Combined: Ice loss quadrupled since 1990s, rising from 105 Gt/yr to 372 Gt/yr (2016-2020)</li> <li>Methods: IMBIE consortium data fusion of altimetry, gravimetry, and ice-velocity mapping</li> </ul> <p>Strengths:</p> <ul> <li>✓ Clear numerical data presentation with uncertainties</li> <li>✓ Strong focus on consensus findings (IMBIE consortium)</li> <li>✓ In-text citations with superscripts</li> <li>✓ Accessible academic writing style</li> <li>✓ Methods explained for each study</li> <li>✓ 10 peer-reviewed sources from Nature, Science, PNAS</li> <li>✓ Concise synthesis format</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#four-way-comparison","level":3,"title":"Four-Way Comparison","text":"Aspect Scholar Labs ChatGPT Deep Research Gemini Deep Research Claude Papers Found 10 10 ~15 academic + 10 other 23 Time to Results Instant ~3 minutes ~5 minutes Seconds Format Annotated list Academic synthesis Formal research report Annotated bibliography Word Count N/A (list) ~1,000 words ~3,500 words N/A (list) Source Types Academic only Academic only Academic + news + reports Academic only Citation Style Visible counts In-text superscripts Bibliography With DOIs Organization Relevance-ranked By region/topic Narrative sections Thematic sections Best For Finding papers Consensus data Grant proposals Comprehensive review <p>Papers all four tools found:</p> <ul> <li>✓ Otosaka et al. (2023) - IMBIE mass balance study (1992-2020)</li> <li>✓ Greene et al. (2024) - Greenland calving acceleration (20% underestimate)</li> <li>✓ Edwards et al. (2021) - Land ice projections</li> <li>✓ Smith et al. (2020) - Science, ICESat altimetry</li> </ul> <p>Unique contributions by tool:</p> <ul> <li>Scholar Labs: Best citation metrics (\"Cited by 441\"), fastest access to papers, institutional library links</li> <li>ChatGPT: Strong IMBIE consortium focus, clear numerical consensus, concise synthesis (~1,000 words)</li> <li>Gemini: Most comprehensive coverage, news sources (Guardian), policy reports (NOAA), teleconnection studies, formal report structure (~3,500 words)</li> <li>Claude: Most papers (23), sea ice regime shift studies, expert elicitation (Bamber et al.), thematic organization</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#workflow-recommendation","level":3,"title":"Workflow Recommendation","text":"<p>For a comprehensive research project, use multiple tools strategically:</p> <p>Quick Start (10 minutes total):</p> <ol> <li>Scholar Labs (instant) → Get 10 high-impact papers with citation counts</li> <li>Claude (30 seconds) → Get 23 papers organized thematically</li> <li>ChatGPT Deep Research (3 min) → Get consensus numerical data and IMBIE focus</li> </ol> <p>Comprehensive Research (15-20 minutes total):</p> <ol> <li>Scholar Labs (instant) → Identify highest-impact papers with institutional access</li> <li>Claude (30 seconds) → Get broad academic coverage across all aspects</li> <li>ChatGPT Deep Research (3 min) → Get clear consensus findings with uncertainties</li> <li>Gemini Deep Research (5 min) → Get formal report with news, policy, and broader context</li> </ol> <p>Result: 35+ unique sources spanning peer-reviewed literature, policy reports, news coverage, and consensus data—ready for synthesis into grant proposals, literature reviews, or background sections.</p> <p>Best tool for specific needs:</p> <ul> <li>Need papers NOW? → Scholar Labs</li> <li>Writing a grant background? → Gemini Deep Research</li> <li>Need consensus numbers? → ChatGPT Deep Research</li> <li>Comprehensive literature review? → Claude</li> </ul>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"education/","level":1,"title":"AI in the Classroom","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Large Language Models (LLMs) and Artificial Intelligence (AI) are rapidly transforming higher education in 2026. With advanced models like ChatGPT, Claude, and Gemini now widely available, AI's influence extends across admissions, classrooms, research, and career preparation. These technologies present both unprecedented opportunities and complex challenges for students, educators, and institutions.</p> <p>This section explores the multifaceted ways these technologies are impacting higher education and provides practical guidance for thoughtful AI integration.</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#quick-navigation","level":3,"title":"Quick Navigation","text":"<p> Teaching with AI - Faculty strategies for AI-integrated instruction</p> <p> AI Tutoring - Student-focused learning support and study tools</p> <p> Admissions &amp; Job Recruiting - AI in application processes</p> <p> Plagiarism &amp; AI Detection - Detection tools and alternative assessment approaches</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#ai-literacy-framework-for-higher-education","level":2,"title":"AI Literacy Framework for Higher Education","text":"<p>As AI becomes integral to academic and professional life, developing AI literacy is essential for all students and faculty. AI literacy extends beyond knowing how to use AI tools—it encompasses understanding their capabilities, limitations, ethical implications, and societal impact.</p> <p>Core Components of AI Literacy</p> <p>Technical Understanding:</p> <ul> <li>How AI systems work (machine learning, neural networks, training data)</li> <li>Capabilities and limitations of different AI models</li> <li>Recognition of AI-generated content and hallucinations</li> </ul> <p>Prompt Literacy:</p> <ul> <li>Effective prompt engineering techniques</li> <li>Iterative refinement and context building</li> <li>Understanding how prompts influence outputs</li> </ul> <p>Critical Evaluation:</p> <ul> <li>Assessing AI output quality and reliability</li> <li>Identifying bias and limitations in AI responses</li> <li>Verifying AI-provided information with authoritative sources</li> </ul> <p>Ethical Application:</p> <ul> <li>Understanding academic integrity in the AI era</li> <li>Appropriate disclosure and attribution practices</li> <li>Recognition of equity and accessibility considerations</li> </ul> <p>The AI4K12 initiative outlines five foundational concepts in AI education that remain relevant for higher education contexts: Perception, Representation &amp; Reasoning, Learning, Natural Interaction, and Societal Impact. The ISTE AI Standards provide additional framework for developing AI competencies across educational levels.</p> How can institutions build AI literacy across campus? <p>For Students:</p> <ul> <li>Integrate AI literacy modules into first-year seminars</li> <li>Require discipline-specific AI training in major courses</li> <li>Provide workshops on prompt engineering and critical AI use</li> <li>Create peer tutoring programs focused on AI tools</li> </ul> <p>For Faculty:</p> <ul> <li>Offer professional development on AI pedagogy</li> <li>Establish faculty learning communities for AI integration</li> <li>Provide stipends for course redesign incorporating AI</li> <li>Create repositories of AI assignment examples and policies</li> </ul> <p>Institutional Level:</p> <ul> <li>Develop campus-wide AI literacy standards</li> <li>Create centralized resources and support services</li> <li>Establish clear institutional AI policies</li> <li>Invest in infrastructure for secure, equitable AI access</li> </ul>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#current-adoption-trends-2024-2026","level":2,"title":"Current Adoption Trends (2024-2026)","text":"<p>AI adoption in higher education has accelerated dramatically. Recent surveys indicate that over 60% of undergraduate students regularly use AI tools for coursework, while faculty adoption varies significantly by discipline and institution type (EDUCAUSE, 2024).</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#adoption-by-institution-type","level":3,"title":"Adoption by Institution Type","text":"Institution Type Faculty Adoption Rate Common Use Cases Primary Challenges R1 Universities High (65-75%) Research assistance, TA automation, course design, literature reviews Policy development, academic integrity concerns Liberal Arts Colleges Medium (40-55%) Writing support, discussion facilitation, personalized tutoring Faculty resistance, philosophical concerns about AI in humanities Community Colleges Growing (30-45%) Accessibility tools, developmental education, ESL support Resource constraints, digital divide, faculty training needs Professional Schools High (70-85%) Clinical simulations, case generation, practical skill development Industry alignment, professional ethics, accreditation requirements","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#learning-management-system-lms-integration","level":3,"title":"Learning Management System (LMS) Integration","text":"<p>Major LMS providers have integrated AI capabilities directly into their platforms:</p> <ul> <li>Canvas AI - IgniteAI search, assignment generation, discussion summaries, and personalized feedback tools</li> <li>Blackboard AI Design Assistant - Course content creation, rubric generation, AI conversations, and accessibility checking</li> <li>Moodle AI Tools - Built-in AI summarization, explanation tools, and integration with OpenAI, Azure AI, and Ollama</li> <li>D2L Brightspace Performance+ - Predictive analytics, at-risk learner identification, and adaptive learning pathways with Lumi AI assistant</li> </ul> <p>These integrations are reducing barriers to faculty AI adoption while raising questions about data privacy and vendor dependence (EDUCAUSE Review, 2025).</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#ai-enhanced-pedagogies","level":2,"title":"AI-Enhanced Pedagogies","text":"<p>Effective AI integration requires rethinking traditional teaching approaches. The following pedagogical strategies have emerged as particularly promising:</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#flipped-classroom-with-ai-preparation","level":3,"title":"Flipped Classroom with AI Preparation","text":"<p>Students use AI tools to prepare for class by:</p> <ul> <li>Generating study questions from readings</li> <li>Creating concept summaries for self-testing</li> <li>Exploring preliminary explanations of complex topics</li> <li>Developing questions to bring to class discussion</li> </ul> <p>Class time focuses on application, synthesis, and critical analysis where human interaction adds value beyond AI capabilities.</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#ai-augmented-active-learning","level":3,"title":"AI-Augmented Active Learning","text":"<p>Combining AI tools with active learning techniques:</p> <ul> <li>Think-Pair-Share-AI: Students first think independently, discuss with peers, then consult AI to challenge or expand their understanding</li> <li>Jigsaw with AI Experts: Small groups become \"experts\" using AI to research different aspects of a topic, then teach peers</li> <li>AI-Assisted Problem-Based Learning: Students use AI as a research assistant while solving authentic, complex problems</li> </ul> <p>Effective AI-Augmented Activities</p> <p>Compare and Contrast: Ask students to generate explanations from multiple AI models (ChatGPT, Claude, Gemini), then analyze differences in approach, accuracy, and perspective.</p> <p>AI as Interlocutor: Have students debate positions with AI, requiring them to defend arguments, identify weaknesses in AI reasoning, and refine their own thinking.</p> <p>Iterative Improvement: Students submit work to AI for feedback, reflect on suggestions, revise accordingly, and document their learning process.</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#collaborative-human-ai-learning","level":3,"title":"Collaborative Human-AI Learning","text":"<p>Students develop skills in effective AI collaboration:</p> <ul> <li>Treating AI as a thought partner, not answer provider</li> <li>Learning when to use AI versus when human expertise is essential</li> <li>Building metacognitive awareness of their own vs. AI contributions</li> <li>Developing accountability for AI-assisted work quality</li> </ul>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#new-opportunities-for-teaching-and-learning","level":2,"title":"New Opportunities for Teaching and Learning","text":"<ul> <li>Personalized Learning Experiences:<ul> <li>LLMs can power adaptive learning platforms that tailor educational content and pace to individual student needs, providing customized feedback and support.</li> <li>Chatbots can act as virtual tutors, offering 24/7 assistance, answering questions, and providing explanations on course material.</li> </ul> </li> <li>Enhanced Student Engagement:<ul> <li>Interactive learning experiences powered by AI can make learning more engaging and enjoyable. Gamification elements and personalized feedback can boost motivation.</li> <li>AI-powered discussion forums can facilitate more dynamic and interactive online discussions.</li> </ul> </li> <li>Automated Administrative Tasks:<ul> <li>Chatbots can handle routine administrative tasks like answering FAQs, providing information about course schedules, and directing students to relevant resources, freeing up faculty time for more meaningful interactions.</li> <li>LLMs can assist with grading, providing feedback on student writing, and even generating initial drafts of course materials.</li> </ul> </li> <li>Accessibility and Inclusivity:<ul> <li>AI-powered tools can provide real-time language translation, text-to-speech and speech-to-text capabilities, making education more accessible to students with disabilities and those from diverse linguistic backgrounds.</li> <li>Automated captioning, alt-text generation for images, and document remediation tools reduce barriers to content accessibility.</li> <li>AI can generate multiple representations of content (visual, auditory, textual) to support Universal Design for Learning (UDL) principles.</li> </ul> </li> <li>AI-Powered Course Analytics:<ul> <li>Learning analytics platforms use AI to identify students at risk of falling behind, enabling early intervention.</li> <li>Predictive models help advisors provide personalized guidance based on student performance patterns.</li> <li>Real-time dashboards give instructors insights into student engagement, comprehension, and participation trends.</li> </ul> </li> <li>Development of New Skills:<ul> <li>The rise of AI necessitates a shift in focus towards skills like critical thinking, problem-solving, creativity, and ethical reasoning, which are less susceptible to automation.</li> <li>Higher education must equip students with the skills to effectively utilize and collaborate with AI tools.</li> </ul> </li> <li>Research Assistance:<ul> <li>LLMs can assist researchers with literature reviews, data analysis, and even drafting research papers, accelerating the research process.</li> </ul> </li> </ul>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#challenges-and-ethical-considerations","level":2,"title":"Challenges and Ethical Considerations","text":"<ul> <li>Academic Integrity:<ul> <li>The ease with which students can use LLMs to generate essays and complete assignments raises serious concerns about plagiarism and academic integrity.</li> <li>AI detection tools have significant limitations and can produce false positives, particularly affecting non-native English speakers (Weber-Wulff et al., 2024).</li> <li>Institutions are moving beyond detection toward process-based assessment and AI-transparent assignments. See Plagiarism &amp; AI Detection for comprehensive coverage of detection tools and alternative approaches.</li> </ul> </li> <li>Bias and Fairness:<ul> <li>LLMs are trained on vast datasets that may reflect existing societal biases. This can lead to biased outputs and perpetuate inequalities in education.</li> <li>Careful consideration must be given to the potential for AI tools to exacerbate existing disparities in access and achievement.</li> </ul> </li> <li>Data Privacy and Security:<ul> <li>The use of AI in education involves collecting and analyzing large amounts of student data. Protecting student privacy and ensuring data security is of paramount importance.</li> <li>Clear guidelines and regulations are needed to govern the collection, use, and storage of student data by AI systems.</li> </ul> </li> <li>Over-Reliance on Technology:<ul> <li>There's a risk that over-reliance on AI tools could diminish the development of critical thinking, problem-solving, and independent learning skills among students.</li> <li>Maintaining a balance between leveraging AI and fostering human interaction and mentorship is crucial.</li> </ul> </li> <li>The Digital Divide:<ul> <li>Unequal access to technology and digital literacy can exacerbate existing inequalities, creating a digital divide between students who have access to and can effectively use AI tools and those who cannot.</li> <li>While many AI tools offer free tiers, premium features that provide competitive advantages may be cost-prohibitive for some students.</li> <li>Internet connectivity requirements and device capabilities create additional equity concerns, particularly for rural and low-income students.</li> </ul> </li> <li>Faculty Resistance and Adaptation:<ul> <li>Some faculty members express concerns about AI undermining traditional educational values or devaluing their expertise.</li> <li>Generational and disciplinary differences affect faculty willingness to integrate AI tools.</li> <li>Inadequate professional development and support contribute to resistance and uneven implementation across departments.</li> </ul> </li> <li>The Role of the Educator:<ul> <li>The role of educators is evolving in the age of AI. Teachers need to adapt their teaching methods and develop new skills to effectively integrate AI into the classroom.</li> <li>Professional development opportunities are needed to support educators in this transition.</li> </ul> </li> <li>Ethical Use of AI:<ul> <li>Students should be educated on the ethical implications of AI, including issues of bias, transparency, accountability, and responsible use.</li> <li>Developing ethical guidelines and frameworks for the use of AI in higher education is essential.</li> </ul> </li> </ul>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#assessment-evolution-moving-beyond-detection","level":2,"title":"Assessment Evolution: Moving Beyond Detection","text":"<p>Traditional assessment methods designed for a pre-AI era are increasingly inadequate. Research from MIT Sloan and other institutions demonstrates that AI detection tools are unreliable, with false positive rates that disproportionately affect certain student populations (Liang et al., 2023).</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#process-based-assessment-strategies","level":3,"title":"Process-Based Assessment Strategies","text":"<p>Rather than focusing on detecting AI use, effective assessment emphasizes the learning process:</p> <p>Draft Submissions and Revision Tracking:</p> <ul> <li>Require multiple drafts showing development of ideas over time</li> <li>Ask students to submit research notes, outlines, and annotated sources</li> <li>Use version control or tracked changes to document the writing process</li> </ul> <p>Reflective Journals:</p> <ul> <li>Students document their research and thinking process</li> <li>Describe challenges encountered and how they were addressed</li> <li>Explain decisions made and resources consulted (including AI)</li> <li>Demonstrate metacognitive awareness of their learning</li> </ul> <p>In-Class Components:</p> <ul> <li>Oral presentations defending written work</li> <li>Synchronous problem-solving sessions</li> <li>Live coding or demonstration of skills</li> <li>Discussion-based assessment showing deep understanding</li> </ul> <p>AI-Transparent Assignments</p> <p>Instead of prohibiting AI use, design assignments that:</p> <ul> <li>Require students to use AI as a tool, then critique its output</li> <li>Ask for comparative analysis of human vs. AI approaches</li> <li>Demand documentation of the AI interaction process (prompt engineering log)</li> <li>Focus on synthesis, evaluation, and application rather than recall or reproduction</li> <li>Include authentic, complex problems where AI provides incomplete solutions</li> </ul> <p>Example: \"Use ChatGPT to generate three possible solutions to this case study. Evaluate each solution's strengths and weaknesses, identify which you would recommend and why, and explain what the AI missed in its analysis.\"</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#authentic-assessment","level":3,"title":"Authentic Assessment","text":"<p>Assignments connected to real-world contexts are more resistant to AI misuse and more valuable for learning:</p> <ul> <li>Community-based projects with external stakeholders</li> <li>Professional portfolio development</li> <li>Simulations of workplace scenarios</li> <li>Creation of original data through experiments, surveys, or fieldwork</li> <li>Multimodal presentations combining text, audio, video, and visual elements</li> </ul> <p>See Teaching with AI for detailed assessment strategies and Plagiarism &amp; AI Detection for comprehensive discussion of detection tools and alternatives.</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#institutional-readiness-for-ai-integration","level":2,"title":"Institutional Readiness for AI Integration","text":"<p>Successful AI integration requires coordinated institutional effort across multiple dimensions:</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#faculty-development","level":3,"title":"Faculty Development","text":"<p>Professional Development Priorities:</p> <ul> <li>Hands-on workshops on AI tool capabilities and limitations</li> <li>Discipline-specific training on AI integration in different fields</li> <li>Course redesign institutes with stipends for AI-integrated assignments</li> <li>Faculty learning communities for ongoing support and idea sharing</li> <li>Just-in-time support through instructional designers and IT staff</li> </ul>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#it-infrastructure-and-support","level":3,"title":"IT Infrastructure and Support","text":"<p>Technical Requirements:</p> <ul> <li>Secure, FERPA-compliant AI tools for institutional use</li> <li>Integration with existing LMS and student information systems</li> <li>Network capacity for AI application bandwidth demands</li> <li>Data governance frameworks for AI-generated content and logs</li> <li>Help desk support trained in AI tool troubleshooting</li> </ul> How do we balance innovation with risk management? <p>Risk Mitigation Strategies:</p> <ul> <li>Start with pilot programs in selected courses or departments</li> <li>Establish clear ethical guidelines and accountability measures</li> <li>Create feedback mechanisms for students and faculty to report concerns</li> <li>Conduct regular audits of AI tool usage and outcomes</li> <li>Maintain human oversight of AI-generated decisions</li> <li>Build in flexibility to adjust policies as technology evolves</li> <li>Learn from peer institutions and share lessons learned</li> </ul> <p>Innovation Enablers:</p> <ul> <li>Provide safe spaces for experimentation (sandbox courses)</li> <li>Celebrate and showcase successful AI integration examples</li> <li>Allocate resources for innovation grants</li> <li>Reduce barriers to trying new approaches (streamlined approval processes)</li> <li>Foster culture of continuous improvement and adaptation</li> </ul> <p>AI4K12</p> <p>The \"AI 4 K-12\" award from the NSF outlined five big ideas in AI for education back in 2020:</p> <p></p> <p>Read more at https://ai4k12.org/</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"ethics/","level":1,"title":"Ethics of Artificial Intelligence","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#history","level":2,"title":"History","text":"<p>In 1956 a small group of scientists gathered at Dartmouth for a Summer Research Project on Artificial Intelligence. </p> <p>A new field of Science had begun. </p> Dartmouth Summer Research Project on Artificial Intelligence, 1956. Credit: IEEE Spectrum, The Minsky Family <p>Over the next 70 years, Artificial Intelligence persisted mainly in the minds of science fiction writers and the small group of industry researchers and academics who continued to work toward creating the digital infrastructure needed for Artificial Intelligence to bloom, and to one day achieve the ultimate goal of Artificial General Intelligence (AGI)(). </p>","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#using-ai-ethically","level":2,"title":"Using AI ethically","text":"<p>As consumers of GPTs and other AI platforms, we must consider in what ways can we use AI both effectively, and ethically.</p>","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#ethical-and-legal-considerations","level":2,"title":"Ethical and Legal Considerations","text":"","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#transparency-accountability","level":2,"title":"Transparency &amp; Accountability","text":"","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#bias-discrimination","level":2,"title":"Bias &amp; Discrimination","text":"","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#assessment","level":2,"title":"Assessment","text":"Can you explain the difference between \"Ethics of AI\" and \"Ethical AI?\" <p>Hint: Refer to how Siau and Wang (2020) define each term</p> Ethics of AI <ul> <li>Ethics of AI refers to principles and regulations</li> </ul> Ethical AI <ul> <li>Ethical AI focuses on how AI behaves</li> </ul> How does Asimov's Three Laws of Robotics relate to modern ethical concerns of AI? Do no harm <p>Asmiov emphasizes preventing harm to humans and how that concept informs current AI safety practices.</p> True or False: The Turing Trap suggests that efforts to make AI more human-like will empower workers' economic and political power. False <p>The Turing Trap warns against replacing humans with AI, and that AI could be used to drive down wages and to a loss of economic and political power. </p> Name at least one major declaration or agreement on AI Ethics International Agreements <ul> <li> <p>Council of Europe Framework Convention on Artificial Intelligence and human rights</p> </li> <li> <p>Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy</p> </li> <li> <p>G20 AI Principles</p> </li> </ul> Principles and Ethics <ul> <li> <p>Asilomar AI Principles</p> </li> <li> <p>UNESCO Recommendation on the Ethics of Artificial Intelligence</p> </li> <li> <p>OECD AI Principles</p> </li> <li> <p>Toronto Declaration</p> </li> </ul> True or False: It is okay to use a GPT to write a research proposal on a topic you have no experience in? <p>Hint: Review \"Using AI Ethically\"</p> False <p>If you do not have the ability to verify output truthfully or accurately, it is not safe to use a GPT for research.</p>","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"execution/","level":1,"title":"Code Execution","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Advanced GPT offerings include Agentic platforms that can write and execute code.</p>","path":["Code Execution"],"tags":[]},{"location":"execution/#agents","level":2,"title":"Agents","text":"","path":["Code Execution"],"tags":[]},{"location":"execution/#jupyter-agent","level":3,"title":"Jupyter Agent","text":"<p> HuggingFace  Jupyter Agent is a HuggingFace Gradio app that accepts prompts and responds with Jupyter Notebook blocks (MarkDown Text, Code, )</p> <p>Another great option is to use the coding execution built into models such as Gemini, </p>","path":["Code Execution"],"tags":[]},{"location":"execution/#chatgpt-canvas","level":3,"title":"ChatGPT Canvas","text":"<p>ChatGPT Canvas, allows you to write normal prompts with an additional IDE editor and console. </p>","path":["Code Execution"],"tags":[]},{"location":"execution/#claude-analysis-tool","level":3,"title":"Claude Analysis Tool","text":"<p>Claude has added an analysis tool that allows you to write code and execute it </p>","path":["Code Execution"],"tags":[]},{"location":"execution/#github-copilot","level":3,"title":"GitHub Copilot","text":"<p>In GitHub Copilot you can work in an online IDE (GitHub CodeSpaces VS Code Server) or locally on your VS Code environment. </p>","path":["Code Execution"],"tags":[]},{"location":"execution/#gemini-code-assist","level":3,"title":"Gemini Code Assist","text":"<p>Google's Gemini Code Assist can be added to VS Code Extensions</p> <p>After January 2025, Gemini Code Assist will require the ability to create a project in Google Cloud to enable the API/</p>","path":["Code Execution"],"tags":[]},{"location":"gemini/","level":1,"title":"Google Gemini","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Setup","Google Gemini"],"tags":[]},{"location":"gemini/#creating-a-gemini-account","level":2,"title":"Creating a Gemini account","text":"<p>There are multiple ways to access and use Google Gemini:</p> <p>1. Through the Gemini Web Application:</p> <ul> <li>Visit gemini.google.com.</li> <li>Sign in with your Google Account. If you don't have one, create one at accounts.google.com.</li> <li>You can start interacting with Gemini through the chat interface. The free tier includes Gemini 2.5 Flash (unlimited) and limited Gemini Pro access.</li> </ul> <p>Gemini Pricing &amp; Comparisons</p> <p>Subscription Options:</p> <ul> <li>Free: Gemini 2.5 Flash unlimited</li> <li>AI Pro ($19.99/mo): Gemini 2.5 Pro access, NotebookLM Plus, 2TB storage - Free for university students (1 year)</li> <li>AI Ultra ($249.99/mo): Gemini 2.5 Pro unlimited, Deep Think, Veo 3 video generation</li> </ul> <p>Compare with other AI platforms: See Choosing the Right AI Platform for detailed comparisons</p> <p>2. Through Google AI Studio (for Developers):</p> <ul> <li>Go to aistudio.google.com</li> <li>Sign in with your Google Account.</li> <li>There you can access the Gemini API and experiment with different model sizes and parameters. You'll get a certain number of free API calls per month.</li> </ul> <p>3. Integrated into Google Products:</p> <ul> <li>Gemini features are gradually rolling out to Google Workspace, Google Search, and other products.</li> <li>NotebookLM is a document based chat interface that allows you to load your own knowledge base and have chatbot conversations. </li> </ul> <p>4. On Android Devices:</p> <ul> <li>Gemini Nano will be available on select Android devices, enabling on-device AI capabilities.</li> </ul>","path":["Setup","Google Gemini"],"tags":[]},{"location":"gemini/#troubleshooting-sign-in-issues","level":2,"title":"Troubleshooting Sign-In Issues","text":"<p>If you encounter issues signing in to your Google Account, follow the steps outlined in Google's support documentation.</p>","path":["Setup","Google Gemini"],"tags":[]},{"location":"gemini/#availability","level":2,"title":"Availability","text":"<p>Google Gemini is continuously expanding its availability in more countries and languages.</p> <p>For University managed accounts (<code>netid@arizona.edu</code>), Gemini access may depend on whether UArizona administrators have enabled it for the Google Workspace.  You can also use Gemini through a personal <code>name@gmail.com</code> address.</p>","path":["Setup","Google Gemini"],"tags":[]},{"location":"gemini/#what-is-gemini","level":2,"title":"What is Gemini?","text":"<p>Gemini is designed to understand and generate text, code, images, audio, and video. </p> <p>While Google initially launched Bard as its conversational AI, it has since been rebranded and significantly upgraded as Gemini.  The Gemini models are being integrated into various Google products and services, including:</p> <ul> <li>Google AI Studio: A web-based IDE for developers to prototype and build with generative AI models.</li> <li>Google Search: Enhancing search results with AI-generated summaries and insights.</li> <li>Google Workspace: AI features to Google Docs, Sheets, Slides, Gmail, and Meet. (Similar to Microsoft's Copilot integration with Office 365).</li> <li>Android: Gemini Nano will power on-device AI features in Android devices.</li> </ul> <p>Setting up your Gemini API Key</p> <p>To use the Gemini API in your own applications, you'll need an API key. This key is linked to a Google Cloud project. Here’s how to set one up:</p> <ol> <li> <p>Go to the Google Cloud Console:</p> <ul> <li>Open your web browser and navigate to console.cloud.google.com.</li> <li>Sign in with your Google Account.</li> </ul> </li> <li> <p>Create or Select a Google Cloud Project:</p> <ul> <li>At the top of the page, click the project selector dropdown menu (it might show an existing project name).</li> <li>In the \"Select a project\" window that appears, click \"New Project\".</li> <li>Give your project a descriptive name (e.g., <code>gemini-api-project</code>) and click \"Create\".</li> </ul> </li> <li> <p>Enable the Gemini API:</p> <ul> <li>Once your project is created and selected, use the navigation menu (☰) on the left to go to \"APIs &amp; Services\" &gt; \"Enabled APIs &amp; services\".</li> <li>Click on \"+ ENABLE APIS AND SERVICES\".</li> <li>In the search bar, type <code>Gemini API</code> and press Enter.</li> <li>Select the \"Gemini API\" from the search results (it may also be listed as \"Generative Language API\").</li> <li>Click the \"Enable\" button. It might take a few moments to complete.</li> </ul> </li> <li> <p>Get Your API Key from Google AI Studio:</p> <ul> <li>Now, go to aistudio.google.com.</li> <li>Click on \"Get API key\" in the top left corner.</li> <li>A new window will open. Click on \"Create API key in new project\" or select the project you created earlier.</li> <li>Your new API key will be generated and displayed. Copy this key and store it securely. You will need it to make calls to the Gemini API.</li> </ul> </li> </ol> <p>Your API key is now ready to use! Remember to keep it confidential and not expose it in client-side code or public repositories.</p>","path":["Setup","Google Gemini"],"tags":[]},{"location":"gradio/","level":1,"title":"Gradio","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#what-is-gradio","level":2,"title":"What is Gradio?","text":"<p>Gradio is an open-source Python library that makes it easy to create interactive web interfaces for machine learning models, data science applications, and AI tools. With just a few lines of code, you can build shareable demos that allow users to interact with your work through a web browser.</p> <p>Why Gradio Matters for Researchers:</p> <ul> <li>Share your work: Create interactive demos of your research for papers, presentations, or collaborators</li> <li>No web development required: Build interfaces using only Python - no HTML, CSS, or JavaScript needed</li> <li>Rapid prototyping: Test and iterate on AI applications quickly</li> <li>Accessibility: Make your models accessible to non-technical colleagues and stakeholders</li> <li>Reproducibility: Package your research into interactive, shareable applications</li> </ul> <p>Gradio and Hugging Face</p> <p>Gradio is developed by Hugging Face and integrates seamlessly with the Hugging Face ecosystem. Most interactive demos you see on Hugging Face Spaces are built with Gradio. This makes it easy to deploy your Gradio apps to the cloud with a single command.</p>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#installation","level":2,"title":"Installation","text":"","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#basic-installation","level":3,"title":"Basic Installation","text":"pipconda <pre><code>pip install gradio\n</code></pre> <pre><code>conda install -c conda-forge gradio\n</code></pre>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#installation-with-additional-dependencies","level":3,"title":"Installation with Additional Dependencies","text":"<p>For working with Hugging Face models:</p> <pre><code>pip install gradio transformers torch\n</code></pre> <p>For working with audio and images:</p> <pre><code>pip install gradio numpy pillow soundfile\n</code></pre>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#verify-installation","level":3,"title":"Verify Installation","text":"<pre><code>import gradio as gr\nprint(gr.__version__)\n</code></pre> <p>As of early 2026, the current stable version is Gradio 5.x.</p>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#quick-start-your-first-gradio-app","level":2,"title":"Quick Start: Your First Gradio App","text":"<p>Let's build a simple interface that takes text input and returns a greeting:</p> <pre><code>import gradio as gr\n\ndef greet(name):\n    return f\"Hello, {name}! Welcome to Gradio.\"\n\n# Create the interface\ndemo = gr.Interface(\n    fn=greet,              # The function to wrap\n    inputs=\"text\",         # Input type\n    outputs=\"text\",        # Output type\n    title=\"Simple Greeter\",\n    description=\"Enter your name to receive a greeting.\"\n)\n\n# Launch the app\ndemo.launch()\n</code></pre> <p>When you run this code, Gradio will:</p> <ol> <li>Start a local web server (typically at <code>http://127.0.0.1:7860</code>)</li> <li>Open your default browser to display the interface</li> <li>Provide a shareable link if you set <code>share=True</code></li> </ol> <p>Running in Jupyter Notebooks</p> <p>Gradio works seamlessly in Jupyter notebooks. The interface will display inline within the notebook cell. This is perfect for iterative development and demonstrations.</p>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#core-concepts","level":2,"title":"Core Concepts","text":"","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#the-interface-class","level":3,"title":"The Interface Class","text":"<p><code>gr.Interface</code> is the simplest way to create a Gradio app. It wraps any Python function with a user interface:</p> <pre><code>gr.Interface(\n    fn=your_function,       # Required: The function to call\n    inputs=input_components, # Required: Input component(s)\n    outputs=output_components, # Required: Output component(s)\n    title=\"App Title\",      # Optional: Display title\n    description=\"Description\", # Optional: Help text\n    examples=[[\"example1\"], [\"example2\"]]  # Optional: Example inputs\n)\n</code></pre>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#common-inputoutput-components","level":3,"title":"Common Input/Output Components","text":"<p>Gradio provides many component types:</p> Component Description Example Use <code>gr.Textbox</code> Text input/output Questions, prompts, responses <code>gr.Number</code> Numeric input Parameters, scores <code>gr.Slider</code> Range selection Temperature, confidence thresholds <code>gr.Dropdown</code> Selection from options Model selection, categories <code>gr.Checkbox</code> Boolean toggle Enable/disable features <code>gr.Image</code> Image upload/display Vision models, image processing <code>gr.Audio</code> Audio upload/playback Speech recognition, synthesis <code>gr.File</code> File upload Document processing <code>gr.Dataframe</code> Tabular data Data analysis results <code>gr.Plot</code> Charts and graphs Visualizations <code>gr.Markdown</code> Formatted text Instructions, results","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#building-practical-applications","level":2,"title":"Building Practical Applications","text":"","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#example-1-text-summarization-interface","level":3,"title":"Example 1: Text Summarization Interface","text":"<p>This example creates a tool for summarizing academic papers or long documents:</p> <pre><code>import gradio as gr\n\ndef summarize_text(text, max_length, style):\n    \"\"\"\n    A placeholder summarization function.\n    In practice, you would connect this to an LLM.\n    \"\"\"\n    # Simulate summarization\n    word_count = len(text.split())\n    summary = f\"[{style} summary of {word_count} words, max {max_length} words]\"\n\n    # In real use, you would call an API or model here:\n    # from transformers import pipeline\n    # summarizer = pipeline(\"summarization\")\n    # result = summarizer(text, max_length=max_length)\n\n    return summary\n\ndemo = gr.Interface(\n    fn=summarize_text,\n    inputs=[\n        gr.Textbox(\n            label=\"Text to Summarize\",\n            placeholder=\"Paste your article, paper abstract, or document here...\",\n            lines=10\n        ),\n        gr.Slider(\n            minimum=50,\n            maximum=500,\n            value=150,\n            step=10,\n            label=\"Maximum Summary Length (words)\"\n        ),\n        gr.Dropdown(\n            choices=[\"Brief\", \"Detailed\", \"Technical\", \"Simplified\"],\n            value=\"Brief\",\n            label=\"Summary Style\"\n        )\n    ],\n    outputs=gr.Textbox(label=\"Summary\", lines=5),\n    title=\"Academic Text Summarizer\",\n    description=\"Paste text from papers, articles, or documents to generate a summary.\",\n    examples=[\n        [\"Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.\", 100, \"Brief\"],\n    ]\n)\n\ndemo.launch()\n</code></pre>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#example-2-image-classification-with-hugging-face-models","level":3,"title":"Example 2: Image Classification with Hugging Face Models","text":"<p>This example demonstrates how to connect Gradio to a Hugging Face model. For more on accessing Hugging Face models, see the Hugging Face documentation.</p> <pre><code>import gradio as gr\nfrom transformers import pipeline\n\n# Load a pre-trained image classification model from Hugging Face\n# See https://huggingface.co/models?pipeline_tag=image-classification\nclassifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n\ndef classify_image(image):\n    \"\"\"Classify an uploaded image and return top predictions.\"\"\"\n    if image is None:\n        return \"Please upload an image.\"\n\n    # Run classification\n    predictions = classifier(image)\n\n    # Format results\n    results = \"\\n\".join([\n        f\"{pred['label']}: {pred['score']:.2%}\"\n        for pred in predictions[:5]\n    ])\n\n    return results\n\ndemo = gr.Interface(\n    fn=classify_image,\n    inputs=gr.Image(type=\"pil\", label=\"Upload an Image\"),\n    outputs=gr.Textbox(label=\"Classification Results\", lines=6),\n    title=\"Image Classifier\",\n    description=\"Upload an image to classify its contents using a Vision Transformer model from Hugging Face.\",\n    examples=[\n        [\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\"]\n    ]\n)\n\ndemo.launch()\n</code></pre> <p>First Run Download</p> <p>The first time you run this code, the <code>transformers</code> library will download the model from Hugging Face. This may take a few minutes depending on your internet connection. Subsequent runs will use the cached model.</p>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#example-3-question-answering-with-context","level":3,"title":"Example 3: Question Answering with Context","text":"<p>This example creates a research assistant that answers questions based on provided context:</p> <pre><code>import gradio as gr\nfrom transformers import pipeline\n\n# Load a question-answering model\nqa_model = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n\ndef answer_question(context, question):\n    \"\"\"Answer a question based on the provided context.\"\"\"\n    if not context or not question:\n        return \"Please provide both context and a question.\"\n\n    result = qa_model(question=question, context=context)\n\n    answer = result['answer']\n    confidence = result['score']\n\n    return f\"**Answer:** {answer}\\n\\n**Confidence:** {confidence:.2%}\"\n\ndemo = gr.Interface(\n    fn=answer_question,\n    inputs=[\n        gr.Textbox(\n            label=\"Context\",\n            placeholder=\"Paste the text passage that contains the answer...\",\n            lines=8\n        ),\n        gr.Textbox(\n            label=\"Question\",\n            placeholder=\"Ask a question about the text above...\"\n        )\n    ],\n    outputs=gr.Markdown(label=\"Answer\"),\n    title=\"Research Document Q&amp;A\",\n    description=\"Paste a passage from a paper or document, then ask questions about it.\",\n    examples=[\n        [\n            \"The transformer architecture was introduced in the paper 'Attention Is All You Need' by Vaswani et al. in 2017. It revolutionized natural language processing by replacing recurrent neural networks with self-attention mechanisms, enabling much faster training through parallelization.\",\n            \"When was the transformer architecture introduced?\"\n        ],\n        [\n            \"CRISPR-Cas9 is a genome editing technology that allows scientists to make precise changes to DNA. It works by using a guide RNA to direct the Cas9 enzyme to a specific location in the genome, where it makes a cut. The cell's natural repair mechanisms then make the desired edit.\",\n            \"How does CRISPR-Cas9 work?\"\n        ]\n    ]\n)\n\ndemo.launch()\n</code></pre>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#example-4-multi-modal-interface-with-blocks","level":3,"title":"Example 4: Multi-Modal Interface with Blocks","text":"<p>For more complex layouts, use <code>gr.Blocks</code> instead of <code>gr.Interface</code>:</p> <pre><code>import gradio as gr\n\ndef analyze_data(file, analysis_type):\n    \"\"\"Placeholder for data analysis function.\"\"\"\n    if file is None:\n        return \"Please upload a file.\", None\n\n    # In practice, you would process the file here\n    # import pandas as pd\n    # df = pd.read_csv(file.name)\n\n    summary = f\"Analysis type: {analysis_type}\\nFile uploaded successfully.\"\n\n    # Generate a placeholder plot\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 10, 100)\n    ax.plot(x, np.sin(x), label='Sample Data')\n    ax.set_xlabel('X axis')\n    ax.set_ylabel('Y axis')\n    ax.set_title(f'{analysis_type} Results')\n    ax.legend()\n\n    return summary, fig\n\n# Create a more complex layout with Blocks\nwith gr.Blocks(title=\"Research Data Analyzer\") as demo:\n    gr.Markdown(\"# Research Data Analyzer\")\n    gr.Markdown(\"Upload your data file and select an analysis type.\")\n\n    with gr.Row():\n        with gr.Column(scale=1):\n            file_input = gr.File(label=\"Upload Data File (CSV, Excel)\")\n            analysis_dropdown = gr.Dropdown(\n                choices=[\"Descriptive Statistics\", \"Correlation Analysis\",\n                         \"Trend Analysis\", \"Outlier Detection\"],\n                label=\"Analysis Type\",\n                value=\"Descriptive Statistics\"\n            )\n            analyze_btn = gr.Button(\"Run Analysis\", variant=\"primary\")\n\n        with gr.Column(scale=2):\n            output_text = gr.Textbox(label=\"Analysis Summary\", lines=5)\n            output_plot = gr.Plot(label=\"Visualization\")\n\n    analyze_btn.click(\n        fn=analyze_data,\n        inputs=[file_input, analysis_dropdown],\n        outputs=[output_text, output_plot]\n    )\n\ndemo.launch()\n</code></pre>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#connecting-to-large-language-models","level":2,"title":"Connecting to Large Language Models","text":"","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#using-hugging-face-inference-api","level":3,"title":"Using Hugging Face Inference API","text":"<p>Connect to models hosted on Hugging Face without downloading them locally:</p> <pre><code>import gradio as gr\nfrom huggingface_hub import InferenceClient\n\n# Initialize the client (requires HF_TOKEN environment variable or explicit token)\n# See the Hugging Face documentation for setting up authentication:\n# https://huggingface.co/docs/huggingface_hub/quick-start#authentication\nclient = InferenceClient()\n\ndef chat_with_model(message, history, system_prompt, model_name):\n    \"\"\"Chat with a Hugging Face model via the Inference API.\"\"\"\n\n    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n\n    # Add conversation history\n    for human, assistant in history:\n        messages.append({\"role\": \"user\", \"content\": human})\n        messages.append({\"role\": \"assistant\", \"content\": assistant})\n\n    # Add current message\n    messages.append({\"role\": \"user\", \"content\": message})\n\n    # Generate response\n    response = client.chat_completion(\n        model=model_name,\n        messages=messages,\n        max_tokens=500,\n        temperature=0.7\n    )\n\n    return response.choices[0].message.content\n\ndemo = gr.ChatInterface(\n    fn=chat_with_model,\n    additional_inputs=[\n        gr.Textbox(\n            value=\"You are a helpful research assistant specializing in academic writing.\",\n            label=\"System Prompt\",\n            lines=2\n        ),\n        gr.Dropdown(\n            choices=[\n                \"meta-llama/Llama-3.2-3B-Instruct\",\n                \"mistralai/Mistral-7B-Instruct-v0.3\",\n                \"Qwen/Qwen2.5-7B-Instruct\"\n            ],\n            value=\"meta-llama/Llama-3.2-3B-Instruct\",\n            label=\"Model\"\n        )\n    ],\n    title=\"Research Assistant Chatbot\",\n    description=\"Chat with open-source LLMs from Hugging Face. Select a model and customize the system prompt.\"\n)\n\ndemo.launch()\n</code></pre> <p>API Rate Limits</p> <p>The Hugging Face Inference API has rate limits for free users. For heavy usage, consider a Hugging Face Pro subscription or running models locally with Ollama.</p>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#using-local-models-with-ollama","level":3,"title":"Using Local Models with Ollama","text":"<p>Connect Gradio to locally-running models via Ollama:</p> <pre><code>import gradio as gr\nimport requests\nimport json\n\ndef chat_with_ollama(message, history, model_name):\n    \"\"\"Chat with a local Ollama model.\"\"\"\n\n    # Build conversation context\n    full_prompt = \"\"\n    for human, assistant in history:\n        full_prompt += f\"User: {human}\\nAssistant: {assistant}\\n\"\n    full_prompt += f\"User: {message}\\nAssistant:\"\n\n    # Call Ollama API\n    response = requests.post(\n        \"http://localhost:11434/api/generate\",\n        json={\n            \"model\": model_name,\n            \"prompt\": full_prompt,\n            \"stream\": False\n        }\n    )\n\n    if response.status_code == 200:\n        return response.json()[\"response\"]\n    else:\n        return f\"Error: {response.status_code}\"\n\ndemo = gr.ChatInterface(\n    fn=chat_with_ollama,\n    additional_inputs=[\n        gr.Dropdown(\n            choices=[\"llama3.2\", \"mistral\", \"qwen2.5\", \"deepseek-r1:8b\"],\n            value=\"llama3.2\",\n            label=\"Local Model (Ollama)\"\n        )\n    ],\n    title=\"Local AI Chat\",\n    description=\"Chat with AI models running locally on your machine via Ollama.\"\n)\n\ndemo.launch()\n</code></pre>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#deploying-to-hugging-face-spaces","level":2,"title":"Deploying to Hugging Face Spaces","text":"<p>Hugging Face Spaces provides free hosting for Gradio applications. This is the easiest way to share your work with collaborators or the public.</p>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#method-1-deploy-from-the-command-line","level":3,"title":"Method 1: Deploy from the Command Line","text":"<ol> <li> <p>Install the Hugging Face CLI:</p> <pre><code>pip install huggingface_hub\n</code></pre> </li> <li> <p>Log in to Hugging Face:</p> <pre><code>huggingface-cli login\n</code></pre> </li> <li> <p>Create your app file (<code>app.py</code>):</p> <pre><code>import gradio as gr\n\ndef my_function(input_text):\n    return f\"You said: {input_text}\"\n\ndemo = gr.Interface(fn=my_function, inputs=\"text\", outputs=\"text\")\ndemo.launch()\n</code></pre> </li> <li> <p>Create a <code>requirements.txt</code> file:</p> <pre><code>gradio\ntransformers\ntorch\n</code></pre> </li> <li> <p>Deploy using the Gradio CLI:</p> <pre><code>gradio deploy\n</code></pre> <p>Follow the prompts to name your Space and configure settings.</p> </li> </ol>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#method-2-create-a-space-on-the-web","level":3,"title":"Method 2: Create a Space on the Web","text":"<ol> <li>Go to huggingface.co/new-space</li> <li>Choose \"Gradio\" as the SDK</li> <li>Name your Space and set visibility (public or private)</li> <li>Upload your <code>app.py</code> and <code>requirements.txt</code> files</li> <li>The Space will automatically build and deploy</li> </ol>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#method-3-use-the-share-feature","level":3,"title":"Method 3: Use the Share Feature","text":"<p>For quick sharing without permanent hosting:</p> <pre><code>demo.launch(share=True)\n</code></pre> <p>This creates a temporary public URL (valid for 72 hours) that anyone can access.</p> <p>Space Hardware</p> <p>Free Hugging Face Spaces run on basic CPU hardware. For GPU-accelerated models, you can upgrade to paid hardware tiers. See Hugging Face Spaces documentation for options.</p>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#best-practices","level":2,"title":"Best Practices","text":"","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#for-academic-applications","level":3,"title":"For Academic Applications","text":"<ol> <li>Add clear documentation: Use <code>gr.Markdown</code> to explain what your tool does and how to use it</li> <li>Provide examples: Include representative examples that demonstrate the tool's capabilities</li> <li>Handle errors gracefully: Validate inputs and provide helpful error messages</li> <li>Include citations: Add references to papers or methods your tool is based on</li> </ol>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#performance-tips","level":3,"title":"Performance Tips","text":"<ol> <li> <p>Cache expensive operations: <pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=100)\ndef expensive_computation(input_data):\n    # This result will be cached\n    return process(input_data)\n</code></pre></p> </li> <li> <p>Use queuing for concurrent users: <pre><code>demo.launch(enable_queue=True)\n</code></pre></p> </li> <li> <p>Stream long outputs: <pre><code>def generate_text(prompt):\n    for word in long_response.split():\n        yield word + \" \"\n\ndemo = gr.Interface(fn=generate_text, inputs=\"text\", outputs=\"text\")\n</code></pre></p> </li> </ol>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#security-considerations","level":3,"title":"Security Considerations","text":"<ul> <li>Never expose API keys in your code - use environment variables</li> <li>Be cautious with file uploads - validate file types and sizes</li> <li>Consider rate limiting for public applications</li> <li>Review Gradio's security guidelines</li> </ul>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#further-resources","level":2,"title":"Further Resources","text":"<ul> <li>Gradio Documentation: https://www.gradio.app/docs/</li> <li>Gradio Guides: https://www.gradio.app/guides/</li> <li>Hugging Face Spaces: https://huggingface.co/spaces</li> <li>Example Spaces Gallery: https://huggingface.co/spaces (browse for inspiration)</li> <li>Gradio GitHub: https://github.com/gradio-app/gradio</li> </ul>","path":["Research","Gradio"],"tags":[]},{"location":"gradio/#related-workshop-materials","level":2,"title":"Related Workshop Materials","text":"<ul> <li>Hugging Face: Learn how to find and use pre-trained models for your Gradio apps</li> <li>Ollama: Run local models that can power your Gradio interfaces</li> <li>Jupyter AI: Integrate AI assistants into your notebook workflows</li> <li>Code Execution: Understand safe practices for running code in AI applications</li> </ul>","path":["Research","Gradio"],"tags":[]},{"location":"huggingface/","level":1,"title":"Hugging Face","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#what-is-hugging-face","level":2,"title":"What is Hugging Face?","text":"<p>Hugging Face is the central hub for the open-source AI community. Think of it as \"GitHub for AI models\" - a platform where researchers and developers share:</p> <ul> <li>Models: Pre-trained AI models ready to download and use</li> <li>Datasets: Training and evaluation data for machine learning</li> <li>Spaces: Interactive demos and applications</li> <li>Documentation: Model cards, papers, and usage guides</li> </ul> <p>For researchers and academics, Hugging Face provides access to state-of-the-art models without needing to train them from scratch, saving significant computational resources and time.</p> Create a Hugging Face Account <p> Hugging Face</p> <p>Follow these instructions to sign up for Hugging Face:</p> <ol> <li> <p>Visit the Hugging Face website: https://huggingface.co</p> </li> <li> <p>Click on the \"Sign Up\" button in the top-right corner of the page.</p> </li> <li> <p>Fill in your email address, username, and password in the respective fields.</p> </li> <li> <p>Check the box to agree to Hugging Face's terms and conditions, then click \"Sign Up.\"</p> </li> <li> <p>You'll receive an email to confirm your account. Click on the confirmation link in the email.</p> </li> <li> <p>Once your account is confirmed, sign in to access Hugging Face's features.</p> </li> </ol> <p>For more information, visit the Hugging Face documentation: https://huggingface.co/docs</p>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#navigating-the-hub","level":2,"title":"Navigating the Hub","text":"","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#finding-models","level":3,"title":"Finding Models","text":"<p>The Model Hub hosts over 1 million models. To find what you need:</p> <ol> <li>Browse by Task: Filter by what you want to do (text generation, image classification, translation, etc.)</li> <li>Sort by Downloads: Popular models are well-tested and documented</li> <li>Filter by License: Important for academic and commercial use</li> <li>Check the Model Card: Every model should have documentation explaining its capabilities and limitations</li> </ol> <p>Popular Model Categories for Researchers:</p> Category Example Models Use Cases Text Generation Llama 3, Mistral, Qwen Writing assistance, code generation, analysis Embeddings BGE, E5, GTE Document search, similarity matching, RAG Vision-Language LLaVA, Qwen-VL Image analysis, chart interpretation Speech Whisper, Wav2Vec2 Transcription, audio analysis","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#finding-datasets","level":3,"title":"Finding Datasets","text":"<p>The Dataset Hub hosts datasets for training and evaluation:</p> <ol> <li>Search by Domain: Academic papers, code, images, audio, etc.</li> <li>Check Size and Format: Ensure it fits your storage and processing capabilities</li> <li>Review the License: Some datasets have restrictions on use</li> </ol>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#installing-the-hugging-face-cli","level":2,"title":"Installing the Hugging Face CLI","text":"<p>The <code>huggingface_hub</code> library provides tools for downloading and managing models.</p>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#installation","level":3,"title":"Installation","text":"pipconda <pre><code>pip install huggingface_hub\n</code></pre> <pre><code>conda install -c conda-forge huggingface_hub\n</code></pre>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#authentication-required-for-some-models","level":3,"title":"Authentication (Required for Some Models)","text":"<p>Some models (especially Llama and other gated models) require you to accept license terms and authenticate:</p> <ol> <li>Create an Access Token:</li> <li>Go to huggingface.co/settings/tokens</li> <li>Click \"New token\" and create a token with \"Read\" access</li> <li> <p>Copy the token (you will only see it once)</p> </li> <li> <p>Login via CLI: <pre><code>huggingface-cli login\n</code></pre>    Paste your token when prompted.</p> </li> <li> <p>Accept Model License (for gated models):</p> </li> <li>Visit the model page (e.g., meta-llama/Llama-3.3-70B-Instruct)</li> <li>Click \"Access repository\" and accept the license terms</li> </ol> <p>Token Security</p> <p>Treat your Hugging Face token like a password. Do not commit it to version control or share it publicly.</p>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#downloading-models","level":2,"title":"Downloading Models","text":"","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#method-1-using-ollama-recommended-for-beginners","level":3,"title":"Method 1: Using Ollama (Recommended for Beginners)","text":"<p>The easiest way to run Hugging Face models locally is through Ollama, which handles all the complexity:</p> <pre><code># Install Ollama (if not already installed)\ncurl -fsSL https://ollama.com/install.sh | sh\n\n# Run popular models directly\nollama run llama3.2\nollama run mistral\nollama run qwen2.5\n</code></pre> <p>Ollama automatically downloads optimized versions of models from Hugging Face.</p>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#method-2-using-huggingface-cli","level":3,"title":"Method 2: Using huggingface-cli","text":"<p>For more control, download models directly:</p> <pre><code># Download a specific model\nhuggingface-cli download microsoft/Phi-3-mini-4k-instruct\n\n# Download to a specific directory\nhuggingface-cli download microsoft/Phi-3-mini-4k-instruct --local-dir ./models/phi3\n\n# Download only specific files (useful for large models)\nhuggingface-cli download meta-llama/Llama-3.2-1B --include \"*.safetensors\"\n</code></pre>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#method-3-using-python","level":3,"title":"Method 3: Using Python","text":"<pre><code>from huggingface_hub import snapshot_download\n\n# Download entire model repository\nmodel_path = snapshot_download(\n    repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n    local_dir=\"./models/phi3\"\n)\n\nprint(f\"Model downloaded to: {model_path}\")\n</code></pre>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#running-models-locally","level":2,"title":"Running Models Locally","text":"<p>Once downloaded, you can run models using various frameworks.</p>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#option-1-transformers-library-most-flexible","level":3,"title":"Option 1: Transformers Library (Most Flexible)","text":"<p>The <code>transformers</code> library from Hugging Face is the standard for working with models:</p> <pre><code>pip install transformers torch accelerate\n</code></pre> <p>Basic Text Generation Example:</p> <pre><code>from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\n# Load model and tokenizer\nmodel_name = \"microsoft/Phi-3-mini-4k-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,  # Use half precision to save memory\n    device_map=\"auto\"           # Automatically use GPU if available\n)\n\n# Generate text\nprompt = \"Explain the process of photosynthesis in simple terms:\"\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=200,\n    temperature=0.7,\n    do_sample=True\n)\n\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)\n</code></pre>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#option-2-llamacpp-efficient-cpugpu-inference","level":3,"title":"Option 2: llama.cpp (Efficient CPU/GPU Inference)","text":"<p>For running models efficiently on consumer hardware, <code>llama.cpp</code> provides optimized inference:</p> <pre><code># Install llama-cpp-python\npip install llama-cpp-python\n\n# Or with GPU support (CUDA)\nCMAKE_ARGS=\"-DGGML_CUDA=on\" pip install llama-cpp-python\n</code></pre> <p>Using GGUF Format Models:</p> <pre><code>from llama_cpp import Llama\n\n# Download a GGUF model from Hugging Face\n# Example: https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF\n\nllm = Llama(\n    model_path=\"./models/mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n    n_ctx=4096,      # Context window\n    n_threads=8,     # CPU threads\n    n_gpu_layers=35  # Layers to offload to GPU (0 for CPU-only)\n)\n\noutput = llm(\n    \"What are the key differences between supervised and unsupervised learning?\",\n    max_tokens=300,\n    temperature=0.7,\n    echo=False\n)\n\nprint(output[\"choices\"][0][\"text\"])\n</code></pre>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#option-3-text-generation-web-ui","level":3,"title":"Option 3: Text Generation Web UI","text":"<p>For a graphical interface, text-generation-webui provides a ChatGPT-like experience for local models.</p>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#recommended-models-for-beginners","level":2,"title":"Recommended Models for Beginners","text":"<p>Here are well-tested models suitable for different hardware configurations:</p>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#small-models-4-8gb-ram","level":3,"title":"Small Models (4-8GB RAM)","text":"Model Size Best For Phi-3-mini 3.8B General tasks, runs on laptops Qwen2.5-3B-Instruct 3B Multilingual, good reasoning Llama-3.2-1B-Instruct 1B Very fast, basic tasks","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#medium-models-16-32gb-ram","level":3,"title":"Medium Models (16-32GB RAM)","text":"Model Size Best For Llama-3.2-3B-Instruct 3B Balanced performance Mistral-7B-Instruct 7B Excellent general purpose Qwen2.5-7B-Instruct 7B Strong reasoning, coding","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#large-models-gpu-required","level":3,"title":"Large Models (GPU Required)","text":"Model Size Best For Llama-3.3-70B-Instruct 70B Near-frontier performance Qwen2.5-72B-Instruct 72B State-of-the-art open model DeepSeek-R1 671B Advanced reasoning (requires cluster) <p>Quantized Models</p> <p>For running larger models on limited hardware, look for quantized versions (GGUF format). These reduce memory requirements with minimal quality loss. Search for model names with \"GGUF\" or visit TheBloke for quantized versions.</p>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#downloading-datasets","level":2,"title":"Downloading Datasets","text":"","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#using-the-datasets-library","level":3,"title":"Using the datasets Library","text":"<pre><code>pip install datasets\n</code></pre> <p>Load a Dataset:</p> <pre><code>from datasets import load_dataset\n\n# Load a dataset from the Hub\ndataset = load_dataset(\"squad\")  # Stanford Question Answering Dataset\n\n# View dataset structure\nprint(dataset)\nprint(dataset[\"train\"][0])  # First training example\n</code></pre> <p>Download for Offline Use:</p> <pre><code>from datasets import load_dataset\n\n# Download and cache locally\ndataset = load_dataset(\n    \"scientific_papers\",\n    \"arxiv\",\n    cache_dir=\"./data/scientific_papers\"\n)\n\n# Save to disk in a specific format\ndataset.save_to_disk(\"./data/arxiv_papers\")\n</code></pre>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#popular-academic-datasets","level":3,"title":"Popular Academic Datasets","text":"Dataset Description Size arxiv-papers ArXiv papers 4.6TB of papers wikipedia Wikipedia articles Multiple languages pile Diverse text corpus 800GB code_search_net Code from GitHub 6M functions","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#spaces-interactive-demos","level":2,"title":"Spaces: Interactive Demos","text":"<p>Hugging Face Spaces hosts interactive applications built with models:</p> <ul> <li>Try before you download: Test models in your browser</li> <li>Share your work: Deploy demos for papers or projects</li> <li>Learn from examples: See how others implement solutions</li> </ul> <p>Most Spaces are built using Gradio, an open-source Python library for creating web interfaces for ML models. You can build and deploy your own Gradio apps to Spaces with just a few lines of code. See our Gradio documentation for tutorials and examples.</p> <p>Notable Spaces for Researchers:</p> <ul> <li>Whisper - Audio transcription</li> <li>Document Question Answering - Extract information from documents</li> <li>Stable Diffusion - Image generation</li> </ul>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#best-practices","level":2,"title":"Best Practices","text":"","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#storage-management","level":3,"title":"Storage Management","text":"<p>Models can be large. Manage your cache:</p> <pre><code># View cache usage\nhuggingface-cli scan-cache\n\n# Delete unused models\nhuggingface-cli delete-cache\n</code></pre>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#model-selection-tips","level":3,"title":"Model Selection Tips","text":"<ol> <li>Start small: Begin with smaller models to test your workflow</li> <li>Check benchmarks: Review model cards for performance on relevant tasks</li> <li>Consider licensing: Ensure the license fits your use case (research vs. commercial)</li> <li>Read the limitations: Model cards describe known issues and biases</li> </ol>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#for-academic-use","level":3,"title":"For Academic Use","text":"<ul> <li>Cite properly: Model cards include citation information</li> <li>Document your setup: Record model versions and parameters for reproducibility</li> <li>Check data provenance: Understand what data was used to train the model</li> </ul>","path":["Research","Hugging Face"],"tags":[]},{"location":"huggingface/#further-resources","level":2,"title":"Further Resources","text":"<ul> <li>Hugging Face Documentation: https://huggingface.co/docs</li> <li>Transformers Library: https://huggingface.co/docs/transformers</li> <li>Hugging Face Course: https://huggingface.co/learn (Free NLP course)</li> <li>Model Hub: https://huggingface.co/models</li> <li>Dataset Hub: https://huggingface.co/datasets</li> <li>Spaces: https://huggingface.co/spaces</li> <li>Gradio (for building Spaces): See our Gradio documentation for tutorials on building interactive demos</li> </ul> <p>Hugging Face vs. Ollama</p> <p>For most workshop participants, we recommend starting with Ollama for running local models. It handles model downloading and optimization automatically. Use Hugging Face directly when you need:</p> <ul> <li>Access to specific model versions or configurations</li> <li>Fine-tuning or training capabilities</li> <li>Datasets for research</li> <li>Models not available in Ollama's library</li> </ul>","path":["Research","Hugging Face"],"tags":[]},{"location":"jupyter/","level":1,"title":"Jupyter AI","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>The Project Jupyter team has incorporated a chatbot plugin called Jupyternaut</p> <p>Jupyter AI</p>","path":["Research","Jupyter AI"],"tags":[]},{"location":"legal/","level":1,"title":"Ethical &amp; Legal Considerations","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#foundations-of-the-ethical-principles-for-ai","level":2,"title":"Foundations of the Ethical principles for AI","text":"<p>This lesson focuses on the ethical principles that ground AI in a legal landscape.</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#science-fiction-or-a-philosophical-theory","level":3,"title":"Science Fiction or a Philosophical Theory?","text":"<p>In the early 1950's Alan Turing the father of all modern computing, proposed a test for intelligence in a computer, requiring that a human being should be unable to distinguish the machine from another human being by using the replies to questions put to both.</p> <p>The Imitation Game </p> <p>\"Can Machines Think?\" -- Alan Turing, 1950</p> Today's Turing Tests <p> </p> <p> </p> <p>Author Isaac Asimov wrote a series of popular science fiction novels in the 1950's through the 1980's. His work continues to be adapted into television series and movies. In his novels, Asimov developed Three Laws of Robotics which described how artificial intelligence interacted with humanity in his fictional universe. </p>  The Three Laws <p>1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.</p> <p>2. A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.</p> <p>3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.</p> <p>Asimov later wrote of a 'zeroth' law which superceded the first three laws,</p> <p>0. A robot may not injure humanity or, through inaction, allow humanity to come to harm.</p> <p></p> <p>Asimov's Three Laws are difficult to interpret in a real-world setting and he himself spent most of his novels describing creative and unexpected ways in which the Three Laws were twisted yet not broken. The basis of the Three Laws as a legal framework is untenable, but does represent a moral and ethical starting point from which we can think about AI and the legal rights of non-biological beings.  </p> <p>Another science-fiction author Sir Arthur C. Clarke, in 1978 provided an interesting perspective on how humanity would have to come to terms with AI once its capabilities surpass our own:</p> <p>Recently, researchers published findings showing that current GPTs are now capable of passing Turing tests. As our conception of intelligence shifts (Mitchell 2024), mostly in reaction to the release of ChatGPT and its myriad of competitors, new standards of the Turing Test are being proposed. </p> <p>Importantly, current AI exposes the limits of Turing Tests based on imitation without comprehension. </p> <p>The Turing Trap is a term coined by Stanford University professor Erik Brynjolfsson to describe the idea that focusing too much on developing human-like artificial intelligence (HLAI) can be detrimental. </p> <p>Brynjolfsson argues that the real potential of AI lies in its ability to augment human abilities, rather than replacing them. He suggests that we should work on challenges that are easy for machines and hard for humans, rather than the other way around. </p> <p>Beware the Turing Trap</p> <p>Automation can replace humans</p> <p>HLAI can replace humans in the workplace, which can lead to: </p> <ul> <li> <p>Lower wages </p> <p>As machines become better substitutes for human labor, wages can be driven down.</p> </li> <li> <p>Loss of economic and political power </p> <p>Workers can lose economic and political bargaining power, and become increasingly dependent on those who control the technology.</p> </li> <li> <p>Decision-making processes incentivize automation</p> <p>Companies may choose to automate tasks to do the same thing faster and cheaper.</p> </li> <li> <p>Misaligned incentives</p> <p>The risks of the Turing Trap are increased by the misaligned incentives of technologists, businesspeople, and policy-makers. </p> </li> </ul>  this text was written by  AI and then reviewed by a human. Do you still trust it? <p>Researchers have found disclosing the use of AI makes people trust you less.</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#ethical-ai","level":2,"title":"Ethical AI","text":"<p>In \"A Unified Framework of Five Principles for AI in Society\" (Floridi &amp; Cowls 2019) core principles for ethical AI are introduced (Table 1).</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#table-1-floridi-cowls-2019-five-principles-for-ai-in-society","level":4,"title":"Table 1: Floridi &amp; Cowls (2019) Five principles for AI in Society","text":"Beneficiance Non-Maleficence Autonomy Justice Explicability Promoting Well-Being, Preserving Dignity, and Sustaining the Planet Privacy, Security and ‘Capability Caution’ The Power to Decide (to Decide) Promoting Prosperity, Preserving Solidarity, Avoiding Unfairness Enabling the Other Principles through Intelligibility and Accountability","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#international-agreements-on-ai","level":2,"title":"International Agreements on AI","text":"<p>A milestone  in the Ethics of Artificial Intelligence () occurred in January 2017 in Pacific Grove, California at the historic Asilomar Hotel and Conference Grounds (Table 2). There the Asilomar AI Principles were signed by leading AI researchers, ethicists, and thought leaders. </p> <p>By 2021, UNESCO had created their own recommendations on AI, focused on human rights and sustainable development.</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#table-2-international-ai-agreements","level":4,"title":"Table 2: International AI agreements","text":"Agreement Date Signatories Description Asilomar AI Principles January 2017 AI researchers, ethicists, and thought leaders A set of 23 principles designed to guide the development of beneficial AI, covering research, ethics, and long-term issues. Toronto Declaration May 16, 2018 Amnesty International, Access Now, Human Rights Watch, Wikimedia Foundation, and others A declaration advocating for the protection of the rights to equality and non-discrimination in machine learning systems. OECD AI Principles May 22, 2019 OECD member countries and others Principles to promote AI that is innovative and trustworthy and that respects human rights and democratic values. G20 AI Principles June 9, 2019 G20 member countries A commitment to human-centered AI, building upon the OECD AI Principles, emphasizing inclusivity, transparency, and accountability. WHO Ethics and governance of artificial intelligence for health June 2021 WHO Ministries of Health members A guidance on  eighteen months of deliberation amongst experts from Ministries of Health UNESCO Recommendation on the Ethics of Artificial Intelligence November 2021 UNESCO member states A global framework to ensure that digital transformations promote human rights and contribute to the achievement of the Sustainable Development Goals. European Union Artificial Intelligence Act July 2024 EU member countries Classifies risk, obligations, legal, and general purpose AI laws UN Resolution A/RES/79/325 August 2025 United Nations Resolution Created the Scientific Panel on AI (like the IPCC for AI) <p>In response to the rapid rise of generative AI, specifically GPTs, new agreements on the application of AI for military use, safety, and on its adoption in business and industry were recently signed (Table 3).</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#table-3-declarations-on-ai","level":4,"title":"Table 3: Declarations on AI","text":"Agreement Date Signatories Description Source Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy February 16, 2023 United States and 50 other countries A declaration outlining principles for the responsible use of AI and autonomy in military applications. U.S. Department of State International Network of AI Safety Institutes May 2024 United Kingdom, United States, Japan, France, Germany, Italy, Singapore, South Korea, Australia, Canada, European Union A network formed to evaluate and ensure the safety of advanced AI models through international collaboration. The Independent AI Safety Agreement between the UK and US June 2024 United Kingdom, United States An agreement to collaborate on testing advanced AI models to ensure safety and manage risks. BBC News Framework Convention on Artificial Intelligence September 5, 2024 United States, United Kingdom, European Union, Andorra, Georgia, Iceland, Norway, Republic of Moldova, San Marino, Israel The first legally binding international treaty on AI, aiming to ensure AI activities are consistent with human rights, democracy, and the rule of law. Council of Europe AI Alliance Network December 11, 2024 Russia, BRICS countries (Brazil, China, India, South Africa), Serbia, Indonesia, and others An initiative to develop AI collaboratively, focusing on joint research, regulation, and commercialization of AI products among member countries. Reuters","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#current-legislation","level":2,"title":"Current Legislation","text":"<p>National Conference of State Legislatures (NCSL) Artificial Intelligence 2025 Legislation</p> <p>The previous administration had proposed a \"Blueprint for an AI Bill of Rights\", and executive order around the \"Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence\" which is now rescinded. </p> <p>The current administration has instead focused most of its efforts on executive orders related to AI and federal agencies. Pending legislation would ban states' ability to enforce AI regulations. </p> <p>2025 Executive Orders</p> <ul> <li> <p>REMOVING BARRIERS TO AMERICAN LEADERSHIP IN ARTIFICIAL INTELLIGENCE, January 23, 2025</p> </li> <li> <p>OMB Accelerating Federal Use of AI through Innovation, Governance, and Public Trust, April 3, 2025</p> <ul> <li>Fact Sheet: Eliminating Barriers for Federal Artificial Intelligence Use and Procurement, April 7, 2025</li> </ul> </li> <li> <p>ADVANCING ARTIFICIAL INTELLIGENCE EDUCATION FOR AMERICAN YOUTH, April 23, 2025</p> </li> <li> <p>Restoring Gold Standard Science, May 23, 2025</p> <ul> <li>Fact Sheet: President Donald J. Trump is Restoring Gold Standard Science in America</li> </ul> </li> </ul> <p>As of today, there are no comprehensive federal laws or regulations that have been enacted to specifically regulate AI in the United States of America.  </p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#ai-ethics","level":2,"title":"AI Ethics","text":"What are we talking about, the Ethics of AI, or Ethical AI? How are they different? <p>They are not the same thing</p> <p>Siau and Wang 2020 delineate \"Ethics of AI\" and \"Ethical AI\" as</p> <p>Ethics of AI: studies the ethical principals, rules, guidelines, policies, and regulations related to AI.</p> <p>Ethical AI: is AI that performs or behaves ethically. </p> <p>As consumers of GPTs and other AI platforms, we must consider in what ways can we use AI both effectively, and ethically.</p> <p>When can you use a GPT for research and education?</p> <pre><code>graph TB\n  A((Start)) --&gt; B(\"Does it matter if the outputs are true?\");\n  B --&gt;| No | F(\"Safe to use GPT\");\n  B --&gt;| Yes | C(\"Do you have the ability to verify output truth and accuracy?\");\n  C --&gt;| Yes | D(\"Understand legal and moral responsibility of your errors?\");\n  C --&gt;| No | E(\"Unsafe to use GPT\");\n  D --&gt;| Yes | F(\"Safe to use GPT\");\n  D --&gt;| No | E(\"Unsafe to use GPT\");\n\n  style A fill:#2ECC71,stroke:#fff,stroke-width:2px,color:#fff\n  style B fill:#F7DC6F,stroke:#fff,stroke-width:2px,color:#000\n  style C fill:#F7DC6F,stroke:#fff,stroke-width:2px,color:#000\n  style D fill:#F7DC6F,stroke:#fff,stroke-width:2px,color:#000\n  style E fill:#C0392B,stroke:#fff,stroke-width:2px,color:#fff\n  style F fill:#2ECC71,stroke:#fff,stroke-width:2px,color:#fff</code></pre> <p>Figure credit:  ChatGPT and Artificial Intelligence in Education, UNESCO 2023 </p> <p></p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#recent-controversy","level":2,"title":"Recent Controversy","text":"","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#maps-of-ai-copyright-lawsuits","level":3,"title":"Maps of AI Copyright Lawsuits","text":"<p> Master list of current lawsuits against AI companies</p> <p>Current AI models are overwhelmingly based on European and North American historical literature and language. Over half of the content on the internet () is written in English. This creates a Eurocentric bias in AI training data, resulting in an erasure of global culture, experience, and language. Such asymmetries need to be addressed, but there is at present a lack economic incentives for large tech companies and organizations (see The Imitation Game  above). </p> <p>The   Bullshit Machines</p> <p>Professors Carl T. Bergstrom and Jevin D. West teach a course at University of Washington titled \"Calling Bullshit\", they have written an e-book on GPTs called:</p> <p>\"Modern-Day Oracles or Bullshit Machines?\"</p> <p>Their website provides online lesson vignettes and materials for instructors.</p> <p>Negative consequences of GPTs explosion into the public space are its mis-use as well as its adoption for illegal activity. </p> <ul> <li> <p>A lawyer submits a legal brief written by ChatGPT and is caught</p> </li> <li> <p>Prompt Injection Attacks</p> </li> </ul> <p>There are deep ethical concerns about the use of AI like GPT and LLMs, particularly concerning their training data. </p> <ul> <li>A Class Action lawsuit: GitHub CoPilot was trained on private repositories</li> </ul> <p>AI companies also effectively steal designs, visual art, and music styles to train their private models. </p> <ul> <li>MidJourney and Dall-E using trademarked imagery and art</li> </ul> <p>ChatGPT has effectively gamified higher education and is being used to spread disinformation and hate speech. </p> <ul> <li> <p>College students using ChatGPT</p> </li> <li> <p>Combating Academic Dishonesty (6-part series)</p> </li> </ul>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#recent-literature","level":2,"title":"Recent Literature","text":"<p>Here are some recent papers that discuss the ethical concerns surrounding AI:</p> <ul> <li> <p>\"AI Safety and the Age of Convergences\" (2024) - Schuett, J., Schuett, J., &amp; Korinek, A. https://doi.org/10.48550/arXiv.2401.06531</p> </li> <li> <p>\"On the Opportunities and Risks of Foundation Models\" (2023) - Bommasani et al. https://doi.org/10.48550/arXiv.2108.07258</p> </li> <li> <p>Unraveling the Ethical Conundrum of Artificial Intelligence: A Synthesis of Literature and Case Studies Poli, P.K.R., Pamidi, S. &amp; Poli, S.K.R. Augment Hum Res 10, 2 (2025). https://doi.org/10.1007/s41133-024-00077-5</p> </li> <li> <p>\"The Ethics of Artificial Intelligence in Education: A Review of the Literature\" (2023) - Zawacki-Richter, O., Marín, V. I., Bond, M., &amp; Gouverneur, F. https://doi.org/10.1007/s10639-019-09882-z</p> </li> <li> <p>\"The Ethical Challenges of Algorithmic Bias in Artificial Intelligence: a scoping review\" (2023) - Borenstein, J., Glikson, E., &amp; Krishnamurthy, V. https://doi.org/10.1007/s43681-023-00313-z</p> </li> <li> <p>\"Ethics of Artificial Intelligence\" (2020) - S. Matthew Liao https://doi.org/10.1093/oso/9780190905033.001.0001</p> </li> <li> <p>The Ethics of AI Ethics: An Evaluation of Guidelines. (2020) Hagendorff, T.  Minds &amp; Machines 30, 99–120. https://doi.org/10.1007/s11023-020-09517-8</p> </li> </ul>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#assessment","level":2,"title":"Assessment","text":"True or False: The \"Turing Trap\" primarily warns against the socio-economic disruptions and misaligned incentives that arise from an overemphasis on creating AI that imitates human intelligence. True <p>The Turing Trap by Stanford University professor Erik Brynjolfsson describes the idea that focusing too much on developing human-like artificial intelligence (HLAI) is detrimental. </p> <p>Brynjolfsson further elaborates risks like lower wages, loss of economic power, and misaligned incentives due to automation replacing humans.</p> True or False: The concepts of \"Ethics of AI\" and \"Ethical AI\" are fundamentally distinct. True <p>Siau and Wang (2020): \"Ethics of AI: studies the ethical principals, rules, guidelines, policies, and regulations related to AI.\" and \"Ethical AI: is AI that performs or behaves ethically.\" </p> Multiple Choice: According to Floridi &amp; Cowls' (2019) \"Unified Framework of Five Principles for AI in Society,\" which principle most directly underscores the importance of AI systems being designed to be understandable, traceable, and accountable for their operations and decisions? <ul> <li>A) Beneficence </li> <li>B) Non-Maleficence </li> <li>C) Justice </li> <li>D) Explicability </li> </ul> Answer <p>D) Explicability</p> <p>Table 1 from Floridi &amp; Cowls (2019) describes Explicability as \"Enabling the Other Principles through Intelligibility and Accountability.\" This directly relates to AI systems being understandable, traceable, and accountable.</p> Multiple Choice: The Asilomar AI Principles, established in 2017, are best characterized as: <ul> <li>A) A legally binding international treaty mandating specific safety protocols for all AI development.</li> <li>B) A technical specification for building universally safe Artificial General Intelligence.</li> <li>C) A foundational set of guiding principles addressing research ethics, societal values, and long-term considerations for developing beneficial AI.</li> <li>D) A corporate social responsibility charter adopted exclusively by major technology companies.</li> </ul> Answer <p>C) A foundational set of guiding principles addressing research ethics, societal values, and long-term considerations for developing beneficial AI.</p> <p>Table 2 describes the Asilomar AI Principles as \"A set of 23 principles designed to guide the development of beneficial AI, covering research, ethics, and long-term issues.\" This aligns with option C and not with the descriptions of a legally binding treaty, a technical specification, or an exclusive corporate charter.</p> What recent international agreement is the \"first legally binding international treaty on AI,\" specifically designed to ensure that AI activities are developed and applied in a manner consistent with human rights, democracy, and the rule of law. What is the name of this treaty? Success <p>Framework Convention on Artificial Intelligence</p> <p>Table 3 lists the Framework Convention on Artificial Intelligence (September 5, 2024) with the description: \"The first legally binding international treaty on AI, aiming to ensure AI activities are consistent with human rights, democracy, and the rule of law.\"</p> True or False: The United States has the strongest regulations and most comprehensive federal laws specifically enacted to regulate AI. False <p>The US has no laws around the regulation of AI to-date. Current legislation around AI is happening at a state level, but that may be stopped by federal legislation banning regulation. Currently, the administration favors Executive Orders.</p> <p>On the other side of the pond, the EU has proposed and is developing regulations through the European Union Artificial Intelligence Act (2024-2031).</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"mcp/","level":1,"title":"Model Context Protocol (MCP)","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"mcp/#what-is-model-context-protocol-mcp","level":2,"title":"What is Model Context Protocol (MCP)?","text":"<p>Model Context Protocol (MCP) is a standardized communication framework designed to allow Large Language Models (LLMs) and other AI tools to access and understand the context of what a user is currently working on within various applications.</p> <p>Think of it as a universal translator and information bridge. It enables your AI assistant to \"see\" and \"interact with\" the content and state of your active applications—be it your code editor, a 3D modeling suite, a design tool, or a document processor.</p> <p>Core Purpose of MCP:</p> <ul> <li>Deepen AI Understanding: By providing LLMs with rich, real-time context from applications, MCP allows them to offer far more accurate, relevant, and integrated assistance. Instead of generic advice, the AI can give specific, actionable suggestions based on your current work.</li> <li>Enable Interoperability: MCP aims to create a common ground for different software tools and AI models to share contextual information seamlessly. This breaks down the traditional silos between applications, allowing for more fluid workflows.</li> <li>Facilitate Dynamic Interaction: MCP is not just about reading context; it can also be about acting on it. This opens the door for AI to suggest modifications, automate tasks, or even co-create content directly within the host application. This is a key component of what some call \"Vibe Coding\" or \"Contextual AI Assistance,\" where the AI has a deep, almost intuitive understanding of the project's flow and the user's intent.</li> </ul> <p>Why is MCP Important?</p> <p>As AI becomes increasingly integrated into professional and creative workflows, the need for it to understand the specifics of our work is paramount. Generic LLMs are powerful, but MCP unlocks a new level of utility by making them context-aware and application-aware.</p>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"mcp/#how-mcp-works-the-core-components","level":2,"title":"How MCP Works: The Core Components","text":"<p>MCP typically operates on a client-server model and defines the rules for how contextual information is exchanged.</p> <pre><code>flowchart LR\n    subgraph \"Your Computer\"\n        Host[\"VS Code\"]\n        S1[\"MCP Weaviate\"]\n        S2[\"MCP GitHub\"]\n        S3[\"MCP iRODS\"]\n        S4[\"MCP Fetch\"]\n        Host &lt;--&gt;|\"MCP Protocol\"| S1\n        Host &lt;--&gt;|\"MCP Protocol\"| S2\n        Host &lt;--&gt;|\"MCP Protocol\"| S3\n        Host &lt;--&gt;|\"MCP Protocol\"| S4\n        S1 &lt;--&gt; D1[(\"Constellate JSON\")]\n        S2 &lt;--&gt; D2[(\"Git Code Repository\")]\n    end\n    subgraph \"Internet\"\n        S3 &lt;--&gt;|\"Web APIs\"| D3[(\"Data Store\")]\n        S4 &lt;--&gt;|\"Web APIs\"| D4[(\"Website\")]\n    end</code></pre> <ul> <li> <p>MCP Servers (Providers):</p> <ul> <li>These are often implemented as extensions, plugins, or add-ons within host applications (e.g., a VS Code Server Extension, a Blender Add-on).</li> <li>Their primary role is to expose relevant contextual information from the application. This might include:<ul> <li>The content of the currently open file(s).</li> <li>User selections (text, objects, layers).</li> <li>Project structure or scene graphs.</li> <li>Application state (e.g., current tool, mode, error messages).</li> <li>Undo/redo history (in more advanced scenarios).</li> </ul> </li> <li>MCP Servers listen for requests from MCP Clients and respond with structured context snippets.</li> <li>They may also expose capabilities for the client to invoke actions within the application.</li> </ul> </li> <li> <p>MCP Clients (Consumers):</p> <ul> <li>These are typically LLMs, AI assistants (like a conceptual Claude Desktop with MCP capabilities), or other tools that need to consume context.</li> <li>They request context from MCP Servers to better understand the user's environment and intent.</li> <li>This context is then used by the LLM to:<ul> <li>Generate more relevant and accurate responses.</li> <li>Offer context-specific suggestions.</li> <li>Formulate requests for actions to be performed in the host application.</li> </ul> </li> </ul> </li> <li> <p>The Protocol Specification:</p> <ul> <li>This is the heart of MCP. It defines the rules of engagement:<ul> <li>Message Formats: How data is structured (commonly JSON or similar).</li> <li>Transport Mechanisms: How messages are sent (e.g., WebSockets, HTTP, gRPC, or other Inter-Process Communication (IPC) methods).</li> <li>Discovery: How clients find and connect to available MCP servers.</li> <li>Context Types: Standardized ways to describe different kinds of context (e.g., <code>text_document_v1</code>, <code>selection_v1</code>, <code>blender_scene_graph_v1</code>). This ensures both client and server understand the data being exchanged.</li> <li>Request/Response Patterns: Defines how clients ask for context (or actions) and how servers provide it (or confirm actions).</li> <li>Capabilities Negotiation: A way for client and server to understand what context types and actions each supports.</li> </ul> </li> </ul> </li> </ul> <p>Simplified Communication Flow:</p> <ol> <li>Discovery &amp; Connection: The MCP Client (e.g., Claude Desktop) discovers and establishes a connection with an MCP Server running in a target application (e.g., Blender). This might happen automatically on application launch or upon user command.</li> <li>User Interaction / AI Trigger: The user asks the AI a question or performs an action that triggers the AI to seek more context.</li> <li>Context Request: The MCP Client sends a request to the MCP Server for specific types of context relevant to the user's query or the AI's needs.</li> <li>Context Provision: The MCP Server gathers the requested information from the host application and sends it back to the Client as one or more context snippets.</li> <li>LLM Processing: The Client (or the LLM it interfaces with) processes the user's original prompt enriched with the received context.</li> <li>Informed Response / Action Invocation:<ul> <li>The LLM generates a more informed and relevant response to the user.</li> <li>Alternatively, the LLM might decide an action is needed within the host application. It would then instruct the MCP Client to send an \"action request\" to the MCP Server.</li> </ul> </li> <li>Action Execution &amp; Feedback (if applicable): The MCP Server receives the action request, validates it, and attempts to perform the action using the host application's APIs. It then sends a response back to the client indicating success or failure.</li> </ol>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"mcp/#benefits-of-using-mcp","level":2,"title":"Benefits of Using MCP","text":"<ul> <li>Hyper-Relevant AI Assistance: LLMs can provide advice, code, or content that is directly applicable to the task at hand.</li> <li>Seamless Workflow Integration: AI becomes a \"native\" part of the application experience, rather than a separate tool requiring constant copy-pasting.</li> <li>Reduced Cognitive Load &amp; Task Switching: Users get help where they are, minimizing disruption.</li> <li>Powerful Automation Capabilities: Enables AI to perform routine or complex tasks within applications on the user's behalf.</li> <li>Enhanced \"Vibe Coding\": The AI can better anticipate needs and understand the nuances of a project by having access to its evolving state.</li> <li>Cross-Application Coordination (Future Potential): Imagine an AI orchestrating tasks across multiple MCP-enabled applications.</li> </ul>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"mcp/#key-takeaways","level":2,"title":"Key Takeaways 🚀","text":"<ul> <li>MCP is a Context Bridge: It connects LLMs to the live working environments of applications.</li> <li>Client-Server Model: Applications (via Servers/Add-ons) provide context and action capabilities; AI tools (Clients) consume and utilize them.</li> <li>Standardization is Crucial: A well-defined protocol (message formats, context types, action IDs) is essential for interoperability.</li> <li>Beyond Information Retrieval: MCP enables AI to become an active participant by invoking actions within tools.</li> <li>The Future is Integrated: MCP and similar protocols are foundational for building truly integrated AI co-pilots and assistants that enhance \"Vibe Coding\" and other context-rich workflows.</li> <li>Still Evolving: While the concepts are powerful, widespread adoption, robust implementations, and universally accepted standards for MCP are areas of active development in the AI and software industries.</li> </ul>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"mcp/#further-exploration-discussion-points","level":2,"title":"Further Exploration &amp; Discussion Points 📚","text":"<ul> <li>Security Implications: How do we ensure that MCP connections are secure and that AI actions are sandboxed or require user confirmation for sensitive operations?</li> <li>Granularity of Context: What is the \"right\" amount of context? Too little is unhelpful; too much can be overwhelming or slow.</li> <li>Discoverability: How can users and AI clients easily discover which applications support MCP and what capabilities they offer?</li> <li>User Experience: How should AI interactions mediated by MCP be presented to the user to be intuitive and non-intrusive?</li> <li>Real-world Implementations: Research existing VS Code extensions or other tool integrations that use similar context-sharing mechanisms (even if not formally labeled \"MCP\"). What can we learn from them?</li> <li>Your Tools: Think about the applications you use daily. How could MCP enhance your workflow with them if an AI could understand and interact with their context?</li> </ul> <p>This workshop provides a foundational understanding of Model Context Protocol. As AI continues to weave itself into the fabric of our digital tools, protocols like MCP will be instrumental in shaping a more intelligent, responsive, and collaborative future.</p>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"microsoft/","level":1,"title":"Microsoft Copilot","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Setup","Microsoft Copilot"],"tags":[]},{"location":"microsoft/#connect-through-your-university-account","level":2,"title":"Connect through your University Account","text":"<p>Make sure you're logged into your Arizona account in the browser, for example through Outlook or Microsoft Office 365</p> <p>Go to https://copilot.cloud.microsoft/</p> <p>Select the \"Enterprise\" option to log in with your <code>@arizona.edu</code> email address</p>","path":["Setup","Microsoft Copilot"],"tags":[]},{"location":"microsoft/#enterprise-data-protection","level":2,"title":"Enterprise data protection","text":"<p>Once logged in, you should see a  shield icon that shows that you have Enterprise Data Protection turned on.</p>","path":["Setup","Microsoft Copilot"],"tags":[]},{"location":"microsoft/#integration-with-microsoft-365","level":2,"title":"Integration with Microsoft 365","text":"<p>The Microsoft 365 app is migrating to Microsoft Copilot at m365.cloud.microsoft.</p> <p>Announcements made by Microsoft in fall 2024 suggest Copilot release in OneDrive early 2025.</p>","path":["Setup","Microsoft Copilot"],"tags":[]},{"location":"notebooklm/","level":1,"title":"Google NotebookLM","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p></p> <p>Google NotebookLM is an AI tool specifically designed for research, writing, and education. What makes it unique amongst all the chatbots out in the world, is that the tool is restricted to only the resources you give it. This puts guardrails on your conversations and prevents the chatbot from presenting information with unknown sources. If you want to work directly with just the sources you trust, NotebookLM is a great choice. </p>","path":["Research","Google NotebookLM"],"tags":[]},{"location":"notebooklm/#key-features-limitations","level":2,"title":"Key Features &amp; Limitations","text":"<ul> <li> <p>Organization</p> <p>The user interface is a bit different than most chatbots. NotebookLM is organized around the concept of a notebook. A notebook is a digital container where resources for a single topic live. You could have a notebook for a class you are teaching or a notebook for a research paper literature review. </p> </li> </ul> <p></p> <ul> <li> <p>Accepted Source Formats</p> <p>PDFs, .txt, markdown, audio (e.g., mp3), html text from a website, text transcripts from Youtube videos. You can drag and drop files or upload files from Google Drive.  </p> </li> <li> <p>Conversation Bounds</p> <p>The conversations you have with the chatbot will just be about the sources you provide. You cannot talk about random topics outside of your resources. You also cannot have the chatbot search the internet. </p> </li> <li> <p>Designed Specifically for Language</p> <p>NotebookLM is designed for reading and writing. It does not analyze quantitative data. </p> </li> <li> <p>Inline Citations</p> <p>Any answered questions or responses will include citations showing you exactly where the information came from.</p> </li> <li> <p>Conversations are Ephemeral but Notes are Permanent</p> <p>If you would like generated text to persist between session, save them as notes. </p> </li> <li> <p>Share your Notebook</p> <p>Just like a Google Doc, users can share the notebook with anyone with different levels of permission. </p> </li> <li> <p>Audio Overview </p> <p>For any notebook you create, users have the option to create an audio overview of the content. This consists of a podcast style media where two hosts talk intelligently about the content. The quality of the AI generated podcast may surprise you!</p> </li> </ul> <p> </p>","path":["Research","Google NotebookLM"],"tags":[]},{"location":"notebooklm/#usage-ideas","level":2,"title":"Usage Ideas","text":"<p>Research Uses:</p> <ul> <li>Literature Reviews:  Upload research papers, articles, and conference proceedings. NotebookLM can quickly identify key themes, summarize findings, and highlight gaps in the existing literature, significantly speeding up the literature review process.</li> <li>Data Analysis:  Analyze qualitative data like interview transcripts or open-ended survey responses by identifying patterns, themes, and key quotes.</li> <li>Hypothesis Generation:  Explore connections between different research sources and brainstorm new research questions or hypotheses based on synthesized knowledge.</li> <li>Grant Proposal Writing:  Organize background research, synthesize relevant literature, and identify key arguments to strengthen grant proposals.</li> <li>Staying Up-to-Date: Researchers can continuously upload new publications in their field and use NotebookLM to stay informed about the latest advancements and emerging trends.</li> </ul> <p></p> <p>Education/Teaching Uses:</p> <ul> <li>Teachers can create a notebook that includes all the material for a given class (syllabus, schedule, lecture notes, textbook chapters, research articles)</li> <li>The teacher can share the notebook with all the students with read-only permission. </li> <li>Teachers can generate quizes on the notebook content.</li> <li>Students have an LLM chatbot restricted to just the course content where they can ask it any questions related to the class. </li> </ul> <p></p> <p>General Productivity:</p> <ul> <li>Use NotebookLM to help you customize your resume and cover letter for a specific job posting</li> <li>Meeting Preparation: Upload meeting agendas, pre-reads, and background documents. NotebookLM can summarize key discussion points, identify action items, and prepare you for productive meetings. </li> </ul>","path":["Research","Google NotebookLM"],"tags":[]},{"location":"notebooklm/#notebooklm-plus","level":2,"title":"NotebookLM Plus","text":"<p>Like most Google products, NotebookLM has a freemium model where the tool is available for free to anyone, but with limitations. Power users can get NotebookLM Plus for a subscription fee. Please check the technical documentation for how to get NotebookLM Plus.</p>","path":["Research","Google NotebookLM"],"tags":[]},{"location":"ollama/","level":1,"title":"Ollama","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#what-is-ollama","level":2,"title":"What is Ollama?","text":"<p>Ollama is an open-source tool that makes it simple to run large language models (LLMs) locally on your own computer. Think of it as a \"Docker for AI models\" - it handles all the complexity of downloading, configuring, and running AI models so you can focus on using them.</p> <p>Why Run AI Models Locally?</p> Benefit Description Privacy Your data never leaves your computer - ideal for sensitive research, patient data, or proprietary information No API Costs After initial setup, unlimited usage with no per-token charges Offline Access Work without internet connectivity once models are downloaded Customization Fine-tune models, adjust parameters, and create custom configurations No Rate Limits Generate as much content as your hardware can handle Reproducibility Lock down specific model versions for reproducible research <p>When to Use Ollama vs. Cloud Services:</p> <ul> <li>Use Ollama when: privacy is paramount, you have adequate hardware, you need offline access, or you want to experiment freely without cost concerns</li> <li>Use Cloud Services (ChatGPT, Claude, etc.) when: you need the most capable models, lack powerful hardware, or need multimodal capabilities like vision</li> </ul> <p>Hardware Requirements</p> <p>Running local models requires computational resources. As a general guideline:</p> <ul> <li>Small models (1-3B parameters): 8GB RAM minimum, runs on most modern laptops</li> <li>Medium models (7-8B parameters): 16GB RAM recommended, GPU acceleration helpful</li> <li>Large models (13B+ parameters): 32GB+ RAM or dedicated GPU with 8GB+ VRAM</li> </ul> <p>Apple Silicon Macs (M1/M2/M3/M4) are particularly well-suited for local AI due to unified memory architecture.</p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#installation","level":2,"title":"Installation","text":"","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#macos","level":3,"title":"macOS","text":"<p>Option 1: Download the App (Recommended)</p> <ol> <li>Visit ollama.com/download</li> <li>Download the macOS installer</li> <li>Open the downloaded file and drag Ollama to your Applications folder</li> <li>Launch Ollama from Applications - it will appear as a llama icon in your menu bar</li> <li>The Ollama service now runs in the background</li> </ol> <p>Option 2: Homebrew</p> <pre><code>brew install ollama\n</code></pre> <p>After installation, start the Ollama service:</p> <pre><code>ollama serve\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#linux","level":3,"title":"Linux","text":"<p>One-Line Install Script:</p> <pre><code>curl -fsSL https://ollama.com/install.sh | sh\n</code></pre> <p>This script:</p> <ul> <li>Detects your Linux distribution (Ubuntu, Debian, Fedora, CentOS, Arch, etc.)</li> <li>Installs Ollama to <code>/usr/local/bin</code></li> <li>Sets up a systemd service for automatic startup</li> <li>Configures GPU support if NVIDIA drivers are detected</li> </ul> <p>Manual Installation (Alternative):</p> <pre><code># Download the binary\ncurl -L https://ollama.com/download/ollama-linux-amd64 -o ollama\n\n# Make it executable\nchmod +x ollama\n\n# Move to system path\nsudo mv ollama /usr/local/bin/\n\n# Start the service\nollama serve\n</code></pre> <p>Start Ollama on Boot:</p> <pre><code># Enable the systemd service\nsudo systemctl enable ollama\n\n# Start the service now\nsudo systemctl start ollama\n\n# Check service status\nsudo systemctl status ollama\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#windows","level":3,"title":"Windows","text":"<p>Option 1: Windows Installer (Recommended)</p> <ol> <li>Visit ollama.com/download</li> <li>Download the Windows installer (<code>.exe</code>)</li> <li>Run the installer and follow the prompts</li> <li>Ollama will start automatically and appear in the system tray</li> </ol> <p>Option 2: Windows Subsystem for Linux (WSL)</p> <p>If you prefer a Linux-like environment on Windows:</p> <pre><code># First, ensure WSL2 is installed and updated\nwsl --install\n\n# Then in your WSL terminal:\ncurl -fsSL https://ollama.com/install.sh | sh\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#docker","level":3,"title":"Docker","text":"<p>For containerized deployments or server environments:</p> <pre><code># Pull and run the Ollama container\ndocker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n\n# With NVIDIA GPU support\ndocker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#verify-installation","level":3,"title":"Verify Installation","text":"<p>After installation, verify Ollama is working:</p> <pre><code># Check Ollama version\nollama --version\n\n# List available models (will be empty initially)\nollama list\n\n# Test the API endpoint\ncurl http://localhost:11434/api/tags\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#downloading-and-managing-models","level":2,"title":"Downloading and Managing Models","text":"","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#the-model-library","level":3,"title":"The Model Library","text":"<p>Ollama maintains a curated library of optimized models at ollama.com/library. These models are:</p> <ul> <li>Pre-quantized for efficient memory usage</li> <li>Tested for compatibility with Ollama</li> <li>Available in multiple size variants</li> <li>Automatically configured for optimal performance</li> </ul>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#downloading-models","level":3,"title":"Downloading Models","text":"<p>Basic Download:</p> <pre><code># Download a model (happens automatically when you run it)\nollama pull llama3.2\n\n# Or run directly - it will download if not present\nollama run llama3.2\n</code></pre> <p>Specify Model Size/Variant:</p> <p>Models often come in multiple sizes. Use tags to select:</p> <pre><code># Llama 3.2 variants\nollama pull llama3.2:1b      # 1 billion parameters (~1GB)\nollama pull llama3.2:3b      # 3 billion parameters (~2GB)\nollama pull llama3.2         # Default (usually the balanced option)\n\n# Qwen 2.5 variants\nollama pull qwen2.5:0.5b     # Tiny - very fast\nollama pull qwen2.5:1.5b     # Small\nollama pull qwen2.5:3b       # Medium\nollama pull qwen2.5:7b       # Large - best quality\nollama pull qwen2.5:14b      # Extra large\nollama pull qwen2.5:32b      # Very large - requires significant RAM/VRAM\nollama pull qwen2.5:72b      # Massive - requires high-end GPU\n\n# DeepSeek R1 distilled models\nollama pull deepseek-r1:1.5b # Smallest reasoning model\nollama pull deepseek-r1:7b   # Good balance\nollama pull deepseek-r1:8b   # Llama-based distillation\nollama pull deepseek-r1:14b  # Higher quality\nollama pull deepseek-r1:32b  # Best distilled quality\nollama pull deepseek-r1:70b  # Full-size distillation\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#managing-downloaded-models","level":3,"title":"Managing Downloaded Models","text":"<pre><code># List all downloaded models\nollama list\n\n# Example output:\n# NAME              ID              SIZE      MODIFIED\n# llama3.2:latest   a3e4c7e8d9f0    2.0 GB    2 hours ago\n# qwen2.5:7b        b5f6c8d9e0a1    4.4 GB    1 day ago\n# deepseek-r1:8b    c7d8e9f0a1b2    4.9 GB    3 days ago\n\n# Show detailed information about a model\nollama show llama3.2\n\n# Delete a model to free disk space\nollama rm llama3.2:1b\n\n# Copy a model (useful for creating variants)\nollama cp llama3.2 my-llama\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#model-storage-location","level":3,"title":"Model Storage Location","text":"<p>Models are stored in:</p> <ul> <li>macOS: <code>~/.ollama/models</code></li> <li>Linux: <code>~/.ollama/models</code> or <code>/usr/share/ollama/.ollama/models</code></li> <li>Windows: <code>C:\\Users\\&lt;username&gt;\\.ollama\\models</code></li> </ul> <p>To change the storage location, set the <code>OLLAMA_MODELS</code> environment variable:</p> <pre><code># Linux/macOS\nexport OLLAMA_MODELS=/path/to/your/models\n\n# Windows PowerShell\n$env:OLLAMA_MODELS = \"D:\\ollama\\models\"\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#running-models","level":2,"title":"Running Models","text":"","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#interactive-chat","level":3,"title":"Interactive Chat","text":"<p>The simplest way to use Ollama is through interactive chat:</p> <pre><code>ollama run llama3.2\n</code></pre> <p>This opens an interactive session where you can type prompts and receive responses. Use <code>/bye</code> or Ctrl+C to exit.</p> <p>Chat Session Commands:</p> Command Description <code>/bye</code> Exit the chat session <code>/clear</code> Clear conversation history <code>/set parameter value</code> Change model parameters <code>/show info</code> Display model information <code>/show license</code> Show model license <code>/load &lt;model&gt;</code> Load a different model <code>/save &lt;name&gt;</code> Save current session","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#single-prompt-execution","level":3,"title":"Single-Prompt Execution","text":"<p>For scripting and automation, pass the prompt directly:</p> <pre><code># Single prompt with immediate response\nollama run llama3.2 \"What is photosynthesis?\"\n\n# Pipe input from a file\ncat essay.txt | ollama run llama3.2 \"Summarize this text:\"\n\n# Save output to a file\nollama run llama3.2 \"Write a haiku about machine learning\" &gt; haiku.txt\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#model-parameters","level":3,"title":"Model Parameters","text":"<p>Adjust model behavior with parameters:</p> <pre><code># In interactive mode\n/set temperature 0.7\n/set num_predict 500\n\n# Or set when starting\nollama run llama3.2 --verbose\n</code></pre> <p>Common Parameters:</p> Parameter Description Default Range <code>temperature</code> Creativity/randomness 0.8 0.0-2.0 <code>top_p</code> Nucleus sampling threshold 0.9 0.0-1.0 <code>top_k</code> Limit vocabulary sampling 40 1-100 <code>num_predict</code> Maximum tokens to generate 128 -1 (unlimited) to n <code>num_ctx</code> Context window size 2048 Model-dependent <code>repeat_penalty</code> Penalty for repetition 1.1 0.0-2.0 <code>seed</code> Random seed for reproducibility Random Any integer","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#multiline-input","level":3,"title":"Multiline Input","text":"<p>For complex prompts, use multiline input:</p> <pre><code>ollama run llama3.2 \"\"\"\nYou are an expert historian. Please analyze the following event\nand provide context about its significance:\n\nThe signing of the Treaty of Westphalia in 1648.\n\nInclude:\n1. Historical context\n2. Key provisions\n3. Long-term impact on international relations\n\"\"\"\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#using-the-ollama-api","level":2,"title":"Using the Ollama API","text":"<p>Ollama provides a REST API that enables integration with other applications. The API runs on <code>http://localhost:11434</code> by default.</p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#generate-completions","level":3,"title":"Generate Completions","text":"<p>Basic Generation:</p> <pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3.2\",\n  \"prompt\": \"Explain quantum computing in simple terms\",\n  \"stream\": false\n}'\n</code></pre> <p>With Parameters:</p> <pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3.2\",\n  \"prompt\": \"Write a creative story about a robot learning to paint\",\n  \"stream\": false,\n  \"options\": {\n    \"temperature\": 0.9,\n    \"num_predict\": 500,\n    \"top_p\": 0.95\n  }\n}'\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#chat-api-conversational","level":3,"title":"Chat API (Conversational)","text":"<p>For multi-turn conversations:</p> <pre><code>curl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama3.2\",\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n    {\"role\": \"user\", \"content\": \"What are the main causes of climate change?\"},\n    {\"role\": \"assistant\", \"content\": \"The main causes include greenhouse gas emissions...\"},\n    {\"role\": \"user\", \"content\": \"How can individuals help reduce these emissions?\"}\n  ],\n  \"stream\": false\n}'\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#streaming-responses","level":3,"title":"Streaming Responses","text":"<p>For real-time output, enable streaming:</p> <pre><code>curl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3.2\",\n  \"prompt\": \"Write a detailed explanation of neural networks\",\n  \"stream\": true\n}'\n</code></pre> <p>Each response chunk is a JSON object. Parse them line by line for real-time display.</p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#api-endpoints-reference","level":3,"title":"API Endpoints Reference","text":"Endpoint Method Description <code>/api/generate</code> POST Generate text completion <code>/api/chat</code> POST Chat with conversation history <code>/api/tags</code> GET List available models <code>/api/show</code> POST Show model information <code>/api/pull</code> POST Download a model <code>/api/delete</code> DELETE Remove a model <code>/api/copy</code> POST Copy a model <code>/api/embeddings</code> POST Generate embeddings","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#python-integration","level":2,"title":"Python Integration","text":"","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#using-the-official-ollama-python-library","level":3,"title":"Using the Official Ollama Python Library","text":"<pre><code>pip install ollama\n</code></pre> <p>Basic Usage:</p> <pre><code>import ollama\n\n# Simple generation\nresponse = ollama.generate(\n    model='llama3.2',\n    prompt='What is machine learning?'\n)\nprint(response['response'])\n</code></pre> <p>Chat Conversation:</p> <pre><code>import ollama\n\n# Multi-turn chat\nmessages = [\n    {'role': 'system', 'content': 'You are a helpful coding assistant.'},\n    {'role': 'user', 'content': 'Write a Python function to calculate factorial'}\n]\n\nresponse = ollama.chat(\n    model='llama3.2',\n    messages=messages\n)\n\nprint(response['message']['content'])\n</code></pre> <p>Streaming Responses:</p> <pre><code>import ollama\n\n# Stream responses for better UX\nstream = ollama.chat(\n    model='llama3.2',\n    messages=[{'role': 'user', 'content': 'Explain the water cycle'}],\n    stream=True\n)\n\nfor chunk in stream:\n    print(chunk['message']['content'], end='', flush=True)\n</code></pre> <p>Generate Embeddings:</p> <pre><code>import ollama\n\n# Generate embeddings for semantic search or RAG\nembedding = ollama.embeddings(\n    model='nomic-embed-text',  # or any embedding model\n    prompt='The quick brown fox jumps over the lazy dog'\n)\n\nprint(f\"Embedding dimension: {len(embedding['embedding'])}\")\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#using-with-langchain","level":3,"title":"Using with LangChain","text":"<p>LangChain provides a powerful framework for building LLM applications:</p> <pre><code>pip install langchain langchain-ollama\n</code></pre> <pre><code>from langchain_ollama import OllamaLLM\n\n# Initialize the model\nllm = OllamaLLM(model=\"llama3.2\")\n\n# Simple invocation\nresponse = llm.invoke(\"What are the benefits of exercise?\")\nprint(response)\n</code></pre> <p>Chat Model with History:</p> <pre><code>from langchain_ollama import ChatOllama\nfrom langchain_core.messages import HumanMessage, SystemMessage\n\nchat = ChatOllama(model=\"llama3.2\", temperature=0.7)\n\nmessages = [\n    SystemMessage(content=\"You are a research assistant specializing in biology.\"),\n    HumanMessage(content=\"Explain CRISPR gene editing.\")\n]\n\nresponse = chat.invoke(messages)\nprint(response.content)\n</code></pre> <p>Building a Simple RAG System:</p> <pre><code>from langchain_ollama import OllamaLLM, OllamaEmbeddings\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\n\n# Initialize components\nllm = OllamaLLM(model=\"llama3.2\")\nembeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n\n# Sample documents (in practice, load from files)\ndocuments = [\n    \"Machine learning is a subset of artificial intelligence...\",\n    \"Neural networks are inspired by biological neurons...\",\n    \"Deep learning uses multiple layers of neural networks...\"\n]\n\n# Split documents\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\nsplits = text_splitter.create_documents(documents)\n\n# Create vector store\nvectorstore = Chroma.from_documents(splits, embeddings)\nretriever = vectorstore.as_retriever()\n\n# Create RAG chain\ntemplate = \"\"\"Answer based on the context:\nContext: {context}\nQuestion: {question}\nAnswer:\"\"\"\n\nprompt = ChatPromptTemplate.from_template(template)\n\nrag_chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n)\n\n# Query\nresponse = rag_chain.invoke(\"What is deep learning?\")\nprint(response)\n</code></pre> <p>For more on RAG systems, see our RAG documentation.</p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#using-with-requests-direct-api","level":3,"title":"Using with Requests (Direct API)","text":"<p>For simple integrations without additional dependencies:</p> <pre><code>import requests\nimport json\n\ndef query_ollama(prompt, model=\"llama3.2\", stream=False):\n    \"\"\"Simple function to query Ollama API.\"\"\"\n    response = requests.post(\n        'http://localhost:11434/api/generate',\n        json={\n            'model': model,\n            'prompt': prompt,\n            'stream': stream\n        }\n    )\n\n    if stream:\n        # Handle streaming response\n        for line in response.iter_lines():\n            if line:\n                chunk = json.loads(line)\n                yield chunk.get('response', '')\n    else:\n        return response.json()['response']\n\n# Usage\nresult = query_ollama(\"What is the capital of France?\")\nprint(result)\n\n# Streaming usage\nfor chunk in query_ollama(\"Tell me a story\", stream=True):\n    print(chunk, end='', flush=True)\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#jupyter-notebook-integration","level":2,"title":"Jupyter Notebook Integration","text":"<p>Ollama integrates seamlessly with Jupyter notebooks for interactive research:</p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#basic-notebook-usage","level":3,"title":"Basic Notebook Usage","text":"<pre><code># Cell 1: Install and import\n!pip install ollama\n\nimport ollama\n\n# Cell 2: List available models\nmodels = ollama.list()\nfor model in models['models']:\n    print(f\"{model['name']}: {model['size'] / 1e9:.1f} GB\")\n\n# Cell 3: Interactive chat\nresponse = ollama.generate(\n    model='llama3.2',\n    prompt='Explain the difference between correlation and causation'\n)\nprint(response['response'])\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#building-a-research-assistant","level":3,"title":"Building a Research Assistant","text":"<pre><code>import ollama\n\nclass ResearchAssistant:\n    \"\"\"A simple research assistant using Ollama.\"\"\"\n\n    def __init__(self, model='llama3.2'):\n        self.model = model\n        self.conversation = []\n\n    def set_context(self, context):\n        \"\"\"Set the research context/system prompt.\"\"\"\n        self.conversation = [{\n            'role': 'system',\n            'content': context\n        }]\n\n    def ask(self, question):\n        \"\"\"Ask a question and get a response.\"\"\"\n        self.conversation.append({\n            'role': 'user',\n            'content': question\n        })\n\n        response = ollama.chat(\n            model=self.model,\n            messages=self.conversation\n        )\n\n        assistant_message = response['message']['content']\n        self.conversation.append({\n            'role': 'assistant',\n            'content': assistant_message\n        })\n\n        return assistant_message\n\n    def summarize_paper(self, abstract):\n        \"\"\"Summarize a research paper abstract.\"\"\"\n        prompt = f\"\"\"Please analyze this research abstract and provide:\n1. Main research question\n2. Methodology used\n3. Key findings\n4. Potential implications\n\nAbstract:\n{abstract}\"\"\"\n\n        return self.ask(prompt)\n\n# Usage in notebook\nassistant = ResearchAssistant(model='llama3.2')\nassistant.set_context(\"You are an expert in computational biology.\")\n\nresponse = assistant.ask(\"What are the latest advances in protein folding prediction?\")\nprint(response)\n</code></pre> <p>For more on Jupyter AI integration, see our Jupyter AI documentation.</p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#creating-custom-models-with-modelfiles","level":2,"title":"Creating Custom Models with Modelfiles","text":"<p>Modelfiles allow you to create customized versions of models with specific behaviors, system prompts, or parameters.</p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#basic-modelfile-structure","level":3,"title":"Basic Modelfile Structure","text":"<p>Create a file called <code>Modelfile</code> (no extension):</p> <pre><code># Base model to customize\nFROM llama3.2\n\n# Set model parameters\nPARAMETER temperature 0.7\nPARAMETER num_ctx 4096\nPARAMETER top_p 0.9\n\n# Set the system prompt\nSYSTEM \"\"\"You are a helpful research assistant specializing in academic writing.\nYou help researchers improve their papers by:\n- Suggesting clearer phrasing\n- Identifying logical gaps\n- Recommending relevant citations\n- Improving overall structure\n\nAlways be constructive and specific in your feedback.\"\"\"\n\n# Optional: Add custom template\nTEMPLATE \"\"\"{{ if .System }}&lt;|system|&gt;\n{{ .System }}&lt;|end|&gt;\n{{ end }}{{ if .Prompt }}&lt;|user|&gt;\n{{ .Prompt }}&lt;|end|&gt;\n{{ end }}&lt;|assistant|&gt;\n{{ .Response }}&lt;|end|&gt;\n\"\"\"\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#create-and-use-the-custom-model","level":3,"title":"Create and Use the Custom Model","text":"<pre><code># Create the custom model\nollama create research-assistant -f Modelfile\n\n# Run your custom model\nollama run research-assistant\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#modelfile-commands-reference","level":3,"title":"Modelfile Commands Reference","text":"Command Description Example <code>FROM</code> Base model (required) <code>FROM llama3.2</code> <code>PARAMETER</code> Set model parameters <code>PARAMETER temperature 0.7</code> <code>SYSTEM</code> Set system prompt <code>SYSTEM \"You are helpful...\"</code> <code>TEMPLATE</code> Custom prompt template <code>TEMPLATE \"...\"</code> <code>ADAPTER</code> Apply LoRA adapter <code>ADAPTER ./lora.gguf</code> <code>LICENSE</code> Specify license <code>LICENSE \"MIT\"</code> <code>MESSAGE</code> Add example messages <code>MESSAGE user \"Hello\"</code>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#example-academic-discipline-specific-assistants","level":3,"title":"Example: Academic Discipline-Specific Assistants","text":"<p>Biology Research Assistant:</p> <pre><code>FROM llama3.2\n\nPARAMETER temperature 0.3\nPARAMETER num_ctx 8192\n\nSYSTEM \"\"\"You are an expert biology research assistant with deep knowledge of:\n- Molecular biology and genetics\n- Cell biology and biochemistry\n- Evolutionary biology\n- Ecology and environmental science\n\nWhen answering questions:\n1. Use precise scientific terminology\n2. Cite relevant concepts and theories\n3. Distinguish between established facts and current hypotheses\n4. Suggest relevant experimental approaches when applicable\"\"\"\n</code></pre> <p>Statistics Tutor:</p> <pre><code>FROM qwen2.5:7b\n\nPARAMETER temperature 0.2\nPARAMETER num_ctx 4096\n\nSYSTEM \"\"\"You are a patient statistics tutor helping graduate students understand\nstatistical concepts. When explaining:\n\n1. Start with intuitive explanations before formal definitions\n2. Use concrete examples from research contexts\n3. Show step-by-step calculations when relevant\n4. Explain assumptions and when methods are appropriate\n5. Suggest R or Python code for implementation\n\nAlways check for understanding and offer to clarify further.\"\"\"\n</code></pre> <p>Code Review Assistant:</p> <pre><code>FROM deepseek-r1:8b\n\nPARAMETER temperature 0.1\nPARAMETER num_ctx 8192\n\nSYSTEM \"\"\"You are a senior software engineer conducting code reviews.\nFor each piece of code you review:\n\n1. Identify potential bugs or errors\n2. Suggest performance improvements\n3. Recommend better naming or structure\n4. Check for security vulnerabilities\n5. Ensure code follows best practices\n\nBe constructive and explain the reasoning behind each suggestion.\"\"\"\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#gpu-configuration-and-performance","level":2,"title":"GPU Configuration and Performance","text":"","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#automatic-gpu-detection","level":3,"title":"Automatic GPU Detection","text":"<p>Ollama automatically detects and uses available GPUs. Check your GPU status:</p> <pre><code>ollama run llama3.2 --verbose\n# Look for \"gpu\" in the output\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#nvidia-gpu-setup-linux","level":3,"title":"NVIDIA GPU Setup (Linux)","text":"<p>Ensure you have the NVIDIA drivers and CUDA toolkit:</p> <pre><code># Check NVIDIA driver\nnvidia-smi\n\n# The Ollama install script usually handles CUDA setup\n# If needed, install CUDA toolkit:\n# sudo apt install nvidia-cuda-toolkit\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#apple-silicon-optimization","level":3,"title":"Apple Silicon Optimization","text":"<p>Apple M1/M2/M3/M4 Macs use Metal for GPU acceleration automatically. Ollama is highly optimized for Apple Silicon:</p> <pre><code># Check Metal usage (models should show \"metal\" backend)\nollama run llama3.2 --verbose\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#memory-management","level":3,"title":"Memory Management","text":"<p>Control GPU Memory Usage:</p> <pre><code># Set maximum VRAM usage (in MB)\nOLLAMA_GPU_MEMORY=8192 ollama serve\n\n# Or in environment\nexport OLLAMA_GPU_MEMORY=8192\n</code></pre> <p>CPU-Only Mode:</p> <pre><code># Disable GPU acceleration\nCUDA_VISIBLE_DEVICES=\"\" ollama serve\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#performance-tuning-parameters","level":3,"title":"Performance Tuning Parameters","text":"Environment Variable Description Example <code>OLLAMA_NUM_PARALLEL</code> Number of parallel requests <code>4</code> <code>OLLAMA_MAX_LOADED_MODELS</code> Models to keep in memory <code>2</code> <code>OLLAMA_GPU_MEMORY</code> Max GPU memory (MB) <code>8192</code> <code>OLLAMA_HOST</code> API bind address <code>0.0.0.0:11434</code> <code>OLLAMA_KEEP_ALIVE</code> Model unload timeout <code>5m</code>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#monitoring-performance","level":3,"title":"Monitoring Performance","text":"<pre><code># Watch GPU memory usage (NVIDIA)\nwatch -n 1 nvidia-smi\n\n# Monitor Ollama logs\njournalctl -u ollama -f  # Linux with systemd\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#model-recommendations","level":2,"title":"Model Recommendations","text":"","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#by-hardware-capability","level":3,"title":"By Hardware Capability","text":"Laptop (8GB RAM)Workstation (16-32GB RAM)GPU Server (24GB+ VRAM) Model Size Best For <code>llama3.2:1b</code> ~700MB Quick responses, basic tasks <code>qwen2.5:1.5b</code> ~1GB Multilingual, reasoning <code>phi3:mini</code> ~2GB Coding, analysis <code>deepseek-r1:1.5b</code> ~1GB Reasoning tasks Model Size Best For <code>llama3.2:3b</code> ~2GB Balanced performance <code>qwen2.5:7b</code> ~4.5GB Strong reasoning, coding <code>mistral:7b</code> ~4GB General purpose <code>deepseek-r1:8b</code> ~5GB Advanced reasoning <code>codellama:13b</code> ~7GB Specialized coding Model Size Best For <code>llama3.3:70b</code> ~40GB Near-frontier capability <code>qwen2.5:32b</code> ~20GB Strong all-around <code>deepseek-r1:70b</code> ~40GB Best open reasoning <code>mixtral:8x7b</code> ~26GB Mixture of experts","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#by-use-case","level":3,"title":"By Use Case","text":"<p>Academic Writing and Research:</p> <pre><code># For writing assistance and analysis\nollama pull qwen2.5:7b\n\n# For reasoning-heavy tasks\nollama pull deepseek-r1:8b\n</code></pre> <p>Coding and Development:</p> <pre><code># General coding\nollama pull deepseek-coder:6.7b\n\n# Code review and debugging\nollama pull codellama:13b\n\n# Fast completions\nollama pull starcoder2:3b\n</code></pre> <p>Data Analysis:</p> <pre><code># Statistical reasoning\nollama pull qwen2.5:7b\n\n# Code generation for analysis\nollama pull deepseek-coder:6.7b\n</code></pre> <p>Teaching and Tutoring:</p> <pre><code># Patient explanations\nollama pull llama3.2:3b\n\n# Math and science tutoring\nollama pull qwen2.5:7b\n</code></pre> <p>Embeddings and RAG:</p> <pre><code># Text embeddings\nollama pull nomic-embed-text\n\n# Multilingual embeddings\nollama pull mxbai-embed-large\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#integration-with-other-tools","level":2,"title":"Integration with Other Tools","text":"","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#open-webui","level":3,"title":"Open WebUI","text":"<p>Open WebUI provides a ChatGPT-like interface for Ollama:</p> <pre><code># Run with Docker\ndocker run -d -p 3000:8080 \\\n  --add-host=host.docker.internal:host-gateway \\\n  -v open-webui:/app/backend/data \\\n  --name open-webui \\\n  ghcr.io/open-webui/open-webui:main\n</code></pre> <p>Access at <code>http://localhost:3000</code>. Open WebUI automatically detects your Ollama installation.</p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#vs-code-integration","level":3,"title":"VS Code Integration","text":"<p>Install the Continue extension for AI-assisted coding with Ollama:</p> <ol> <li>Install the Continue extension from VS Code marketplace</li> <li>Configure to use Ollama in settings:</li> </ol> <pre><code>{\n  \"models\": [\n    {\n      \"title\": \"Ollama\",\n      \"provider\": \"ollama\",\n      \"model\": \"deepseek-coder:6.7b\"\n    }\n  ]\n}\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#obsidian-integration","level":3,"title":"Obsidian Integration","text":"<p>Use the Ollama plugin for Obsidian for note-taking with AI assistance.</p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#api-compatible-services","level":3,"title":"API-Compatible Services","text":"<p>Ollama's API is compatible with the OpenAI API format. Many tools that support OpenAI can work with Ollama:</p> <pre><code># Using OpenAI library with Ollama\nfrom openai import OpenAI\n\nclient = OpenAI(\n    base_url='http://localhost:11434/v1',\n    api_key='ollama'  # Ollama doesn't require a key, but the library needs something\n)\n\nresponse = client.chat.completions.create(\n    model='llama3.2',\n    messages=[\n        {'role': 'user', 'content': 'Hello!'}\n    ]\n)\n\nprint(response.choices[0].message.content)\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#troubleshooting","level":2,"title":"Troubleshooting","text":"","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#common-issues-and-solutions","level":3,"title":"Common Issues and Solutions","text":"Model fails to load - Out of Memory <p>Symptoms: Error messages about memory allocation, system becomes unresponsive</p> <p>Solutions:</p> <ol> <li> <p>Try a smaller model variant:     <pre><code># Instead of\nollama run llama3.2\n\n# Try\nollama run llama3.2:1b\n</code></pre></p> </li> <li> <p>Close other memory-intensive applications</p> </li> <li> <p>Reduce context window:     <pre><code>ollama run llama3.2 --num-ctx 2048\n</code></pre></p> </li> <li> <p>Use quantized versions (look for <code>q4_0</code> or <code>q4_K_M</code> tags)</p> </li> </ol> Ollama service not running <p>Symptoms: Connection refused errors, <code>curl: (7) Failed to connect</code></p> <p>Solutions:</p> <ol> <li> <p>Start the service:     <pre><code># macOS/Windows: Launch the Ollama app\n# Linux:\nollama serve\n# Or with systemd:\nsudo systemctl start ollama\n</code></pre></p> </li> <li> <p>Check if another process is using port 11434:     <pre><code>lsof -i :11434\n</code></pre></p> </li> <li> <p>Use a different port:     <pre><code>OLLAMA_HOST=127.0.0.1:11435 ollama serve\n</code></pre></p> </li> </ol> Slow generation speed <p>Symptoms: Model runs much slower than expected</p> <p>Solutions:</p> <ol> <li> <p>Verify GPU is being used:     <pre><code>ollama run llama3.2 --verbose\n# Look for \"gpu\" or \"metal\" in output\n</code></pre></p> </li> <li> <p>Check GPU drivers are up to date</p> </li> <li> <p>Ensure sufficient VRAM:     <pre><code>nvidia-smi  # For NVIDIA GPUs\n</code></pre></p> </li> <li> <p>Try a smaller model or quantization</p> </li> </ol> Model gives poor quality responses <p>Symptoms: Responses are incoherent, repetitive, or off-topic</p> <p>Solutions:</p> <ol> <li> <p>Adjust temperature:     <pre><code>/set temperature 0.7\n</code></pre></p> </li> <li> <p>Increase context window for complex tasks:     <pre><code>/set num_ctx 4096\n</code></pre></p> </li> <li> <p>Try a larger model variant</p> </li> <li> <p>Be more specific in your prompts</p> </li> </ol> Cannot connect from other devices <p>Symptoms: API works on localhost but not from other machines</p> <p>Solutions:</p> <ol> <li> <p>Bind to all interfaces:     <pre><code>OLLAMA_HOST=0.0.0.0:11434 ollama serve\n</code></pre></p> </li> <li> <p>Check firewall settings:     <pre><code># Linux\nsudo ufw allow 11434\n</code></pre></p> </li> <li> <p>Verify network connectivity</p> </li> </ol>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#getting-help","level":3,"title":"Getting Help","text":"<ul> <li>Official Documentation: github.com/ollama/ollama</li> <li>Discord Community: discord.gg/ollama</li> <li>GitHub Issues: github.com/ollama/ollama/issues</li> </ul>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#academic-use-cases","level":2,"title":"Academic Use Cases","text":"","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#literature-review-assistance","level":3,"title":"Literature Review Assistance","text":"<pre><code>import ollama\n\ndef analyze_abstract(abstract):\n    \"\"\"Analyze a research paper abstract.\"\"\"\n    prompt = f\"\"\"Analyze this research abstract and provide:\n1. Research question or hypothesis\n2. Methodology\n3. Key findings\n4. Limitations mentioned\n5. Potential follow-up questions\n\nAbstract:\n{abstract}\n\"\"\"\n\n    response = ollama.generate(model='qwen2.5:7b', prompt=prompt)\n    return response['response']\n\n# Example usage\nabstract = \"\"\"\nWe present a novel approach to protein structure prediction using\ngraph neural networks. Our method achieves state-of-the-art results\non the CASP14 benchmark, outperforming existing methods by 15% in\nGDT-TS score. We demonstrate that incorporating evolutionary\ninformation through multiple sequence alignments significantly\nimproves prediction accuracy.\n\"\"\"\n\nanalysis = analyze_abstract(abstract)\nprint(analysis)\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#grant-writing-support","level":3,"title":"Grant Writing Support","text":"<pre><code>import ollama\n\ndef improve_grant_section(text, section_type):\n    \"\"\"Suggest improvements for grant application sections.\"\"\"\n    prompt = f\"\"\"You are an experienced grant reviewer. Review this {section_type}\nsection and provide specific suggestions to strengthen it:\n\n{text}\n\nPlease provide:\n1. Strengths of the current text\n2. Areas that need improvement\n3. Specific rewrite suggestions\n4. Questions a reviewer might ask\"\"\"\n\n    response = ollama.generate(model='qwen2.5:7b', prompt=prompt)\n    return response['response']\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#teaching-assistant","level":3,"title":"Teaching Assistant","text":"<pre><code>import ollama\n\ndef create_quiz_questions(topic, difficulty, num_questions):\n    \"\"\"Generate quiz questions on a topic.\"\"\"\n    prompt = f\"\"\"Create {num_questions} {difficulty}-level multiple choice questions\nabout {topic}. For each question:\n1. Provide the question\n2. Give 4 options (A, B, C, D)\n3. Indicate the correct answer\n4. Explain why the correct answer is right\n\nFormat clearly with separators between questions.\"\"\"\n\n    response = ollama.generate(model='llama3.2', prompt=prompt)\n    return response['response']\n\n# Generate quiz\nquiz = create_quiz_questions(\n    topic=\"the scientific method\",\n    difficulty=\"intermediate\",\n    num_questions=5\n)\nprint(quiz)\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#data-analysis-helper","level":3,"title":"Data Analysis Helper","text":"<pre><code>import ollama\n\ndef suggest_analysis(data_description):\n    \"\"\"Suggest statistical analyses for a dataset.\"\"\"\n    prompt = f\"\"\"Based on this data description, suggest appropriate statistical\nanalyses and explain the rationale:\n\n{data_description}\n\nPlease provide:\n1. Recommended statistical tests/methods\n2. Assumptions to check\n3. Python/R code snippets for implementation\n4. How to interpret potential results\"\"\"\n\n    response = ollama.generate(model='qwen2.5:7b', prompt=prompt)\n    return response['response']\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#further-resources","level":2,"title":"Further Resources","text":"<ul> <li>Ollama Website: ollama.com</li> <li>Model Library: ollama.com/library</li> <li>GitHub Repository: github.com/ollama/ollama</li> <li>API Documentation: github.com/ollama/ollama/blob/main/docs/api.md</li> <li>Discord Community: discord.gg/ollama</li> </ul>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#related-workshop-materials","level":2,"title":"Related Workshop Materials","text":"<ul> <li>Hugging Face: Find and download models for use with Ollama</li> <li>Gradio: Build web interfaces for your Ollama-powered applications</li> <li>RAG: Implement retrieval-augmented generation with local models</li> <li>Jupyter AI: Integrate AI assistance into your research notebooks</li> <li>Agentic AI: Build autonomous AI agents with local models</li> <li>MCP: Connect Ollama to external tools and data sources</li> </ul> <p>Getting Started Recommendation</p> <p>If you're new to running local AI models, start with these steps:</p> <ol> <li>Install Ollama using the method for your operating system</li> <li>Download a small model: <code>ollama pull llama3.2:3b</code></li> <li>Try interactive chat: <code>ollama run llama3.2:3b</code></li> <li>Experiment with the Python library for programmatic access</li> <li>Create a custom Modelfile for your specific use case</li> </ol> <p>Once comfortable, explore larger models and integrations with tools like Open WebUI or LangChain.</p>","path":["Research","Ollama"],"tags":[]},{"location":"plagiarism/","level":1,"title":"Plagiarism Detection and AI-Generated Content","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#introduction","level":2,"title":"Introduction","text":"<p>The advent of sophisticated AI writing tools like ChatGPT, Claude, and Gemini has fundamentally changed conversations about plagiarism and academic integrity in higher education. By 2026, the landscape has shifted from \"Can we detect AI-generated content?\" to \"How do we assess learning authentically in an AI-augmented world?\"</p> <p>This guide provides comprehensive coverage of AI detection tools, their significant limitations, and—more importantly—alternative assessment approaches that emphasize learning over policing.</p> <p>The Limits of AI Detection</p> <p>Research is clear: AI detection tools are unreliable and produce significant false positives, particularly affecting non-native English speakers (Weber-Wulff et al., 2024). The MIT Sloan research consortium concluded that \"AI detectors don't work\" as a reliable enforcement mechanism.</p> <p>This guide emphasizes moving beyond detection toward process-based assessment and AI-transparent assignment design.</p>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#understanding-ai-detection","level":2,"title":"Understanding AI Detection","text":"","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#how-ai-detectors-work","level":3,"title":"How AI Detectors Work","text":"<p>AI detection tools analyze text for patterns characteristic of AI-generated content:</p> <p>Perplexity Analysis:</p> <ul> <li>Perplexity measures how \"surprising\" or unpredictable text is</li> <li>Human writing has higher perplexity (more varied, less predictable)</li> <li>AI writing tends toward lower perplexity (more consistent, predictable patterns)</li> <li>However, good human writers can have low perplexity, and AI can be prompted to increase it</li> </ul> <p>Burstiness Detection:</p> <ul> <li>Burstiness measures variation in sentence structure and complexity</li> <li>Human writing alternates between simple and complex sentences</li> <li>AI writing tends toward more uniform sentence structures</li> <li>But this varies significantly by writing style and genre</li> </ul> <p>Statistical Pattern Recognition:</p> <ul> <li>Detectors are trained on known AI-generated vs. human-written text</li> <li>They identify linguistic patterns, word choice frequencies, and structural markers</li> <li>Models improve at mimicking human writing faster than detectors improve at detection</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#why-detection-is-difficult","level":3,"title":"Why Detection is Difficult","text":"<p>Multiple factors make reliable AI detection nearly impossible:</p> <p>1. Human-AI Collaboration</p> <ul> <li>Most real-world AI use involves collaboration (human outlines, AI drafts, human edits)</li> <li>Mixed authorship defeats detection algorithms designed for binary classification</li> <li>No clear line between \"acceptable editing assistance\" and \"AI-generated content\"</li> </ul> <p>2. Rapid AI Model Improvements</p> <ul> <li>Each new AI model generation becomes harder to detect</li> <li>Models are optimized to produce more human-like text</li> <li>Detection tools constantly play catch-up</li> <li>By the time detectors adapt, new models have been released</li> </ul> <p>3. Paraphrasing and Editing</p> <ul> <li>Students can use AI to write, then manually rephrase to avoid detection</li> <li>Running AI output through multiple models reduces detectability</li> <li>Simple editing of AI-generated text significantly lowers detection confidence</li> </ul> <p>4. Multilingual Challenges</p> <ul> <li>Detectors perform poorly on non-English text</li> <li>Non-native English speakers are disproportionately flagged as AI users</li> <li>Cultural variations in academic writing styles confuse detection algorithms</li> </ul> <p>5. False Positives</p> <p>Research shows detection tools produce false positive rates of 10-30%, meaning innocent students are regularly accused of AI use (Liang et al., 2023).</p>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#major-detection-tools-comprehensive-coverage","level":2,"title":"Major Detection Tools: Comprehensive Coverage","text":"","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#turnitin","level":3,"title":"Turnitin","text":"<p>Most Widely Used Institutional Tool</p> <p>Turnitin is the market leader in plagiarism detection and added AI writing detection in April 2023.</p> <p>AI Detection Features:</p> <ul> <li>Integrated into existing Turnitin plagiarism detection platform</li> <li>Claims 98% accuracy on fully AI-generated content (drops significantly for mixed authorship)</li> <li>Provides percentage likelihood that text is AI-generated</li> <li>Highlights specific passages flagged as potentially AI-written</li> </ul> <p>Institutional Adoption:</p> <ul> <li>Integrated with Canvas, Blackboard, Moodle, and D2L Brightspace</li> <li>Requires institutional licensing (no individual purchase option)</li> <li>Most common tool used by universities worldwide</li> <li>Faculty can enable/disable AI detection per assignment</li> </ul> <p>Pricing:</p> <ul> <li>Institutional licensing only (pricing not public, negotiated per institution)</li> <li>Typically bundled with plagiarism detection service</li> <li>Large-scale adoption discounts available</li> </ul> <p>Limitations:</p> <ul> <li>High false positive rate on non-native English speakers</li> <li>Struggles with edited or paraphrased AI content</li> <li>Cannot reliably detect hybrid human-AI writing</li> <li>Accuracy claims based on idealized laboratory conditions, not real student work</li> </ul> <p>Turnitin Key Facts</p> <ul> <li>Launched: April 2023</li> <li>Accuracy Claim: 98% on fully AI-generated content (much lower on real mixed-authorship scenarios)</li> <li>LMS Integration: Excellent (Canvas, Blackboard, Moodle, D2L)</li> <li>Best For: Institutions already using Turnitin for plagiarism detection</li> <li>Major Limitation: Cannot reliably detect AI-assisted (vs. AI-generated) work</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#ithenticate","level":3,"title":"iThenticate","text":"<p>Research and Professional Publishing Focus</p> <p>iThenticate is Turnitin's professional-grade service for researchers, publishers, and graduate programs.</p> <p>Primary Use Cases:</p> <ul> <li>Dissertation and thesis originality checking</li> <li>Manuscript submission for journal publication</li> <li>Grant proposal review</li> <li>Professional writing integrity verification</li> </ul> <p>AI Detection:</p> <ul> <li>Similar technology to Turnitin's AI detection</li> <li>Integrated with existing plagiarism detection</li> <li>Preferred by academic publishers and graduate schools</li> </ul> <p>Pricing:</p> <ul> <li>Per-document pricing ($19-40 per document depending on volume)</li> <li>Institutional subscriptions available</li> <li>Individual researcher access through publishers or institutions</li> </ul> <p>Best For:</p> <ul> <li>Graduate students submitting dissertations</li> <li>Researchers preparing manuscripts for publication</li> <li>Publishers screening submitted work</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#copyleaks","level":3,"title":"Copyleaks","text":"<p>Multilingual and Enterprise-Focused</p> <p>Copyleaks offers comprehensive AI detection with strong multilingual support.</p> <p>Key Features:</p> <ul> <li>Supports 120+ languages (strongest multilingual offering)</li> <li>API access for custom integration</li> <li>Batch document processing</li> <li>Code plagiarism detection (unique among major tools)</li> <li>Real-time scanning as students type (optional feature)</li> </ul> <p>Accuracy Claims:</p> <ul> <li>Claims 99.1% accuracy (similar caveats as other tools about mixed authorship)</li> <li>Provides sentence-level highlighting</li> <li>Confidence scores for each flagged section</li> </ul> <p>LMS Integration:</p> <ul> <li>Canvas, Blackboard, Moodle, Google Classroom</li> <li>API allows custom LMS integration</li> </ul> <p>Pricing:</p> <ul> <li>Tiered pricing based on usage volume</li> <li>Educational discounts available</li> <li>Free tier with limited scans per month</li> <li>Enterprise pricing for large institutions</li> </ul> <p>Best For:</p> <ul> <li>Institutions with significant multilingual student populations</li> <li>Computer science departments (code detection feature)</li> <li>Organizations requiring API integration</li> </ul> <p>Copyleaks Multilingual Advantage</p> <p>If your institution serves large international student populations, Copyleaks' multilingual detection (120+ languages) may reduce false positives compared to English-focused tools.</p>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#gptzero","level":3,"title":"GPTZero","text":"<p>AI-Specific Detection Tool</p> <p>GPTZero was built specifically for detecting AI-generated content, particularly from ChatGPT.</p> <p>Key Features:</p> <ul> <li>Free for educators (premium tiers available)</li> <li>Chrome extension for quick scanning</li> <li>Batch document upload</li> <li>Detailed scan reports with sentence-level highlighting</li> <li>\"Writing Report\" showing perplexity and burstiness scores</li> </ul> <p>Educator Features:</p> <ul> <li>Dashboard for tracking scans across classes</li> <li>Integration with Google Classroom</li> <li>Student-facing version for self-checking before submission</li> <li>API access for developers</li> </ul> <p>Pricing:</p> <ul> <li>Free tier: Limited scans per month for individual educators</li> <li>Essential Plan: $9.99/month for regular classroom use</li> <li>Premium Plan: $29.99/month for department-level use</li> <li>Institutional: Custom pricing for universities</li> </ul> <p>Limitations:</p> <ul> <li>Newer tool with less institutional trust than Turnitin</li> <li>No integration with major LMS platforms (Canvas, Blackboard)</li> <li>Same fundamental detection limitations as other tools</li> <li>Accuracy not independently verified</li> </ul> <p>Best For:</p> <ul> <li>Individual instructors experimenting with AI detection</li> <li>K-12 and community colleges with limited budgets</li> <li>Quick spot-checks of suspicious submissions</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#scribbr","level":3,"title":"Scribbr","text":"<p>Student-Focused Detection and Writing Support</p> <p>Scribbr combines AI detection with plagiarism checking and writing assistance tools aimed at students.</p> <p>Key Features:</p> <ul> <li>AI detection bundled with plagiarism checker</li> <li>Citation generation and proofreading services</li> <li>Student-friendly interface and pricing</li> <li>Educational resources about academic integrity</li> </ul> <p>Pricing:</p> <ul> <li>Per-document pricing: $19.95 per scan (includes plagiarism + AI detection)</li> <li>No subscription required: Pay as you go</li> <li>Academic writing bundles: Combined services at discount</li> </ul> <p>Target Market:</p> <ul> <li>Undergraduate students self-checking work before submission</li> <li>Graduate students preparing dissertations</li> <li>International students needing writing support</li> </ul> <p>Limitations:</p> <ul> <li>No institutional integration or bulk scanning</li> <li>Designed for individual student use, not institutional enforcement</li> <li>Same detection accuracy issues as other tools</li> </ul> <p>Best For:</p> <ul> <li>Students wanting to self-check before submitting to institutional detectors</li> <li>Combining AI detection with citation help and proofreading</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#paperpal","level":3,"title":"PaperPal","text":"<p>AI Writing Assistant with Integrity Checking</p> <p>PaperPal is unique in offering both AI writing enhancement and AI detection.</p> <p>Key Features:</p> <ul> <li>AI-powered writing suggestions (grammar, clarity, academic tone)</li> <li>Plagiarism detection</li> <li>AI content detection</li> <li>Designed for academic writing (research papers, theses)</li> </ul> <p>Dual Use Cases:</p> <ul> <li>For Students: Improve writing while checking for unintentional plagiarism or AI overuse</li> <li>For Faculty: Screen submissions while understanding AI was used for enhancement</li> </ul> <p>Pricing:</p> <ul> <li>Free tier: Limited features and scans</li> <li>Premium: $9.99/month for enhanced features</li> <li>Institutional: Custom pricing for universities</li> </ul> <p>Philosophy:</p> <p>PaperPal embraces AI as a writing aid while helping users maintain academic integrity—a more nuanced approach than pure detection.</p> <p>Best For:</p> <ul> <li>Students using AI appropriately for writing enhancement</li> <li>Faculty accepting regulated AI use with disclosure</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#originalityai","level":3,"title":"Originality.AI","text":"<p>Content Marketing and Education Hybrid</p> <p>Originality.AI serves both content marketers (checking for AI-generated web content) and educators.</p> <p>Key Features:</p> <ul> <li>AI detection + plagiarism checking</li> <li>Fact-checking capabilities (unique feature)</li> <li>Readability scoring</li> <li>Team collaboration tools</li> </ul> <p>Pricing:</p> <ul> <li>Credit-based: $0.01 per 100 words scanned (pay-per-use)</li> <li>Base package: $30 for 30,000 scans</li> <li>Team plans: Volume discounts for organizations</li> </ul> <p>Best For:</p> <ul> <li>Online education programs and MOOCs</li> <li>Institutions creating content at scale</li> <li>Teams needing collaborative review workflows</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#other-notable-tools","level":3,"title":"Other Notable Tools","text":"<p>Brief Overview of Additional Options:</p> Tool Focus Pricing Key Feature Winston AI Education &amp; publishing $12-49/month Multiple AI model detection Content at Scale Content creation $49-99/month SEO-optimized content creation + detection Writer.com Enterprise writing Custom enterprise Brand consistency + AI detection Sapling AI Customer service $25/user/month AI writing + grammar for business ZeroGPT Free detection Free (ad-supported) No account required, quick checks","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#comprehensive-detection-tool-comparison","level":2,"title":"Comprehensive Detection Tool Comparison","text":"Tool Primary Use AI Detection Plagiarism LMS Integration Pricing Model Accuracy Claims Best For Turnitin Higher Ed Yes Yes Canvas, Blackboard, Moodle, D2L Institutional licensing 98% full AI content Universities with existing Turnitin iThenticate Research/Professional Yes Yes Publisher systems Per-document or subscription Similar to Turnitin Dissertations, journal submissions Copyleaks Enterprise/Education Yes Yes Canvas, Blackboard, Moodle, API Tiered usage-based 99.1% claimed Multilingual institutions (120+ languages) GPTZero K-12 &amp; Higher Ed Yes No Google Classroom only Free-Premium ($0-30/mo) Not disclosed Individual educators, budget-conscious Scribbr Students Yes Yes None (student-facing) Per-document ($19.95) Not disclosed Students self-checking before submission PaperPal Academic Writing Yes Yes None (standalone) Freemium ($0-10/mo) Not disclosed Students using AI for writing enhancement Originality.AI Content/Education Yes Yes API available Credit-based ($0.01/100 words) Not disclosed Online education, content teams","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#institutional-implementation","level":2,"title":"Institutional Implementation","text":"","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#choosing-a-detection-tool","level":3,"title":"Choosing a Detection Tool","text":"<p>Needs Assessment Framework:</p> <p>Before adopting a detection tool, institutions should evaluate:</p> <p>1. Integration Requirements</p> <ul> <li>Does it integrate with your LMS (Canvas, Blackboard, Moodle, D2L)?</li> <li>Can faculty enable/disable per assignment?</li> <li>Does it support your workflow (batch uploads, API access)?</li> </ul> <p>2. Budget Considerations</p> <ul> <li>Institutional licensing vs. per-use pricing?</li> <li>Total cost for your student population?</li> <li>Cost compared to alternative assessment redesign?</li> </ul> <p>3. Privacy and Data Security</p> <ul> <li>Is the vendor FERPA-compliant?</li> <li>Where is student data stored?</li> <li>How long is data retained?</li> <li>Can students' work be used to train detection models?</li> </ul> <p>4. Multilingual Support</p> <ul> <li>Do you have significant non-native English speaker populations?</li> <li>Does the tool work well in languages your students write in?</li> <li>What are false positive rates for non-native speakers?</li> </ul> <p>5. Accuracy and Reliability</p> <ul> <li>What are independently verified accuracy rates (not just vendor claims)?</li> <li>How does it handle hybrid human-AI writing?</li> <li>What is the false positive rate in real-world conditions?</li> </ul> <p>6. Faculty and Student Support</p> <ul> <li>Training resources for faculty?</li> <li>Clear guidance for students?</li> <li>Technical support responsiveness?</li> <li>Appeals process for false positives?</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#policy-development","level":3,"title":"Policy Development","text":"<p>Effective institutional policies balance enforcement with education:</p> <p>Policy Components:</p> Transparent AI Use PolicyAI-Transparent Assessment PolicyAI Detection and Due Process Policy <p>Sample Institutional Policy Language:</p> <p>AI Use in Coursework</p> <p>[Institution] recognizes that artificial intelligence tools are increasingly part of academic and professional life. Our approach emphasizes:</p> <ol> <li>Transparency: Students must disclose significant AI use in submitted work</li> <li>Learning First: Assignments should demonstrate genuine learning, not AI-generated shortcuts</li> <li>Faculty Autonomy: Individual instructors set AI policies for their courses (must be stated in syllabus)</li> <li>Educational Approach: First violations addressed through education; repeated violations subject to academic integrity processes</li> </ol> <p>AI Detection Use:</p> <ul> <li>Faculty may use AI detection tools to screen submissions</li> <li>Detection is one data point, not sole evidence of misconduct</li> <li>Students flagged by detection tools receive opportunity to explain their process</li> <li>False positives are treated seriously; students will not be penalized without substantial evidence</li> </ul> <p>Appeals Process:</p> <p>Students accused of inappropriate AI use based on detection tool results may appeal by providing: * Draft documents showing writing process * Explanation of AI tools used and how * Original notes, outlines, or research materials</p> <p>Sample Course-Level Policy:</p> <p>AI Policy for [Course Name]</p> <p>In this course, AI tools are permitted under the following conditions:</p> <p>Permitted Uses: * Brainstorming and generating ideas * Explaining concepts you're learning * Grammar and clarity checking on your own writing * Generating practice problems for self-study</p> <p>Prohibited Uses: * Writing any portion of assignments submitted for credit * Generating solutions to problem sets or labs * Taking quizzes or completing exams</p> <p>Disclosure Requirement: All assignments must include an \"AI Use Statement\" describing any AI assistance and how it was used.</p> <p>Rationale: This policy helps you develop skills in effective AI collaboration while ensuring you build genuine understanding of course material.</p> <p>Sample Procedures for AI Detection:</p> <p>When AI Detection Flags a Submission:</p> <ol> <li>Initial Review (Faculty):</li> <li>Review detection report and student's work holistically</li> <li>Consider: Does the writing match the student's typical work? Are there other indicators of AI use?</li> <li> <p>If substantial concerns, proceed to Step 2</p> </li> <li> <p>Student Conference (Required Before Formal Accusation):</p> </li> <li>Meet with student to discuss the flagged submission</li> <li>Ask student to explain their writing process</li> <li>Request any draft documents, notes, or outlines</li> <li> <p>Provide opportunity for student to respond to concerns</p> </li> <li> <p>Faculty Decision:</p> </li> <li>Dismiss concern if student provides satisfactory explanation</li> <li>Assign educational consequence (revision, academic integrity training) for minor violations</li> <li> <p>Report to academic integrity office for substantial violations</p> </li> <li> <p>Student Appeals:</p> </li> <li>Students may appeal faculty decisions to [designated office]</li> <li>Appeals process includes independent review of detection evidence</li> <li>False positive determinations result in record expungement</li> </ol>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#training-and-rollout","level":3,"title":"Training and Rollout","text":"<p>Phased Implementation Approach:</p> <p>Phase 1: Planning and Policy Development (Semester 1)</p> <ul> <li>Form task force with faculty, students, IT, and academic integrity officers</li> <li>Research tools and develop institutional policy</li> <li>Draft faculty and student guidance documents</li> <li>Create appeals process and support structures</li> </ul> <p>Phase 2: Pilot Program (Semester 2)</p> <ul> <li>Select 10-15 volunteer faculty across disciplines</li> <li>Provide intensive training and support</li> <li>Test detection tool in real courses</li> <li>Gather feedback on accuracy, usability, and student reactions</li> <li>Refine policies based on pilot results</li> </ul> <p>Phase 3: Expanded Rollout (Year 2)</p> <ul> <li>Offer professional development workshops for all faculty</li> <li>Provide discipline-specific guidance</li> <li>Launch student education campaign about AI policies</li> <li>Make detection tool available campus-wide</li> <li>Monitor for false positives and policy issues</li> </ul> <p>Phase 4: Ongoing Evaluation and Adjustment (Ongoing)</p> <ul> <li>Annual review of detection tool accuracy and effectiveness</li> <li>Regular updates to policies as AI technology evolves</li> <li>Continuous faculty and student education</li> <li>Share best practices across departments</li> </ul> <p>Faculty Training Topics:</p> <ul> <li>How AI detection tools work (and their limitations)</li> <li>Interpreting detection reports critically</li> <li>Conducting student conferences about flagged work</li> <li>Redesigning assignments to emphasize process and learning</li> <li>Balancing detection with pedagogical goals</li> </ul> <p>Student Education:</p> <ul> <li>What constitutes appropriate vs. inappropriate AI use</li> <li>How to disclose AI assistance properly</li> <li>Understanding detection tools and their limitations</li> <li>Academic integrity in the AI era</li> <li>Resources for using AI effectively for learning</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#beyond-detection-alternative-approaches","level":2,"title":"Beyond Detection: Alternative Approaches","text":"<p>The Most Important Section of This Guide</p> <p>Research increasingly shows that detection is an arms race institutions cannot win. The most effective approach is designing assessments where AI use is transparent, regulated, or incorporated—rendering detection unnecessary.</p>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#process-based-assessment","level":3,"title":"Process-Based Assessment","text":"<p>Focus on the learning process rather than just the final product:</p> <p>Draft Submissions and Revision Tracking:</p> <pre><code>Assignment Structure:\n- Submit initial outline (Week 2)\n- Submit annotated bibliography with your notes (Week 4)\n- Submit first draft with track changes enabled (Week 6)\n- Submit revised draft with revision memo explaining changes (Week 8)\n- Submit final draft (Week 10)\n\nGrade based on:\n- 30%: Quality of process (research, outlining, revision)\n- 40%: Improvement from draft to final\n- 30%: Final product quality\n</code></pre> <p>Reflective Journals:</p> <p>Require students to document their research and thinking process:</p> <pre><code>Weekly Learning Journal Prompts:\n- What sources did you consult this week? What did you learn from each?\n- What challenges did you encounter? How did you address them?\n- What decisions did you make about your argument? Why?\n- If you used AI tools, how did they help? What did they miss?\n- What will you work on next week?\n</code></pre> <p>In-Class Components:</p> <ul> <li>Oral presentations defending written work</li> <li>Synchronous problem-solving sessions</li> <li>Live coding or demonstrations</li> <li>Discussion-based assessment showing deep understanding</li> </ul> <p>Process-Based Assessment Examples by Discipline</p> <p>History:</p> <ul> <li>Submit annotated primary sources with analysis notes</li> <li>Present findings to class before final paper</li> <li>Reflective memo on historiographical debates</li> </ul> <p>STEM:</p> <ul> <li>Lab notebooks documenting experimental process</li> <li>Error analysis and troubleshooting documentation</li> <li>Peer review of methodology before final submission</li> </ul> <p>Writing:</p> <ul> <li>Multiple drafts with peer review feedback</li> <li>Revision rationale explaining changes</li> <li>Portfolio of process documents (brainstorming, outlines, drafts)</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#ai-integrated-assignments","level":3,"title":"AI-Integrated Assignments","text":"<p>Instead of prohibiting AI, design assignments requiring thoughtful AI use:</p> <p>Comparative Analysis Assignments:</p> <pre><code>Assignment: Climate Change Policy Analysis\n\nPart 1: Generate three policy proposals using ChatGPT/Claude by providing:\n- Current climate data and constraints\n- Policy objectives\n- Stakeholder considerations\n\nPart 2: Analyze each AI-generated proposal:\n- What are the strengths and limitations of each?\n- What did the AI miss or misunderstand?\n- Which proposal is best? Why?\n- How would you improve the best proposal?\n\nPart 3: Write your own policy proposal incorporating insights from your AI analysis\n\nDeliverable:\n- AI conversation logs (prompts and responses)\n- 5-page analysis and original proposal\n- Reflection on what you learned about both the topic and AI's capabilities/limitations\n</code></pre> <p>AI Tool Critique:</p> <pre><code>Assignment: Evaluating AI for [Your Field]\n\n1. Use 3 different AI tools to solve the same problem in [field]\n2. Compare outputs for accuracy, completeness, and usefulness\n3. Identify errors, biases, or gaps in each AI's response\n4. Research the correct answer using scholarly sources\n5. Write a report analyzing:\n   - How AI tools can assist professionals in [field]\n   - Their limitations and risks\n   - Best practices for using AI in [field] responsibly\n\nDemonstrate your understanding by critiquing AI, not by avoiding it.\n</code></pre> <p>Prompt Engineering Assignments:</p> <pre><code>Assignment: The Art of the Prompt\n\nTask: Solve [complex problem] using AI assistance\n\nRequirements:\n1. Document 5-10 prompts you used, showing iteration and refinement\n2. Explain your prompting strategy and how you improved prompts based on responses\n3. Evaluate the AI's final output critically\n4. Demonstrate deep understanding by explaining what the AI got right and wrong\n5. Produce final work that integrates AI assistance with your expertise\n\nAssessment Criteria:\n- Quality of prompts (specificity, context, iteration)\n- Critical evaluation of AI outputs\n- Integration of AI insights with original thinking\n- Clear documentation of process\n</code></pre>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#oral-and-performance-assessments","level":3,"title":"Oral and Performance Assessments","text":"<p>Assessments requiring synchronous demonstration of knowledge:</p> <p>Presentations and Defenses:</p> <ul> <li>Students present written work and answer questions</li> <li>Demonstrate ability to explain, defend, and extend arguments</li> <li>\"Defense\" format similar to thesis defense for major papers</li> </ul> <p>Live Problem-Solving:</p> <ul> <li>Timed in-class problem sets where students explain their thinking</li> <li>Open-book, open-AI, but must articulate process</li> <li>Assess understanding, not just correct answers</li> </ul> <p>Video Reflections:</p> <ul> <li>Students record themselves explaining their project/paper</li> <li>Demonstrate understanding by teaching the content</li> <li>Show their face while explaining to verify authenticity</li> </ul> <p>Synchronous Discussions:</p> <ul> <li>Participation in live class discussions demonstrating preparation</li> <li>Socratic seminars where students must engage with texts</li> <li>Fishbowl discussions requiring deep textual knowledge</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#authentic-assessment","level":3,"title":"Authentic Assessment","text":"<p>Connect assignments to real-world contexts where AI provides incomplete solutions:</p> <p>Community-Based Projects:</p> <ul> <li>Partner with local organizations on real problems</li> <li>Deliverables go to actual clients with real stakes</li> <li>AI can assist but cannot replace community engagement and context</li> </ul> <p>Professional Portfolio Development:</p> <ul> <li>Build portfolios demonstrating skills over time</li> <li>Include reflections on growth and learning</li> <li>Authentic representation of student capabilities</li> </ul> <p>Original Data Creation:</p> <ul> <li>Conduct experiments, surveys, or fieldwork generating original data</li> <li>AI cannot fabricate data that doesn't exist</li> <li>Analysis must be grounded in actual results</li> </ul> <p>Multimodal Projects:</p> <ul> <li>Create podcasts, videos, infographics, or interactive media</li> <li>Demonstrate understanding through multiple formats</li> <li>AI assistance possible but human creativity and voice central</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#honor-code-evolution","level":3,"title":"Honor Code Evolution","text":"<p>Reframe academic integrity for the AI era:</p> <p>Updated Honor Code Principles:</p> <p>Instead of:</p> <p>\"I will not use unauthorized assistance on assignments.\"</p> <p>Consider:</p> <p>\"I will engage honestly with course material, using tools appropriately to support my learning. I will be transparent about my process and attribute assistance received, whether from humans or AI.\"</p> <p>AI Use Pledge Example:</p> <p>I pledge to: </p> <ol> <li>Use AI as a learning tool, not a replacement for learning</li> <li>Disclose all significant AI assistance in my work</li> <li>Verify AI-generated information against authoritative sources</li> <li>Ensure my submissions represent my own understanding</li> <li>Ask my instructor when unsure whether AI use is appropriate</li> </ol> <p>Educational Approach to Violations:</p> <ul> <li>First-time violations: Educational intervention (integrity workshop, assignment revision)</li> <li>Repeated violations: Traditional academic integrity consequences</li> <li>Focus on growth and learning rather than pure punishment</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#for-students-understanding-detection","level":2,"title":"For Students: Understanding Detection","text":"","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#what-triggers-detection","level":3,"title":"What Triggers Detection","text":"<p>Common patterns that flag AI-written content:</p> <p>Writing Characteristics:</p> <ul> <li>Unusually consistent sentence structure</li> <li>Perfect grammar with no typos</li> <li>Sophisticated vocabulary inconsistent with prior work</li> <li>Generic examples rather than specific, personal details</li> <li>Lack of clear thesis development across paragraphs</li> <li>Overly formal or stilted academic language</li> <li>Missing the \"messiness\" of authentic human thought</li> </ul> <p>Red Flags for Instructors:</p> <ul> <li>Sudden dramatic improvement in writing quality</li> <li>Style inconsistent with student's previous submissions</li> <li>Content that doesn't reflect class discussions or readings</li> <li>Perfect formatting and citations (unusual for students)</li> <li>Text that reads like an encyclopedia or generic essay</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#false-positive-scenarios","level":3,"title":"False Positive Scenarios","text":"<p>Legitimate writing that may be flagged:</p> <ul> <li>Non-native English speakers who write formally</li> <li>Students who use grammar checkers extensively (Grammarly)</li> <li>Well-prepared students with strong writing skills</li> <li>Students who heavily edit and revise their work</li> <li>Writing in formal academic genres (lab reports, literature reviews)</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#if-youre-falsely-accused","level":3,"title":"If You're Falsely Accused:","text":"<p>Steps to take if you're accused of using AI inappropriately:</p> <p>1. Stay Calm and Professional</p> <ul> <li>Don't panic or get defensive</li> <li>Academic integrity processes have due process protections</li> <li>False positives are relatively common with AI detection</li> </ul> <p>2. Gather Evidence of Your Process</p> <ul> <li>Draft documents with timestamps</li> <li>Research notes and annotated sources</li> <li>Outlines and brainstorming documents</li> <li>Email drafts or version history</li> <li>Google Docs version history (shows your writing process over time)</li> </ul> <p>3. Request Specifics</p> <ul> <li>Ask which tool was used for detection</li> <li>Request the specific detection report</li> <li>Understand what percentage/sections were flagged</li> <li>Ask what other evidence supports the accusation (beyond detection tool)</li> </ul> <p>4. Prepare Your Explanation</p> <ul> <li>Document your writing process honestly</li> <li>Explain any tools you used (grammar checkers, AI for brainstorming)</li> <li>Demonstrate your understanding of the content</li> <li>Offer to discuss your work in detail or rewrite under supervision</li> </ul> <p>5. Know Your Rights</p> <ul> <li>You have the right to see evidence against you</li> <li>You can appeal decisions you believe are unfair</li> <li>Many institutions provide student advocates</li> <li>False accusations should be documented and appealed</li> </ul> <p>6. Learn from the Experience</p> <ul> <li>Understand your institution's AI policies better</li> <li>Document your process more carefully in future assignments</li> <li>Consider disclosing all AI use proactively, even minor uses</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#ethical-ai-use","level":3,"title":"Ethical AI Use","text":"<p>Best Practices for Students:</p> <p>Disclosure Templates:</p> <pre><code>AI Use Statement for Assignment:\n\n\"I used ChatGPT to brainstorm initial topic ideas for this essay. After selecting\na topic, I conducted my own research using library databases. I used Grammarly to\ncheck grammar and clarity on my final draft. All ideas, analysis, and arguments\nare my own, developed through my research and understanding of course material.\"\n</code></pre> <p>Citation Methods for AI:</p> <p>When citing AI assistance in your work:</p> <pre><code>APA Style (7th edition):\nOpenAI. (2026). ChatGPT (version GPT-4.5) [Large language model].\nhttps://chat.openai.com/\n\nIn-text: (OpenAI, 2026)\n\nNote: Include the specific prompt and response in an appendix if requested by instructor.\n</code></pre> <p>Process Documentation:</p> <p>Keep records of:</p> <ul> <li>All drafts with dates</li> <li>Research notes and sources consulted</li> <li>Any AI interactions (save conversation logs)</li> <li>Revisions and the thinking behind them</li> <li>Notes from professor feedback and how you addressed it</li> </ul> <p>Proactive Documentation</p> <p>Best practice: Document your process even when not required. This protects you if ever questioned and helps you reflect on your own learning.</p>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#practical-resources","level":2,"title":"Practical Resources","text":"","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#for-faculty","level":3,"title":"For Faculty","text":"<p>Syllabus Language Templates</p> <p>Assignment Redesign Checklist:</p> <ul> <li> Does this assignment require demonstration of process, not just product?</li> <li> Can students easily complete it using AI without learning?</li> <li> Have I included opportunities for students to show their thinking?</li> <li> Is there an in-class or synchronous component?</li> <li> Do students need to create original data or use course-specific materials?</li> <li> Would I learn about student understanding from their AI use patterns?</li> </ul> <p>Student Conversation Scripts:</p> <pre><code>Opening a Conversation About Flagged Work:\n\n\"I'd like to talk with you about your recent assignment. The similarity detection\ntool flagged some portions as potentially AI-generated. I'm not accusing you of\nmisconduct—I want to understand your process. Can you walk me through how you\napproached this assignment and what tools or resources you used?\"\n\n[Listen to student explanation]\n\n\"Thank you for explaining. To help me understand your work better, do you have any\ndrafts, notes, or outlines you can share? I'm interested in seeing your thinking\nprocess.\"\n</code></pre>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#for-administrators","level":3,"title":"For Administrators","text":"<p>Policy Template:</p> <p>See \"Policy Development\" section above for comprehensive institutional policy templates.</p> <p>Budget Justification Document:</p> <pre><code>Proposal: AI Detection Tool Implementation\n\nEstimated Costs:\n- Detection tool licensing: $XX,XXX annually\n- Faculty training and support: $X,XXX\n- Student education campaign: $X,XXX\n- IT integration and maintenance: $X,XXX\nTotal: $XX,XXX\n\nAlternative Approach:\n- Faculty professional development on assessment redesign: $XX,XXX\n- Instructional designer support for course revision: $XX,XXX\n- Student AI literacy programming: $X,XXX\nTotal: $XX,XXX (potentially more sustainable investment)\n\nRecommendation:\nInvest in assessment transformation rather than detection arms race.\nIf detection tool adopted, combine with significant pedagogical support.\n</code></pre> <p>Implementation Checklist:</p> <ul> <li> Task force formed with diverse stakeholders</li> <li> Institutional policy drafted and vetted</li> <li> Faculty handbook updated</li> <li> Student code of conduct revised</li> <li> LMS integration tested</li> <li> Faculty training schedule developed</li> <li> Student education materials created</li> <li> Appeals process established</li> <li> Data privacy audit completed</li> <li> Assessment plan for effectiveness created</li> </ul>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#for-students","level":3,"title":"For Students","text":"<p>AI Use Disclosure Template:</p> <pre><code>AI Use Statement\n\nFor this assignment, I used the following AI tools:\n\n[Tool Name]: Used for [specific purpose]\n- Prompts used: [brief description or examples]\n- How I used the output: [explanation]\n\nAll analysis, arguments, and conclusions are my own, developed through [describe your\nprocess: research, class materials, discussions, etc.].\n\n[Your Name]\n[Date]\n</code></pre> <p>Self-Assessment Checklist:</p> <p>Before submitting an assignment, ask yourself:</p> <ul> <li> Can I explain every idea in this assignment in my own words?</li> <li> Do I understand the reasoning behind my arguments?</li> <li> Could I defend this work in a conversation with my professor?</li> <li> Have I disclosed all significant AI assistance?</li> <li> Does this work represent my learning, not just AI output?</li> <li> Am I proud of this work and what I learned creating it?</li> </ul> <p>If you answer \"no\" to any question, revise before submitting.</p>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"plagiarism/#additional-resources","level":2,"title":"Additional Resources","text":"<p>For All Stakeholders:</p> <ul> <li>MIT Sloan EdTech: Why AI Detectors Don't Work</li> <li>Weber-Wulff et al. (2024): AI Detection Tool Analysis</li> <li>Liang et al. (2023): GPT Detectors Biased Against Non-Native English Writers</li> </ul> <p>Related Workshop Materials:</p> <ul> <li>Education Overview - AI's broader impact on higher education</li> <li>Teaching with AI - Faculty strategies for AI integration</li> <li>AI Tutoring - Student learning support</li> <li>Admissions &amp; Recruiting - AI in application processes</li> </ul> <p>Last Updated: January 2026</p> <p>This guide will be updated as detection technology and institutional practices evolve.</p>","path":["Education","Plagiarism Detection and AI-Generated Content"],"tags":[]},{"location":"posit/","level":1,"title":"Posit (RStudio)","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#overview","level":2,"title":"Overview","text":"<p>Posit (formerly RStudio) is a company dedicated to creating open-source data science tools. Their ecosystem includes:</p> <ul> <li>RStudio Desktop/Server - The classic IDE for R programming</li> <li>Positron - A next-generation data science IDE built on VS Code</li> <li>Quarto - A scientific publishing system</li> <li>Shiny - Web application framework for R and Python</li> <li>tidyverse/tidymodels - Popular R package collections</li> </ul> <p>Posit has developed powerful LLM integration packages that work across their IDEs:</p> Package Language Description ellmer R Unified interface for 20+ LLM providers chatlas Python LLM chat framework with streaming and tool calling <p>These packages allow researchers to integrate AI assistance directly into their data analysis workflows, from interactive exploration to reproducible reports.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#why-use-posit-tools-for-ai","level":2,"title":"Why Use Posit Tools for AI?","text":"<p>For R Users:</p> <ul> <li>Native integration with tidyverse workflows</li> <li>Seamless use in R Markdown and Quarto documents</li> <li>Support for both cloud APIs and local models via Ollama</li> <li>Interactive chat within the IDE console</li> </ul> <p>For Python Users:</p> <ul> <li>Model-agnostic design for easy provider switching</li> <li>Automatic streaming in notebooks and consoles</li> <li>Tool calling for agentic capabilities</li> <li>Async support for scalable applications</li> </ul> <p>For Academic Research:</p> <ul> <li>Reproducible AI-assisted analysis pipelines</li> <li>Local model support for sensitive data</li> <li>Easy switching between providers for cost optimization</li> <li>Integration with Quarto for publishable documents</li> </ul>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#installation-positron-beta","level":2,"title":"Installation: Positron (Beta)","text":"<p>Positron is Posit's next-generation data science IDE. Built on VS Code's foundation, it provides native support for Python, R, and AI-assisted coding with a familiar interface for data scientists.</p> <p>Current Version: 2026.01.0-147 (January 2026)</p> <p>Positron is in active beta development. While stable for daily use, expect continued improvements and occasional breaking changes.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#system-requirements","level":3,"title":"System Requirements","text":"Platform Requirement Windows Windows 10 or 11 (x64) macOS macOS 11.0+ (Apple Silicon or Intel) Linux Ubuntu 20+ or RHEL 9","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#macos-installation","level":3,"title":"macOS Installation","text":"Apple Silicon (M1/M2/M3/M4)Intel Mac <ol> <li>Download Positron-2026.01.0-147-arm64.dmg (~598 MB)</li> <li>Open the downloaded <code>.dmg</code> file</li> <li>Drag Positron to your Applications folder</li> <li>Launch Positron from Applications</li> <li>If prompted about an unidentified developer, go to System Preferences &gt; Security &amp; Privacy and click \"Open Anyway\"</li> </ol> <ol> <li>Download Positron-2026.01.0-147-x64.dmg (~601 MB)</li> <li>Open the downloaded <code>.dmg</code> file</li> <li>Drag Positron to your Applications folder</li> <li>Launch Positron from Applications</li> </ol>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#windows-installation","level":3,"title":"Windows Installation","text":"System-wide (Recommended)User Installation (No Admin) <ol> <li>Download Positron-2026.01.0-147-Setup-x64.exe (~315 MB)</li> <li>Run the installer with administrator privileges</li> <li>Follow the installation wizard prompts</li> <li>Launch Positron from the Start menu</li> </ol> <ol> <li>Download Positron-2026.01.0-147-UserSetup-x64.exe (~315 MB)</li> <li>Run the installer (no admin rights needed)</li> <li>Follow the installation wizard prompts</li> <li>Launch Positron from the Start menu</li> </ol>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#linux-installation","level":3,"title":"Linux Installation","text":"Ubuntu/DebianFedora/RHEL/CentOS <pre><code># Download the .deb package (x64)\nwget https://github.com/posit-dev/positron/releases/download/2026.01.0-147/Positron-2026.01.0-147-x64.deb\n\n# Install with dpkg\nsudo dpkg -i Positron-2026.01.0-147-x64.deb\n\n# Fix any dependency issues\nsudo apt-get install -f\n\n# Launch Positron\npositron\n</code></pre> <p>For ARM64 systems, download <code>Positron-2026.01.0-147-arm64.deb</code> instead.</p> <pre><code># Download the .rpm package (x64)\nwget https://github.com/posit-dev/positron/releases/download/2026.01.0-147/Positron-2026.01.0-147-x64.rpm\n\n# Install with dnf (Fedora/RHEL 8+)\nsudo dnf install Positron-2026.01.0-147-x64.rpm\n\n# Or with yum (older systems)\nsudo yum localinstall Positron-2026.01.0-147-x64.rpm\n\n# Launch Positron\npositron\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#positron-key-features","level":3,"title":"Positron Key Features","text":"<ul> <li>Multi-language Console - Switch between R and Python in the same session</li> <li>Variables Pane - Inspect data frames, lists, and objects visually</li> <li>Data Viewer - Explore large datasets with filtering and sorting</li> <li>Plot Pane - View and export visualizations</li> <li>VS Code Extensions - Access the full VS Code extension marketplace</li> <li>Quarto Integration - Native support for scientific publishing</li> </ul>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#installation-rstudio-desktop","level":2,"title":"Installation: RStudio Desktop","text":"<p>RStudio Desktop is the classic, mature IDE for R development used by millions of data scientists and researchers.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#macos-installation_1","level":3,"title":"macOS Installation","text":"<ol> <li>Visit posit.co/download/rstudio-desktop</li> <li>Download the macOS installer (<code>.dmg</code>)</li> <li>Open the downloaded file</li> <li>Drag RStudio to your Applications folder</li> <li>Launch RStudio from Applications</li> </ol> <p>R Required</p> <p>RStudio requires R to be installed. Download R from CRAN before installing RStudio.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#windows-installation_1","level":3,"title":"Windows Installation","text":"<ol> <li>Visit posit.co/download/rstudio-desktop</li> <li>Download the Windows installer (<code>.exe</code>)</li> <li>Run the installer and follow the prompts</li> <li>Launch RStudio from the Start menu</li> </ol>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#linux-installation_1","level":3,"title":"Linux Installation","text":"Ubuntu/DebianFedora/RHEL <pre><code># Install R first (if not already installed)\nsudo apt update\nsudo apt install r-base r-base-dev\n\n# Download RStudio (check website for latest version)\nwget https://download1.rstudio.org/electron/jammy/amd64/rstudio-2024.12.0-467-amd64.deb\n\n# Install RStudio\nsudo dpkg -i rstudio-2024.12.0-467-amd64.deb\n\n# Fix dependencies if needed\nsudo apt-get install -f\n</code></pre> <pre><code># Install R first\nsudo dnf install R\n\n# Download RStudio (check website for latest version)\nwget https://download1.rstudio.org/electron/rhel9/x86_64/rstudio-2024.12.0-467-x86_64.rpm\n\n# Install RStudio\nsudo dnf install rstudio-2024.12.0-467-x86_64.rpm\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#installation-rstudio-server","level":2,"title":"Installation: RStudio Server","text":"<p>RStudio Server provides browser-based access to RStudio, ideal for:</p> <ul> <li>Shared research computing environments</li> <li>HPC cluster access</li> <li>Cloud deployments</li> <li>Teaching labs</li> </ul>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#ubuntudebian-installation","level":3,"title":"Ubuntu/Debian Installation","text":"<pre><code># Install R\nsudo apt update\nsudo apt install r-base r-base-dev\n\n# Install RStudio Server dependencies\nsudo apt install gdebi-core\n\n# Download RStudio Server\nwget https://download2.rstudio.org/server/jammy/amd64/rstudio-server-2024.12.0-467-amd64.deb\n\n# Install RStudio Server\nsudo gdebi rstudio-server-2024.12.0-467-amd64.deb\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#fedorarhel-installation","level":3,"title":"Fedora/RHEL Installation","text":"<pre><code># Install R\nsudo dnf install R\n\n# Download RStudio Server\nwget https://download2.rstudio.org/server/rhel9/x86_64/rstudio-server-rhel-2024.12.0-467-x86_64.rpm\n\n# Install RStudio Server\nsudo dnf install rstudio-server-rhel-2024.12.0-467-x86_64.rpm\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#starting-and-managing-the-server","level":3,"title":"Starting and Managing the Server","text":"<pre><code># Start RStudio Server\nsudo systemctl start rstudio-server\n\n# Enable on boot\nsudo systemctl enable rstudio-server\n\n# Check status\nsudo systemctl status rstudio-server\n\n# View logs\nsudo journalctl -u rstudio-server\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#accessing-rstudio-server","level":3,"title":"Accessing RStudio Server","text":"<p>After installation, access RStudio Server at:</p> <pre><code>http://your-server-ip:8787\n</code></pre> <p>Log in with your Linux system credentials.</p> <p>Security Configuration</p> <p>For production deployments, configure:</p> <ul> <li>SSL/TLS certificates for HTTPS</li> <li>Firewall rules to restrict access</li> <li>Authentication integration (LDAP, PAM)</li> </ul> <p>See the RStudio Server Admin Guide for details.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#ellmer-r-package-for-llms","level":2,"title":"ellmer: R Package for LLMs","text":"<p>ellmer is Posit's R package that makes it easy to use large language models from R. It provides a unified interface for 20+ providers with support for streaming, tool calling, and structured data extraction.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#installation","level":3,"title":"Installation","text":"<pre><code># Install from CRAN\ninstall.packages(\"ellmer\")\n\n# Or install development version from GitHub\n# install.packages(\"pak\")\npak::pak(\"tidyverse/ellmer\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#supported-providers","level":3,"title":"Supported Providers","text":"<p>ellmer supports a wide range of LLM providers:</p> Provider Function Notes OpenAI <code>chat_openai()</code> GPT-4.1, GPT-4o, o3 models Anthropic <code>chat_anthropic()</code> Claude 4.5 models Google <code>chat_google_gemini()</code> Gemini models Azure OpenAI <code>chat_azure_openai()</code> Enterprise Azure deployment AWS Bedrock <code>chat_aws_bedrock()</code> Multiple models via AWS Ollama <code>chat_ollama()</code> Local models (free) Mistral <code>chat_mistral()</code> Mistral models Groq <code>chat_groq()</code> Fast inference DeepSeek <code>chat_deepseek()</code> DeepSeek models Hugging Face <code>chat_huggingface()</code> HF Inference API GitHub Models <code>chat_github()</code> GitHub model marketplace Perplexity <code>chat_perplexity()</code> Search-augmented OpenRouter <code>chat_openrouter()</code> Multi-provider gateway","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#basic-usage","level":3,"title":"Basic Usage","text":"<pre><code>library(ellmer)\n\n# Create a chat with OpenAI\nchat &lt;- chat_openai(\n  model = \"gpt-4o-mini\",\n  system_prompt = \"You are a helpful data science assistant.\"\n)\n\n# Have a conversation\nchat$chat(\"What is the tidyverse?\")\n\n# Continue the conversation (context is retained)\nchat$chat(\"Which packages are included?\")\n\n# View token usage\nchat$token_usage()\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#using-anthropic-claude","level":3,"title":"Using Anthropic Claude","text":"<pre><code>library(ellmer)\n\n# Create a chat with Claude\nchat &lt;- chat_anthropic(\n  model = \"claude-sonnet-4-5-20250514\",\n  system_prompt = \"You are an expert R programmer.\"\n)\n\n# Ask about R code\nchat$chat(\"How do I read a CSV file with readr?\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#streaming-responses","level":3,"title":"Streaming Responses","text":"<pre><code>library(ellmer)\n\nchat &lt;- chat_openai(model = \"gpt-4o-mini\")\n\n# Stream the response to the console\nchat$chat(\"Explain the central limit theorem\", echo = \"all\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#structured-data-extraction","level":3,"title":"Structured Data Extraction","text":"<p>ellmer can extract structured data from text:</p> <pre><code>library(ellmer)\n\n# Define the structure you want to extract\npaper_info &lt;- type_object(\n  title = type_string(\"The paper title\"),\n  authors = type_array(type_string(\"Author names\")),\n  year = type_integer(\"Publication year\"),\n  journal = type_string(\"Journal name\")\n)\n\nchat &lt;- chat_openai(model = \"gpt-4o-mini\")\n\n# Extract structured information\nresult &lt;- chat$extract_data(\n  \"Smith, J., &amp; Jones, M. (2024). Machine learning in ecology.\n   Nature Ecology &amp; Evolution, 8(3), 234-245.\",\n  type = paper_info\n)\n\nprint(result)\n# $title\n# [1] \"Machine learning in ecology\"\n#\n# $authors\n# [1] \"Smith, J.\" \"Jones, M.\"\n#\n# $year\n# [1] 2024\n#\n# $journal\n# [1] \"Nature Ecology &amp; Evolution\"\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#tool-calling-function-calling","level":3,"title":"Tool Calling (Function Calling)","text":"<p>Enable the model to call R functions:</p> <pre><code>library(ellmer)\n\n# Define a tool\nget_weather &lt;- function(city) {\n  # In practice, this would call a weather API\n  paste(\"The weather in\", city, \"is sunny and 72F\")\n}\n\nchat &lt;- chat_openai(\n  model = \"gpt-4o-mini\",\n  system_prompt = \"You help users with weather information.\"\n)\n\n# Register the tool\nchat$register_tool(\n  name = \"get_weather\",\n  description = \"Get the current weather for a city\",\n  arguments = list(\n    city = type_string(\"The city name\")\n  ),\n  fn = get_weather\n)\n\n# The model will call the function when appropriate\nchat$chat(\"What's the weather like in Phoenix?\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#chatlas-python-package-for-llms","level":2,"title":"chatlas: Python Package for LLMs","text":"<p>chatlas is Posit's Python package for building LLM chat applications. It provides automatic streaming, tool calling, and a model-agnostic design.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#installation_1","level":3,"title":"Installation","text":"<pre><code>pip install -U chatlas\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#supported-providers_1","level":3,"title":"Supported Providers","text":"Provider Class Notes OpenAI <code>ChatOpenAI</code> GPT-4.1, GPT-4o models Anthropic <code>ChatAnthropic</code> Claude 4.5 models Google <code>ChatGoogle</code> Gemini models Azure OpenAI <code>ChatAzureOpenAI</code> Enterprise Azure AWS Bedrock <code>ChatBedrockAnthropic</code> Claude via AWS Ollama <code>ChatOllama</code> Local models (free) Mistral <code>ChatMistral</code> Mistral models Groq <code>ChatGroq</code> Fast inference DeepSeek <code>ChatDeepSeek</code> DeepSeek models Hugging Face <code>ChatHuggingFace</code> HF Inference API Any Provider <code>ChatAuto</code> Auto-detect provider","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#basic-usage_1","level":3,"title":"Basic Usage","text":"<pre><code>from chatlas import ChatOpenAI\n\n# Create a chat\nchat = ChatOpenAI(\n    model=\"gpt-4o-mini\",\n    system_prompt=\"You are a helpful data science assistant.\"\n)\n\n# Have a conversation\nchat.chat(\"What is pandas in Python?\")\n\n# Continue the conversation\nchat.chat(\"How do I read a CSV file?\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#using-anthropic-claude_1","level":3,"title":"Using Anthropic Claude","text":"<pre><code>from chatlas import ChatAnthropic\n\nchat = ChatAnthropic(\n    model=\"claude-sonnet-4-5-20250514\",\n    system_prompt=\"You are an expert Python programmer.\"\n)\n\nchat.chat(\"How do I create a scatter plot with matplotlib?\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#tool-calling","level":3,"title":"Tool Calling","text":"<pre><code>from chatlas import ChatOpenAI\n\nchat = ChatOpenAI(\n    model=\"gpt-4o-mini\",\n    system_prompt=\"You help users with weather information.\"\n)\n\n# Define a tool as a Python function\ndef get_current_weather(city: str) -&gt; str:\n    \"\"\"Get the current weather for a city.\"\"\"\n    # In practice, call a weather API\n    return f\"The weather in {city} is sunny and 72F\"\n\n# Register the tool\nchat.register_tool(get_current_weather)\n\n# The model will call the function when needed\nchat.chat(\"What's the weather in Tucson?\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#structured-data-extraction_1","level":3,"title":"Structured Data Extraction","text":"<pre><code>from chatlas import ChatOpenAI\nfrom pydantic import BaseModel\n\n# Define structure with Pydantic\nclass PaperInfo(BaseModel):\n    title: str\n    authors: list[str]\n    year: int\n    journal: str\n\nchat = ChatOpenAI(model=\"gpt-4o-mini\")\n\n# Extract structured data\nresult = chat.extract_data(\n    \"Smith, J., &amp; Jones, M. (2024). Machine learning in ecology. \"\n    \"Nature Ecology &amp; Evolution, 8(3), 234-245.\",\n    data_model=PaperInfo\n)\n\nprint(result)\n# title='Machine learning in ecology' authors=['Smith, J.', 'Jones, M.']\n# year=2024 journal='Nature Ecology &amp; Evolution'\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#parallel-and-batch-processing","level":3,"title":"Parallel and Batch Processing","text":"<pre><code>from chatlas import ChatOpenAI, parallel_chat_text\n\nchat = ChatOpenAI(model=\"gpt-4o-mini\")\n\n# Process multiple prompts in parallel\nprompts = [\n    \"Summarize the scientific method\",\n    \"Explain photosynthesis\",\n    \"Describe natural selection\"\n]\n\nresults = parallel_chat_text(chat, prompts)\nfor prompt, result in zip(prompts, results):\n    print(f\"Q: {prompt}\\nA: {result}\\n\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#api-key-setup","level":2,"title":"API Key Setup","text":"<p>Both ellmer and chatlas require API keys for cloud providers. Here's how to set them up securely.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#setting-environment-variables","level":3,"title":"Setting Environment Variables","text":"<p>Security Best Practices</p> <ul> <li>Never commit API keys to version control (Git)</li> <li>Never hardcode keys in scripts</li> <li>Use environment variables or secure credential management</li> <li>Rotate keys periodically</li> </ul>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#method-1-renviron-file-recommended-for-r","level":4,"title":"Method 1: .Renviron File (Recommended for R)","text":"<p>Create or edit <code>~/.Renviron</code> in your home directory:</p> <pre><code># OpenAI\nOPENAI_API_KEY=sk-your-openai-key-here\n\n# Anthropic\nANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\n\n# Google\nGOOGLE_API_KEY=your-google-api-key-here\n\n# Mistral\nMISTRAL_API_KEY=your-mistral-key-here\n\n# Groq\nGROQ_API_KEY=your-groq-key-here\n</code></pre> <p>Restart R/RStudio after editing <code>.Renviron</code>.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#method-2-env-file-python","level":4,"title":"Method 2: .env File (Python)","text":"<p>Create a <code>.env</code> file in your project directory:</p> <pre><code>OPENAI_API_KEY=sk-your-openai-key-here\nANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\nGOOGLE_API_KEY=your-google-api-key-here\n</code></pre> <p>Load with <code>python-dotenv</code>:</p> <pre><code>from dotenv import load_dotenv\nload_dotenv()\n\nfrom chatlas import ChatOpenAI\nchat = ChatOpenAI()  # Automatically uses OPENAI_API_KEY\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#method-3-shell-configuration","level":4,"title":"Method 3: Shell Configuration","text":"<p>Add to <code>~/.bashrc</code>, <code>~/.zshrc</code>, or <code>~/.profile</code>:</p> <pre><code>export OPENAI_API_KEY=\"sk-your-openai-key-here\"\nexport ANTHROPIC_API_KEY=\"sk-ant-your-anthropic-key-here\"\n</code></pre> <p>Reload your shell: <code>source ~/.bashrc</code></p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#obtaining-api-keys","level":3,"title":"Obtaining API Keys","text":"Provider Where to Get Key Pricing OpenAI platform.openai.com/api-keys Pay-per-token Anthropic console.anthropic.com Pay-per-token Google aistudio.google.com Free tier + paid Mistral console.mistral.ai Pay-per-token Groq console.groq.com Free tier available","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#verifying-your-setup-r","level":3,"title":"Verifying Your Setup (R)","text":"<pre><code>library(ellmer)\n\n# Test OpenAI\ntryCatch({\n  chat &lt;- chat_openai(model = \"gpt-4o-mini\")\n  chat$chat(\"Say hello!\")\n  message(\"OpenAI API key is working!\")\n}, error = function(e) {\n  message(\"OpenAI API key issue: \", e$message)\n})\n\n# Test Anthropic\ntryCatch({\n  chat &lt;- chat_anthropic(model = \"claude-sonnet-4-5-20250514\")\n  chat$chat(\"Say hello!\")\n  message(\"Anthropic API key is working!\")\n}, error = function(e) {\n  message(\"Anthropic API key issue: \", e$message)\n})\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#verifying-your-setup-python","level":3,"title":"Verifying Your Setup (Python)","text":"<pre><code>from chatlas import ChatOpenAI, ChatAnthropic\n\n# Test OpenAI\ntry:\n    chat = ChatOpenAI(model=\"gpt-4o-mini\")\n    chat.chat(\"Say hello!\")\n    print(\"OpenAI API key is working!\")\nexcept Exception as e:\n    print(f\"OpenAI API key issue: {e}\")\n\n# Test Anthropic\ntry:\n    chat = ChatAnthropic(model=\"claude-sonnet-4-5-20250514\")\n    chat.chat(\"Say hello!\")\n    print(\"Anthropic API key is working!\")\nexcept Exception as e:\n    print(f\"Anthropic API key issue: {e}\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#ollama-integration-local-models","level":2,"title":"Ollama Integration (Local Models)","text":"<p>Both ellmer and chatlas support Ollama for running LLMs locally. This is ideal for:</p> <ul> <li>Privacy - Data never leaves your computer</li> <li>Cost - No API charges after initial setup</li> <li>Offline access - Work without internet</li> <li>Experimentation - Unlimited usage for testing</li> </ul>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#prerequisites","level":3,"title":"Prerequisites","text":"<ol> <li>Install Ollama following our Ollama guide</li> <li>Download a model:    <pre><code>ollama pull llama3.2\n</code></pre></li> <li>Verify Ollama is running:    <pre><code>curl http://localhost:11434/api/tags\n</code></pre></li> </ol>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#using-ollama-with-ellmer-r","level":3,"title":"Using Ollama with ellmer (R)","text":"<pre><code>library(ellmer)\n\n# List available Ollama models\nmodels_ollama()\n\n# Create a chat with a local model\nchat &lt;- chat_ollama(\n  model = \"llama3.2\",\n  system_prompt = \"You are a helpful research assistant.\"\n)\n\n# Chat with the local model\nchat$chat(\"Explain the difference between correlation and causation\")\n</code></pre> <p>Custom Ollama Server:</p> <pre><code># Connect to Ollama on a different host\nchat &lt;- chat_ollama(\n  model = \"llama3.2\",\n  base_url = \"http://192.168.1.100:11434\"  # Remote Ollama server\n)\n</code></pre> <p>Available Parameters:</p> <pre><code>chat &lt;- chat_ollama(\n  model = \"llama3.2\",\n  system_prompt = \"You are a statistics tutor.\",\n  params = params(\n    temperature = 0.7,  # Creativity (0-2)\n    num_ctx = 4096      # Context window size\n  )\n)\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#using-ollama-with-chatlas-python","level":3,"title":"Using Ollama with chatlas (Python)","text":"<pre><code>from chatlas import ChatOllama\n\n# Create a chat with a local model\nchat = ChatOllama(\n    model=\"llama3.2\",\n    system_prompt=\"You are a helpful research assistant.\"\n)\n\n# Chat with the local model\nchat.chat(\"What are the assumptions of linear regression?\")\n</code></pre> <p>Custom Configuration:</p> <pre><code>from chatlas import ChatOllama\n\nchat = ChatOllama(\n    model=\"llama3.2\",\n    base_url=\"http://localhost:11434\",  # Default\n    system_prompt=\"You are an expert statistician.\",\n    temperature=0.7,\n    num_ctx=4096\n)\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#complete-ollama-workflow-example-r","level":3,"title":"Complete Ollama Workflow Example (R)","text":"<pre><code>library(ellmer)\nlibrary(tidyverse)\n\n# 1. Create an Ollama chat for data analysis assistance\nanalyst &lt;- chat_ollama(\n  model = \"llama3.2\",\n  system_prompt = \"You are a data analysis expert. Provide R code examples\n                   using tidyverse packages. Be concise and practical.\"\n)\n\n# 2. Get help with data manipulation\nanalyst$chat(\"How do I group data by multiple columns and calculate\n              summary statistics in dplyr?\")\n\n# 3. The model provides code - let's use it\nmtcars %&gt;%\n  group_by(cyl, gear) %&gt;%\n  summarise(\n    mean_mpg = mean(mpg),\n    sd_mpg = sd(mpg),\n    n = n(),\n    .groups = \"drop\"\n  )\n\n# 4. Ask follow-up questions\nanalyst$chat(\"How can I visualize this with ggplot2?\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#complete-ollama-workflow-example-python","level":3,"title":"Complete Ollama Workflow Example (Python)","text":"<pre><code>from chatlas import ChatOllama\nimport pandas as pd\n\n# 1. Create an Ollama chat for data analysis\nanalyst = ChatOllama(\n    model=\"llama3.2\",\n    system_prompt=\"\"\"You are a data analysis expert. Provide Python code\n                     examples using pandas and matplotlib. Be concise.\"\"\"\n)\n\n# 2. Get help with data manipulation\nanalyst.chat(\"How do I group data by multiple columns and calculate \"\n             \"summary statistics in pandas?\")\n\n# 3. Apply the suggested code\nimport seaborn as sns\ndf = sns.load_dataset(\"tips\")\n\nsummary = df.groupby([\"day\", \"time\"]).agg({\n    \"total_bill\": [\"mean\", \"std\", \"count\"],\n    \"tip\": [\"mean\", \"std\"]\n}).round(2)\n\nprint(summary)\n\n# 4. Ask follow-up questions\nanalyst.chat(\"How can I create a grouped bar chart of this summary?\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#recommended-ollama-models-for-rpython-work","level":3,"title":"Recommended Ollama Models for R/Python Work","text":"Model Size Best For <code>llama3.2:3b</code> ~2GB Quick responses, basic coding <code>qwen2.5:7b</code> ~4.5GB Reasoning, data analysis <code>deepseek-coder:6.7b</code> ~4GB Code generation <code>deepseek-r1:8b</code> ~5GB Complex reasoning <code>codellama:13b</code> ~7GB Advanced coding <pre><code># Download recommended models\nollama pull llama3.2:3b\nollama pull qwen2.5:7b\nollama pull deepseek-coder:6.7b\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#practical-examples","level":2,"title":"Practical Examples","text":"","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#example-1-literature-review-assistant-r","level":3,"title":"Example 1: Literature Review Assistant (R)","text":"<pre><code>library(ellmer)\nlibrary(tidyverse)\n\n# Create a specialized assistant\nlit_review &lt;- chat_ollama(\n  model = \"qwen2.5:7b\",\n  system_prompt = \"You are an academic research assistant specializing in\n                   literature reviews. Help researchers:\n                   1. Identify key themes in abstracts\n                   2. Suggest search terms\n                   3. Evaluate methodology descriptions\n                   Be scholarly but accessible.\"\n)\n\n# Analyze an abstract\nabstract &lt;- \"This study examines the impact of social media use on\nadolescent mental health using a longitudinal design with 5,000 participants\nover 3 years. We found significant associations between daily social media\ntime and symptoms of anxiety and depression, with effect sizes varying by\nplatform type and usage patterns.\"\n\nlit_review$chat(paste(\"Analyze this abstract and identify:\",\n                      \"1. Research question\",\n                      \"2. Methodology strengths\",\n                      \"3. Potential limitations\",\n                      \"4. Related search terms for similar studies\",\n                      \"\\n\\nAbstract:\", abstract))\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#example-2-statistical-analysis-helper-r","level":3,"title":"Example 2: Statistical Analysis Helper (R)","text":"<pre><code>library(ellmer)\n\n# Create a statistics tutor\nstats_help &lt;- chat_ollama(\n  model = \"llama3.2\",\n  system_prompt = \"You are a patient statistics tutor for graduate students.\n                   When explaining:\n                   1. Start with intuition before formulas\n                   2. Use concrete examples\n                   3. Show R code for implementation\n                   4. Explain when methods are appropriate\"\n)\n\n# Get help choosing a statistical test\nstats_help$chat(\"I have a dataset with one continuous outcome variable and\n                 two categorical predictors (treatment group with 3 levels,\n                 and gender with 2 levels). I want to understand if there's\n                 an interaction effect. What test should I use and why?\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#example-3-code-documentation-generator-r","level":3,"title":"Example 3: Code Documentation Generator (R)","text":"<pre><code>library(ellmer)\n\n# Create a documentation assistant\ndoc_helper &lt;- chat_openai(\n  model = \"gpt-4o-mini\",\n  system_prompt = \"You are an R documentation expert. When given R code,\n                   generate roxygen2-style documentation including:\n                   @title, @description, @param, @return, @examples\"\n)\n\n# Generate documentation for a function\nmy_function &lt;- \"\ncalculate_effect_size &lt;- function(group1, group2, pooled_sd = TRUE) {\n  n1 &lt;- length(group1)\n  n2 &lt;- length(group2)\n  m1 &lt;- mean(group1)\n  m2 &lt;- mean(group2)\n\n  if (pooled_sd) {\n    s &lt;- sqrt(((n1-1)*var(group1) + (n2-1)*var(group2)) / (n1+n2-2))\n  } else {\n    s &lt;- sd(c(group1, group2))\n  }\n\n  d &lt;- (m1 - m2) / s\n  return(list(cohens_d = d, n1 = n1, n2 = n2))\n}\n\"\n\ndoc_helper$chat(paste(\"Generate roxygen2 documentation for this R function:\\n\",\n                      my_function))\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#example-4-data-analysis-pipeline-python","level":3,"title":"Example 4: Data Analysis Pipeline (Python)","text":"<pre><code>from chatlas import ChatOllama\nimport pandas as pd\nimport numpy as np\n\n# Create an analysis assistant\nanalyst = ChatOllama(\n    model=\"llama3.2\",\n    system_prompt=\"\"\"You are a data science assistant. When helping with\n                     analysis:\n                     1. Explain your reasoning\n                     2. Provide complete, runnable Python code\n                     3. Suggest visualizations when appropriate\n                     4. Note potential issues or assumptions\"\"\"\n)\n\n# Load some data\nnp.random.seed(42)\ndf = pd.DataFrame({\n    \"treatment\": np.random.choice([\"A\", \"B\", \"C\"], 100),\n    \"age\": np.random.normal(45, 10, 100),\n    \"outcome\": np.random.normal(50, 15, 100) +\n               np.where(np.random.choice([\"A\", \"B\", \"C\"], 100) == \"A\", 10, 0)\n})\n\n# Get analysis suggestions\nanalyst.chat(f\"\"\"I have a dataset with these characteristics:\n{df.describe().to_string()}\n\nColumns: treatment (A/B/C), age (continuous), outcome (continuous)\n\nWhat analysis would you recommend to understand the relationship\nbetween treatment and outcome while controlling for age?\"\"\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#example-5-quarto-document-with-ai-r-markdownquarto","level":3,"title":"Example 5: Quarto Document with AI (R Markdown/Quarto)","text":"<p>Create a Quarto document that uses ellmer for AI-assisted analysis:</p> <pre><code>---\ntitle: \"AI-Assisted Data Analysis\"\nformat: html\n---\n\n```{r setup, include=FALSE}\nlibrary(ellmer)\nlibrary(tidyverse)\n\n# Use a local model for reproducibility\nchat &lt;- chat_ollama(model = \"llama3.2\")\n```\n\n## Data Overview\n\n```{r}\n# Load and summarize data\ndata(mtcars)\nsummary(mtcars)\n```\n\n## AI-Generated Analysis Suggestions\n\n```{r}\n# Ask the AI for analysis suggestions\nresponse &lt;- chat$chat(\n  paste(\"Given a dataset about cars with variables:\",\n        paste(names(mtcars), collapse = \", \"),\n        \"suggest three interesting analyses and visualizations.\"),\n  echo = FALSE\n)\n```\n\nThe AI suggests the following analyses:\n\n`r response`\n\n## Implementing the Suggestions\n\n```{r}\n# Create a visualization based on AI suggestion\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"MPG vs Weight by Cylinder Count\",\n       x = \"Weight (1000 lbs)\",\n       y = \"Miles per Gallon\",\n       color = \"Cylinders\") +\n  theme_minimal()\n```\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#other-r-packages-for-ai-integration","level":2,"title":"Other R Packages for AI Integration","text":"<p>Beyond ellmer and chatlas, several other R packages provide AI capabilities:</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#tidyllm","level":3,"title":"tidyllm","text":"<p>tidyllm - Tidy interface for LLMs with piped workflows:</p> <pre><code># install.packages(\"tidyllm\")\nlibrary(tidyllm)\n\nllm_message(\"Explain linear regression\") |&gt;\n  openai_chat(model = \"gpt-4o-mini\") |&gt;\n  get_reply()\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#gptstudio","level":3,"title":"gptstudio","text":"<p>gptstudio - RStudio addins for AI assistance:</p> <pre><code># install.packages(\"gptstudio\")\nlibrary(gptstudio)\n\n# Provides RStudio addins for:\n# - Code explanation\n# - Documentation writing\n# - Code commenting\n# - Spelling/grammar checking\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#chattr","level":3,"title":"chattr","text":"<p>chattr - Chat interface in RStudio:</p> <pre><code># install.packages(\"chattr\")\nlibrary(chattr)\n\n# Opens an interactive chat pane in RStudio\nchattr_app()\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#ollamar","level":3,"title":"ollamar","text":"<p>ollamar - Direct Ollama API access:</p> <pre><code># install.packages(\"ollamar\")\nlibrary(ollamar)\n\n# Low-level Ollama API access\nlist_models()\ngenerate(\"llama3.2\", \"Hello!\")\n</code></pre>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#troubleshooting","level":2,"title":"Troubleshooting","text":"API Key Not Found <p>Symptoms: Error messages like \"API key not set\" or \"authentication failed\"</p> <p>Solutions:</p> <ol> <li> <p>Verify the key is set correctly:    <pre><code># R\nSys.getenv(\"OPENAI_API_KEY\")\n</code></pre> <pre><code># Python\nimport os\nprint(os.getenv(\"OPENAI_API_KEY\"))\n</code></pre></p> </li> <li> <p>Check <code>.Renviron</code> has no spaces around <code>=</code></p> </li> <li> <p>Restart R/RStudio after editing <code>.Renviron</code></p> </li> <li> <p>Ensure the key is valid at the provider's console</p> </li> </ol> Ollama Connection Refused <p>Symptoms: \"Connection refused\" or \"Could not connect to Ollama\"</p> <p>Solutions:</p> <ol> <li> <p>Verify Ollama is running:    <pre><code>curl http://localhost:11434/api/tags\n</code></pre></p> </li> <li> <p>Start Ollama if needed:    <pre><code>ollama serve\n</code></pre></p> </li> <li> <p>Check if using the correct base_url:    <pre><code>chat &lt;- chat_ollama(model = \"llama3.2\",\n                   base_url = \"http://localhost:11434\")\n</code></pre></p> </li> </ol> Model Not Found <p>Symptoms: \"Model not found\" errors</p> <p>Solutions:</p> <ol> <li> <p>For Ollama, download the model first:    <pre><code>ollama pull llama3.2\n</code></pre></p> </li> <li> <p>List available models:    <pre><code># ellmer\nmodels_ollama()\n</code></pre></p> </li> <li> <p>Check exact model name spelling</p> </li> </ol> Out of Memory <p>Symptoms: R/Python crashes or \"out of memory\" errors</p> <p>Solutions:</p> <ol> <li> <p>Use a smaller model:    <pre><code>chat &lt;- chat_ollama(model = \"llama3.2:1b\")  # 1B instead of 3B\n</code></pre></p> </li> <li> <p>Reduce context window:    <pre><code>chat &lt;- chat_ollama(model = \"llama3.2\",\n                   params = params(num_ctx = 2048))\n</code></pre></p> </li> <li> <p>Close other applications to free memory</p> </li> </ol>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"posit/#further-resources","level":2,"title":"Further Resources","text":"<p>Posit Resources:</p> <ul> <li>Posit Website</li> <li>Positron Downloads</li> <li>RStudio Downloads</li> </ul> <p>Package Documentation:</p> <ul> <li>ellmer Documentation</li> <li>chatlas Documentation</li> </ul> <p>Related Workshop Materials:</p> <ul> <li>Ollama - Running local LLMs</li> <li>Hugging Face - Model hub and downloads</li> <li>Jupyter AI - AI in Jupyter notebooks</li> <li>RAG - Retrieval-augmented generation</li> <li>Vibe Coding - AI-assisted coding IDEs</li> </ul> <p>Community:</p> <ul> <li>Posit Community Forums</li> <li>RStudio GitHub</li> <li>Positron GitHub</li> </ul> <p>Getting Started Recommendation</p> <p>If you're new to using LLMs with R or Python:</p> <ol> <li>Install Positron for the best integrated experience</li> <li>Start with Ollama to avoid API costs while learning</li> <li>Install ellmer (R) or chatlas (Python) depending on your language</li> <li>Download a small model: <code>ollama pull llama3.2:3b</code></li> <li>Try the basic examples in this guide</li> <li>Graduate to cloud APIs (OpenAI, Anthropic) when you need more capability</li> </ol> <p>For sensitive research data, Ollama provides complete privacy since all processing happens locally on your machine.</p>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"prompts/","level":1,"title":"Prompt Engineering","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p></p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#introduction-to-prompt-engineering","level":2,"title":"Introduction to Prompt Engineering","text":"<p>Prompt Engineering is a technique of crafting effective instructions using AI large language models. With modern AI-powered tools like Claude Desktop, ChatGPT, Gemini, and NotebookLM offering capabilities to upload documents, search the web, and process multiple file types, mastering prompt engineering has become essential for productive AI interactions.</p> <p>What You'll Learn</p> <ul> <li>Fundamentals: How AI models process and respond to prompts</li> <li>Modern Features: Leveraging document uploads, web search, and multi-modal inputs</li> <li>Best Practices: Structured approaches to writing effective prompts</li> <li>Advanced Techniques: Context management, chaining, and custom instructions</li> </ul>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#understanding-modern-ai-capabilities","level":2,"title":"Understanding Modern AI Capabilities","text":"","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#core-features-of-todays-ai-tools","level":3,"title":"Core Features of Today's AI Tools","text":"<p>Modern AI assistants have evolved beyond simple text chat:</p> Feature  Claude  ChatGPT  Gemini NotebookLM  CoPilot Document Upload PDFs, text, code PDFs, images, data PDFs, images, GDrive PDFs, Google Docs PDFs, OneDrive Web Search Via MCP Yes Yes Yes Yes Context Window (tokens) 200K 128K 2M Document-based 128K File Analysis Yes Yes Yes Deep analysis Yes Code Execution Yes (MCP) Yes Yes No Yes","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#how-ai-models-process-your-input","level":3,"title":"How AI Models Process Your Input","text":"<p>The Processing Pipeline</p> <ol> <li>Tokenization: Your prompt is broken into smaller units (tokens)</li> <li>Context Assembly: Uploaded documents and conversation history are included</li> <li>Attention Mechanism: The model identifies relevant information</li> <li>Generation: Response is produced token by token</li> <li>Formatting: Output is structured according to your specifications</li> </ol>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#getting-started-basic-prompt-structure","level":2,"title":"Getting Started: Basic Prompt Structure","text":"","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#the-foundation-clear-instructions","level":3,"title":"The Foundation: Clear Instructions","text":"<p>Start with simple, direct prompts before advancing to complex techniques:</p> <pre><code># Basic Prompt\n\"Summarize this research paper in 3 bullet points\"\n</code></pre> <pre><code># Better Prompt\n\"As a research scientist, summarize the key findings from this paper \nin 3 bullet points, focusing on methodology and results\"\n</code></pre> <pre><code># Best Prompt\n\"You are a research scientist reviewing papers for a journal. \nSummarize the attached PDF in 3 bullet points that cover:\n1. Research question and hypothesis\n2. Methodology and sample size\n3. Key findings and limitations\nFormat as a bullet list with sub-points for clarity.\"\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#working-with-documents","level":3,"title":"Working with Documents","text":"<p>Modern AI tools excel at document analysis. Here's how to maximize their potential:</p> <p>Document Upload Best Practices</p> <ul> <li>Specify the document: \"In the attached PDF...\" or \"Based on the uploaded spreadsheet...\"</li> <li>Direct attention: \"Focus on Section 3.2 of the document\"</li> <li>Request specific outputs: \"Create a table comparing the methods described in chapters 2 and 5\"</li> <li>Combine multiple sources: \"Compare the findings in these three papers\"</li> </ul>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#example-multi-document-analysis","level":4,"title":"Example: Multi-Document Analysis","text":"<pre><code>I've uploaded three research papers on climate change. Please:\n\n1. Create a comparison table with columns for:\n   - Paper title and authors\n   - Methodology\n   - Key findings\n   - Limitations\n\n2. Identify common themes across all papers\n\n3. Highlight any contradictory findings\n\nFormat the response with clear headers and use markdown tables.\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#the-craft-framework","level":2,"title":"The CRAFT Framework","text":"<p>For consistent, high-quality results, use the CRAFT framework:</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#context","level":3,"title":"Context","text":"<p>Provide background information and set the scene</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#role","level":3,"title":"Role","text":"<p>Define who the AI should act as</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#action","level":3,"title":"Action","text":"<p>Specify exactly what you want done</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#format","level":3,"title":"Format","text":"<p>Describe how the output should be structured</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#tone","level":3,"title":"Tone","text":"<p>Indicate the style and voice to use</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#craft-example","level":4,"title":"CRAFT Example","text":"<pre><code>Context: I'm preparing a grant proposal for NSF funding on AI in education\n\nRole: Act as an experienced grant writer and education researcher\n\nAction: Review my draft introduction and suggest improvements\n\nFormat: Provide feedback as tracked changes with explanations\n\nTone: Professional, constructive, and encouraging\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#advanced-techniques","level":2,"title":"Advanced Techniques","text":"","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#1-custom-instructions-and-system-prompts","level":3,"title":"1. Custom Instructions and System Prompts","text":"<p>Modern AI platforms allow you to set persistent instructions:</p> <p>'Custom Instructions' or 'System Instructions'</p> <p>Platforms like Gemini and Claude allow you to add \"Custom Instructions\" or \"System Instructions\" as prior prompts, which act as a global rule to subsequent prompt chaining.</p> <p>For example:</p> <pre><code># Project Context\nI'm a data scientist working on machine learning projects.\nAlways provide Python code examples using scikit-learn and pandas.\nInclude docstrings and type hints in all code.\n\n# Response Preferences\n- Be concise but thorough\n- Explain complex concepts with analogies\n- Always cite sources when making factual claims\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#2-leveraging-web-search","level":3,"title":"2. Leveraging Web Search","text":"<p>Most featured GPTs now feature a web browse or search engine capability.</p> <p>Enabling search allows the GPT to use document retrieval on websites and PDFs when reasoning out its response.</p> <pre><code>Search for the latest research on the public health benefits of vaccination published in 2024. \n\nFocus on:\n- Papers from top conferences (AHA, ASPPH, NRHA, ICFMDP)\n- mRNA\n- Bird Flu and COVID\n\nSummarize the top 5 papers with links to the originals.\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#3-multi-modal-prompting","level":3,"title":"3. Multi-Modal Prompting","text":"<p>Combine different input types for richer interactions:</p> <pre><code>I've uploaded:\n1. A screenshot of my dashboard\n2. The underlying data in CSV format\n3. Our brand guidelines PDF\n\nCreate a redesigned dashboard that:\n- Improves data visualization based on best practices\n- Adheres to our brand colors and fonts\n- Highlights the KPIs mentioned in the data dictionary\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#4-prompt-chaining","level":3,"title":"4. Prompt Chaining","text":"<p>Build complex outputs through sequential prompts:</p> <p>Effective Chaining Strategy</p> <ol> <li>Start broad: \"Outline a research paper on sustainable AI\"</li> <li>Zoom in: \"Expand section 3 on energy-efficient training methods\"</li> <li>Refine: \"Add citations and make the tone more academic\"</li> <li>Polish: \"Format according to IEEE standards\"</li> </ol>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#5-using-examples-few-shot-learning","level":3,"title":"5. Using Examples (Few-Shot Learning)","text":"<p>Provide examples to guide the AI's output:</p> <pre><code>I need to classify customer feedback. Here are examples:\n\n\"The product arrived damaged\" → Category: Shipping Issue\n\"Can't log into my account\" → Category: Technical Support\n\"Love the new features!\" → Category: Positive Feedback\n\nNow classify these:\n1. \"The app keeps crashing on startup\"\n2. \"Best purchase I've made this year\"\n3. \"Package was left in the rain\"\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#practical-applications","level":2,"title":"Practical Applications","text":"","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#research-and-analysis","level":3,"title":"Research and Analysis","text":"<pre><code>Analyze the attached dataset (CSV) and:\n1. Identify statistical patterns and outliers\n2. Create visualizations for the top 3 insights\n3. Write a methods section describing the analysis\n4. Suggest additional analyses based on the data\n\nUse pandas profiling techniques and create matplotlib visualizations.\nInclude code that I can run locally.\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#writing-and-editing","level":3,"title":"Writing and Editing","text":"<pre><code>I've uploaded my draft manuscript. Please:\n\n1. Check for consistency in terminology throughout\n2. Ensure all figures are referenced in the text\n3. Verify the citation format matches APA 7th edition\n4. Highlight any unclear passages\n5. Suggest improvements for flow between sections\n\nProvide a tracked-changes version and a summary of major edits.\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#code-development","level":3,"title":"Code Development","text":"<pre><code>Based on the uploaded requirements document:\n\n1. Create a Python class structure for the described system\n2. Include comprehensive docstrings and type hints\n3. Add unit tests for each method\n4. Create a README with installation and usage instructions\n5. Follow PEP 8 style guidelines\n\nUse modern Python features (3.10+) and include error handling.\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#common-pitfalls-and-solutions","level":2,"title":"Common Pitfalls and Solutions","text":"","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#pitfall-1-vague-instructions","level":3,"title":"Pitfall 1: Vague Instructions","text":"<p>❌ Poor: \"Make this better\"</p> <p>✅ Better: \"Improve this abstract by making it more concise (under 250 words), adding keywords, and ensuring it follows the journal's structure: background, methods, results, conclusions\"</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#pitfall-2-information-overload","level":3,"title":"Pitfall 2: Information Overload","text":"<p>❌ Poor: Uploading 50 documents without guidance</p> <p>✅ Better: \"Focus on documents 1-3 which contain the methodology. Ignore the appendices.\"</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#pitfall-3-assuming-knowledge","level":3,"title":"Pitfall 3: Assuming Knowledge","text":"<p>❌ Poor: \"Fix the usual issues\"</p> <p>✅ Better: \"Check for: passive voice, sentences over 25 words, undefined acronyms, and missing Oxford commas\"</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#pitfall-4-no-output-format","level":3,"title":"Pitfall 4: No Output Format","text":"<p>❌ Poor: \"Summarize this\"</p> <p>✅ Better: \"Create an executive summary with:  - 3-sentence overview - 5 key points as bullets - 1 paragraph on implications - Formatted with markdown headers\"</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#quick-reference-card","level":2,"title":"Quick Reference Card","text":"<p>Prompt Engineering Checklist</p> <ul> <li> Clear objective: What do you want to achieve?</li> <li> Context provided: Background information included?</li> <li> Role defined: Who should the AI act as?</li> <li> Specific action: Exact task described?</li> <li> Output format: Structure specified?</li> <li> Examples given: For complex tasks?</li> <li> Constraints noted: Length, style, or content limits?</li> <li> Documents referenced: If using uploads?</li> <li> Follow-up planned: For iterative improvement?</li> </ul>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#assessment-questions","level":2,"title":"Assessment Questions","text":"How do modern AI tools handle uploaded documents? <p>Answer</p> <p>Modern AI tools process uploaded documents by:</p> <ul> <li> <p>Converting them to text (OCR for images/PDFs)</p> </li> <li> <p>Adding them to the context window</p> </li> <li> <p>Allowing specific references (\"In section 2.3...\")</p> </li> <li> <p>Enabling cross-document analysis</p> </li> <li> <p>Maintaining document structure awareness</p> </li> </ul> What's the most important element of an effective prompt? <p>Answer</p> <p>Clarity of instruction is paramount. The AI needs to understand:</p> <ul> <li> <p>What you want done (action)</p> </li> <li> <p>How you want it done (format)</p> </li> <li> <p>Why you want it done (context)</p> </li> </ul> <p>Without clear instructions, even the most advanced AI will produce suboptimal results.</p> How can you ensure consistent outputs across multiple sessions? <p>Answer</p> <ol> <li> <p>Use custom instructions (ChatGPT, Claude) or system prompts</p> </li> <li> <p>Create templates for common tasks</p> </li> <li> <p>Save successful prompts for reuse</p> </li> <li> <p>Use platform features like GPTs or Projects</p> </li> <li> <p>Include examples in your prompts</p> </li> <li> <p>Specify exact formats with templates</p> </li> </ol> True or False: Longer prompts always produce better results <p>False</p> <p>Prompt quality matters more than length. A well-structured, concise prompt often outperforms a lengthy, unfocused one. However, providing sufficient context and clear instructions is important. Aim for:</p> <ul> <li> <p>Completeness over brevity</p> </li> <li> <p>Clarity over complexity</p> </li> <li> <p>Structure over stream-of-consciousness</p> </li> </ul>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#further-resources","level":2,"title":"Further Resources","text":"<ul> <li> <p> Anthropic's Prompt Engineering Guide</p> </li> <li> <p> OpenAI's Best Practices</p> </li> <li> <p> Google's Gemini Prompting Strategies</p> </li> <li> <p> Awesome ChatGPT Prompts</p> </li> <li> <p>Learn Prompting Online Courses</p> </li> </ul>","path":["Prompt Engineering"],"tags":[]},{"location":"rag/","level":1,"title":"Retrieval Augmented Generation (RAG)","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#what-is-rag","level":2,"title":"What is RAG?","text":"<p>Retrieval-Augmented Generation (RAG) is a technique that enhances AI language models by giving them access to external knowledge sources. Instead of relying solely on what a model learned during training, RAG allows AI to retrieve relevant information from your own documents, databases, or knowledge bases and use that information to generate more accurate, up-to-date, and contextually relevant responses.</p> <p>Why RAG Matters</p> <p>Large language models (LLMs) have a knowledge cutoff date and can sometimes generate plausible-sounding but incorrect information (\"hallucinations\"). RAG addresses these limitations by:</p> <ul> <li>Grounding responses in your actual documents and data</li> <li>Providing citations so you can verify information</li> <li>Keeping knowledge current without retraining the model</li> <li>Maintaining privacy by keeping sensitive data in your own systems</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#rag-vs-traditional-ai-chat","level":3,"title":"RAG vs. Traditional AI Chat","text":"Aspect Traditional LLM RAG-Enhanced LLM Knowledge source Training data only (static) Training data + your documents (dynamic) Currency Limited to training cutoff Can access current information Accuracy May hallucinate facts Grounded in retrieved sources Citations Usually none Can cite specific sources Customization Generic responses Tailored to your domain Privacy Data may be used for training Your data stays private","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#real-world-examples-of-rag","level":3,"title":"Real-World Examples of RAG","text":"<p>You may already be using RAG without realizing it:</p> <ul> <li>NotebookLM: Google's research tool uses RAG to answer questions based only on your uploaded sources</li> <li>ChatGPT with file uploads: When you upload PDFs, ChatGPT retrieves relevant sections to answer your questions</li> <li>Claude Projects: Custom knowledge bases that Claude references during conversations</li> <li>OpenWebUI: Self-hosted interface with Knowledge collections for local, private RAG</li> <li>Enterprise search tools: Company wikis and knowledge bases that use AI to find and synthesize information</li> <li>Legal research platforms: AI tools that search case law and statutes to answer legal questions</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#how-rag-works","level":2,"title":"How RAG Works","text":"<p>RAG operates through a pipeline that connects your documents to the AI model. Understanding this pipeline helps you use RAG tools more effectively and troubleshoot when responses aren't what you expect.</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#the-rag-pipeline","level":3,"title":"The RAG Pipeline","text":"<pre><code>flowchart LR\n    A[Your Documents] --&gt; B[Chunking]\n    B --&gt; C[Embedding]\n    C --&gt; D[(Vector Database)]\n    E[User Query] --&gt; F[Query Embedding]\n    F --&gt; G[Similarity Search]\n    D --&gt; G\n    G --&gt; H[Retrieved Context]\n    H --&gt; I[LLM Generation]\n    E --&gt; I\n    I --&gt; J[Response with Citations]\n\n    style A fill:#e1f5ff\n    style D fill:#fff3e0\n    style J fill:#c8e6c9</code></pre> <p>Step-by-step explanation:</p> <ol> <li>Document Ingestion: Your documents (PDFs, web pages, databases) are loaded into the system</li> <li>Chunking: Documents are split into smaller, manageable pieces (chunks)</li> <li>Embedding: Each chunk is converted into a numerical representation (vector) that captures its meaning</li> <li>Storage: Vectors are stored in a specialized database optimized for similarity search</li> <li>Query Processing: When you ask a question, your query is also converted to a vector</li> <li>Retrieval: The system finds chunks whose vectors are most similar to your query</li> <li>Generation: The LLM generates a response using both your question and the retrieved context</li> <li>Citation: The response includes references to the source documents</li> </ol>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#embeddings","level":3,"title":"Embeddings","text":"<p>Text passages (or other data, like images) are transformed into numerical representations known as \"embeddings.\" These embeddings capture semantic meaning, so similar concepts end up being close together in vector space.</p> Understanding Embeddings <p>What are Embeddings? - Vicki Boykis - download PDF </p> <p>Embeddings are a way to represent data (words, images, etc.) as numerical vectors in a multi-dimensional space. These vectors capture semantic relationships between data points, meaning similar items are located closer together in the embedding space.</p> <p>Embedded space for geospatial applications:</p> <p><p>Visualizing how embeddings can organize satellite imagery. Millions of points covering the state of Alabama move between their geographic position and their location in the embedding space. pic.twitter.com/Z6FtoMQ84B</p>— Caleb Kruse (@clkruse) May 15, 2023 </p> <p>Embedded space for natural language:</p> <p>Credit: Stephen Wolfram</p> <p></p> <p>Why are Embeddings Important?</p> <ul> <li>Semantic Search: Embeddings enable semantic search, where you can find information based on meaning rather than just keyword matching. \"Car\" and \"automobile\" will be close together even though they share no letters.</li> <li>Machine Learning: Embeddings are essential for training machine learning models, as they provide a way to represent complex data in a format that algorithms can understand.</li> <li>Recommendation Systems: Embeddings help power recommendation systems by identifying items with similar characteristics.</li> <li>Data Visualization: Embeddings can be used to visualize relationships between data points in a lower-dimensional space.</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#vector-databases","level":3,"title":"Vector Databases","text":"<p>A vector database stores embeddings efficiently, using specialized data structures to handle large-scale, high-dimensional searches. Unlike traditional databases that match exact values, vector databases find the most semantically similar items to your query.</p> <p>Table: Popular RAG Vector Database Software</p> Platform Type Best For Documentation Pinecone Managed (Serverless) Production RAG apps with minimal DevOps; teams wanting fully managed infrastructure Pinecone Docs Weaviate Open Source / Managed Hybrid search (vector + keyword); multimodal data (text, images) Weaviate Docs Qdrant Open Source / Managed Cost-sensitive workloads; edge deployments; powerful filtering Qdrant Docs Milvus / Zilliz Open Source / Managed Billion-scale vector search; enterprise teams with data engineering resources Milvus Docs Chroma Open Source Prototyping and development; small to medium applications; easy local setup Chroma Docs Choosing a Vector Database <ul> <li>Pinecone: Best if you want a fully managed, serverless solution with minimal operational overhead. Query times often under 50ms.</li> <li>Weaviate: Ideal for hybrid search combining vector similarity with keyword matching and metadata filtering in a single query.</li> <li>Qdrant: Great balance of performance and cost; compact footprint makes it suitable for resource-constrained environments.</li> <li>Milvus/Zilliz: Choose when you need industrial-scale deployments with billions of vectors and have infrastructure expertise.</li> <li>Chroma: Perfect for getting started quickly, prototyping RAG applications, and learning vector database concepts.</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#using-rag-without-code","level":2,"title":"Using RAG Without Code","text":"<p>You do not need to be a programmer to benefit from RAG. Several platforms provide RAG capabilities through user-friendly interfaces.</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#consumer-friendly-rag-tools","level":3,"title":"Consumer-Friendly RAG Tools","text":"Tool How to Access RAG Best For NotebookLM Upload sources to a notebook Research, literature reviews, studying ChatGPT Plus Upload files or enable \"Browse\" General document Q&amp;A Claude Pro Create a Project with files Long-form document analysis Gemini Advanced Upload files or connect Google Drive Google Workspace integration Microsoft Copilot Access via Microsoft 365 Enterprise documents OpenWebUI Create Knowledge collections or upload files Privacy-sensitive data, local/offline use <p>Try It: RAG with NotebookLM</p> <ol> <li>Go to NotebookLM</li> <li>Create a new notebook</li> <li>Upload 2-3 research papers on a topic you are studying</li> <li>Ask questions like:<ul> <li>\"What are the main findings across these papers?\"</li> <li>\"Where do these authors disagree?\"</li> <li>\"Summarize the methodology used in each study\"</li> </ul> </li> <li>Notice how responses include citations to specific sources</li> </ol>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#rag-with-openwebui","level":3,"title":"RAG with OpenWebUI","text":"<p>OpenWebUI is an open-source, self-hosted web interface for running AI models locally. It provides built-in RAG capabilities that allow you to chat with your own documents while keeping all data on your own computer or server---ideal for sensitive research data or when you want complete control over your AI infrastructure.</p> What is OpenWebUI? <p>OpenWebUI is a user-friendly web interface that works with local language models (via Ollama) and cloud APIs (OpenAI, Anthropic, etc.). Key features include:</p> <ul> <li>Privacy-first: All processing happens locally; your documents never leave your machine</li> <li>Model flexibility: Use any Ollama model (Llama, Mistral, Phi, etc.) or connect to cloud APIs</li> <li>No subscription fees: Free and open-source (though you need hardware to run local models)</li> <li>Institutional deployment: Many universities run OpenWebUI instances for researchers</li> </ul> <p>If your institution provides an OpenWebUI instance, you may already have access. Check with your IT department or research computing group.</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#how-rag-works-in-openwebui","level":4,"title":"How RAG Works in OpenWebUI","text":"<p>OpenWebUI offers two complementary ways to use RAG:</p> <ol> <li>Quick Document Chat: Upload files directly in a conversation using the <code>+</code> button or drag-and-drop</li> <li>Knowledge Collections: Create reusable document libraries that persist across conversations</li> </ol> <pre><code>flowchart LR\n    A[Your Documents] --&gt; B{Upload Method}\n    B --&gt;|Single Chat| C[Direct Upload]\n    B --&gt;|Persistent| D[Knowledge Collection]\n    C --&gt; E[# Reference in Chat]\n    D --&gt; E\n    E --&gt; F[RAG-Enhanced Response]\n\n    style A fill:#e1f5ff\n    style D fill:#fff3e0\n    style F fill:#c8e6c9</code></pre>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#step-by-step-creating-a-knowledge-collection","level":4,"title":"Step-by-Step: Creating a Knowledge Collection","text":"<p>Knowledge collections are the recommended approach for documents you will reference repeatedly, such as course materials, research literature, or project documentation.</p> <p>Step 1: Access the Knowledge Section</p> <ol> <li>Log into your OpenWebUI instance</li> <li>Navigate to Workspace in the left sidebar</li> <li>Select Knowledge</li> </ol> <p>Step 2: Create a New Knowledge Base</p> <ol> <li>Click + Create Knowledge (or the <code>+</code> button)</li> <li>Configure your knowledge base:<ul> <li>Name: Give it a descriptive name (e.g., \"Climate Policy Papers 2024\")</li> <li>Description: Briefly describe the contents</li> <li>Access: Choose Private for personal use or Public to share with others on your instance</li> </ul> </li> <li>Click Create</li> </ol> <p>Step 3: Add Documents</p> <ol> <li>Open your newly created knowledge base</li> <li>Add documents by:<ul> <li>Drag and drop files directly into the window</li> <li>Click Add Content and select files from your computer</li> <li>Paste a URL to import web content</li> </ul> </li> <li>Supported formats include: PDF, TXT, Markdown, DOCX, CSV, and more</li> <li>Wait for processing to complete (you will see a progress indicator)</li> </ol> <p>Step 4: Use Your Knowledge in Conversations</p> <ol> <li>Start a new chat</li> <li>Type <code>#</code> to see available knowledge collections</li> <li>Select your knowledge base from the dropdown</li> <li>Ask questions---OpenWebUI will retrieve relevant context from your documents</li> </ol> <p>Try It: Chat with Research Papers</p> <ol> <li>Create a knowledge collection called \"Literature Review\"</li> <li>Upload 3-5 PDF papers related to your research</li> <li>In a new chat, type <code>#</code> and select your \"Literature Review\" collection</li> <li>Try these queries:<ul> <li>\"What methodologies are used across these papers?\"</li> <li>\"Summarize the key findings from each study\"</li> <li>\"What gaps in the literature do these authors identify?\"</li> </ul> </li> <li>Notice how responses include citations showing which document provided each piece of information</li> </ol>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#quick-document-upload-per-conversation","level":4,"title":"Quick Document Upload (Per-Conversation)","text":"<p>For one-time document queries, you can upload files directly into a conversation:</p> <ol> <li>Click the + button in the chat input area</li> <li>Select Upload Files (or drag files directly into the chat)</li> <li>Choose your document(s)</li> <li>Once processed, reference them with <code>#</code> followed by the filename</li> <li>Ask your questions</li> </ol> <p>Quick Upload vs. Knowledge Collections</p> Use Case Recommended Method One-time document analysis Quick upload in chat Recurring reference materials Knowledge collection Course readings for a semester Knowledge collection Reviewing a paper before a meeting Quick upload in chat Lab protocols and documentation Knowledge collection","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#web-content-in-rag","level":4,"title":"Web Content in RAG","text":"<p>OpenWebUI can also retrieve content from web pages:</p> <ol> <li>In the chat input, type <code>#</code> followed by a URL</li> <li>Example: <code>#https://www.nature.com/articles/s41586-024-00001-1</code></li> <li>OpenWebUI will fetch, parse, and index the page content</li> </ol> <p>Web Retrieval Tips</p> <ul> <li>Link to reader-friendly or raw text versions when available (web pages often contain navigation menus, footers, and ads that add noise)</li> <li>Some sites block automated fetching---if retrieval fails, download the content and upload it instead</li> <li>For academic papers, downloading the PDF typically yields better results than fetching the publisher's web page</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#openwebui-rag-best-practices","level":4,"title":"OpenWebUI RAG Best Practices","text":"<p>Document Preparation</p> <ul> <li>Use text-based PDFs whenever possible (not scanned images)</li> <li>Descriptive filenames help you identify documents when using <code>#</code> references</li> <li>For long documents, consider whether the entire document is relevant or if excerpts would be better</li> <li>Markdown files often index more cleanly than complex PDFs</li> </ul> <p>Chunking Configuration (Administrators)</p> <p>If you manage an OpenWebUI instance, you can tune RAG performance in Admin Panel &gt; Settings &gt; Documents:</p> <ul> <li>Chunk Size: Larger chunks preserve more context but may dilute relevance</li> <li>Chunk Overlap: Higher overlap prevents important information from being split across chunks</li> <li>Markdown Header Splitting: Enable this for structured documents to keep sections together</li> </ul> <p>Query Strategies</p> <ul> <li>Be specific: \"What does Section 3.2 say about sampling methods?\" works better than \"Tell me about methods\"</li> <li>Ask for citations: \"Include the source for each claim\"</li> <li>For complex questions, break them into parts and ask sequentially</li> <li>If results seem incomplete, try rephrasing---different wording retrieves different chunks</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#comparison-openwebui-vs-other-rag-tools","level":4,"title":"Comparison: OpenWebUI vs. Other RAG Tools","text":"Feature OpenWebUI NotebookLM ChatGPT (Plus) Claude Projects Cost Free (self-hosted) Free $20/month $20/month Data Privacy Full local control Google servers OpenAI servers Anthropic servers Model Choice Any Ollama/API model Gemini only GPT-4 only Claude only Setup Complexity Requires installation None None None Persistent Collections Yes Yes (Notebooks) Limited Yes (Projects) Offline Use Yes (local models) No No No Best For Privacy-sensitive data, technical users Research, studying General use Long documents","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#openais-vector-store-and-file-search","level":3,"title":"OpenAI's Vector Store and File Search","text":"<p>OpenAI Platform allows developers and advanced users to upload data to a vector store and enable file search in custom assistants. This provides more control over the RAG process compared to simple file uploads.</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#building-rag-applications","level":2,"title":"Building RAG Applications","text":"<p>For researchers and developers who want more control, building custom RAG applications enables:</p> <ul> <li>Processing large document collections</li> <li>Customizing retrieval strategies</li> <li>Integrating with existing systems</li> <li>Maintaining full data privacy</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#rag-frameworks","level":3,"title":"RAG Frameworks","text":"<p>Several frameworks simplify building RAG applications:</p> Framework Language Description LangChain Python, JavaScript Most popular RAG framework with extensive integrations LlamaIndex Python Specialized for connecting LLMs with data sources Haystack Python Production-ready NLP framework with RAG support Semantic Kernel Python, C#, Java Microsoft's SDK for AI orchestration Simple RAG with LangChain (Python) <p>This example demonstrates the core RAG workflow using LangChain:</p> <pre><code>from langchain_community.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\n\n# 1. Load your documents\nloader = PyPDFLoader(\"research_paper.pdf\")\ndocuments = loader.load()\n\n# 2. Split into chunks\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200\n)\nchunks = text_splitter.split_documents(documents)\n\n# 3. Create embeddings and store in vector database\nembeddings = OpenAIEmbeddings()\nvectorstore = Chroma.from_documents(chunks, embeddings)\n\n# 4. Create a retrieval chain\nllm = ChatOpenAI(model=\"gpt-4\")\nqa_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    chain_type=\"stuff\",\n    retriever=vectorstore.as_retriever()\n)\n\n# 5. Ask questions\nresponse = qa_chain.invoke(\"What are the main findings?\")\nprint(response)\n</code></pre> <p>Note: This requires API keys and Python packages. See Code Execution for environment setup.</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#rag-for-academic-research","level":2,"title":"RAG for Academic Research","text":"<p>RAG is particularly valuable for academic work where accuracy, citations, and working with large document collections are essential.</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#use-cases-in-research","level":3,"title":"Use Cases in Research","text":"<p>Literature Reviews</p> <ul> <li>Upload dozens or hundreds of papers to a RAG system</li> <li>Ask synthesis questions: \"How has methodology evolved in this field?\"</li> <li>Identify gaps: \"What aspects of this topic are under-researched?\"</li> <li>Find contradictions: \"Where do researchers disagree?\"</li> </ul> <p>Grant Writing</p> <ul> <li>Create a knowledge base of successful grant proposals</li> <li>Query for specific section examples: \"Show me aims page structures\"</li> <li>Synthesize background literature for significance sections</li> </ul> <p>Data Analysis Support</p> <ul> <li>Upload codebooks, documentation, and methodology papers</li> <li>Ask questions about variable definitions and procedures</li> <li>Get help interpreting statistical results in context</li> </ul> <p>Teaching Preparation</p> <ul> <li>Build a knowledge base of textbook chapters and supplementary materials</li> <li>Generate quiz questions based on specific content</li> <li>Create study guides that reference source materials</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#best-practices-for-academic-rag","level":3,"title":"Best Practices for Academic RAG","text":"<p>Maximizing RAG Quality</p> <p>Document Preparation</p> <ul> <li>Use high-quality OCR for scanned documents</li> <li>Ensure PDFs are text-based, not image-only</li> <li>Include metadata (titles, authors, dates) when possible</li> <li>Organize documents logically before upload</li> </ul> <p>Querying Strategies</p> <ul> <li>Be specific: \"According to Smith et al. (2023)...\" vs. \"What do researchers say...\"</li> <li>Ask for citations: \"Include page numbers in your response\"</li> <li>Break complex questions into parts</li> <li>Verify AI-provided citations against original sources</li> </ul> <p>Quality Control</p> <ul> <li>Always verify critical facts against source documents</li> <li>Check that citations actually support the claims made</li> <li>Be aware that retrieval may miss relevant passages</li> <li>Use multiple queries to cross-check important information</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#limitations-and-considerations","level":2,"title":"Limitations and Considerations","text":"<p>RAG is powerful but not perfect. Understanding its limitations helps you use it appropriately.</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#technical-limitations","level":3,"title":"Technical Limitations","text":"<ul> <li>Chunk boundaries: Important information split across chunks may not be retrieved together</li> <li>Retrieval quality: The system may not always find the most relevant passages</li> <li>Context window limits: Very long retrieved passages may be truncated</li> <li>Embedding quality: Some specialized vocabulary may not embed well</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#practical-considerations","level":3,"title":"Practical Considerations","text":"<ul> <li>Garbage in, garbage out: Poor quality documents produce poor quality responses</li> <li>Not a replacement for reading: RAG helps you navigate documents, not avoid reading them</li> <li>Citation verification required: AI may misattribute or misquote sources</li> <li>Domain expertise still matters: You need expertise to evaluate response quality</li> </ul> <p>Important Caveats</p> <ul> <li>RAG reduces but does not eliminate hallucination</li> <li>Retrieved context may be incomplete or biased toward certain documents</li> <li>Complex reasoning across many sources remains challenging</li> <li>Always verify citations and facts for high-stakes applications</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#assessment-questions","level":2,"title":"Assessment Questions","text":"What problem does RAG solve that traditional LLMs cannot? <p>Answer</p> <p>RAG addresses several key limitations of traditional LLMs:</p> <ol> <li>Knowledge currency: LLMs have a training cutoff date; RAG can access current documents</li> <li>Hallucination: LLMs may generate plausible but false information; RAG grounds responses in actual sources</li> <li>Domain specificity: LLMs have general knowledge; RAG can incorporate your specialized documents</li> <li>Citations: LLMs cannot cite sources; RAG can reference specific documents</li> <li>Privacy: With RAG, your documents can stay on your own systems rather than being sent for training</li> </ol> Explain the role of embeddings in RAG systems <p>Answer</p> <p>Embeddings are numerical representations of text that capture semantic meaning. In RAG:</p> <ol> <li>Document chunks are converted to embedding vectors during indexing</li> <li>User queries are converted to embedding vectors at query time</li> <li>Similar vectors indicate similar meaning (even with different words)</li> <li>The system finds document chunks with vectors closest to the query vector</li> <li>This enables \"semantic search\" - finding relevant content based on meaning, not just keywords</li> </ol> <p>For example, a query about \"vehicle maintenance\" would retrieve documents about \"car repair\" because their embeddings are similar, even though the words differ.</p> What factors affect the quality of RAG responses? <p>Answer</p> <p>Several factors influence RAG quality:</p> <p>Document Quality</p> <ul> <li>Text extraction quality (OCR accuracy)</li> <li>Document completeness and organization</li> <li>Relevance to expected queries</li> </ul> <p>Chunking Strategy</p> <ul> <li>Chunk size (too small loses context, too large dilutes relevance)</li> <li>Chunk overlap (prevents splitting important passages)</li> <li>Respecting document structure</li> </ul> <p>Retrieval</p> <ul> <li>Number of chunks retrieved</li> <li>Embedding model quality</li> <li>Similarity threshold settings</li> </ul> <p>Generation</p> <ul> <li>LLM capability and context window</li> <li>Prompt design for using retrieved context</li> <li>Temperature and other generation parameters</li> </ul> True or False: RAG eliminates the need to verify AI responses <p>False</p> <p>RAG reduces but does not eliminate the need for verification:</p> <ul> <li>Retrieved passages may not be the most relevant</li> <li>The LLM may misinterpret or misquote retrieved content</li> <li>Important context may be split across chunks not retrieved together</li> <li>Citations should always be verified against original sources</li> <li>Domain expertise is still needed to evaluate response quality</li> </ul> <p>RAG provides better grounding and traceability, but critical applications still require human verification.</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#further-resources","level":2,"title":"Further Resources","text":"","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#documentation-and-guides","level":3,"title":"Documentation and Guides","text":"<ul> <li> LangChain RAG Tutorial</li> <li> LlamaIndex Getting Started</li> <li> Pinecone RAG Guide</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#academic-papers","level":3,"title":"Academic Papers","text":"<ul> <li>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks - The original RAG paper (Lewis et al., 2020)</li> <li>A Survey on Retrieval-Augmented Text Generation - Comprehensive survey of RAG techniques</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#related-workshop-content","level":3,"title":"Related Workshop Content","text":"<ul> <li>NotebookLM - Consumer-friendly RAG for research</li> <li>Text Mining - Techniques for processing large text collections</li> <li>Code Execution - Setting up environments for custom RAG development</li> <li>Agentic AI - How RAG combines with autonomous AI agents</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"research/","level":1,"title":"Overview","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#introduction","level":2,"title":"Introduction","text":"<p>GPTs excel at scientific research, but become specialized rapidly depending upon their application. GPTs and LLMs also fit as a cog within the larger AI ecosystem of natural language processing, and machine learning.</p> <p>When deployed privately into secure data enclaves, GPTs can be used with sensitive and secure data (e.g., FERPA, HIPAA, or CUI) without the risk of data breaches or interception over internet traffic. </p> Generative AI Predictive AI Generative Adversarial Networks (GANs) Linear Regression Variational Autoencoders (VAEs) Logistic Regression Generative Pretrained Transformers (GPTs) Decision Trees Diffusion Models Random Forest Autoregressive Models Support Vector Machines (SVMs) <p>Generative AI and Academic Research</p> <p>Generative AI has revolutionized academic research by enabling the creation of synthetic data, accelerating drug discovery, and aiding in the development of new materials. </p> <ul> <li>Synthetic Data Generation: GANs can create realistic synthetic datasets, addressing privacy concerns and data scarcity.</li> <li>Drug Discovery: Generative models can design novel drug molecules with desired properties.</li> <li>Material Science: AI-powered generative design can optimize material properties for specific applications.</li> </ul> <p>Predictive AI and Climate Modeling</p> <p>Predictive AI plays a crucial role in climate modeling by analyzing historical data to forecast future climate patterns.</p> <ul> <li>Climate Change Prediction: Machine learning models can predict temperature changes, sea-level rise, and extreme weather events.</li> <li>Climate Impact Assessment: AI-powered tools can assess the impact of climate change on ecosystems and human societies.</li> </ul> <p>Predictive AI and Protein Folding</p> <p>Predictive AI has made significant strides in protein folding, a fundamental challenge in biology.</p> <ul> <li>Protein Structure Prediction: Deep learning models like AlphaFold can accurately predict protein structures from amino acid sequences.</li> <li>Drug Design: Understanding protein structures enables the design of targeted drugs.</li> </ul> <p>Generative AI and Language Models</p> <p>Generative AI, particularly GPTs, has significantly advanced Natural Language Processing (NLP). These models are trained on massive amounts of text data and can generate human-quality text, translate languages, write different kinds of creative content, and answer your questions in an informative way.</p> <p>Generative AI and Retrieval Augmented Generation</p> <p>Retrieval Augmented Generation (RAG) combines the strengths of generative AI and information retrieval. It allows models to access and incorporate relevant information from external sources, improving the quality and factual accuracy of generated text.</p> <p>Predictive AI and Machine Learning</p> <p>Predictive AI is a subset of machine learning that focuses on forecasting future trends and outcomes. It leverages statistical techniques and algorithms to analyze historical data and make predictions.</p> <p>Predictive AI and Transformers</p> <p>Transformers, a type of neural network architecture, have revolutionized predictive AI. They are particularly effective in tasks like time series forecasting, natural language processing, and computer vision.</p> <p>Predictive AI, Stable Diffusion, and Generative AI</p> <p>While Stable Diffusion is a powerful generative AI model, it is not directly related to predictive AI. Generative AI, on the other hand, can be used to generate synthetic data for training predictive models, enhancing their performance and robustness.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#workshop-lessons","level":2,"title":"Workshop Lessons","text":"<p>Specific to this workshop, we focus on code interpreters and code execution using GPTs, but we will also touch upon the creation and deployment of custom AI applications and how to use commercial and open source GPTs for each.</p> <p>In a future workshop we will cover the deployment of secure private GPTs and LLMs in data enclaves </p> <p>Why use GPTs for research?</p> <p>Advantages</p> <ul> <li> <p>Increased Efficiency and Productivity: perhaps the most obvious and enticing reason for using GPTs is to automate tedious and repetitive tasks, creating more time for analyses and research.</p> </li> <li> <p>Accuracy &amp; Objectivity: GPTs analyze data without human bias. </p> </li> <li> <p>Pattern Recogition: GPTs may identify patterns and connections in data that a human cannot.</p> </li> </ul> <p>Disadvantages</p> <ul> <li> <p>Human Oversight: GPTs should not be used to replace human expertise. Researchers must always evaluate and ensure GPT output are factual and align with published research artifacts.</p> </li> <li> <p>Bias: GPTs can reduce human bias, but suffer from their own training biases.</p> </li> <li> <p>Potential Misuse: GPTs can be used to fabricate scientific research papers or manipulate data, undermining the integrity of science.  </p> </li> </ul>","path":["Research","Overview"],"tags":[]},{"location":"research/#literature-review-and-synthesis","level":2,"title":"Literature Review and Synthesis","text":"<p>GPTs are excellent summarization tools. When coupled with large corpuses of published research they can be invaluable for literature review and synthesis. </p> <p>Perplexity.ai has established itself as a popular GPT for search and summary of existing web-based material. </p> <p>Google Deep Research is positioning itself as a platform for in depth prompts on specific topics.</p> <p>Google NotebookLM allows you to personalize your research by providing your own literature or knowledge (files, images, audio).</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#custom-chatgpts-for-literature-review","level":3,"title":"Custom ChatGPTs for Literature Review","text":"","path":["Research","Overview"],"tags":[]},{"location":"research/#scholarai","level":4,"title":"ScholarAI","text":"<p>ScholarAI is the most highly starred  ai research assistant on custom GPTs on ChatGPT for research.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#scholargpt","level":4,"title":"ScholarGPT","text":"<p>ScholarGPT was one of the early custom GPTs created on ChatGPT and has many millions of resources embedded within it. </p>","path":["Research","Overview"],"tags":[]},{"location":"research/#semantic-scholar","level":4,"title":"Semantic Scholar","text":"<p>Semantic Scholar is a free, AI-powered research tool for scientific literature, based at Ai2.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#huggingface","level":3,"title":"HuggingFace","text":"<p>HuggingFace is the dominant registry for AI models and model data. </p>","path":["Research","Overview"],"tags":[]},{"location":"research/#data-analysis","level":2,"title":"Data Analysis","text":"Linux Guru <p>ChatGPT is trained on common data science languages, like Python, Julia, and R. Use ChatGPT to help develop basic code or to explain and debug code you're trying to write. </p> <p>Using ChatGPT can be a time savings, reducing the time it takes to look for the answers yourself over conventional search.</p> <pre><code>I want you to act as a humble data scientist who works a lot with Python and scientific visualization\n\nCreate a Python script which generates a visually pleasing and compelling heat map for a CSV dataset\n</code></pre> <p>You can also use it to summarize code or to help explain its operation</p> <pre><code>I want you to act as a humble data scientist who works a lot with Linux \n\nExplain to me what the following code does:\n\n$ find /home/www \\( -type d -name .git -prune \\) -o -type f -print0 | xargs -0 sed -i 's/subdomainA\\.example\\.com/subdomainB.example.com/g'\n</code></pre> <p>Other valuable uses:</p> <ul> <li> <p>Change variable names and file names! When you have a large dataset with many files and folder names, you can ask ChatGPT to help design a schema for renaming your project's content</p> </li> <li> <p>Regular Expressions, or <code>regex</code> is a bane of many programmers. ChatGPT can write, edit, and explain complex <code>regex</code></p> </li> </ul> <p>```markdown I want you to act as a regex generator. Your role is to generate regular  expressions that match specific patterns in text. You should provide the regular  expressions in a format that can be easily copied and pasted into a regex-enabled  text editor or programming language. Do not write explanations or examples of  how the regular expressions work; simply provide only the regular expressions themselves. </p> <p>remove any numbers from a string and replace them with a capital X</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#hypothesis-generation","level":3,"title":"Hypothesis generation","text":"<p>Examples of roles you might ask for are: a domain science expert, an IT or DevOps engineer, software programmer, journal editor, paper reviewer, mentor, teacher, or student. You can even instruct ChatGPT to respond as though it were a Linux terminal, a web browser, a search engine, or language interpreter.</p> Data Scientist <p>Let's try an example prompt with role-playing to help write code in the R programming language.</p> <pre><code>I want you to act as a data scientist with complete knowledge of the R language, \nthe TidyVerse, and RStudio. \n\nWrite the code required to create a new R project environment,\nDownload and load the Palmer Penguins dataset, and plot regressions of body mass, \nbill length, and width for the species of Penguins in the dataset. \n\nYour response output should be in R and RMarkDown format \nwith text and code delineated with ``` blocks.\n\nAt the beginning of new file make sure to install any \nRStudio system dependencies and R libraries that Palmer Penguins requires.\n</code></pre> <p>Example can use <code>GPT o1</code> or <code>Gemini 2.0</code> </p> Talk to Dead Scientists <p>Try to ask a question with and without Internet access enabled:</p> <p><pre><code>I want you to respond as though you are the mathematician Benoit Mandelbrot\n\nExplain the relationship of lacunarity and fractal dimension for a self-affine series\n\nShow your results using mathematical equations in LaTeX or MathJax style format\n</code></pre> Again, there is no guarantee that the results ChatGPT provides are factual, but it does greatly improve the odds that they are relevant to the prompt. Most importantly, these extensions provide citations for their results, allowing you to research the results yourself. </p>","path":["Research","Overview"],"tags":[]},{"location":"research/#feedback","level":3,"title":"Feedback","text":"","path":["Research","Overview"],"tags":[]},{"location":"research/#example-3-programming-help","level":3,"title":"Example 3: Programming help","text":"<p>Another impressive application of ChatGPT is in the field of programming. You can use it as a coding assistant, where it can help write code, debug issues, or explain complex code snippets. By asking it to convert your high-level descriptions into code, or to suggest improvements for existing code, you can significantly enhance your programming productivity.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#coding-assistant","level":4,"title":"Coding Assistant","text":"<p>Suppose you're working on a Python program to perform data analysis, but you're not sure how to write a function to calculate the median from a list of numbers. You might use ChatGPT like this:</p> Python median function <pre><code>I'm trying to write a Python function that takes a list of numbers as an argument and returns the median. I'm not sure about the best way to implement this. Could you help me write the code?\n</code></pre> <p>ChatGPT could then provide you with a suitable Python function, demonstrating the logic to calculate the median from a list of numbers.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#debugging","level":4,"title":"Debugging","text":"<p>Let's say you're having trouble with a piece of JavaScript code that's not behaving as expected. You could ask ChatGPT for help as follows:</p> <p>Debugging JavaScript</p> <p><pre><code>my JavaScript code to add event listeners to buttons isn't working as expected. Here's the code:\n</code></pre> <pre><code>let buttons = document.querySelectorAll('.btn');\nfor (let i = 0; i &lt; buttons.length; i++) {\n    buttons[i].addEventListener('click', function() {\n        console.log('Button ' + i + ' clicked');\n    });\n}\n</code></pre> <pre><code>When I click a button, it always logs 'Button 5 clicked', no matter which button I click. What's going wrong, and how can I fix it?\"\n</code></pre></p> <p>ChatGPT could then explain the issue (in this case, a common pitfall with JavaScript closures) and suggest a corrected version of your code.</p> <p>Limitations</p> <p>Remember, while ChatGPT is knowledgeable in many programming languages and concepts, it doesn't replace a full Integrated Development Environment (IDE) or debugger and should be used as a supplementary tool for coding assistance.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#popular-uses-of-prompt-engineering-in-research-data-science-and-code-interpreters","level":3,"title":"Popular Uses of Prompt Engineering in Research (Data Science and Code Interpreters)","text":"<ul> <li>Data Cleaning and Preprocessing: Automate the process of cleaning and preparing data for analysis, including handling missing values, data normalization, and outlier detection.</li> <li>Code Generation: Generate code snippets for specific data analysis tasks, such as statistical tests, data visualization, and machine learning model implementation.</li> <li>Algorithm Selection and Design: Suggest appropriate algorithms or models based on the characteristics of the data and the research question.</li> <li>Automated Report Writing: Generate summaries of data analysis results, including key findings, visualizations, and interpretations.</li> <li>Literature Review Assistance: Quickly find and summarize relevant research papers, identify key concepts, and extract important information.</li> <li>Hypothesis Generation: Explore potential research questions and hypotheses based on existing data and literature.</li> <li>Experimental Design: Assist in designing experiments, including determining sample sizes, selecting appropriate variables, and suggesting control measures.</li> </ul>","path":["Research","Overview"],"tags":[]},{"location":"teaching/","level":1,"title":"Teaching with AI","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Full Disclosure: Material on this website was copy edited or is based on suggestions made by a GPT</p> <p>Have you integrated AI into your coursework yet?</p> No, and thats OKAY! <p>A thoughtful, wait and see, approach to incorporating AI into your educational material is rational and reasonable.</p> <p>Making the decision to incorporate an AI into your education strategy, student assessment, and grading is no easy task. </p> <p>Further, costs and accessibility issues around AI continue to persist across academia. Underserved institutions and colleges with small budgets, or little investment into IT may not have the ability to meet security requirements needed for secure access to student's coursework or personal data (protected by FERPA).</p> <p>An important fact to consider though is that most of your students are already making use of AI for their assignments and study. (ref:  Source ).</p> <p>Read about  OpenAI Educator Considerations</p> Yes, but go ahead and read on <p>Thats great! </p> <p>Make sure to read through the rest of this section to make sure that you're using GPTs in ways that keep your student's data and personal information safe. </p> <p>Also, ensure that you're using approved AI software that has been vetted by university security and IT staff.</p> <p>By 2026, AI has become a transformative force in higher education. Research indicates that approximately 65-75% of faculty at R1 universities have integrated AI tools into their teaching practice, with adoption rates varying by institution type and discipline. Student usage remains even higher, with over 60% of undergraduates regularly using AI for coursework (EDUCAUSE, 2024).</p> <p>GPTs can compose essays, pass advanced tests, and initially appeared as a threat to academic integrity (Eke 2023). Online education faced extreme challenges regarding effective remote student assessment (Susnjak &amp; McIntosh 2024).</p> <p>However, attempting to modify coursework to avoid assessment techniques where GPTs excel or using detection tools to identify AI-generated content has proven largely futile (MIT Sloan EdTech 2024). Detection tools produce significant false positives and disproportionately flag work by non-native English speakers (Liang et al., 2023); (Weber-Wulff et al., 2024).</p> <p>\"Instead of engaging in a futile cheating arms race, why not embrace AI strategically?\"</p> <p>Proponents of integrating AI into educational curricula () argue that by adapting and integrating GPTs into the curriculum, we also develop a modern workforce who are empowered by AI assistants. </p> <p>Cain (2023) explores ways in which prompt engineering can be brought into the classroom and \"transition [students] from passive recipients to active co-creators of their learning experiences.\"</p> Pro vs Cons of AI in Economics Classrooms <p>At the 2024 EconEd conference Professor Justin Wolfers examined how AI is revolutionizing economics education by enhancing student learning and easing educators' workloads. In response, Professor Jon Meer discussed how educators are navigating AI integration in the classroom. Meer’s session provides a practical and valuable roadmap for effective implementation.</p> <p>https://www.macmillanlearning.com/college/us/events/econed </p> <p>Justin's Pros presentation: https://www.youtube.com/watch?v=sTeOLgMN4UM</p> <p></p> <p>Jon's Cons presentation: https://www.youtube.com/watch?v=NXbEvLd1vVk</p> <p></p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#ai-augmented-course-design","level":2,"title":"AI-Augmented Course Design","text":"<p>Effective integration of AI into teaching begins with intentional course design. AI can support every stage of the backward design process, from defining learning objectives to creating assessments and learning activities.</p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#backward-design-with-ai-assistance","level":3,"title":"Backward Design with AI Assistance","text":"<p>Using AI tools to support the backward design process:</p> <p>1. Define Learning Objectives</p> <p>AI can help generate, refine, and align learning objectives with Bloom's Taxonomy:</p> <pre><code>Prompt: I'm designing a course on [topic] for [level] students. Help me create\n5-7 measurable learning objectives at the analysis and synthesis levels of\nBloom's Taxonomy. The course should prepare students to [intended outcomes].\n</code></pre> <p>2. Plan Assessments</p> <p>AI assists in designing assessments that measure learning objectives:</p> <pre><code>Prompt: Based on these learning objectives: [paste objectives], suggest 3\ndifferent assessment methods that would effectively measure student achievement.\nFor each method, explain how it addresses specific objectives and provide one\ndetailed example.\n</code></pre> <p>3. Design Learning Activities</p> <p>AI helps create scaffolded learning activities aligned with objectives and assessments:</p> <pre><code>Prompt: Given these learning objectives [paste] and this final assessment [describe],\ndesign a sequence of 4-5 learning activities that would prepare students for success.\nInclude active learning strategies and opportunities for formative feedback.\n</code></pre> <p>Curriculum Mapping with AI</p> <p>Use AI to check curriculum alignment:</p> <ul> <li>Upload your syllabus and ask AI to identify gaps between objectives, activities, and assessments</li> <li>Request suggestions for better scaffolding or pacing</li> <li>Generate visual curriculum maps showing how topics build across the semester</li> <li>Identify prerequisite knowledge that may need review</li> </ul> <p>Example Prompt: <pre><code>Analyze this syllabus for alignment between learning objectives, weekly topics,\nand assessments. Identify any gaps or misalignments and suggest improvements.\n</code></pre></p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#syllabus-ai-policies-2026-best-practices","level":3,"title":"Syllabus AI Policies (2026 Best Practices)","text":"<p>One of the most critical decisions faculty face is how to address AI use in the syllabus. Research shows that clear, explicit policies reduce confusion and academic integrity violations (Ithaka S+R, 2025).</p> <p>Consider these approaches along a spectrum from prohibited to encouraged:</p> Prohibited ApproachRegulated ApproachEncouraged Approach <p>When to use: High-stakes writing courses, foundational skill development, or when authentic individual work is essential for learning.</p> <p>Sample Syllabus Language:</p> <p>AI Policy: Prohibited Use</p> <p>\"In this course, all work must be your own, completed without the assistance of AI tools such as ChatGPT, Claude, Gemini, or similar technologies. Using AI to generate, edit, or substantially assist with any assignment constitutes a violation of academic integrity and will be treated as plagiarism under the University Code of Academic Integrity.</p> <p>Rationale: This course focuses on developing your individual writing and critical thinking skills. Using AI shortcuts this development and prevents you from building essential capabilities.</p> <p>If you're unsure: Ask before submitting. It's always better to clarify than to face integrity consequences.\"</p> <p>When to use: Most courses where some AI use is acceptable but needs boundaries and disclosure.</p> <p>Sample Syllabus Language:</p> <p>AI Policy: Regulated Use with Disclosure</p> <p>\"AI tools like ChatGPT, Claude, and Gemini can be valuable learning aids when used appropriately. In this course:</p> <p>Permitted Uses:</p> <ul> <li>Brainstorming and generating ideas</li> <li>Grammar and clarity checking</li> <li>Explaining concepts you've encountered in readings</li> <li>Generating practice problems for self-study</li> <li>Creating study guides and summaries</li> </ul> <p>Prohibited Uses:</p> <ul> <li>Writing any portion of assignments submitted for credit</li> <li>Completing problem sets or lab work</li> <li>Taking quizzes or exams</li> <li>Generating citations or conducting literature searches (you must verify all sources)</li> </ul> <p>Disclosure Requirement:</p> <p>All assignments must include an \"AI Use Statement\" describing any AI tools used and how. Example: \"I used ChatGPT to check grammar and clarity on my final draft.\"</p> <p>Failure to disclose AI use is an academic integrity violation.\"</p> <p>When to use: Professional programs, advanced courses, or when AI collaboration skills are learning objectives.</p> <p>Sample Syllabus Language:</p> <p>AI Policy: Encouraged Use with Documentation</p> <p>\"In this course, you are required to use AI tools as part of your professional skill development. However, you must use them thoughtfully and document your process.</p> <p>Learning Objectives:</p> <ul> <li>Develop effective prompt engineering skills</li> <li>Learn to critically evaluate AI output</li> <li>Understand when AI is helpful vs. when human expertise is essential</li> <li>Practice ethical AI collaboration</li> </ul> <p>Requirements:</p> <ol> <li>Document Your Process: For each major assignment, submit a \"Process Log\" showing:</li> <li>Prompts you used</li> <li>AI responses you received</li> <li>How you evaluated, modified, or rejected AI suggestions</li> <li> <p>Your final decisions and why you made them</p> </li> <li> <p>Demonstrate Learning: Your grade is based on your critical engagement with AI, not just the final product. Show me your thinking.</p> </li> <li> <p>Cite AI Appropriately: Use this format: \"Initial draft developed in collaboration with Claude 4.5 (Anthropic, 2026). See appendix for interaction log.\"</p> </li> </ol> <p>This approach treats AI as a professional tool you must learn to use effectively, not as a shortcut.\"</p> <p>Key Elements for Any Policy</p> <p>Regardless of approach, your policy should include:</p> <ul> <li>Clear boundaries - Specific examples of what is/isn't allowed</li> <li>Rationale - Help students understand why the policy exists</li> <li>Disclosure requirements - How students should document AI use</li> <li>Consequences - What happens if policy is violated</li> <li>Support resources - Where students can get help or ask questions</li> </ul> <p>Update your policy at the start of each term as AI capabilities and norms evolve.</p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#learning-objective-generation","level":3,"title":"Learning Objective Generation","text":"<p>AI excels at helping faculty articulate clear, measurable learning objectives:</p> How can AI help write better learning objectives? <p>Technique 1: Bloom's Taxonomy Alignment <pre><code>I want students to understand [concept]. Generate 3 learning objectives at the\n'apply' level and 3 at the 'evaluate' level using Bloom's Taxonomy. Make them\nmeasurable and appropriate for undergraduate juniors.\n</code></pre></p> <p>Technique 2: Discipline-Specific Objectives <pre><code>I'm teaching [course name] in [discipline]. What are the core competencies students\nshould develop? Frame these as measurable learning objectives using action verbs.\n</code></pre></p> <p>Technique 3: SMART Objectives <pre><code>Refine these draft learning objectives to be SMART (Specific, Measurable, Achievable,\nRelevant, Time-bound): [paste your draft objectives]\n</code></pre></p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#automated-grading-and-feedback","level":2,"title":"Automated Grading and Feedback","text":"<p>AI-powered grading tools are advancing rapidly, offering faculty ways to provide more timely, detailed feedback while managing workload. However, human oversight remains essential to ensure fairness and catch AI limitations.</p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#tools-and-platforms","level":3,"title":"Tools and Platforms","text":"Tool Primary Use Features LMS Integration Pricing Best For Gradescope AI Coding &amp; written assignments AI-assisted rubric creation, pattern recognition, similarity detection Canvas, Blackboard, Moodle Institutional licensing Computer science, STEM courses Magic School AI K-12 &amp; general education Assignment generation, feedback, report card comments Limited $99/year individual K-12 and general ed courses Education Copilot Lesson plans &amp; materials Automated lesson planning, handout generation, AI chat for students None (standalone) Free tier, $9-15/mo pro Course material creation Grammarly for Education Writing feedback Grammar, clarity, tone, plagiarism Google Classroom, Canvas Institutional licensing Writing-intensive courses Turnitin Feedback Studio Writing with AI detection Automated feedback, originality checking, AI detection Canvas, Blackboard, Moodle, D2L Institutional licensing Writing courses across disciplines <p>FERPA Compliance for Grading Tools</p> <p>When using AI grading tools:</p> <ul> <li>Verify the vendor has signed a FERPA agreement with your institution</li> <li>Understand where student data is stored and how it's used</li> <li>Never upload student identifying information to consumer AI tools</li> <li>Use anonymous student IDs when possible</li> <li>Review your institution's approved vendor list before adopting tools</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#when-to-automate-and-when-not-to","level":3,"title":"When to Automate (and When Not To)","text":"<p>Good Candidates for AI-Assisted Grading:</p> <ul> <li>Large enrollment courses with standardized rubrics</li> <li>Multiple-choice or short-answer questions with clear correct answers</li> <li>Code assignments where output can be objectively tested</li> <li>Grammar and mechanics in writing (not argument quality or originality)</li> <li>Initial screening of submissions before human review</li> </ul> <p>Keep Human Grading For:</p> <ul> <li>Nuanced argumentation and critical analysis</li> <li>Creative work where originality and voice matter</li> <li>Complex problem-solving with multiple valid approaches</li> <li>Work from students with disabilities or accommodations</li> <li>High-stakes assessments affecting grades significantly</li> </ul> <p>Hybrid Approach (Best Practice):</p> <ol> <li>AI provides initial feedback and suggested scoring</li> <li>Instructor reviews AI assessment for accuracy and fairness</li> <li>Instructor adds personalized comments and adjusts scores</li> <li>Students receive both automated and human feedback</li> </ol> Effective Automated Feedback Strategies <p>Formative, Not Just Summative:</p> <ul> <li>Use AI feedback on drafts before final submission</li> <li>Let students revise based on AI suggestions (and explain what they changed)</li> <li>Track improvement over multiple submissions</li> </ul> <p>Transparent with Students:</p> <ul> <li>Tell students when AI is being used for grading</li> <li>Explain the human review process</li> <li>Offer appeal mechanisms for AI-assigned grades</li> </ul> <p>Iterative Improvement:</p> <ul> <li>Review AI feedback for patterns of errors or bias</li> <li>Adjust rubrics and training data based on mismatches</li> <li>Share concerning patterns with tool vendors</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#classroom-management-with-ai","level":2,"title":"Classroom Management with AI","text":"","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#ai-teaching-assistants","level":3,"title":"AI Teaching Assistants","text":"<p>Virtual teaching assistants powered by AI can handle routine student questions, freeing instructors for higher-level support:</p> <p>Implementation Models:</p> <ul> <li>Q&amp;A Chatbot: Answer common questions about syllabus, due dates, policies 24/7</li> <li>Content Explainer: Provide clarifications on course concepts with links to resources</li> <li>Assignment Guide: Walk students through assignment requirements and submission process</li> <li>Office Hours Support: Pre-answer common questions so office hours focus on complex issues</li> </ul> <p>Example Tools:</p> <ul> <li>Custom GPTs (ChatGPT Team/Enterprise): Create a bot with your syllabus, policies, and FAQs</li> <li>Claude Projects: Upload course materials for students to query (if institutionally licensed)</li> <li>Course-specific chatbots: Khanmigo, Ivy.ai, AdmitHub (check institutional partnerships)</li> </ul> <p>Teaching Assistant Limitations</p> <p>What AI TAs Cannot Do:</p> <ul> <li>Provide medical or crisis counseling (always direct to professional services)</li> <li>Make exceptions to policies or grant extensions (instructor decision)</li> <li>Access or discuss individual student grades (FERPA violation)</li> <li>Substitute for meaningful instructor-student relationships</li> </ul> <p>Always include a disclaimer: \"I'm an AI assistant for [Course Name]. For complex questions, accommodations, or personal matters, please contact Prof. [Name] directly.\"</p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#discussion-facilitation","level":3,"title":"Discussion Facilitation","text":"<p>AI can enhance online and hybrid discussions:</p> <ul> <li>Seed Questions: Generate discussion prompts that encourage critical thinking</li> <li>Summarization: AI synthesizes long discussion threads for students joining late</li> <li>Participation Analytics: Identify students not participating and suggest engagement strategies</li> <li>Debate Preparation: Students practice arguments with AI before peer discussion</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#real-time-engagement-tools","level":3,"title":"Real-Time Engagement Tools","text":"<p>Live Polling and Q&amp;A (AI-Enhanced):</p> <ul> <li>Mentimeter AI: Generates word clouds and summarizes open responses</li> <li>Slido: AI-powered Q&amp;A moderation and question clustering</li> <li>Poll Everywhere: Real-time sentiment analysis of student responses</li> </ul> <p>Use Cases:</p> <ul> <li>Gauge understanding during lectures (concept checks)</li> <li>Identify confusing points requiring clarification</li> <li>Crowdsource questions for Q&amp;A sessions</li> <li>Generate discussion topics from student input</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#multimodal-teaching-materials","level":2,"title":"Multimodal Teaching Materials","text":"<p>AI enables faculty to create diverse teaching materials without specialized technical skills.</p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#video-generation","level":3,"title":"Video Generation","text":"<p>AI Video Tools:</p> <ul> <li>Synthesia: Create video lectures with AI avatars (text-to-video)</li> <li>HeyGen: Generate personalized video content with your digital likeness</li> <li>Descript: AI-powered video editing, transcription, and overdubbing</li> <li>Lumen5: Transform text content into engaging video presentations</li> </ul> <p>Educational Use Cases:</p> <ul> <li>Pre-recorded \"micro-lectures\" for flipped classroom models</li> <li>Multilingual course content (AI translation + dubbed videos)</li> <li>Accessible video content with automatic captions and translations</li> <li>Personalized video feedback on assignments</li> </ul> <p>Video Generation Best Practices</p> <p>Quality Control:</p> <ul> <li>Always review AI-generated videos for accuracy before sharing</li> <li>Watch for unnatural speech patterns or lip-sync issues</li> <li>Test videos with students and gather feedback</li> </ul> <p>Accessibility:</p> <ul> <li>Use AI to generate accurate captions and transcripts</li> <li>Provide text alternatives for all video content</li> <li>Ensure color contrast and visual accessibility</li> </ul> <p>Authenticity:</p> <ul> <li>Consider whether AI avatar video feels authentic for your teaching style</li> <li>Some students may prefer genuine instructor presence</li> <li>Use AI video strategically, not as complete replacement</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#interactive-simulations","level":3,"title":"Interactive Simulations","text":"<p>AI-Powered Interactive Learning:</p> <ul> <li>Claude Artifacts: Create interactive visualizations, simulations, and tools directly in conversation</li> <li>ChatGPT Canvas: Collaborative space for building and refining educational content</li> <li>Custom Web Apps: Use AI to generate interactive HTML/JavaScript tools for demonstrations</li> </ul> <p>Examples:</p> <ul> <li>Interactive graphs showing economic concepts</li> <li>Scientific simulations (physics, chemistry)</li> <li>Data visualization tools students can manipulate</li> <li>Choose-your-own-adventure scenarios for case studies</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#educational-image-generation","level":3,"title":"Educational Image Generation","text":"<p>AI Image Tools:</p> <ul> <li>DALL-E 3 (via ChatGPT Plus): Generate custom diagrams, illustrations, examples</li> <li>Midjourney: High-quality artistic images for presentations</li> <li>Adobe Firefly: Commercial-safe AI images integrated with Adobe tools</li> <li>Stable Diffusion: Open-source image generation (requires technical setup)</li> </ul> <p>Use Cases:</p> <ul> <li>Create custom diagrams and infographics</li> <li>Generate historical scene reconstructions</li> <li>Visualize abstract concepts</li> <li>Develop test questions with novel images</li> </ul> <p>Copyright and AI-Generated Images</p> <ul> <li>AI-generated images may have unclear copyright status</li> <li>Some tools train on copyrighted work (ethical concerns)</li> <li>Attribution practices are still evolving</li> <li>Check institutional policies before using AI images in published materials</li> <li>For commercial textbooks or MOOCs, consult legal counsel</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#security-and-ferpa-considerations-for-gpts-in-higher-education","level":2,"title":"Security and FERPA Considerations for GPTs in Higher Education","text":"<p>The integration of GPTs into classrooms introduces challenges, particularly in terms of data security and compliance with the Family Educational Rights and Privacy Act (FERPA). </p> <p>This section outlines key considerations for educators and administrators.</p> <p>FERPA and GDPR Protections</p> <p>FERPA (United States):</p> <p>FERPA protects the privacy of student education records. It gives parents certain rights regarding their children's education records. These rights transfer to the student at 18 years of age or beyond the high school level.</p> <ul> <li>Education Records: Includes files, documents, or other materials that contain information directly related to a student and are maintained by an agency or institution of education.</li> <li>Directory Information: Information contained in an education record that would not generally be considered harmful or an invasion of privacy if disclosed.</li> <li>Rights Under FERPA: Parents and eligible students have the right to inspect and review the student's education records, request the amendment of records they believe are inaccurate or misleading, and have some control over disclosing personally identifiable information from education records.</li> </ul> <p>GDPR (European Union &amp; International Students):</p> <p>If your institution enrolls international students from the EU, GDPR may apply:</p> <ul> <li>Stricter consent requirements - Explicit opt-in consent needed for data processing</li> <li>Right to erasure - Students can request deletion of their data (\"right to be forgotten\")</li> <li>Data portability - Students can request their data in machine-readable format</li> <li>Breach notification - Stricter timelines (72 hours) for reporting data breaches</li> <li>Cross-border transfers - Additional safeguards for data transferred outside EU</li> </ul> <p>Many AI platforms (especially those based in US or non-EU countries) may not be GDPR-compliant by default. Consult your institutional data privacy office before using AI tools with international student data.</p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#generative-ai-and-compliance-with-ferpa-and-gdpr","level":2,"title":"Generative AI and Compliance with FERPA and GDPR","text":"<p>Commercial GPTs, such as those used for creating educational content, chatbots, or data analysis tools, can potentially handle personal or sensitive information. </p> <p>Faculty members must ensure that using these technologies complies with FERPA regulations before using them in the classroom.</p> <p>FERPA mandates the protection of student education records. </p> <p>Before using GPTs in educational settings, remember:</p> <ul> <li>Do not use student education records with Commercial or external AI tools, unless the data falls under directory information, and even then make certain you are compliant with university policy.</li> <li>When using student data, implement data minimization which anonymizes student information to avoid release of personally identifiable information (PII).</li> <li>Be extremely cautious when inputting student data into GPTs, as this can lead to unintended data leaks or exposure of PII.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#identifying-and-securing-student-data","level":3,"title":"Identifying and Securing Student Data","text":"<p>To ensure FERPA compliance:</p> <ul> <li>Consult with your university's information technology and information security unit before using an AI software. Ensure that you only use secure, vetted, platforms that are approved by your university.  </li> <li>Do not use 3<sup>rd</sup> party software (plugins or extensions) to analyze or prompt with student data.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#security-risks-and-mitigation-strategies","level":2,"title":"Security Risks and Mitigation Strategies","text":"","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#data-leakage-and-exposure","level":3,"title":"Data Leakage and Exposure","text":"<ul> <li>Avoid copying sensitive emails, video/audio transcripts, or student information into GPT platforms for summarization or analysis.</li> <li>Educate all staff and teaching assistants on the risks of sharing personal or confidential information with AI systems.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#academic-integrity","level":3,"title":"Academic Integrity","text":"<ul> <li>Develop clear policies on the appropriate use of AI tools for all assignments and exams. The existing Code of Academic Integrity already explains how to deal with cases of plagiarism.</li> <li>Note on AI Detection Tools: Research shows AI detection tools are unreliable, producing false positives that disproportionately affect non-native English speakers (Liang et al., 2023); (Weber-Wulff et al., 2024). Rather than relying on detection, consider process-based assessment and AI-transparent assignments. See Plagiarism &amp; AI Detection for comprehensive discussion of detection tools, their limitations, and alternative assessment approaches.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#technical-security-measures","level":3,"title":"Technical Security Measures","text":"<ul> <li>Implement zero-trust security solutions, such as secure web gateways, to control access to GPT tools.</li> <li>Use URL and content filtering to prevent unauthorized data uploads and limit access to AI platforms.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#ethical-considerations","level":3,"title":"Ethical Considerations","text":"<ul> <li>Address potential equity issues arising from unequal access to AI tools among students.</li> <li>Consider the impact of AI on critical thinking skills and social interactions in the learning environment.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#guiding-graduate-students-and-postdoctoral-researchers-in-ai-usage","level":2,"title":"Guiding Graduate Students and Postdoctoral Researchers in AI Usage","text":"<p>Training the next generation of researchers to use AI effectively and ethically is a crucial aspect of graduate mentorship. By 2026, AI has become an integral part of the research workflow for most graduate students, and advisors play a critical role in shaping how students engage with these powerful tools.</p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#balancing-ai-assistance-with-independent-learning","level":3,"title":"Balancing AI Assistance with Independent Learning","text":"<p>Platforms like ChatGPT and Claude are available 24/7 to address virtually any question or problem, offering unprecedented support for graduate student research. However, it is essential to strike a balance between AI assistance and the development of independent critical thinking and research skills.</p> <p>To achieve this balance, advisors should:</p> <p>Encourage AI Literacy:</p> <ul> <li>Provide students with resources to understand AI capabilities and limitations</li> <li>Discuss how AI tools work, including training data biases and hallucination risks</li> <li>Share discipline-specific guidance on appropriate AI use in your field</li> </ul> <p>Teach Responsible AI Usage:</p> <ul> <li>Emphasize using AI as a tool to support research, not replace critical thinking</li> <li>Model appropriate AI use in your own research and writing</li> <li>Demonstrate prompt engineering techniques for research applications</li> </ul> <p>Discuss Ethical Considerations:</p> <ul> <li>Foster open discussions about ethical implications of AI in research</li> <li>Address issues of bias, fairness, transparency, and accountability</li> <li>Discuss authorship and attribution for AI-assisted work</li> <li>Review journal and publisher policies on AI use</li> </ul> <p>Promote Thoughtful Collaboration:</p> <ul> <li>Encourage students to leverage AI strengths while developing their own expertise</li> <li>Teach students to verify AI outputs against primary sources</li> <li>Help students recognize when human expertise is essential vs. when AI can assist</li> </ul> <p>Stay Updated:</p> <ul> <li>Ensure both advisors and students stay informed about evolving AI capabilities</li> <li>Share best practices and potential pitfalls as they emerge</li> <li>Participate in discussions about AI in your disciplinary organizations</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#dissertation-and-thesis-support","level":3,"title":"Dissertation and Thesis Support","text":"<p>AI can significantly accelerate dissertation progress when used appropriately:</p> <p>Literature Review Augmentation:</p> <ul> <li>Initial exploration: Use AI to identify key themes, methodological approaches, and research gaps in a body of literature</li> <li>Source organization: AI can help categorize and synthesize findings from dozens of papers</li> <li>Gap identification: Ask AI to analyze your literature review and suggest underexplored areas</li> <li>Synthesis assistance: Generate initial frameworks for organizing complex literature</li> </ul> <p>Example Prompt for Literature Review: <pre><code>I'm conducting a literature review on [topic] with focus on [specific aspect].\nI've read these 20 papers [provide titles or upload PDFs]. Help me:\n1. Identify the main theoretical frameworks used\n2. Summarize methodological approaches\n3. Highlight areas of consensus and debate\n4. Suggest potential research gaps\n\nI'll verify your analysis against the original sources.\n</code></pre></p> <p>Research Proposal Development:</p> <ul> <li>Brainstorm research questions and hypotheses</li> <li>Generate alternative methodological approaches</li> <li>Draft sections of proposals (with significant human revision)</li> <li>Create project timelines and milestones</li> <li>Identify potential funding sources and grant opportunities</li> </ul> <p>Data Analysis Support:</p> <ul> <li>Generate code for statistical analyses or data visualization</li> <li>Troubleshoot analysis problems</li> <li>Interpret statistical outputs (with advisor verification)</li> <li>Draft methods sections based on analysis steps taken</li> </ul> <p>Writing and Revision:</p> <ul> <li>Improve clarity and academic tone</li> <li>Generate alternative ways to frame arguments</li> <li>Create outlines for dissertation chapters</li> <li>Identify logical gaps or weak transitions</li> <li>Assist with formatting and citation management</li> </ul> <p>Dissertation AI Use Guidelines</p> <p>Always Required:</p> <ul> <li>Consult with your advisor about acceptable AI use in your program</li> <li>Disclose all AI assistance in acknowledgments or methodology sections</li> <li>Verify all AI-generated information against primary sources</li> <li>Ensure final work represents your original thinking and contribution</li> </ul> <p>Never Acceptable:</p> <ul> <li>Using AI to write dissertation chapters without significant human intellectual contribution</li> <li>Fabricating data, sources, or citations suggested by AI</li> <li>Submitting AI-generated work as original without disclosure</li> <li>Bypassing required research methods or analysis steps</li> </ul> <p>Many universities now have specific policies on AI use in dissertations. Check your graduate school handbook and discuss with your dissertation committee.</p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#training-teaching-assistants-for-the-ai-era","level":3,"title":"Training Teaching Assistants for the AI Era","text":"<p>Graduate TAs need guidance on using AI in their teaching responsibilities while maintaining academic integrity:</p> <p>TA Training Workshop Topics:</p> <ol> <li>AI Tools Overview (1 hour)</li> <li>Capabilities and limitations of current AI tools</li> <li>Hands-on exploration of ChatGPT, Claude, and Gemini</li> <li> <p>Discipline-specific AI applications</p> </li> <li> <p>Grading with AI (1.5 hours)</p> </li> <li>When AI-assisted grading is appropriate vs. problematic</li> <li>How to use AI for feedback while maintaining fairness</li> <li>Detecting AI-generated student work (and its limitations)</li> <li> <p>Handling suspected AI misuse</p> </li> <li> <p>Creating Course Materials (1 hour)</p> </li> <li>Using AI to generate practice problems, quiz questions, discussion prompts</li> <li>Creating accessible materials with AI assistance</li> <li> <p>Copyright and attribution for AI-generated content</p> </li> <li> <p>Supporting Students (1 hour)</p> </li> <li>Teaching students effective AI use for learning</li> <li>Responding to student questions about AI policies</li> <li> <p>Balancing AI assistance with genuine learning</p> </li> <li> <p>Ethical Considerations (30 min)</p> </li> <li>FERPA compliance when using AI with student data</li> <li>Bias and fairness in AI tools</li> <li>Maintaining student privacy and trust</li> </ol> <p>TA Guidelines Document (Template):</p> <pre><code># Teaching Assistant Guidelines for AI Use in [Course Name]\n\n## Permitted Uses:\n\n* Generating practice problems or study questions\n* Creating answer keys (must verify accuracy)\n* Providing feedback on student writing (grammar/clarity only)\n* Answering routine student questions about logistics\n\n## Prohibited Uses:\n\n* Grading assignments without instructor review\n* Sharing student work or data with consumer AI tools\n* Creating exam questions without instructor approval\n* Providing students with AI-generated solutions to assignments\n\n## Best Practices:\n\n* Always disclose to students when you've used AI to create course materials\n* Document your AI use and share with supervising professor\n* When in doubt, ask the instructor before using AI for any teaching task\n* Verify accuracy of all AI-generated content before sharing with students\n\n## Reporting Requirements:\n\n* Report any suspected student AI misuse to the instructor (not directly accuse)\n* Document situations where AI tools gave problematic or biased responses\n* Share creative uses of AI that worked well in teaching\n</code></pre>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#cross-institutional-resources","level":3,"title":"Cross-Institutional Resources","text":"<p>Point graduate students to these research-focused AI resources:</p> <ul> <li>Anthropic Claude for Research</li> <li>OpenAI Research Portal</li> <li>Research guidance from major publishers (Elsevier, Springer, etc.)</li> <li>Your university's graduate school AI guidance</li> <li>Discipline-specific professional society statements</li> </ul> <p>I will no longer approve graduate student dissertation proposals or dissertations unless they used ChatGPT or a similar AI to help them write part of it! (With appropriate acknowledgment). Yes, I am serious! We're training PhDs to think, not to be robots.</p>— Seth (@DrSethMurray) April 4, 2023","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#teaching-with-chatbots","level":2,"title":"Teaching with Chatbots","text":"<p>ChatGPT and Gemini can improve teaching and learning processes by generating and assessing information and can be used as a standalone tool or  integrated into other systems. It can perform simple or technical tasks and examples show how it can augment teaching and learning.</p> <p>Gemini LearnLM is available in Google's AI Studio and has advanced features for teaching or tutoring.</p> <p>Table: Potential role playing examples for chatbots for teaching and tutoring</p> Role playing Description Example of implementation Possibility engine AI can suggest alternative ways to express an idea Students can write queries in ChatGPT/Gemini and use the \"Regenerate\" response function to explore alternative responses. Socratic opponent AI can act as an opponent to develop an argument Students can enter prompts into ChatGPT/Gemini, using the  structure of a conversation or debate. Teachers can ask their students  to use ChatGPT/Gemini to prepare for discussions. Collaboration coach AI helps groups to research and solve problems together When completing tasks and assignments, students can use ChatGPT/Gemini to find information while working in groups. Guide on the side AI acts as a guide to navigating physical and conceptual spaces Teachers use ChatGPT/Gemini to generate content for their  classes or courses, such as discussion questions, and to seek advice on  how to support students in learning specific concepts. Personal tutor AI tutors each student and gives immediate feedback on progress ChatGPT/Gemini provides personalized feedback to students based on information provided by students or teachers (e.g., test scores). Co-designer AI assists throughout the design process Teachers can seek ideas from ChatGPT/Gemini for designing or  updating a curriculum, including rubrics for assessment. Alternatively,  they can focus on specific goals, such as making the curriculum more  accessible. ChatGPT can provide recommendations and suggestions to help  achieve these objectives. Exploratorium AI provides tools to play with, explore, and interpret data Teachers provide basic information to students who  write different queries in ChatGPT to find out more. ChatGPT/Gemini can be used  to support language learning. Study buddy AI helps the student reflect on learning material Students explain their current level of understanding  to ChatGPT/Gemini and ask for ways to help them study the material. ChatGPT/Gemini  could also be used to help students prepare for other tasks (e.g., job  interviews). Motivator AI offers games and challenges to extend learning Teachers or students ask ChatGPT/Gemini for ideas about how to  extend students' learning after providing a summary of the current  level of knowledge (e.g., quizzes, exercises). Dynamic assessment AI provides educators with a profile of each student's current knowledge Students engage in a tutorial-style dialogue with  ChatGPT/Gemini, and then request that ChatGPT/Gemini create a summary of their current  knowledge for sharing with their teacher or for assessment purposes. Assessment Designer AI creates rubrics, test questions, and alternative assessments aligned with learning objectives Teachers provide learning objectives and assessment criteria, and AI generates draft rubrics, exam questions, or project guidelines. Instructors refine and customize these to fit their course needs. Accessibility Advocate AI generates accommodations, alt-text, transcripts, and accessible materials Teachers upload course materials and request AI-generated captions for videos, alt-text for images, simplified versions for different reading levels, or translated content for multilingual learners.","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#more-resources-on-ai-at-university-of-arizona","level":2,"title":"More Resources on AI at University of Arizona","text":"<p>University of Arizona Artificial Intelligence </p> <p>University of Arizona Library Student Guide to AI </p> <p>University of Arizona Data Lab AI Workshop Series </p> <p> Google for Education</p> <p>Google offers self-paced courses on generative AI. </p> <p>Register with your @arizona.edu Google account and enroll in this 2-hour workshop:   Generative AI For Educators </p> <p>Teaching with ChatGPT</p> <p>ChatGPT for Teachers by We Are Teachers</p> <p>Using AI in the Classroom by University of Wisconsin Madison</p> <p>ChatGPT Resources for Faculty by University of Pittsburg</p> <p>AI in the Classroom by Greylock Podcast</p> <p>How to handle AI in Schools by CommonSense.org</p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#references","level":2,"title":"References","text":"<ul> <li>ChatGPT Cheat Sheet. Neural Magic.</li> <li>ChatGPT Cheat Sheet. Max Rascher.</li> <li>ChatGPT for Studying: How to use the AI-powered chatbot to learn anything you want. StudySmarter.</li> <li>Learn Prompting. </li> <li>Prompt Engineering Guide.</li> <li>The Prompt's The Thing: An Essential Guide to Google Gemini. Skyscape.</li> <li>100+ Creative ideas to use AI in education. Sandra Abegglen, Marianna Karatsiori and Antonio Martinez-Arboleda.</li> <li>200+ Best Gemini AI prompts you can't miss - ChatGPT compatible. TipSeason.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"text_mining/","level":1,"title":"Text Mining Resources","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>This guide provides information on text mining resources</p>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"text_mining/#ai-taxonomy","level":2,"title":"AI Taxonomy","text":"<ul> <li> <p>NIST Artificial Intelligence Risk Management Framework:  refers to an AI system as an engineered or machine-based system that can, for a given set of objectives, generate outputs such as predictions, recommendations, or decisions influencing real or virtual environments. AI systems are designed to operate with varying levels of autonomy.</p> </li> <li> <p>NIST Trustworthy and Responsible AI :  aims to provide a flexible means of classifying how an AI system contributes to an outcome. The taxonomy sets forward 16 AI use “activities” which are independent of AI techniques and domains. Tasks are combinations of one or more AI use activities.</p> </li> <li> <p>Generalist Repository Ecosystem Initiative (GREI) AI Taxonomy: funded by the NIH, developed an AI taxonomy tailored to data repository roles to guide AI integration across repository management. It categorizes the roles into stages, including acquisition, validation, organization, enhancement, analysis, sharing, and user support, providing a structured framework for implementing AI in repository workflows.</p> </li> </ul>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"text_mining/#text-data-sources","level":2,"title":"Text Data Sources","text":"<ul> <li> <p>Constellate: Constellate was the text analytics service from ITHAKA (JSTOR and Portico). It was a platform for teaching, learning, and performing text analysis using archival repositories of scholarly and primary source content. Constellate was sunset in June 2025.</p> <p>Access Note: create a free account with your @arizona.edu email address to obtain full functionality of the platform.</p> </li> <li> <p>Dimensions Plus API: Dimensions Plus includes grants, publications, citations, alternative metrics, clinical trials, patents, and policy documents. Must register with NetID and Password and email support@dimensions.ai to enable API access. </p> </li> <li> <p>Elsevier API: Elsevier's API program allows you to integrate content and data from Elsevier products into your own website and applications. APIs are free for the products Arizona subscribes to: Scopus, Engineering Village, and subscribed journals in Science Direct. </p> </li> <li> <p>Scopus Search: Scopus search API includes basic, advanced, and AI powered queries of the Scopus literature archive.</p> </li> <li> <p>IEEE API Portal: API portal for IEEE. </p> </li> <li> <p>JSTOR for Data Research: Data for Research (DfR) provides datasets of content on JSTOR for use in research and teaching. Researchers may use DfR to define and submit their desired dataset to be automatically processed. Data available through the service includes metadata, n-grams, and word counts for most articles and book chapters, and for all research reports and pamphlets on JSTOR. Datasets are produced at no cost to researchers and may include data for up to 25,000 documents. </p> </li> <li> <p>LexisNexis Web Services Kit: Lexis Nexis Web Services Kit is a mediated service that allows bulk download of Nexis UNI content (formerly Lexis Nexis Academic). Up to 250 documents and 1000 metadata downloads are allowable on Nexus UNI without use of the API. Contact your subject librarian for access to LexisNexis Web Services Kit. </p> </li> <li> <p>PLOS API: Python tool for downloading/updating/maintaining a repository of all PLOS XML article files. Use this program to download all PLOS XML article files instead of doing web scraping. </p> </li> <li> <p>ProQuest TDM Studio: ProQuest TDM (Text and Data Mining) Studio allows you to create and analyze datasets from ProQuest content. </p> </li> <li> <p>Ravenpack News Analytics: Use for financial and economic analysis. Access through WRDS. </p> </li> <li> <p>Web of Science: is a collection of databases that index the world’s leading scholarly literature in the sciences, social sciences, arts, and humanities, as published in journals, conference proceedings, symposia, seminars, colloquia, workshops, and conventions across the globe.</p> </li> </ul>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"text_mining/#freely-available-text-data-sources","level":2,"title":"Freely Available Text Data Sources","text":"<ul> <li> <p>arXiv Bulk Data: Our mission is to provide rapid dissemination of scientific results at no cost to authors or readers. Providing free Application Programming Interfaces (APIs) helps us to advance that mission by enabling platforms and projects that extend the discoverability of arXiv e-prints and provide valuable services to scientists and interested readers. </p> </li> <li> <p>Books to Scrape: Demo website for web scraping purposes. Prices and ratings here were randomly assigned and have no real meaning. </p> </li> <li> <p>CORE: Open Access Research Papers: CORE provides a central API to access full content from tens of thousands of openly available scientific publications from thousands of OA repositories. Full datasets available by request. </p> </li> <li> <p>HathiTrust Research Center Analytics: Supports large-scale computational analysis of the works in the HathiTrust Digital Library to facilitate non-profit and educational research. </p> </li> <li> <p>Internet Archive: Internet Archive is a non-profit library of millions of free books, movies, software, music, websites, and more. </p> </li> <li> <p>Library of Congress (LC) for Robots: We hope this list of APIs, bulk downloads, and tutorials will help you begin exploring the many ways the Library of Congress provides machine-readable access to its digital collections. </p> </li> <li> <p>New York Times Developer Network: All the APIs fit to post. </p> </li> <li> <p>Project Gutenberg Robot Access: Project Gutenberg is a library of over 60,000 free eBooks. Information about robot access to our pages outlines allowable automated access to content. </p> </li> <li> <p>PubMed APIs: PMC hosts a number of important article datasets and makes our APIs and some code available via public code repositories. </p> </li> <li> <p>OpenAlex: is a fully open catalog of the global research system. It's named after the ancient Library of Alexandria and made by the nonprofit OurResearch.</p> </li> </ul>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"text_mining/#social-media-and-the-web","level":1,"title":"Social Media and the Web","text":"<p>For data collection from social media, it is typical to use the publicly available APIs made available by the social media platforms, such as the following:</p> <ul> <li> <p>X API   Access Twitter (X) data for posts, threads, comments, users, and more. Suitable for data mining and analysis.</p> </li> <li> <p>Google Blogger   API for accessing and managing Blogger content programmatically.</p> </li> <li> <p>Internet Archive Bulk Download   Download files from archive.org in an automated way using tools like <code>wget</code>.</p> </li> <li> <p>Reddit API   Access data from posts, threads, comments, users, and more from Reddit and its subreddits.</p> </li> <li> <p>Pushshift Reddit Data     Historical Reddit data collected as monthly CSV downloads.</p> </li> <li> <p>Stanford Large Network Dataset Collection (SNAP)   The SNAP library collects data on large social and information networks since 2004.</p> </li> <li> <p>Twitter Streaming APIs   Public streams provide access to real-time public data flowing through Twitter. Suitable for following specific users or topics and data mining. You can also access single-user streams, containing roughly all of the data corresponding with a single user’s view of Twitter.</p> </li> <li> <p>Wikipedia Data Dumps   Monthly database backups of all Wikimedia wikis in various formats.</p> </li> <li> <p>Yelp API   Access to business data, including location, photos, Yelp rating, price levels, hours of operation, and types of transactions. Also includes a Review API, which returns up to 3 review excerpts for a business.</p> </li> <li> <p>Blog Authorship Corpus   Over 600,000 posts from more than 19 thousand bloggers.</p> </li> </ul>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"text_mining/#government-documents","level":2,"title":"Government Documents","text":"<ul> <li> <p>Congress.gov API   Includes bills, amendments, summaries, Congress members, the Congressional Record, committee reports, nominations, treaties, and House Communications. Over time, hearing transcripts and Senate Communications will be added. Sign up for a free API key to use.</p> </li> <li> <p>ProQuest Congressional Text 1824-2020   Full text of United States Congressional Hearings (both House and Senate) from 1824-2020 as extracted by ProQuest. Delivered in bulk as XML files with pre-processing completed to extract individual hearing files, rename by hearing ID, and group into folders by decade. By accessing the data, you agree to abide by the included Terms of Use file. Read it thoroughly before use.</p> </li> <li> <p>CourtListener API / Bulk Legal Data   Access opinions, docket files, and more from 420 courts.</p> </li> <li> <p>FDSys Bulk Download   Bulk data downloads of major US Government publications including Congressional Bills, Commerce Business Daily, Federal Register, Public Papers of the Presidents of the United States, Supreme Court Decisions 1937-1975 (FLITE), and more.</p> </li> <li> <p>Harvard Caselaw Access Project   Includes all official, book-published United States case law—every volume designated as an official report of decisions by a court within the United States. Research scholars can qualify for bulk data access by agreeing to certain use and redistribution restrictions. Request a bulk access agreement by creating an account and then visiting your account page.</p> </li> <li> <p>U.S. Department of the Interior: Bureau of Land Management - General Land Office Records (GLO)   Provides direct access to all of the data behind the glorecords.blm.gov website with a series of web service methods in XML format.</p> </li> <li> <p>Voxgov   Provides access to real-time documents, press releases, and social media posts from candidates for Congress and governor across the U.S. Options to compare candidates and groups (e.g., Senate Democrats vs. Republicans), filter by geography or demographics, and generate term frequency charts and word clouds.</p> </li> <li> <p>United States Patent &amp; Trademark Open Data Portal   \"Open data\" is publicly available data that is structured in a way that enables the data to be fully discoverable and usable by end users. It can be freely used, reused, and redistributed by anyone. Its value lies not only in what it does today but also in what it can do in the future. It is a valuable national resource and a strategic asset to the federal government, its partners, and the public.</p> </li> </ul> <p>Original Source: https://libguides.princeton.edu/textmining/sources</p>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"transparency/","level":1,"title":"Transparency and Accountability","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Transparency is a cornerstone of developing trust, specifically when AI is involved in research, government, or healthcare.</p> <p>Definitions</p> <p>AI transparency is the degree of openness in a system design, the data that it uses, its operational framework. Transparency includes:</p> <ul> <li>Access to the data a system was trained upon</li> <li>Explanation of how a model arrives at its decisions</li> <li>List of guardrails, safeguards, and measures in place to mitigate bias</li> </ul> <p>Explainable AI (XAI) focuses on describing specific sequence of steps that an AI model undertakes to arrive at a result, prediction, or response. XAI includes AI transparency and enables comprehension. </p> <ul> <li>UNESCO's \"Transparency and Explainability\" is a core ethical principle, deeming it essential for the ethical deployment and trustworthy adoption of XAI technologies.</li> </ul>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"transparency/#establishing-accountability","level":2,"title":"Establishing Accountability","text":"<p>Coalition for Health AI (CHAI) advances the responsible development, deployment, and oversight of AI in healthcare</p> <p>NIST AI Risk Management Framework (AI RMF) has developed a framework to better manage risks to individuals, organizations, and society associated with AI.</p> <p>Organization for Economic Cooperation and Development (OECD) AI Principles promote use of AI that is innovative and trustworthy and that respects human rights and democratic values.</p> <p>World Health Organization (WHO) has released AI Ethics and governance guidelines for large multi-modal models </p> <p>EU AI Act is comprehensive legislation that includes oversight of AI with a six year (2031) implementation timeline, which is already underway.</p>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"transparency/#mechanisms","level":3,"title":"Mechanisms","text":"<p>Audits - regular systematic audits are essential, these includ bias audits to detect discrimination and fairness evaluations, security vulnerability checks, and performance reviews for accuracy and reliability. </p> <p>Human Oversight - high risk systems require human-in-the-loop approaches which are validated by human experts before implementation</p> <p>Governance Structures - clear and effective governance structures are fundamental to AI accountability. This involves defined leadership and oversight (boards), where responsibility across organizations is formalized and put into standard operating procedures. </p> <p>Record-keeping / Logs - traceability and auditability require detailed records of the AI system's operation and user actions. Audit rails provide invaluable resources for incident investigation, understanding system responses, and demonstrating compliance. </p>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"transparency/#transparency","level":2,"title":"Transparency","text":"The Black Box Problem  <p>Many AI models rely on complex architectures that function as \"black boxes,\" where their internal decision-making processes are opaque and not easily understood by human observers. This lack of transparency creates significant accountability challenges, especially in high-stakes fields like healthcare.</p> <p>A real-world example is the case of AI-enabled pulse oximeters, which were found to overstate blood oxygen saturation in individuals with darker skin. This flaw, rooted in biased training data, highlights how a lack of transparency can hide life-threatening biases within a medical device, leading to unequal care. (Read more at the ACLU)</p>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"transparency/#strategies-for-mitigation","level":3,"title":"Strategies for Mitigation","text":"<p>To counter the black box problem and foster responsible AI, several strategies are essential:</p> <ul> <li>Promoting Data Diversity and Bias Mitigation: Actively working to ensure training datasets are representative of the entire population to prevent algorithmic bias. This includes collecting more diverse data and using techniques to identify and correct biases in models.</li> <li>Strengthening Data Security and Privacy: Implementing robust security measures and privacy-preserving techniques (like federated learning or differential privacy) to protect sensitive data used by AI systems.</li> <li>Fostering Human-in-the-Loop (HITL) Approaches: Integrating human expertise and oversight into AI workflows. This ensures that critical decisions are validated by experts and allows for continuous monitoring and correction of AI behavior.</li> <li>Enhancing Transparency and Explainable AI (XAI): Developing and deploying XAI methods that can provide clear explanations for how a model arrived at a specific decision. This is crucial for building trust and enabling meaningful audits. For example, the open science movement advocates for making data and models used in health research publicly available to allow for independent verification and scrutiny. (Learn about Open Science in AI for Health)</li> </ul>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"transparency/#assessment","level":2,"title":"Assessment","text":"True or False: The 'black box' problem refers to the physical appearance of AI hardware. <p>False</p> <p>The \"black box\" problem describes the difficulty in understanding the internal decision-making processes of complex AI models.</p> Which of the following is NOT a core component of AI transparency? <p>A. Access to the data a system was trained upon</p> <p>B. The speed of the algorithm's computation</p> <p>C. Explanation of how a model arrives at its decisions</p> <p>D. List of safeguards in place to mitigate bias</p> Answer <p>B. The speed of the algorithm's computation </p> <p>While computational speed is a performance metric, it is not a core component of transparency, which focuses on openness, data, and decision-making logic.</p> What is the primary goal of Explainable AI (XAI)? <p>A. To make AI models run faster</p> <p>B. To describe the steps an AI model takes to reach a result</p> <p>C. To replace human oversight entirely</p> <p>D. To secure AI systems from cyberattacks</p> Answer <p>B: To describe the steps an AI model takes to reach a result</p> <p>XAI focuses on making the decision-making process of an AI model understandable to humans.</p> True or False: The EU AI Act is a set of voluntary guidelines for companies to consider. <p>False</p> <p>The EU AI Act is comprehensive legislation with a formal implementation timeline, making it a mandatory legal framework for AI governance in the European Union.</p> Which organization developed the AI Risk Management Framework (AI RMF) to manage risks associated with AI? <p>A. World Health Organization (WHO)</p> <p>B. Coalition for Health AI (CHAI)</p> <p>C. National Institute of Standards and Technology (NIST)</p> <p>D. Organization for Economic Cooperation and Development (OECD)</p> Answer <p>C: National Institute of Standards and Technology (NIST)</p> <p>NIST is responsible for the AI Risk Management Framework.</p>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"tutoring/","level":1,"title":"AI Tutoring: Student's Guide to Learning with AI","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#introduction","level":2,"title":"Introduction","text":"<p>Generative AI tools have transformed self-directed learning in 2026, offering 24/7 personalized tutoring support that was previously accessible only to students with private tutors or extensive institutional resources. Tools like ChatGPT 4.5, Claude 4.5, and Gemini 2.0 Flash provide sophisticated explanations, practice problems, and study support across virtually every academic subject.</p> <p>Beyond simply providing answers to prompts, AI can be used to interactively engage with topics, assess your understanding, generate practice materials, and provide feedback tailored to your individual learning style and needs.</p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#equity-and-access","level":3,"title":"Equity and Access","text":"<p>Access to AI unlocks new learning opportunities for traditionally underserved students:</p> <ul> <li>English Language Learners: AI tutors can explain concepts in your native language while helping you develop English proficiency. Platforms like Duolingo now use advanced AI for personalized language instruction.</li> <li>Students with Disabilities: Text-to-speech, voice interfaces, and multimodal interactions make AI tutoring accessible in ways traditional tutoring may not be.</li> <li>Resource-Constrained Students: Free AI tools provide tutoring support that would otherwise cost hundreds of dollars per month for human tutors.</li> <li>Non-Traditional Learners: Study at any time, at your own pace, without scheduling constraints of human tutors or office hours.</li> </ul> <p>However, it's essential to use AI as a learning tool, not a shortcut. This guide will help you leverage AI effectively while building genuine understanding and skills. </p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#use-cases","level":2,"title":"Use Cases","text":"<p>Here's how you can use AI to become a more effective self-tutor:</p> Explain Concepts <p>Struggling to grasp a difficult concept from lectures or textbooks? </p> <p>Have the AI explain them to you in a way that you understand.</p> <p>Complex ideas</p> PromptChatGPT o1 ResponseGemini Pro 2.0 Response <pre><code>Explain the concept of photosynthesis in simple terms, \nas if you were talking to a person who had never taken \nintroductory biology.\n</code></pre> <p>Photosynthesis is like a plant’s way of making its own food using sunlight. Here’s a simple way to picture what happens:</p> <ol> <li> <p>Sunlight as an Energy Source Plants have special “solar panels” in their leaves (the green parts called chloroplasts). These panels absorb sunlight.</p> </li> <li> <p>Taking In Raw Materials </p> </li> <li>Carbon Dioxide: Plants pull in a gas called carbon dioxide (CO₂) from the air through tiny holes in their leaves.  </li> <li> <p>Water: Plants also draw water (H₂O) up through their roots from the soil.</p> </li> <li> <p>Making Food (Sugar) and Releasing Oxygen Using sunlight as energy, plants combine the carbon dioxide and water to make a type of sugar (this is like a plant’s “food”). A byproduct of this process is oxygen, which is released into the air.</p> </li> <li> <p>Why It Matters </p> </li> <li>Plants Grow and Live: The sugar produced helps the plant grow, develop, and carry out all its functions.  </li> <li>We Breathe Oxygen: The oxygen released during photosynthesis is what most living things (including humans) need to breathe.  </li> </ol> <p>In short, photosynthesis is a natural process that keeps both plants and animals alive: plants get food for themselves, and they give off oxygen for us to breathe.</p> <p>Okay, imagine plants are like little chefs that make their own food. But instead of using an oven or a stove, they use sunlight! That process of making food using sunlight is called photosynthesis.</p> <p>Think of it like this:</p> <ol> <li> <p>Ingredients: Plants need ingredients to make their food, just like we do. They use two main things:</p> <ul> <li>Carbon dioxide: This is a gas that's in the air all around us. We actually breathe it out when we exhale! Plants \"breathe\" it in through tiny holes in their leaves.</li> <li>Water: Plants drink water through their roots, like we drink with a straw.</li> </ul> </li> <li> <p>The \"Kitchen\": Inside plant leaves, there are tiny little \"kitchens\" called chloroplasts. These are special because they are green, thanks to something called chlorophyll. Chlorophyll is like the chef's magic tool – it can capture the energy from sunlight.</p> </li> <li> <p>Cooking with Sunlight:  When sunlight hits the leaves, the chlorophyll traps its energy. This energy is then used like a power source to mix the carbon dioxide and water together.</p> </li> <li> <p>Food is Ready! This mixing process creates a kind of sugar called glucose, which is the plant's food. It's like the yummy meal the plant-chef made. The plant uses this food to grow, make flowers, fruits, and all that good stuff.</p> </li> <li> <p>Bonus – Oxygen!  As a byproduct of this amazing food-making process, plants release oxygen into the air.  This is fantastic for us because we need oxygen to breathe!</p> </li> </ol> <p>So, in a nutshell, photosynthesis is how plants use sunlight, water, and carbon dioxide to make their own food (sugar) and release oxygen into the air. It's like a super-efficient, solar-powered kitchen inside each leaf!</p> <p>It's a really important process because it's how plants grow, and it's also how we get the oxygen we need to live. Pretty cool, huh?                </p> <p>Use analogies and metaphors</p> Prompt <p>These can make abstract ideas more relatable. </p> <p>For example: </p> <pre><code>Give me an analogy to understand the concept of photosynthesis.\n</code></pre> <p>Explore different perspectives</p> Prompt <p>Ask the AI to explain a concept from various angles. </p> <p>For example, </p> <pre><code>Explain the theory of evolution in plants from \na biological, historical, and philosophical perspective.\n</code></pre> Reinforcement Learning <p>Generate practice questions</p> Prompt <p>Specify the topic and type of question. </p> <p>For example: </p> <pre><code>Create 5 multiple-choice questions about the causes \nof World War I.\n</code></pre> <p>Get feedback on your answers</p> <p>Paste in your answers and ask for a critique. </p> <p>For example: </p> <pre><code>Here's my answer to the question: [question]. \n\n[answer]\n\nIs it correct, and how could I improve it?\n</code></pre> <p>Create study guides and summaries</p> <p>For example: </p> <pre><code>Generate a study guide for the chapter on the \nFrench Revolution in my history textbook\n</code></pre> <p>or </p> <pre><code>Create flashcards of the key reactions, \nincluding their reactant, products and the \nmechanism for this Organic Chemistry chapter\n</code></pre> Facilitated Discussion <p>Use Case: Want to engage in deeper discussions about the material, but study partners are unavailable?</p> <p>Simulated debate</p> <p>Take a stance on a topic and ask the AI to argue the opposing viewpoint. </p> <p>For example: </p> <pre><code>I believe social media has a net positive impact on society. \n\nArgue against this position.\n</code></pre> <p>Explore \"what if\" scenarios:</p> <p>Pose hypothetical questions to probe the material further. </p> <p>For example: </p> <pre><code>What if the outcome of the American Civil War had been different? \n\nHow might history have changed?\n</code></pre> <p>Role-play historical figures or characters:</p> <p>For example: </p> <pre><code>Pretend you are Marie Curie, and explain your research on radioactivity \nin a way that a non-scientist could understand.\n</code></pre> Enhancing Writing and Research Skills <p>Use Case: Struggling with essay writing, research paper organization, or finding relevant sources?</p> <p>Brainstorm essay topics and outlines:</p> <p>For example: </p> <pre><code>Help me brainstorm topics for an essay on the impact of climate change.\n</code></pre> <p>or </p> <pre><code>Create an outline for a research paper on the ethical implications of artificial intelligence.\n</code></pre> <p>Get feedback on your writing:</p> <p>Paste in your draft and ask for suggestions on clarity, grammar, and style. </p> <p>For example: </p> <pre><code>Review this paragraph and suggest improvements to make it more concise and impactful.\n</code></pre> <p>Summarize research articles:</p> <p>For example: </p> <pre><code>Summarize the main findings of this research article: [link to article or text of article].\n</code></pre> <pre><code>Please extract the key takeaways from the following report on renewable energy trends.\n</code></pre> Reflecting on Your Learning Process <p>Use Case: Need help identifying your learning strengths and weaknesses or developing better study habits?</p> <p>Analyze your study sessions:</p> <p>Describe your study routine to the AI and ask for suggestions for improvement.  For example: </p> <pre><code>I tend to study for long hours but get easily distracted. \nHow can I make my study sessions more efficient?\n</code></pre> <p>Identify knowledge gaps:</p> <p>Ask the AI to quiz you on a topic and point out areas where you need further review. </p> <p>For example: </p> <pre><code>Quiz me on the main concepts of macroeconomics, and tell me which areas I need to study more.\n</code></pre> <p>Get personalized learning recommendations:</p> <p>Explain your learning style and preferences to the AI and ask for tailored advice. </p> <p>For example: </p> <pre><code>I'm a visual learner. What are some effective study strategies for me?\n</code></pre>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#using-chatgptgemini-as-a-study-buddy","level":2,"title":"Using ChatGPT/Gemini as a Study Buddy","text":"<p>Exam Preparation</p> Generate questions Prompt <pre><code>Generate practice questions on this: {paste material or give topic}\n</code></pre> Multiple-choice questions Prompt <pre><code>Generate multiple choice questions on this: {paste material or give topic\n</code></pre> Create flashcards Prompt <pre><code>Create flashcards on this topic for me: {paste material or give topic}\n</code></pre> Improve text/explanation Prompt <pre><code>How can the following text/explanation about {topic} be improved?: {paste text}\n</code></pre> Mnemonics Prompt <pre><code>Help me remember the 5 most common facts/properties about {topic}\n</code></pre> Historical or factual events Prompt <pre><code>Help me memorize US History\n</code></pre> <p>Formulas and equations assistance</p> Step-by-step instructions Prompt <pre><code>Find the derivative of f(x) = 3x^3 + 2x^2 + 1\n</code></pre> Concepts clarification Prompt <pre><code>Clarify the concept for the equation: Find the derivative of f(x) = 3x^3 + 2x^2 + 1\n</code></pre> <p>Language learning</p> Vocabulary building Prompt <pre><code>What does 'aimer' mean in French and what is the antonym?\n</code></pre> Conversation practice Prompt <pre><code>Engage me in a conversation in French (I'm a beginner)\n</code></pre>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#specialized-tutoring-ai-by-subject","level":2,"title":"Specialized Tutoring AI by Subject","text":"<p>While general-purpose AI tools like ChatGPT and Claude are powerful, subject-specific AI tutors often provide more targeted support with specialized features:</p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#mathematics-and-stem","level":3,"title":"Mathematics and STEM","text":"<ul> <li>Photomath AI: Take a photo of a math problem and get step-by-step solutions with explanations. Now includes AI-powered tutoring beyond just solving.</li> <li>Wolfram Alpha: Computational knowledge engine for advanced math, science, and engineering problems. Provides symbolic computation and detailed solutions.</li> <li>Mathway: Math problem solver with AI-powered explanations across algebra, calculus, statistics, and more.</li> </ul>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#writing-and-composition","level":3,"title":"Writing and Composition","text":"<ul> <li>Grammarly AI: Beyond grammar checking, now offers AI-powered writing suggestions, tone detection, and clarity improvements.</li> <li>QuillBot: AI paraphrasing, summarization, grammar checking, and citation generation. Useful for rephrasing complex text or improving clarity.</li> <li>Hemingway Editor: Analyzes writing for readability and suggests simpler alternatives.</li> </ul> <p>Using Writing AI Ethically</p> <p>Acceptable:</p> <ul> <li>Grammar and clarity checking on your own writing</li> <li>Suggestions for rephrasing awkward sentences</li> <li>Learning about different ways to express ideas</li> </ul> <p>Unacceptable:</p> <ul> <li>Having AI write your assignments</li> <li>Using AI-generated text without disclosure</li> <li>Paraphrasing sources through AI to avoid citation</li> </ul> <p>Always check your course syllabus for specific AI policies. When in doubt, ask your instructor.</p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#coding-and-computer-science","level":3,"title":"Coding and Computer Science","text":"<ul> <li>GitHub Copilot (Student): AI pair programmer that suggests code completions and entire functions. Free for students.</li> <li>Replit AI: AI-powered code explanation, generation, and debugging in an online IDE.</li> <li>CodeAcademy AI Assistant: Built-in AI tutor for coding lessons and exercises.</li> </ul>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#science-labs-and-simulations","level":3,"title":"Science Labs and Simulations","text":"<ul> <li>Labster AI: Virtual lab simulations with AI-guided experiments for biology, chemistry, and physics.</li> <li>PhET Interactive Simulations: Free science and math simulations (AI-enhanced guidance in development).</li> </ul>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#subject-specific-comparison-table","level":3,"title":"Subject-Specific Comparison Table","text":"Subject Best AI Tool Strengths Free/Paid Algebra &amp; Calculus Photomath AI, Wolfram Alpha Step-by-step solutions, visual graphs Freemium Writing &amp; Essays Grammarly, QuillBot, Claude Grammar, style, clarity feedback Freemium Coding (Python, Java, etc.) GitHub Copilot, Replit AI Code completion, debugging, explanations Free for students Chemistry Labster, ChatGPT with images Virtual labs, reaction explanations Mixed Languages Duolingo Max, ChatGPT Voice Conversation practice, pronunciation Freemium History &amp; Humanities ChatGPT, Claude Essay feedback, source analysis Freemium","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#multimodal-learning-with-ai","level":2,"title":"Multimodal Learning with AI","text":"<p>Modern AI tutors support multiple interaction modes beyond text, making learning more engaging and accessible:</p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#voice-based-tutoring","level":3,"title":"Voice-Based Tutoring","text":"<p>ChatGPT Voice Mode (ChatGPT Plus/Team/Enterprise):</p> <ul> <li>Have spoken conversations with your AI tutor</li> <li>Practice pronunciation for language learning</li> <li>Discuss concepts hands-free while studying</li> <li>Useful for students with reading difficulties or visual impairments</li> </ul> <p>Claude on Mobile (Claude app):</p> <ul> <li>Voice input for questions and explanations</li> <li>Text-to-speech for responses</li> <li>Useful for studying on the go</li> </ul> <p>Google Gemini Voice:</p> <ul> <li>Integrated with Google Assistant</li> <li>Ask questions verbally and receive spoken responses</li> <li>Hands-free learning while commuting or exercising</li> </ul> <p>Effective Voice Tutoring Strategies</p> <p>For Language Learning: <pre><code>\"Let's have a conversation in Spanish. I'm at an intermediate level.\nCorrect my pronunciation and grammar gently as we talk.\"\n</code></pre></p> <p>For Concept Review: <pre><code>\"I'm going to explain [concept] to you verbally. Listen and then\npoint out any gaps or errors in my understanding.\"\n</code></pre></p> <p>For Study Sessions: <pre><code>\"Quiz me verbally on [topic]. After I answer, explain what I got\nright and where I need to improve.\"\n</code></pre></p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#image-based-problem-solving","level":3,"title":"Image-Based Problem Solving","text":"<p>Upload images of:</p> <ul> <li>Handwritten homework problems - Get step-by-step solutions</li> <li>Textbook pages - Ask questions about specific content</li> <li>Diagrams and charts - Request explanations of visual data</li> <li>Lab results - Analyze data and suggest interpretations</li> <li>Historical documents - Analyze primary sources</li> </ul> <p>Example Tools:</p> <ul> <li>ChatGPT Plus/Team - Advanced image understanding with GPT-4.5</li> <li>Claude 4.5 - Excellent at analyzing complex diagrams and charts</li> <li>Gemini 2.0 Flash - Fast image analysis, good for quick questions</li> <li>Google Lens - Identify objects, plants, landmarks, translate text</li> </ul> <p>Uploading Homework for Help</p> <p>Good Practice:</p> <ol> <li>Upload image of the problem</li> <li>Ask AI to explain the concept, not just solve it</li> <li>Try solving similar problems yourself</li> <li>Use AI to check your work and explain errors</li> </ol> <p>Example Prompt: <pre><code>[Upload image of calculus problem]\n\nI'm stuck on this problem. Don't give me the answer directly.\nInstead, explain what concept I need to use and give me a hint\nfor the first step. Then let me try before you help more.\n</code></pre></p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#video-explanations","level":3,"title":"Video Explanations","text":"<p>AI-Generated Video Content:</p> <ul> <li>Use AI to create study videos on demand</li> <li>Generate animations of scientific processes</li> <li>Create visual timelines for historical events</li> </ul> <p>Tools:</p> <ul> <li>Ask ChatGPT or Claude to create educational videos via plugins/tools</li> <li>Use AI to generate presentation slides with explanations</li> <li>Request flowcharts, concept maps, and diagrams</li> </ul>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#study-planning-and-metacognition","level":2,"title":"Study Planning and Metacognition","text":"<p>AI can help you become a more strategic, self-aware learner by supporting study planning and reflection on your learning process.</p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#ai-study-schedule-generators","level":3,"title":"AI Study Schedule Generators","text":"<p>Create personalized study schedules based on your courses, commitments, and learning style:</p> <pre><code>I have the following exams coming up:\n- Organic Chemistry midterm on March 15 (worth 30% of grade, need to review 8 chapters)\n- Calculus II final on March 20 (comprehensive, 12 chapters total)\n- Spanish presentation on March 10 (need to prepare 10-minute talk)\n\nI have class M/W/F from 9-12 and work T/Th from 2-6pm. Create a detailed\nstudy schedule for the next 3 weeks that uses spaced repetition and\nbalances all three subjects. Include specific study tasks for each session.\n</code></pre>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#spaced-repetition-optimization","level":3,"title":"Spaced Repetition Optimization","text":"<p>AI can design review schedules that leverage spaced repetition for better retention:</p> <pre><code>I'm learning [topic] and have created these flashcard sets [list topics].\nBased on the forgetting curve, design a review schedule that optimizes\nlong-term retention. Tell me what to review each day for the next 2 weeks.\n</code></pre>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#progress-tracking-prompts","level":3,"title":"Progress Tracking Prompts","text":"<p>Use AI to reflect on your learning and identify areas needing more focus:</p> <pre><code>I just finished studying [topic] for 2 hours. Quiz me with 5 questions\nof increasing difficulty to assess my understanding. Based on my responses,\ntell me which concepts I should review more and which I've mastered.\n</code></pre>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#metacognitive-reflection","level":3,"title":"Metacognitive Reflection","text":"<p>Build self-awareness about your learning process:</p> <pre><code>I've been struggling with [specific topic] despite studying for several\nhours. Help me analyze why I might be struggling:\n- What are common misconceptions about this topic?\n- What prerequisite knowledge might I be missing?\n- What alternative explanations or approaches might help me understand?\n- What study strategies would be most effective for this type of material?\n</code></pre> <p>Study Planning Prompt Template</p> <p>Weekly Study Review: <pre><code>This week I studied:\n- [Subject 1]: [Hours spent] on [specific topics]\n- [Subject 2]: [Hours spent] on [specific topics]\n- [Subject 3]: [Hours spent] on [specific topics]\n\nMy performance on quizzes/assignments:\n- [Subject 1]: [Grade/feedback]\n- [Subject 2]: [Grade/feedback]\n\nBased on this, create a prioritized study plan for next week that:\n1. Allocates more time to subjects where I'm struggling\n2. Maintains review of subjects where I'm doing well\n3. Uses effective study strategies for each subject type\n4. Fits into [X] hours of available study time\n</code></pre></p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#ai-limitations-for-students-when-not-to-use-ai","level":2,"title":"AI Limitations for Students: When NOT to Use AI","text":"<p>While AI tutoring offers tremendous benefits, it's crucial to understand when using AI can actually hurt your learning. Overreliance on AI can prevent you from developing critical skills and genuine understanding.</p> <p>Don't Let AI Replace Learning</p> <p>AI is a tool to support learning, not a replacement for learning.</p> <p>Using AI inappropriately can:</p> <ul> <li>Prevent development of critical thinking skills</li> <li>Create dependency rather than independence</li> <li>Lead to academic integrity violations</li> <li>Result in shallow understanding that fails on exams</li> <li>Prevent development of problem-solving abilities</li> </ul>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#when-you-should-not-use-ai","level":3,"title":"When You Should NOT Use AI","text":"<p>1. During Exams and Quizzes (Unless Explicitly Allowed)</p> <ul> <li>Using AI during assessments is cheating</li> <li>Violates academic integrity policies</li> <li>Can result in failing the course or expulsion</li> <li>Defeats the purpose of assessment (measuring YOUR knowledge)</li> </ul> <p>2. For Final Drafts of Assignments (Without Disclosure)</p> <ul> <li>Having AI write your assignments is plagiarism</li> <li>Submitting AI-generated work without disclosure violates academic integrity</li> <li>You miss the learning opportunity that comes from struggling with ideas</li> <li>Professors can often detect AI-generated work</li> </ul> <p>3. When You Need to Build Foundational Skills</p> <ul> <li>Learning basic arithmetic (before moving to advanced math)</li> <li>Developing initial writing skills</li> <li>Building problem-solving strategies</li> <li>Memorizing essential foundational knowledge</li> </ul> <p>Using AI too early prevents building the foundation you need for advanced work.</p> <p>4. When You Should Be Struggling (Productive Struggle)</p> <p>Learning often requires productive struggle—working through challenges builds neural pathways and deep understanding. If you immediately ask AI every time you're confused:</p> <ul> <li>You deny yourself the \"aha!\" moment that leads to true understanding</li> <li>You don't develop perseverance and problem-solving strategies</li> <li>You miss the opportunity to learn from mistakes</li> </ul> <p>Better approach: Struggle for 10-15 minutes first, then use AI to get a hint (not the full answer).</p> <p>5. For Verifying Information Without Fact-Checking</p> <ul> <li>AI can hallucinate (make up) facts, dates, citations, and sources</li> <li>AI may present biased or outdated information</li> <li>AI doesn't have access to current events or recent developments</li> <li>AI may misunderstand specialized or technical terminology</li> </ul> <p>Always verify AI information against:</p> <ul> <li>Course textbooks and readings</li> <li>Peer-reviewed academic sources</li> <li>Expert sources in the field</li> <li>Your instructor's explanations</li> </ul>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#recognizing-ai-hallucinations","level":3,"title":"Recognizing AI Hallucinations","text":"<p>AI tutors sometimes confidently present incorrect information. Watch for:</p> <p>Red Flags for Hallucinations:</p> <ul> <li>Specific facts, dates, or names that seem too convenient</li> <li>Citations to sources that don't exist (AI makes up author names and titles)</li> <li>Scientific claims without supporting evidence</li> <li>Historical events described with suspicious precision</li> <li>Mathematical solutions that don't check when you verify</li> </ul> <p>How to Catch Hallucinations:</p> <ul> <li>Cross-reference: Check AI claims against your textbook or course materials</li> <li>Ask for sources: Request where the information comes from (but don't trust AI-provided citations without verification)</li> <li>Test the logic: Does the explanation make sense? Does the math work?</li> <li>Ask your instructor: When AI contradicts course materials, ask your professor</li> </ul> Real Hallucination Examples <p>Example 1: Fake Citation</p> <p>Student: \"What research exists on [topic]?\"</p> <p>AI: \"According to Smith &amp; Jones (2021) in their paper 'XYZ Study' published in Journal of ABC...\"</p> <p>Reality: This paper doesn't exist. AI made it up.</p> <p>Example 2: Confidently Wrong Math</p> <p>Student: \"What's the derivative of f(x) = x^2 + 3x + 2?\"</p> <p>AI: \"The derivative is f'(x) = 2x + 3x + 0 = 5x\"</p> <p>Reality: The derivative is f'(x) = 2x + 3. AI incorrectly added the terms.</p> <p>Example 3: Historical Fiction</p> <p>Student: \"Tell me about the Treaty of [fictional name].\"</p> <p>AI: [Provides detailed description of treaty, dates, signatories, implications]</p> <p>Reality: No such treaty exists. AI generated plausible but fictional history.</p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#building-genuine-understanding-vs-answer-seeking","level":3,"title":"Building Genuine Understanding vs. Answer-Seeking","text":"<p>Answer-Seeking (Ineffective Learning):</p> <p>❌ \"What's the answer to problem 5 on page 142?\"</p> <p>❌ \"Write a 500-word essay on [topic].\"</p> <p>❌ \"Solve this for me: [complex equation].\"</p> <p>Understanding-Building (Effective Learning):</p> <p>✓ \"I'm trying to solve problem 5 on page 142. I think I should use [concept], but I'm not sure how to start. Can you explain the concept without solving it for me?\"</p> <p>✓ \"I'm writing an essay on [topic]. I've drafted this thesis: [your thesis]. Is my logic sound? What counterarguments should I address?\"</p> <p>✓ \"I tried solving [equation] using [method] and got [your answer]. Can you check my work and point out where I went wrong without giving me the answer?\"</p> <p>The Difference:</p> <ul> <li>Answer-seeking gets you the right answer but teaches you nothing</li> <li>Understanding-building helps you develop the skills to solve similar problems independently</li> </ul>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#academic-integrity-boundaries","level":3,"title":"Academic Integrity Boundaries","text":"<p>Different institutions and instructors have different AI policies. Always:</p> <ol> <li>Read your syllabus - Specific AI policies may be outlined</li> <li>Ask when unclear - Email your instructor if AI use is ambiguous</li> <li>Disclose AI use - When submitting work, note how you used AI</li> <li>Err on the side of caution - If unsure whether AI use is allowed, ask first</li> </ol> <p>Generally Safe:</p> <ul> <li>Explaining concepts covered in course materials</li> <li>Generating practice problems for self-study</li> <li>Checking grammar and clarity (not content) of your writing</li> <li>Creating study guides and flashcards</li> </ul> <p>Generally Problematic:</p> <ul> <li>Writing any portion of assignments submitted for credit</li> <li>Using AI during exams or timed assessments</li> <li>Having AI solve homework problems you submit</li> <li>Using AI to generate citations without verification</li> </ul> <p>See Plagiarism &amp; AI Detection for comprehensive discussion of academic integrity in the AI era and Teaching with AI for understanding faculty perspectives.</p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#peer-tutoring-with-ai","level":2,"title":"Peer Tutoring with AI","text":"<p>AI can enhance peer tutoring programs and peer-led study groups:</p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#using-ai-to-support-peer-tutoring-sessions","level":3,"title":"Using AI to Support Peer Tutoring Sessions","text":"<p>Preparation:</p> <ul> <li>Peer tutors use AI to brush up on concepts before tutoring sessions</li> <li>Generate example problems at different difficulty levels</li> <li>Prepare alternative explanations for challenging concepts</li> <li>Create visual aids and diagrams for explanations</li> </ul> <p>During Sessions:</p> <ul> <li>Use AI to look up information quickly when tutor isn't sure</li> <li>Generate additional practice problems on the spot</li> <li>Provide multiple approaches to explaining the same concept</li> <li>Create immediate feedback for student work</li> </ul> <p>After Sessions:</p> <ul> <li>Document what was covered for tutor reports</li> <li>Generate follow-up practice materials for tutees</li> <li>Create study guides summarizing session content</li> </ul>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#ai-enhanced-study-groups","level":3,"title":"AI-Enhanced Study Groups","text":"<p>Effective Study Group Prompts:</p> <pre><code>Our study group is preparing for an exam on [topics]. Generate:\n1. 10 multiple choice questions covering key concepts\n2. 5 short-answer questions requiring application of concepts\n3. 2 essay questions requiring synthesis of ideas\n4. Answer keys with explanations\n\nWe'll divide these among group members to solve, then teach each other.\n</code></pre> <pre><code>We're a study group of 4 students. Create a jigsaw activity where\neach person becomes an \"expert\" on one aspect of [topic], then teaches\nthe others. Provide:\n- 4 distinct subtopics that together cover the whole concept\n- Key points each expert should understand\n- Questions the other students should ask each expert\n</code></pre>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#training-peer-tutors-with-ai","level":3,"title":"Training Peer Tutors with AI","text":"<p>Peer tutoring programs can use AI to train student tutors:</p> <ul> <li>Simulate challenging tutee scenarios and questions</li> <li>Practice explaining concepts in multiple ways</li> <li>Generate rubrics for assessing tutee understanding</li> <li>Create documentation templates for tracking progress</li> </ul> <p>Peer Tutoring Best Practice</p> <p>Use AI as a resource, not a crutch:</p> <ul> <li>Try answering the question yourself first</li> <li>Use AI to verify your explanation or get additional context</li> <li>Encourage tutees to engage with AI independently for practice</li> <li>Focus human interaction on motivation, metacognition, and complex problem-solving</li> </ul>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"tutoring/#educational-ai-platforms","level":2,"title":"Educational AI Platforms","text":"<p>For a comprehensive comparison of AI-powered educational platforms including IXL, Khan Academy, Duolingo, Codecademy, and more, see:</p> <p>📚 Educational AI Platforms Comparison Table</p> <p>The table includes: - Subject areas and target audiences - Current pricing (verified January 2026) - Key features and capabilities - Links to all platforms</p> <p>Popular platforms include: - Free Options: Khan Academy, Duolingo (basic), Quizlet (basic), Google Classroom - Affordable: IXL (\\(9.95-\\)19.95/mo), Codecademy Pro (\\(39.99/mo), Brilliant (\\)24.99/mo) - Career Development: Google Career Certificates ($49/mo), Coursera, EdX - Language Learning: Duolingo, with AI-powered conversation practice </p>","path":["Education","AI Tutoring: Student's Guide to Learning with AI"],"tags":[]},{"location":"vibe/","level":1,"title":"Vibe Coding","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>\"Vibe coding\" refers to using an LLM to generate and edit code directly within your IDE (e.g., VS Code). This approach allows for a more fluid and interactive coding experience, where the LLM acts as a collaborative partner.</p> Who coined the term 'vibe coding'? <p>The term \"vibe coding\" originated with a tweet by Andrej Karpathy in February 2025,</p> <p><p>There's a new kind of coding I call \"vibe coding\", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. I just mass chat, mass accept, skip to errors,…</p>— Andrej Karpathy (@karpathy) February 2, 2025 </p> <p>Allowing an LLM to execute code on your computer may be a violation of institutional security and privacy policy</p> <p>Desktop applications like Claude Desktop or OpenAI's ChatGPT Desktop give you the option to allow 'execution' of code on your computer (laptop or PC). </p> <p>You must understand the implications of giving these AI assistants the authority to execute code on your computer and access to the network it is running upon.</p> <p>Malicious code lives on the internet, and your Vibing AI assistant might install something bad while you're not paying attention</p> <p>Read more:  Vibe Check: False Packages A New LLM Security Risk (Note: This is a fictional link as per the example for demonstration).</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#available-platforms","level":2,"title":"Available Platforms","text":"Emoji Meaning VS Code GitHub CodeSpace Apple OS Windows Linux Command Line Interface Open Source Licensed API based","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#desktop-ides-and-standalone-editors","level":3,"title":"Desktop IDEs and Standalone Editors","text":"","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#claude-desktop","level":4,"title":"Claude Desktop","text":"<p>An easy-to-install desktop platform that connects to Anthropic's powerful LLM API, and allows you to connect to MCP servers.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#vs-code","level":4,"title":"VS Code","text":"<p>Microsoft's popular open-source code editor with extensive extension ecosystem, including numerous AI coding assistants (see VS Code Extensions section below).</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#cursor","level":4,"title":"Cursor","text":"<p>A popular standalone fork of VS Code, focused on integrating new models with stability and offering a flat-fee pricing model.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#positron","level":4,"title":"Positron","text":"<p>A next-generation data science IDE built on VS Code, developed by Posit (formerly RStudio), with native support for Python, R, and AI-assisted coding.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#firebase-studio","level":4,"title":"Firebase Studio","text":"<p>Firebase's integrated development environment for building and deploying Firebase apps with AI-powered code generation and assistance.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#google-antigravity","level":4,"title":"Google Antigravity","text":"<p>Google's experimental AI-powered standalone IDE with advanced Gemini integration for next-generation development workflows.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#windsurf","level":4,"title":"Windsurf","text":"<p>Standalone editor offering similar agentic and inline features with tiered pricing and a \"just works\" usability orientation.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#vs-code-extensions","level":3,"title":"VS Code Extensions","text":"","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#claude-code","level":4,"title":"Claude Code","text":"<p>Official Anthropic VS Code extension providing AI pair programming with Claude 4.5 models, featuring multi-file editing, debugging, and terminal integration.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#gemini-cli-companion","level":4,"title":"Gemini CLI Companion","text":"<p>Google's VS Code extension powered by Gemini models, offering code completion, generation, and chat assistance with Google Cloud integration.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#openai-codex","level":4,"title":"OpenAI Codex","text":"<p>Codex is integrated as an extension in VS Code</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#github-copilot","level":4,"title":"GitHub Copilot","text":"<p>Integrated with VS Code and GitHub CodeSpaces, provides agentic coding with periodic performance fluctuations and tiered pricing.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#cline","level":4,"title":"Cline","text":"<p>VS Code extension that's open-source and model-agnostic, pioneering features like \"bring your own model\" (BYOM) and operating on a per-request billing structure.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#roo-code","level":4,"title":"Roo Code","text":"<p>VS Code extension derived from Cline, prioritizes rapid feature development and customization, serving users interested in experimental capabilities.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#command-line-interface-cli-tools","level":3,"title":"Command Line Interface (CLI) Tools","text":"","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#aider","level":4,"title":"Aider","text":"<p>A popular command-line tool for AI-driven coding, often used with local or remote LLMs.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#claude-code-cli","level":4,"title":"Claude Code CLI","text":"<p>Official Anthropic command-line interface for Claude, enabling AI-assisted development directly from the terminal with support for MCP servers.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#openai-codex-cli","level":4,"title":"OpenAI Codex CLI","text":"<p>Command-line access to OpenAI's Codex models, integrated with GitHub Copilot for terminal-based AI assistance.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#google-gemini-cli","level":4,"title":"Google Gemini CLI","text":"<p>Google's command-line interface for Gemini models, providing AI coding assistance and integration with Google Cloud services.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#opencodeai","level":4,"title":"OpenCode.ai","text":"<p>Open-source CLI tool supporting multiple AI models for code generation, analysis, and refactoring from the command line.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#browser-based-vibe-coding","level":3,"title":"Browser-based Vibe Coding","text":"","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#claude-code_1","level":4,"title":"Claude Code","text":"<p>Browser-based version of Claude Code providing AI pair programming capabilities through the web, featuring multi-file editing, code generation, and debugging without requiring a desktop installation.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#chatgpt","level":4,"title":"ChatGPT","text":"<p>OpenAI's ChatGPT Plus and Team tiers include Code Interpreter (Advanced Data Analysis) for executing Python code, analyzing data, and generating visualizations directly in the browser.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#google-gemini","level":4,"title":"Google Gemini","text":"<p>Google Gemini's web interface features code execution capabilities, allowing you to run Python code and see results inline with AI-generated explanations.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#openwebui","level":4,"title":"OpenWebUI","text":"<p>Self-hostable, open-source web interface supporting multiple LLM providers (OpenAI, Anthropic, Ollama) with built-in code execution, function calling, and customizable workflows.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#model-context-protocol-mcp","level":1,"title":"Model Context Protocol (MCP)","text":"<p> Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools. This ensures interoperability and allows developers to more easily swap out models or context sources without re-engineering their entire application.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vscode/","level":1,"title":"Visual Studio Code and AI-Powered Development","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#overview","level":2,"title":"Overview","text":"<p>Visual Studio Code (VS Code) has become the world's most popular code editor, used by over 70% of developers worldwide. Its extensibility, cross-platform support, and vibrant ecosystem make it an ideal foundation for AI-powered development workflows.</p> <p>This guide covers:</p> <ul> <li>VS Code installation on all major platforms</li> <li>Alternative VS Code-based IDEs (Positron, Google Antigravity)</li> <li>AI coding extensions (Claude Code, GitHub Copilot, Cline, Roo Code, and more)</li> <li>Local AI integration with Ollama</li> <li>Practical workflows for academic users</li> </ul> <p>Why VS Code for AI-Assisted Coding?</p> <p>VS Code offers unique advantages for AI-powered development:</p> <ul> <li>Extensive AI extension ecosystem - Choose from dozens of AI assistants</li> <li>Integrated terminal - Run AI-generated code without leaving the editor</li> <li>Multi-file editing - AI tools can understand and modify entire projects</li> <li>Git integration - Version control your AI-assisted work</li> <li>Free and open-source - No licensing costs for the base editor</li> <li>Cross-platform - Same experience on Windows, macOS, and Linux</li> </ul>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#1-installing-visual-studio-code","level":2,"title":"1. Installing Visual Studio Code","text":"","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#windows","level":3,"title":"Windows","text":"Windows Installer (Recommended)Windows Package Manager (winget)Chocolatey <ol> <li>Download the VS Code installer for Windows</li> <li>Run the downloaded <code>.exe</code> file</li> <li>Follow the installation wizard:<ul> <li>Accept the license agreement</li> <li>Choose the installation location (default is recommended)</li> <li>Select additional tasks:<ul> <li> Add \"Open with Code\" to context menu</li> <li> Register Code as an editor for supported file types</li> <li> Add to PATH (important for command-line use)</li> </ul> </li> </ul> </li> <li>Click Install and then Finish</li> </ol> <pre><code># Install VS Code via winget\nwinget install Microsoft.VisualStudioCode\n\n# Verify installation\ncode --version\n</code></pre> <pre><code># Install Chocolatey first if not installed\n# Then install VS Code\nchoco install vscode\n\n# Verify installation\ncode --version\n</code></pre>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#macos","level":3,"title":"macOS","text":"Direct Download (Recommended)Homebrew <ol> <li>Download VS Code for macOS</li> <li>Open the downloaded <code>.zip</code> file</li> <li>Drag Visual Studio Code.app to the Applications folder</li> <li>Launch VS Code from Applications or Spotlight</li> <li>(Optional) Add to Dock for quick access</li> </ol> <p>Enable Command Line:</p> <ol> <li>Open VS Code</li> <li>Press Cmd+Shift+P to open the Command Palette</li> <li>Type \"shell command\" and select Shell Command: Install 'code' command in PATH</li> <li>Now you can open files with <code>code filename.py</code> from Terminal</li> </ol> <pre><code># Install VS Code via Homebrew\nbrew install --cask visual-studio-code\n\n# Verify installation\ncode --version\n</code></pre>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#linux","level":3,"title":"Linux","text":"Ubuntu/Debian (apt)Fedora/RHEL (dnf)SnapFlatpak <pre><code># Download and install the Microsoft GPG key\nwget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor &gt; packages.microsoft.gpg\nsudo install -D -o root -g root -m 644 packages.microsoft.gpg /etc/apt/keyrings/packages.microsoft.gpg\n\n# Add the VS Code repository\nsudo sh -c 'echo \"deb [arch=amd64,arm64,armhf signed-by=/etc/apt/keyrings/packages.microsoft.gpg] https://packages.microsoft.com/repos/code stable main\" &gt; /etc/apt/sources.list.d/vscode.list'\n\n# Update and install\nsudo apt update\nsudo apt install code\n\n# Verify installation\ncode --version\n</code></pre> <pre><code># Import the Microsoft GPG key\nsudo rpm --import https://packages.microsoft.com/keys/microsoft.asc\n\n# Add the VS Code repository\nsudo sh -c 'echo -e \"[code]\\nname=Visual Studio Code\\nbaseurl=https://packages.microsoft.com/yumrepos/vscode\\nenabled=1\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc\" &gt; /etc/yum.repos.d/vscode.repo'\n\n# Install VS Code\nsudo dnf check-update\nsudo dnf install code\n\n# Verify installation\ncode --version\n</code></pre> <pre><code># Install VS Code via Snap\nsudo snap install code --classic\n\n# Verify installation\ncode --version\n</code></pre> <pre><code># Install VS Code via Flatpak\nflatpak install flathub com.visualstudio.code\n\n# Run VS Code\nflatpak run com.visualstudio.code\n</code></pre>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#verify-installation","level":3,"title":"Verify Installation","text":"<p>After installation, verify VS Code is working:</p> <pre><code># Check VS Code version\ncode --version\n\n# Open current directory in VS Code\ncode .\n\n# Open a specific file\ncode myfile.py\n</code></pre>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#2-alternative-vs-code-based-ides","level":2,"title":"2. Alternative VS Code-Based IDEs","text":"<p>Several alternative IDEs build on VS Code's foundation, offering specialized features for different workflows.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#posit-positron","level":3,"title":"Posit Positron","text":"<p> Positron is a next-generation data science IDE developed by Posit (formerly RStudio). Built on VS Code's foundation, it provides native support for Python and R with a data-science-focused interface.</p> <p>Key Features:</p> Feature Description Multi-language Console Switch between R and Python in the same session Variables Pane Inspect data frames, lists, and objects visually Data Viewer Explore large datasets with filtering and sorting Plot Pane View and export visualizations interactively VS Code Extensions Access the full VS Code extension marketplace Quarto Integration Native support for scientific publishing <p>AI Integration:</p> <p>Positron supports the same AI extensions as VS Code, plus Posit's own AI packages:</p> <ul> <li>ellmer (R) - Unified interface for 20+ LLM providers</li> <li>chatlas (Python) - LLM chat framework with streaming and tool calling</li> </ul> <p>See Full Installation Instructions</p> <p>For detailed Positron installation instructions, see our Posit (RStudio) guide.</p> <p>Best For: Data scientists, statisticians, R programmers, and researchers who need robust data exploration tools alongside AI assistance.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#google-antigravity","level":3,"title":"Google Antigravity","text":"<p> Google Antigravity is Google's experimental AI-first code editor built on VS Code. It features deep Gemini integration for next-generation development workflows.</p> <p>What Makes Antigravity Different:</p> <ul> <li>Built-in Gemini AI Chat - No extension installation required</li> <li>Agentic Coding - AI can run commands, edit files, and iterate on tasks</li> <li>Google Cloud Integration - Seamless connection to Google Cloud services</li> <li>Experimental Features - Early access to Google's latest AI capabilities</li> </ul>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#installation","level":4,"title":"Installation","text":"macOSWindowsLinux <p>Apple Silicon (M1/M2/M3/M4):</p> <ol> <li>Visit antigravity.google/download</li> <li>Download the macOS ARM64 installer</li> <li>Open the downloaded <code>.dmg</code> file</li> <li>Drag Antigravity to your Applications folder</li> <li>Launch from Applications or Spotlight</li> </ol> <p>Intel Mac:</p> <ol> <li>Download the macOS x64 installer from the same page</li> <li>Follow the same installation steps</li> </ol> <ol> <li>Visit antigravity.google/download</li> <li>Download the Windows installer (<code>.exe</code>)</li> <li>Run the installer and follow the setup wizard</li> <li>Launch Antigravity from the Start menu</li> </ol> <pre><code># Ubuntu/Debian\n# Download the .deb package from antigravity.google/download\nsudo dpkg -i antigravity-*.deb\nsudo apt-get install -f\n\n# Fedora/RHEL\n# Download the .rpm package\nsudo dnf install antigravity-*.rpm\n\n# Launch Antigravity\nantigravity\n</code></pre>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#using-antigravitys-built-in-ai","level":4,"title":"Using Antigravity's Built-in AI","text":"<p>Antigravity includes a built-in AI chat interface powered by Gemini:</p> <ol> <li>Open AI Chat: Press Ctrl+Shift+I (Windows/Linux) or Cmd+Shift+I (macOS)</li> <li>Start Chatting: Type your request in natural language</li> <li>Apply Suggestions: AI can directly edit your code with your approval</li> <li>Run Commands: The AI can execute terminal commands to test and verify changes</li> </ol> <p>Example Workflow:</p> <pre><code>You: Create a Python script that reads a CSV file and generates a summary report\n\nAntigravity AI: I'll create that for you. Let me:\n1. Create a new file called csv_analyzer.py\n2. Write the code using pandas for data analysis\n3. Add error handling and documentation\n\n[AI creates the file and shows preview]\n\nWould you like me to run this script to test it?\n</code></pre> <p>Authentication:</p> <ul> <li>Sign in with your Google account when first launching Antigravity</li> <li>Gemini API usage is included (no separate API key needed for basic features)</li> <li>Google Cloud integration requires additional authentication</li> </ul>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#antigravity-vs-vs-code","level":4,"title":"Antigravity vs VS Code","text":"Feature VS Code Antigravity Base Editor VS Code core VS Code fork AI Assistant Extensions required Built-in Gemini Pricing Free + extension costs Free (Google account) Agentic Features Via extensions Native support Extension Support Full marketplace VS Code compatible Cloud Integration Via extensions Native Google Cloud Stability Production-ready Experimental <p>When to Use Antigravity</p> <p>Choose Antigravity if:</p> <ul> <li>You want AI built-in without extension setup</li> <li>You're already using Google Cloud services</li> <li>You want to try Google's latest AI features</li> <li>You prefer Gemini models for coding</li> </ul> <p>Choose VS Code if:</p> <ul> <li>You need production stability</li> <li>You want to choose your own AI provider</li> <li>You need maximum extension compatibility</li> <li>You prefer Claude, GPT, or other models</li> </ul>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#3-ai-extensions-for-vs-code","level":2,"title":"3. AI Extensions for VS Code","text":"<p>VS Code's extension marketplace offers numerous AI coding assistants. Here are the most powerful options:</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#claude-code-anthropic","level":3,"title":"Claude Code (Anthropic)","text":"<p> Claude Code is Anthropic's official VS Code extension, bringing Claude's powerful coding abilities directly into your editor.</p> <p>Key Features:</p> <ul> <li>Multi-file context awareness</li> <li>Inline code completion and suggestions</li> <li>Interactive chat panel for complex requests</li> <li>Terminal command generation and execution</li> <li>Git integration for version control assistance</li> <li>Support for Claude 4.5 Sonnet, Opus, and Haiku models</li> </ul> <p>Installation:</p> <ol> <li>Open VS Code</li> <li>Press Ctrl+Shift+X (Windows/Linux) or Cmd+Shift+X (macOS) to open Extensions</li> <li>Search for \"Claude Code\"</li> <li>Click Install on the official Anthropic extension</li> </ol> <p>Setup:</p> <ol> <li>Click the Claude icon in the Activity Bar</li> <li>Sign in with your Claude.ai account, or</li> <li>Enter your Anthropic API key (get one at console.anthropic.com)</li> </ol> <p>Quick Start Example:</p> <pre><code>Press Ctrl+Shift+P → \"Claude: Open Chat\"\n\nYou: Explain this function and suggest improvements\n\n[Select code in editor]\n\nClaude: This function calculates factorial recursively. Here's my analysis:\n- Time complexity: O(n)\n- Space complexity: O(n) due to call stack\n- Issue: No handling for negative numbers\n\nSuggested improvements:\n[Claude provides refactored code with error handling]\n</code></pre> <p>See Full Tutorial</p> <p>For comprehensive Claude Code workflows, see our Claude Code Tutorial.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#github-copilot","level":3,"title":"GitHub Copilot","text":"<p> GitHub Copilot is GitHub's AI pair programmer, offering real-time code suggestions as you type.</p> <p>Key Features:</p> <ul> <li>Inline code completions (ghost text)</li> <li>Multi-line suggestions</li> <li>Context-aware from open files</li> <li>Support for dozens of programming languages</li> <li>GitHub Copilot Chat for conversational assistance</li> </ul> <p>Pricing:</p> Plan Price Features Individual $10/month Code completions, chat Business $19/user/month Team management, policy controls Enterprise $39/user/month Advanced security, fine-tuning Free for Education $0 Full access for verified students/educators <p>See Full Setup Instructions</p> <p>For detailed GitHub Copilot setup, see our GitHub Copilot guide.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#cline-formerly-claude-dev","level":3,"title":"Cline (formerly Claude Dev)","text":"<p> Cline is an open-source VS Code extension that pioneered the \"bring your own model\" (BYOM) approach, allowing you to use any AI provider.</p> <p>Key Features:</p> <ul> <li>Model-agnostic: Use Claude, GPT, Gemini, or local models</li> <li>Agentic capabilities: Can run commands and modify files</li> <li>MCP (Model Context Protocol) support</li> <li>Transparent pricing: Pay per API request</li> <li>Open-source and community-driven</li> </ul> <p>Installation:</p> <ol> <li>Open VS Code Extensions (Ctrl+Shift+X)</li> <li>Search for \"Cline\"</li> <li>Click Install</li> </ol> <p>API Key Setup:</p> <ol> <li>Open Cline settings (gear icon in Cline panel)</li> <li>Select your provider:</li> </ol> Anthropic (Claude)OpenAI (GPT)Google (Gemini)Ollama (Local) <ol> <li>Get API key from console.anthropic.com</li> <li>Paste key in Cline settings</li> <li>Select model (Claude 4.5 Sonnet recommended)</li> </ol> <ol> <li>Get API key from platform.openai.com</li> <li>Paste key in Cline settings</li> <li>Select model (GPT-4o recommended)</li> </ol> <ol> <li>Get API key from aistudio.google.com</li> <li>Paste key in Cline settings</li> <li>Select model (Gemini 2.5 Pro recommended)</li> </ol> <ol> <li>Ensure Ollama is running locally</li> <li>Select \"Ollama\" as provider in Cline</li> <li>Choose from your downloaded models</li> <li>No API key required</li> </ol> <p>Usage Example:</p> <pre><code>Open Cline panel → Type your request\n\nYou: Create a REST API endpoint for user authentication using FastAPI\n\nCline: I'll create that for you. Here's my plan:\n1. Create auth.py with login/logout endpoints\n2. Add JWT token generation\n3. Create user model and validation\n4. Update main.py to include the router\n\n[Cline shows file changes for approval]\n\nDo you want me to apply these changes?\n</code></pre>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#roo-code","level":3,"title":"Roo Code","text":"<p> Roo Code is a fork of Cline focused on rapid feature development and customization.</p> <p>Key Features:</p> <ul> <li>All Cline features plus experimental capabilities</li> <li>Custom model presets and configurations</li> <li>Advanced prompt customization</li> <li>Frequent updates with new features</li> <li>Community-driven development</li> </ul> <p>Installation:</p> <ol> <li>Open VS Code Extensions</li> <li>Search for \"Roo Code\" or \"Roo Cline\"</li> <li>Click Install</li> <li>Configure API keys same as Cline</li> </ol> <p>Best For: Users who want cutting-edge features and don't mind occasional instability.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#chatgpt-codegpt-extensions","level":3,"title":"ChatGPT / CodeGPT Extensions","text":"<p> Several extensions bring OpenAI's GPT models to VS Code:</p> <p>CodeGPT - Popular multi-provider extension</p> <p>Installation:</p> <ol> <li>Open VS Code Extensions</li> <li>Search for \"CodeGPT\"</li> <li>Click Install</li> </ol> <p>Setup:</p> <ol> <li>Open CodeGPT settings</li> <li>Select \"OpenAI\" as provider</li> <li>Enter your API key from platform.openai.com</li> <li>Select model (GPT-4o or GPT-4o-mini)</li> </ol> <p>OpenAI Account Setup</p> <p>For detailed OpenAI account and API setup, see our ChatGPT guide.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#google-gemini-extensions","level":3,"title":"Google Gemini Extensions","text":"<p> Gemini CLI Companion brings Google's Gemini models to VS Code.</p> <p>Installation:</p> <ol> <li>Open VS Code Extensions</li> <li>Search for \"Gemini\" (look for official Google extension)</li> <li>Click Install</li> </ol> <p>Setup:</p> <ol> <li>Sign in with your Google account, or</li> <li>Enter API key from aistudio.google.com</li> </ol> <p>Google AI Account Setup</p> <p>For detailed Gemini account setup, see our Gemini guide.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#4-ai-extension-comparison","level":2,"title":"4. AI Extension Comparison","text":"Extension Provider Pricing Agentic Local Models Best For Claude Code Anthropic API or subscription Yes No Full-stack development, documentation GitHub Copilot GitHub/OpenAI $10-39/month Limited No Inline completions, GitHub users Cline Multi-provider API costs only Yes Yes (Ollama) Budget-conscious, model flexibility Roo Code Multi-provider API costs only Yes Yes (Ollama) Experimental features CodeGPT Multi-provider API costs only Limited Yes (Ollama) Simple setup, multi-provider Gemini Companion Google API or free tier Limited No Google Cloud users <p>Recommendation for Academic Users</p> <p>For beginners: Start with GitHub Copilot (free for educators/students) for inline completions.</p> <p>For research: Use Cline with Ollama for privacy-sensitive work with local models.</p> <p>For serious development: Claude Code offers the best balance of capability and reliability.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#5-setting-up-api-keys","level":2,"title":"5. Setting Up API Keys","text":"","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#vs-code-user-settings","level":3,"title":"VS Code User Settings","text":"<p>Store API keys in VS Code settings for extension-specific configuration:</p> <ol> <li>Press Ctrl+, (Windows/Linux) or Cmd+, (macOS)</li> <li>Search for your extension name</li> <li>Find the API key setting and enter your key</li> </ol> <p>Security Note</p> <p>API keys stored in VS Code settings are saved in plain text. For better security, use environment variables.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#environment-variables","level":3,"title":"Environment Variables","text":"<p>The most secure way to manage API keys:</p> macOS/LinuxWindows (PowerShell)Windows (System Settings) <p>Add to your shell profile (<code>~/.bashrc</code>, <code>~/.zshrc</code>, or <code>~/.bash_profile</code>):</p> <pre><code># Anthropic Claude\nexport ANTHROPIC_API_KEY=\"sk-ant-your-key-here\"\n\n# OpenAI\nexport OPENAI_API_KEY=\"sk-your-key-here\"\n\n# Google AI\nexport GOOGLE_API_KEY=\"your-key-here\"\n\n# Reload your shell\nsource ~/.zshrc  # or ~/.bashrc\n</code></pre> <pre><code># Set for current session\n$env:ANTHROPIC_API_KEY = \"sk-ant-your-key-here\"\n$env:OPENAI_API_KEY = \"sk-your-key-here\"\n\n# Set permanently (user level)\n[System.Environment]::SetEnvironmentVariable(\"ANTHROPIC_API_KEY\", \"sk-ant-your-key-here\", \"User\")\n</code></pre> <ol> <li>Press Win+R, type <code>sysdm.cpl</code>, press Enter</li> <li>Click Advanced tab</li> <li>Click Environment Variables</li> <li>Under \"User variables\", click New</li> <li>Enter variable name (e.g., <code>ANTHROPIC_API_KEY</code>) and value</li> </ol>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#security-best-practices","level":3,"title":"Security Best Practices","text":"<p>Never Commit API Keys to Git</p> <pre><code># Add to your .gitignore\n.env\n.env.local\n*.key\n</code></pre> <p>Best Practices:</p> <ol> <li>Use environment variables instead of hardcoding keys</li> <li>Rotate keys regularly (every 90 days recommended)</li> <li>Use separate keys for development and production</li> <li>Set spending limits in your provider dashboards</li> <li>Revoke compromised keys immediately</li> </ol>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#6-ollama-integration-local-models","level":2,"title":"6. Ollama Integration (Local Models)","text":"<p>Run AI models locally for privacy, offline access, and cost savings. See our full Ollama guide for installation.</p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#extensions-supporting-ollama","level":3,"title":"Extensions Supporting Ollama","text":"Extension Ollama Support Configuration Cline Native Select \"Ollama\" provider Roo Code Native Select \"Ollama\" provider CodeGPT Native Select \"Ollama\" provider Continue Native Add Ollama to config","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#configuration-example-cline","level":3,"title":"Configuration Example (Cline)","text":"<ol> <li>Install and start Ollama</li> <li> <p>Pull a coding model:</p> <pre><code># Recommended for coding\nollama pull codellama:13b\n\n# Or for general use\nollama pull llama3.2:latest\n\n# Or for smaller machines\nollama pull qwen2.5-coder:7b\n</code></pre> </li> <li> <p>In Cline settings:</p> <ul> <li>Provider: Ollama</li> <li>Model: Select from your downloaded models</li> <li>Base URL: <code>http://localhost:11434</code> (default)</li> </ul> </li> </ol>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#example-workflow","level":3,"title":"Example Workflow","text":"<pre><code># Terminal: Start Ollama (if not running as service)\nollama serve\n\n# In VS Code with Cline:\n# 1. Open Cline panel\n# 2. Ensure Ollama is selected as provider\n# 3. Start coding!\n\nYou: Explain this Python decorator and add type hints\n\nCline (via local Codellama): [Provides explanation and modified code]\n# All processing happens locally - no data leaves your machine\n</code></pre> <p>Model Recommendations for Coding</p> Model Size RAM Needed Best For <code>qwen2.5-coder:7b</code> 4.7GB 8GB Fast coding on laptops <code>codellama:13b</code> 7.4GB 16GB Balanced coding <code>deepseek-coder:33b</code> 19GB 32GB Complex coding tasks <code>codestral:latest</code> 12GB 24GB Multi-language coding","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#7-practical-examples","level":2,"title":"7. Practical Examples","text":"","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#code-generation","level":3,"title":"Code Generation","text":"<p>Request: <pre><code>Create a Python class for managing a bibliography with BibTeX import/export\n</code></pre></p> <p>AI Response (via Claude Code): <pre><code>import bibtexparser\nfrom dataclasses import dataclass, field\nfrom typing import List, Optional\nfrom pathlib import Path\n\n@dataclass\nclass BibEntry:\n    \"\"\"Represents a single bibliography entry.\"\"\"\n    entry_type: str\n    cite_key: str\n    title: str\n    authors: List[str]\n    year: int\n    journal: Optional[str] = None\n    volume: Optional[str] = None\n    pages: Optional[str] = None\n    doi: Optional[str] = None\n\nclass BibliographyManager:\n    \"\"\"Manage academic bibliography with BibTeX support.\"\"\"\n\n    def __init__(self):\n        self.entries: List[BibEntry] = []\n\n    def import_bibtex(self, filepath: Path) -&gt; int:\n        \"\"\"Import entries from a BibTeX file.\"\"\"\n        with open(filepath) as f:\n            bib_db = bibtexparser.load(f)\n\n        for entry in bib_db.entries:\n            self.entries.append(BibEntry(\n                entry_type=entry.get('ENTRYTYPE', 'article'),\n                cite_key=entry.get('ID', ''),\n                title=entry.get('title', ''),\n                authors=entry.get('author', '').split(' and '),\n                year=int(entry.get('year', 0)),\n                journal=entry.get('journal'),\n                doi=entry.get('doi')\n            ))\n\n        return len(bib_db.entries)\n\n    def export_bibtex(self, filepath: Path) -&gt; None:\n        \"\"\"Export all entries to a BibTeX file.\"\"\"\n        # Implementation continues...\n</code></pre></p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#code-explanation","level":3,"title":"Code Explanation","text":"<p>Select code, then ask: <pre><code>Explain this regex pattern and suggest improvements for readability\n</code></pre></p> <p>AI explains: <pre><code>This regex `r'^(?P&lt;year&gt;\\d{4})-(?P&lt;month&gt;\\d{2})-(?P&lt;day&gt;\\d{2})$'` matches ISO date format:\n\n- `^` - Start of string\n- `(?P&lt;year&gt;\\d{4})` - Named group \"year\": exactly 4 digits\n- `-` - Literal hyphen\n- `(?P&lt;month&gt;\\d{2})` - Named group \"month\": exactly 2 digits\n- `-` - Literal hyphen\n- `(?P&lt;day&gt;\\d{2})` - Named group \"day\": exactly 2 digits\n- `$` - End of string\n\nSuggested improvement for readability:\n```python\nDATE_PATTERN = re.compile(\n    r'^'\n    r'(?P&lt;year&gt;\\d{4})'   # Year: 4 digits\n    r'-'\n    r'(?P&lt;month&gt;\\d{2})'  # Month: 01-12\n    r'-'\n    r'(?P&lt;day&gt;\\d{2})'    # Day: 01-31\n    r'$',\n    re.VERBOSE\n)\n</code></pre></p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#debugging-assistance","level":3,"title":"Debugging Assistance","text":"<p>Paste error message: <pre><code>TypeError: 'NoneType' object is not subscriptable at line 45\n</code></pre></p> <p>AI diagnosis: <pre><code>This error occurs when you try to access an index or key on a None value.\n\nLooking at line 45: `result = data['key'][0]`\n\nThe issue is likely that `data['key']` returns None instead of a list.\n\nSuggested fix:\n```python\n# Add defensive check\nvalue = data.get('key')\nif value is not None and len(value) &gt; 0:\n    result = value[0]\nelse:\n    result = default_value  # or raise a more informative error\n</code></pre></p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#refactoring","level":3,"title":"Refactoring","text":"<p>Request: <pre><code>Refactor this function to use list comprehension and add error handling\n</code></pre></p> <p>Before: <pre><code>def process_files(paths):\n    results = []\n    for path in paths:\n        f = open(path)\n        data = f.read()\n        results.append(data.upper())\n        f.close()\n    return results\n</code></pre></p> <p>After (AI refactored): <pre><code>from pathlib import Path\nfrom typing import List\n\ndef process_files(paths: List[str]) -&gt; List[str]:\n    \"\"\"\n    Read files and return their contents in uppercase.\n\n    Args:\n        paths: List of file paths to process\n\n    Returns:\n        List of file contents converted to uppercase\n\n    Raises:\n        FileNotFoundError: If any file doesn't exist\n        PermissionError: If any file can't be read\n    \"\"\"\n    results = []\n    for path in paths:\n        try:\n            content = Path(path).read_text(encoding='utf-8')\n            results.append(content.upper())\n        except (FileNotFoundError, PermissionError) as e:\n            raise type(e)(f\"Error processing {path}: {e}\") from e\n\n    return results\n</code></pre></p>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#8-choosing-the-right-tool","level":2,"title":"8. Choosing the Right Tool","text":"","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#ide-selection-guide","level":3,"title":"IDE Selection Guide","text":"<pre><code>graph TD\n    A[What's your primary use case?] --&gt; B{Data Science?}\n    B --&gt;|Yes| C{R or Python?}\n    B --&gt;|No| D{Want built-in AI?}\n\n    C --&gt;|R focused| E[Positron]\n    C --&gt;|Python focused| F{Need data viewers?}\n\n    F --&gt;|Yes| E\n    F --&gt;|No| G[VS Code + Extensions]\n\n    D --&gt;|Yes| H{Google Cloud user?}\n    D --&gt;|No| G\n\n    H --&gt;|Yes| I[Antigravity]\n    H --&gt;|No| J{Prefer Gemini?}\n\n    J --&gt;|Yes| I\n    J --&gt;|No| G</code></pre>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#extension-selection-guide","level":3,"title":"Extension Selection Guide","text":"If you need... Use this... Why Best inline completions GitHub Copilot Industry standard, fast, reliable Strongest reasoning Claude Code Best for complex tasks, documentation Maximum flexibility Cline Use any model, including local Privacy/offline Cline + Ollama Everything runs locally Google integration Gemini extensions Native Google Cloud support Free option Copilot (edu) or Cline + Ollama No cost for students/educators Experimental features Roo Code Cutting-edge capabilities","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#combining-multiple-extensions","level":3,"title":"Combining Multiple Extensions","text":"<p>You can install multiple AI extensions and use them for different tasks:</p> <ol> <li>GitHub Copilot - Always-on inline completions</li> <li>Claude Code - Complex refactoring and documentation</li> <li>Cline + Ollama - Privacy-sensitive or offline work</li> </ol> <p>Avoiding Conflicts</p> <p>If you have multiple AI extensions:</p> <ul> <li>Disable inline completions in all but one extension</li> <li>Use keyboard shortcuts to invoke specific assistants</li> <li>Check for conflicting keybindings in VS Code settings</li> </ul>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#9-troubleshooting","level":2,"title":"9. Troubleshooting","text":"","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#common-issues","level":3,"title":"Common Issues","text":"Extension won't authenticate <p>Symptoms: \"Invalid API key\" or \"Authentication failed\" errors</p> <p>Solutions:</p> <ol> <li>Verify your API key is correct (no extra spaces)</li> <li>Check if your API key has expired</li> <li>Ensure you have sufficient credits/quota</li> <li>Try regenerating a new API key</li> <li>Check firewall/proxy settings aren't blocking requests</li> </ol> Slow or no responses <p>Symptoms: Long wait times or timeouts</p> <p>Solutions:</p> <ol> <li>Check your internet connection</li> <li>Verify the AI service isn't experiencing outages</li> <li>Try a different/faster model</li> <li>For Ollama: ensure you have enough RAM for the model</li> <li>Reduce context size (close unnecessary files)</li> </ol> Code suggestions are wrong or outdated <p>Symptoms: AI suggests deprecated APIs or incorrect syntax</p> <p>Solutions:</p> <ol> <li>Provide more context in your prompts</li> <li>Specify the language version explicitly</li> <li>Include relevant documentation links</li> <li>Use a more capable model</li> <li>Update the extension to latest version</li> </ol> Ollama models won't load <p>Symptoms: \"Model not found\" or memory errors</p> <p>Solutions:</p> <ol> <li>Verify model is downloaded: <code>ollama list</code></li> <li>Check available RAM vs model requirements</li> <li>Try a smaller model</li> <li>Restart Ollama service</li> <li>Check Ollama logs: <code>ollama logs</code></li> </ol> Extension conflicts <p>Symptoms: Multiple completions, keyboard shortcut issues</p> <p>Solutions:</p> <ol> <li>Disable inline suggestions in all but one extension</li> <li>Check keybindings: Ctrl+K Ctrl+S</li> <li>Use Command Palette to invoke specific extensions</li> <li>Update all extensions to latest versions</li> </ol>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#10-further-resources","level":2,"title":"10. Further Resources","text":"","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#official-documentation","level":3,"title":"Official Documentation","text":"<ul> <li>VS Code Documentation</li> <li>VS Code Extension API</li> <li>Positron Documentation</li> <li>Google Antigravity</li> </ul>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#workshop-guides","level":3,"title":"Workshop Guides","text":"Topic Guide Claude Code workflows Claude Code Tutorial GitHub Copilot setup GitHub Copilot Guide OpenAI account setup ChatGPT Guide Google AI setup Gemini Guide Posit tools and Positron Posit Guide Local AI with Ollama Ollama Guide Vibe coding overview Vibe Coding","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"vscode/#community-resources","level":3,"title":"Community Resources","text":"<ul> <li>VS Code GitHub Discussions</li> <li>Cline GitHub</li> <li>Ollama Discord</li> <li>r/vscode Subreddit</li> </ul> <p>Getting Started Checklist</p> <ol> <li> Install VS Code (or Positron/Antigravity)</li> <li> Choose and install an AI extension</li> <li> Set up API keys securely</li> <li> Test with a simple coding request</li> <li> Explore additional extensions as needed</li> <li> Consider local models for privacy-sensitive work</li> </ol>","path":["Research","Visual Studio Code and AI-Powered Development"],"tags":[]},{"location":"tutorials/publichealth/casestudy/","level":1,"title":"Public Health","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#bias-and-data-quality","level":2,"title":"Bias and Data Quality","text":"","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#ethics-transparency-accountability","level":2,"title":"Ethics: Transparency &amp; Accountability","text":"","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#standardization","level":2,"title":"Standardization","text":"<p>The standardization of protocols and controls is critical for ensuring consistent, high-quality public health practices across different organizations and regions. </p> <p>AI Protocol Analysis and Harmonization</p> <p>AI can analyze multiple existing protocols to identify commonalities, differences, and best practices:</p> Example prompt <pre><code>Analyze different measles testing protocols from various health departments\nin Arizona, Texas, New Mexico, Sonora, and Chihuahua. \nIdentify:\n- Common required steps across all protocols\n- Key differences in methodology\n- Best practices that appear in multiple protocols\n- Potential gaps or missing elements\n- Recommendations for a standardized protocol\n</code></pre> <p>Natural Language Processing for Protocol Extraction</p> <p>AI can extract structured information from unstructured protocol documents:</p> <ul> <li>Convert narrative guidelines into step-by-step procedures</li> <li>Identify required equipment, materials, and personnel</li> <li>Extract critical values, thresholds, and decision points</li> <li>Create standardized terminology mappings</li> </ul> <p>Automated Protocol Validation</p> <p>AI systems can check protocols for: - Completeness (all necessary steps included) - Consistency (no contradictory instructions) - Compliance with regulations and standards - Evidence-based practice alignment</p>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#human-in-the-loop-hitl-approaches","level":3,"title":"Human-in-the-Loop (HITL) Approaches","text":"<p>Human-in-the-loop systems combine AI efficiency with human expertise to improve accuracy and reliability:</p> <p>Key HITL Components:</p> <ul> <li>Expert Annotation: Subject matter experts review and annotate AI-generated protocols</li> <li>Iterative Refinement: AI learns from expert corrections to improve future outputs</li> <li>Decision Points: Critical decisions require human approval before proceeding</li> <li>Quality Assurance: Random sampling and human verification of AI outputs</li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#key-infrastructure-requirements","level":3,"title":"Key Infrastructure Requirements","text":"<ul> <li>Scalability: Handle increasing protocol volumes and complexity</li> <li>Interoperability: Connect with existing health information systems</li> <li>Security: Protect sensitive health information</li> <li>Reliability: 99.9% uptime for critical health operations</li> <li>Traceability: Complete audit trails for regulatory compliance</li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#implementation-considerations","level":3,"title":"Implementation Considerations","text":"<ul> <li>Change Management: Training staff on new AI-assisted workflows</li> <li>Ethical Guidelines: Ensuring AI decisions are fair and unbiased</li> <li>Regulatory Compliance: Meeting local and federal health regulations</li> <li>Performance Monitoring: Tracking AI accuracy and human satisfaction</li> <li>Continuous Learning: Regular model updates based on new evidence</li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#best-practices-for-implementation","level":3,"title":"Best Practices for Implementation","text":"<ol> <li>Start Small: Pilot with non-critical protocols first</li> <li>Maintain Transparency: Document AI decision-making processes</li> <li>Preserve Expertise: AI augments, not replaces, human judgment</li> <li>Regular Audits: Systematic review of AI performance</li> <li>Stakeholder Engagement: Include all users in design and testing</li> <li>Continuous Training: Keep both AI models and humans updated</li> </ol> <p>Human-in-the-loop approaches that improve accuracy and reliability, combined with robust AI infrastructure, allow for more seamless integration into public health practices while maintaining the critical human oversight necessary for healthcare decision-making. </p>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#case-studies","level":2,"title":"Case Studies","text":"","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#awesome-lists","level":4,"title":"Awesome Lists","text":"<p>Maintained on GitHub and often feature the badge: , Awesome lists contain community-maintained lists of popular and widely used software, data, and code for almost everything on the internet.</p> <ul> <li> <p> Awesome Healthcare</p> </li> <li> <p> Awesome Healthcare Datasets</p> </li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#diagnostics","level":3,"title":"Diagnostics","text":"<p>AI has great promise for enhancing diagnostic capabilities, but have exhibited biases on race and ethnicity. There are calls to address these biases in big data and AI for health care by taking an open science approach</p> <p>List of FDA approved AI medical devices: https://www.datawrapper.de/_/IBGhg/</p> <p> </p> <p>Positive Examples</p> <p>High speed internet access via wired, broadband, or satellite allows clinicians to stream data to the cloud and larger AI resources and improved access to specialty care in Underserved and Rural Areas.</p> <p>Negative Examples:</p> <ul> <li>AI-enabled pulse oximeters overstate blood oxygen saturation in individuals with darker skin, exacerbating racial bias</li> </ul> <p>Readings:</p> <ul> <li> <p>https://www.medtechdive.com/news/fda-ai-medical-devices-growth/728975/</p> </li> <li> <p>https://nam.edu/perspectives/advancing-artificial-intelligence-in-health-settings-outside-the-hospital-and-clinic/</p> </li> <li> <p>https://www.nature.com/articles/s41746-018-0040-6</p> </li> <li> <p>https://www.digitaldiagnostics.com/products/eye-disease/lumineticscore/</p> </li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#disease-surveillance-prediction","level":3,"title":"Disease Surveillance &amp; Prediction","text":"<p>AI-powered predictions change the landscape of population-level public health surveillance. </p> <p>Machine learning (predictive AI) has been used for many years to analyze data and make predictions around disease spread and outbreak detection. </p> <p>AI-systems can quickly analyze electronic health records (EHRs), social media platforms, online search queries, environmental data, genomic sequences, wearable devices,  Of course. Here is the updated markdown table with public URLs for every example. Any examples for which I could not find a reliable, public URL have been removed.</p> Application Area AI Technique(s) Used Data Sources Leveraged Specific Examples/Platforms Key Outcomes/Impacts Early Outbreak Detection Machine Learning, NLP Social Media, News Reports, Airline Travel Data, Official Health Reports BlueDot, HealthMap Early warning for COVID-19 by detecting initial signals before official reports; faster public health response. Real-Time Monitoring Machine Learning, NLP EHRs, Lab Reports, Public Health Data, Free-text data CDC NLP analysis for vaccine safety Continuous tracking of disease spread and monitoring safety of vaccines by analyzing large volumes of free-text data. Epidemic Forecasting Machine Learning, Deep Learning Historical Disease Data, Climate Patterns, Population Mobility, Search Queries CDC FluSight, Dengue/Influenza models Improved prediction accuracy for flu seasons, dengue outbreaks; better preparedness. Identifying High-Risk Populations Machine Learning Demographic, Socioeconomic, Health Data, Aerial Imagery TowerScout Enables targeted interventions, such as identifying cooling towers from imagery to speed up response to Legionnaires' disease outbreaks. Pathogen Genomic Surveillance AI Algorithms, Machine Learning Genomic Sequences of Pathogens Nextstrain Rapid detection of new variants (e.g., SARS-CoV-2), understanding transmissibility/virulence changes. Syndromic Surveillance (Unconv.) NLP, Machine Learning, Image Analysis Online Search Queries, Social Media Posts, Wikipedia page views, Chest X-rays AI for TB detection from X-rays Early detection of community transmission before clinical reporting and improved speed and accuracy for TB surveillance. Antimicrobial Resistance (AMR) Tracking Predictive Analytics, ML Clinical Data, Epidemiological Data, Lab Results AI-driven AMR surveillance systems Improved detection of AMR trends, rapid pathogen ID and resistance profiling, guidance for stewardship. Vector-Borne Disease Prediction Machine Learning Environmental Data (temp, humidity, rainfall), Satellite Imagery, Historical Case Data AI models for Malaria prediction Prediction of high-risk areas for outbreaks, enabling targeted vector control measures. Resource Allocation Prediction Machine Learning Outbreak Data, Hospital Capacity Data, Supply Chain Information NHS A&amp;E demand forecasting tool Optimization of resource deployment during public health emergencies. Misinformation Monitoring NLP Social Media Content, Online News Project Heal, EPIWATCH Identification of false narratives that could impede public health responses, enabling counter-messaging. <p>Readings:</p> <ul> <li> <p>Zeng et al. (2021) Artificial intelligence–enabled public health surveillance—from local detection to global epidemic monitoring and control. Artificial Intelligence in Medicine Technical Basis and Clinical Applications</p> </li> <li> <p>Hattab, G. et al. (2025) The Way Forward to Embrace Artificial Intelligence in Public Health. American Journal of Public Health 115, 123_128</p> </li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#resource-allocation","level":3,"title":"Resource Allocation","text":"<p>Perhaps the most ethically fraught application of AI in health care is on resource allocation. Decisions made by algorithms for high-risk care have exhibited racial biases. </p> <p>Positive Examples:</p> <ul> <li>The UK's National Health Service (NHS) uses an AI-powered tool to forecast demand for emergency services, helping to optimize the allocation of staff, beds, and other resources to improve patient outcomes. (Read more)</li> </ul> <p>Negative Examples:</p> <ul> <li>Training data based on historical spending for health care on black vs white patients resulted in an algorithm systematically biased toward spending on more on white patients than on black patients, resulting in a perpetuation and exacerbation of the health disparity. </li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#clinical-decision-support","level":3,"title":"Clinical Decision Support","text":"<p>AI-powered tools can assist healthcare providers in making more informed decisions, but they must be used with caution as they can also perpetuate existing biases.</p> <p>Positive Examples:</p> <ul> <li>Oncology Screening: Development and validation of an autonomous artificial intelligence agent for clinical decision-making in oncology</li> <li>Diabetic Retinopathy Detection: AI systems like LumineticScore can analyze retinal images to detect diabetic retinopathy, a leading cause of blindness, enabling early intervention and treatment, particularly in areas with limited access to specialists.</li> <li>Drug Discovery: Language models like Google's TxGemma are being developed to accelerate drug discovery by understanding and predicting the properties of therapeutic compounds.</li> <li>Diagnostic Conversations: Research systems like Google's AMIE are exploring the potential for AI to conduct diagnostic conversations and improve medical reasoning. (Read more)</li> </ul> <p>Negative Examples:</p> <ul> <li>Skin Cancer Detection: AI models for detecting skin cancer have shown lower accuracy on darker skin tones, which can lead to missed or delayed diagnoses for patients from underrepresented racial and ethnic groups.</li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#mental-health","level":3,"title":"Mental Health","text":"<p>The application of AI in mental health presents both significant opportunities and serious risks, particularly concerning the well-being of vulnerable populations.</p> <p>Positive Examples:</p> <ul> <li>Increased Access to Care: AI-powered chatbots and virtual therapists can help mitigate shortages of mental health providers, especially in rural and underserved areas, by offering accessible, on-demand support. (Read more)</li> <li>Potential for Effective Treatment: Early research suggests that generative AI chatbots may become a valuable tool in mental health treatment, with some studies showing promising outcomes. (Read the study)</li> <li>Positive Mental Health: AI is being explored for applications in positive psychology, focusing on well-being and flourishing. (Read the review)</li> </ul> <p>Negative Examples:</p> <ul> <li>Unregulated and Unaccountable Care: The proliferation of unlicensed and unaccountable AI chatbots posing as therapists raises serious ethical concerns, as they may provide harmful advice or fail to respond appropriately in crisis situations. (Read more)</li> <li>Risk of Harm: Unregulated AI has been accused of contributing to negative mental health outcomes, including exacerbating distress, cyberbullying, and even being implicated in cases of suicide.</li> <li>Lack of Oversight: There is currently little regulatory oversight for AI therapy companies, creating a gap in ensuring the safety and effectiveness of these services. (Read more)</li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#further-reading","level":2,"title":"Further Reading","text":"<p>WHO Guidance: Ethics and Governance of Artificial Intelligence for Health</p> <p>Focus Group on \"Artificial Intelligence for Health\" (FG-AI4H)</p>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/gis/","level":1,"title":"Vibe coding a Public Health Map","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Setup</p> <p>Desktop LLM Apps</p> <p>Claude Desktop</p> <p>( Windows,  Mac OS)</p> <p>Connects automatically to Anthropic Claude. </p> <p> Claude Desktop https://claude.ai/download </p> <p>AnythingLLM Desktop</p> <p>( Windows,  Mac OS,  Linux)</p> <p> AnythingLLM https://anythingllm.com/desktop </p> <p>Integrated Development Environment (IDE) Desktops</p> <p> VS Code</p> <p>( Windows,  Mac OS,  Linux)</p> <p> https://code.visualstudio.com/download</p> <p>Positron</p> <p> https://positron.posit.co/ </p> <p>API Access</p> <p> https://console.anthropic.com/</p> <p>Cline ( VS Code Extension)  https://cline.bot/</p> <p>Optional:  QGIS https://qgis.org/download/</p> <p> QGISMCP</p> <p> https://github.com/jjsantos01/qgis_mcp</p>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#prompt-engineering-vibe-coding","level":2,"title":"Prompt Engineering &amp; Vibe Coding","text":"<p>The goal of this lab is to guide your LLM agent (Claude, Cline, etc.) through a reproducible workflow that turns open geospatial data into an interactive story map. Copy-and-paste the prompts below in order. Adjust ONLY the bracketed values (<code>&lt;…&gt;</code>) to match your environment.  </p>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#prerequisites-checklist","level":3,"title":"Prerequisites (checklist)","text":"✔︎ Requirement Notes Frontier-class LLM access (API or Desktop) Claude 4, GPT-4.5, Gemini 2.5 Pro, etc. IDE with Cline or Roo Code extension or Claude Desktop Enables local tool use &amp; file ops Filesystem MCP server running Gives the AI read/write access Git &amp; GitHub account (optional but recommended) For version control &amp; sharing","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-0-add-a-system-instruction-or-workspace-rules-file","level":3,"title":"Step 0 – Add a System Instruction or Workspace Rules file.","text":"<p>These are sometimes called an EigenPrompt -- because they come before any other prompts.</p> EigenPrompts <p>We are using Cline on VS Code, so we will create a unique Workspace Rules file, these are located in the <code>.clinerules</code> folder -- clicking on the :material-scales: icon will take you to Cline Rules </p> Copy/Paste <pre><code>**Eigenprompt: Rigorous Code Generation &amp; Automated Validation**\n\n**Objective:** Generate [code for a specific function/module/class | architectural outline] for [project/feature description] with a focus on correctness, testability, maintainability, and automated verification via Cline Workspace Rules.\n\n**I. Code Generation Specifications:**\n\n1. **Functionality:**  \n  - Clearly define input(s), output(s), and the intended behavior.\n\n2. **Language/Framework:**  \n  - Specify the programming language and version clearly (e.g., Python 3.10, JavaScript ES2022, Go 1.18).\n\n3. **Dependencies:**  \n  - Explicitly list external libraries or modules required.\n\n4. **Error Handling:**  \n  - Define expected errors explicitly with handling methods (exceptions, error codes, fallbacks).\n\n5. **Performance Constraints (Optional):**  \n  - Describe any important time or memory constraints clearly.\n\n6. **Code Style:**  \n  - Follow defined style guides (e.g., PEP 8, Google Java Style).  \n  - Clearly document non-obvious or complex logic concisely, specifying reasons (\"why\") and behavior (\"what\").\n\n**II. Testing &amp; Validation Requirements:**\n\n1. **Unit Tests:**  \n  - Specify testing framework explicitly (e.g., unittest, Jest, Mocha).  \n  - List and implement critical test cases clearly:\n    - Typical valid inputs.\n    - Edge cases.\n    - Invalid inputs and related error-handling tests.\n  - Indicate desired code coverage clearly [% of coverage as applicable].\n\n2. **Validation Criteria:**  \n  - Clearly describe measurable criteria for successful test results.  \n  - Specify validation datasets, criteria, or methods if needed.\n\n**III. Automated Execution, Validation, and Bug-Fixing Workflow (Cline Workspace Rules):**\n\n1. **Terminal Execution Validation:**\n  - After execution of generated code or tests via ChatGPT API in VS Code Terminal, automatically inspect the outputs.\n  - Verify explicitly that the commands have exited without errors or warnings.\n\n2. **Error &amp; Warning Inspection:**\n  - Check VS Code's \"Problems\" pane for reported errors, warnings, or alerts promptly after running code or tests.\n\n3. **Automated Re-examination on Errors:**\n  - In case of any detected terminal output issues or problems pane alerts:\n    - Automatically re-inspect the relevant code and identify root causes clearly.\n    - Promptly propose corrected or improved code, addressing identified issues directly.\n    - Re-run tests and terminal commands, verifying fixes iteratively until no critical issues persist.\n\n4. **Final Confirmation:**\n  - Explicitly confirm successful execution (no persistent errors or warnings) before finishing the task.\n\n**IV. Project Structure &amp; Documentation (Initialize/Update):**\n\n1. **`README.md`:**\n  - **Project Title:**\n  - **Description:** Succinct description.\n  - **Setup Instructions:** Clearly outlined installation and execution steps.\n  - **Usage:** Simple demonstration or examples.\n  - **Testing Instructions:** Exact commands to run provided unit tests.\n\n2. **`prompts/` directory:**\n  - Log initial eigenprompt clearly as `prompts/001_initial_eigenprompt.md`.\n  - Log ChatGPT API's full responses (code, documentation, README) as `prompts/001_response.md`.\n  - Future interactions follow sequential convention (e.g., `002_refinement_prompt.md`, `002_response.md`).\n\n**V. Output Format (Concise &amp; Complete):**\n\n- Clearly named source code files according to module criteria (e.g., `module_name.py`).\n- Clearly named unit test files aligned with testing framework (e.g., `test_module_name.py`).\n- Complete and concise README.md file content.\n- Confirmation that automated validation via Cline Workspace Rules has executed successfully or corrections documented explicitly.\n- Confirmation of structured prompt logging.\n\n---\n\n**Illustrative Usage Example:**\n\n**Objective:** Generate efficient Python code for calculating Fibonacci numbers with memoization, fully tested and automatically validated via Cline Workspace Rules.\n\n- **Code Specifications:**\n  - Input: non-negative integer `n`; Output: nth Fibonacci number.\n  - Use memoization for efficiency, with clear descriptive comments.\n  - Error Handling: Raise explicit `ValueError` on negative input.\n  - Python version: 3.10; Adhere strictly to PEP 8 style.\n\n- **Unit Testing:**\n  - Framework: `unittest`.\n  - Test cases: `fib(0)`→`0`, `fib(1)`→`1`, `fib(10)`→`55`, `fib(20)`→`6765`; negative inputs raise `ValueError`.\n\n- **Automated Validation (Cline Workflow):**\n  - Upon running tests in terminal through ChatGPT API integration with VS Code, check terminal output immediately.\n  - Automatically examine the \"Problems\" pane for errors or warnings.\n  - If issues detected, automatically re-inspect code, clearly identify and implement fixes, and iteratively rerun validation steps until no problems remain.\n\n- **Project Structure &amp; Logs:**\n  - Create README.md, `prompts/` structure and log prompts/responses precisely as described.\n\n- **Final Output:**\n  - Files: `fibonacci.py`, `test_fibonacci.py`, `README.md`.\n  - Explicit confirmation that code and tests execute without errors or warnings and validation is automated successfully.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-1-initialize-project-folders","level":3,"title":"Step 1 – Initialize project folders","text":"<pre><code>TASK\nCreate the following directory structure in the current repo  \n  data/  \n  map/  \n  code/  \n  prompts/\nAcknowledge when folders exist.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-2-download-unzip-snow-dataset","level":3,"title":"Step 2 – Download &amp; unzip “snow” dataset","text":"<pre><code>TASK\n1. Download https://geodacenter.github.io/data-and-lab/data/snow.zip into data/  \n2. Unzip it in place, then delete the original .zip  \n3. Write a brief summary of extracted files \n\nUse Python scripting; save the script as code/download_data.py\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-3-organize-geojson-layers","level":3,"title":"Step 3 – Organize GeoJSON layers","text":"<pre><code>TASK\nIn the unzipped snow dataset, locate every *.geojson file.  \nMove the .geojson files into the map/ folder\n\nIgnore all other file types.  \n\nConfirm moves as successful.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-4-summarize-accompanying-pdfs","level":3,"title":"Step 4 – Summarize accompanying PDFs","text":"<pre><code>TASK\nWithin data/snow/, there are several PDF documentation files.\n\n1. Extract their plain-text content and generate a markdown summary (≤ 200 words) of key variables &amp; metadata.  \n2. Save these markdown text as data/snow_docs_summary.md\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-5-build-a-storytelling-leaflet-map","level":3,"title":"Step 5 – Build a storytelling Leaflet map","text":"<pre><code>TASK\nUsing Leaflet HTML, CSS, and JavaScript, create  \n  map/snow_storymap.html\nRequirements:\n  • The HTML must scroll like a Story Map,\n  • Layers appear when scrolled to and disappear when they are scrolled past\n  • Summarized text explains the relevance and meaning of each data set\n  • Use chloropleth colors for presence or absence of observations, such as 'deaths' and 'deathdens' for deaths and death density\n  • add the death count to polygons but not point layers\n  • Run local python web server on a high random port (e.g., 51234) to avoid conflicts  \n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-6-iterate-for-aesthetics","level":3,"title":"Step 6 – Iterate for aesthetics","text":"<pre><code>TASK\nOpen map/snow_storymap.html and critique its look (colors, fonts, layout).  \nSuggest up to three improvements.  \nWait for user approval, then implement changes inside the same file.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-7-log-every-prompt","level":3,"title":"Step 7 – Log every prompt","text":"<pre><code>TASK\nCreate code/log_prompts.py that appends each user &amp; assistant message  \nfrom this session into prompts/session_&lt;timestamp&gt;.md  \nEnsure it runs automatically at the end of each assistant response.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-8-commit-push","level":3,"title":"Step 8 – Commit &amp; push","text":"<pre><code>TASK\nGit add all new/modified files  \nCommit with message \"Add snow GIS story-map lab\"  \nPush to &lt;your-GitHub-remote&gt;  \nReport the commit URL on success.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-9-one-shot-prompt","level":3,"title":"Step 9 – One Shot Prompt","text":"<p>Now, try a new chat session and let's push everything through at once to see how it turns out:</p> <pre><code>The goal for this project is to create a story map that tells the story of 1850's the cholera outbreak in London. We will use HTML, JS, CSS, and Python for the code. \n\n\nFirst task,\n\n1. Download https://geodacenter.github.io/data-and-lab/data/snow.zip into a new folder called `data/`  \n2. Unzip the .zip file in place, then delete the .zip  \n3. Write a short summary in MarkDown of the steps to this in the `data/` folder.\n\nSecond task,\n\n4. In the unzipped dataset, locate every *.geojson file.  \n5. Move the .geojson files into a new `map/` folder. Ignore the data in the __MACOSX folder. Ignore all other file types.\n\nThird task,\n\n6. Summarize accompanying PDFs in the `data/` folder and save the summaries in a new MarkDown file.\n\nFinal task,\n\n6. Build a scrolling story telling map. Using Leaflet, HTML, CSS, and JavaScript, create a `map/snow_storymap.html` which will read the GeoJSON files we got earlier.\n\nRequirements:\n  • The HTML must scroll like a Story Map that is effective both on mobile and desktop\n  • the layers should appear when scrolled over and disappear when they are scrolled past\n  • Use the summarized text to explain the relevance and meaning of each data set in the context of the larger story\n  • Use chloropleth colors for presence or absence of observations, such as 'deaths' and 'deathdens' for deaths and death density\n  • add the death count to polygons as labels, but to the not point layers\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#next-steps","level":3,"title":"Next Steps","text":"<p>• Modify the prompts to use QGISMCP and build the layers there.</p> <p>• Deploy the code and map via GitHub Pages.</p>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]}]}