{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Generative AI &amp; Prompt Engineering","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p></p> <p></p>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#workshop-agenda","level":2,"title":"Workshop Agenda","text":"<p>Welcome to our workshop on generative AI and Prompt Engineering for academic research and education.</p> <p>Generative AI are now deeply integrated into how we work, conduct research, teach, and learn. This workshop will introduce basic skills to effectively utilize these powerful tools, focusing on the art of crafting \"prompts\" — the instructions that guide AI models — and exploring how to integrate AI into daily productivity.</p> <p>Learning Objectives</p> <p>After this workshop, you should be able to:</p> <ul> <li>Identify how the workplace and classroom are being impacted by AI.</li> <li>Create effective prompts for leading AI models like Gemini, ChatGPT, Copilot, Claude, and others.</li> <li>Decide when to integrate AI into your own life and work.</li> </ul>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#setup","level":2,"title":"Setup","text":"<p>Prerequisites</p> <p>We will be using Professional paid versions of GPTs for this workshop. </p> <p>If your department does not provide you with a subscription to a major GPT, or you cannot afford to purchase a monthly subscription, please contact the organizers for details about getting a demo account for the workshop.</p> <p>Account Setup Instructions</p> <p>  Claude</p> <p>  Gemini</p> <p>  ChatGPT</p> <p>  Microsoft Copilot</p> <p>  GitHub Copilot</p> <p>  HuggingFace</p>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#ai-landscape","level":2,"title":"AI Landscape","text":"<p>An examination of the generative AI landscape, as of today. </p> <p>Includes an overview of Large Language Models within the greater AI ecosystem, ethics of AI, and future directions. </p>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#ethics-of-ai","level":2,"title":"Ethics of AI","text":"<p>An overview of the history of AI, ethical concerns, and international declarations and principles on AI.</p>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#prompt-engineering","level":2,"title":"Prompt Engineering","text":"<p>Next, we will cover the basics of Prompt Engineering for daily productivity, as well as in academic teaching and research</p> <p>General Productivity</p> <p> Go to our lesson on Daily Productivity with AI</p> <p>Generative AI is transforming everyday tasks. Learn how to leverage AI tools to streamline your workflows, enhance your writing, automate tasks, and boost your overall productivity. This section will likely cover:</p> <ul> <li>AI-Powered Writing Assistants:  Tools integrated into word processors, email clients, and other applications.</li> <li>Smart Summarization and Note-Taking: Using AI to quickly digest information and generate concise summaries.</li> <li>Automated Task Management:  Leveraging AI to schedule meetings, set reminders, and manage projects.</li> </ul>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#education","level":2,"title":"Education","text":"<p>We will discuss strategies for integrating AI into your teaching style, AI use in the classroom, and providing students with the ability to learn from AI as virtual tutors and teaching assistants.</p> <p>Education</p> <p> AI in the Classroom</p> <p> Ethics of AI in Education</p> <p>Explore the transformative potential of AI in education. Learn how to use AI to:</p> <ul> <li>Personalize Learning: Create customized learning experiences for students.</li> <li>Generate Educational Content: Develop lesson plans, quizzes, and interactive learning materials.</li> <li>Provide Intelligent Tutoring: Offer students personalized support and feedback.</li> <li>Enhance Accessibility:  Make learning more inclusive for all students.</li> </ul>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"#research","level":2,"title":"Research","text":"<p>We will briefly touch on the applications of AI for scientific research, primarily through the use of code interpreters and code execution using commercial software.</p> <p>A future workshop on advanced uses of AI for scientific research will cover the creation and deployment of AI for science gateways and integration of custom, private, GPTs and LLMs for private and secure applications. </p> <p>Research</p> <p> Go to our lesson on AI in Research</p> <p>Discover how generative AI is accelerating research across disciplines. This section will cover topics such as:</p> <ul> <li>Literature Review and Synthesis: Using AI to quickly analyze and summarize research papers.</li> <li>Data Analysis and Exploration: Leveraging AI to identify patterns and insights in complex datasets.</li> <li>Writing:  Utilizing AI to assist in crafting compelling grant proposals.</li> <li>Code Interpreter and execution: Using AI tools like GitHub Copilot to streamline the coding process.</li> </ul> <p>Tools and Platforms</p> <p> Go to our lesson on  GitHub Copilot</p> <p> Go to our lesson on   the OpenAI API</p> <p> Go to our lesson on the  Gemini API</p> <p> Go to our lesson on   HuggingFace</p> <p> Go to our lesson on   Gradio UI for Model Deployment</p>","path":["Home","Generative AI &amp; Prompt Engineering"],"tags":[]},{"location":"admissions/","level":1,"title":"Admissions","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Like it or not, AI is now both determining student admissions and in use for hiring graduates from our universities. </p> <p>Prospective high school applicants use AI to write their admissions essays and to prepare for university entrance exams (1, 2, 3). </p> <p>University admissions officers are using AI (4, 5, 6) to scan and evaluate applications.</p> <p>Preparing a Graduate School application</p> <p>Resume Builder</p> Prompt <pre><code>I am applying to a job at a major technology company, my resume hasn't been updated in several years.\n\nHelp me update my resume with my more recent accomplishments using my LinkedIn page and my Google Scholar.\n</code></pre>","path":["Education","Admissions"],"tags":[]},{"location":"agenda/","level":1,"title":"TBD 2025 Workshop Agenda","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p></p> <p>Registration Link</p>","path":["Home","TBD 2025 Workshop Agenda"],"tags":[]},{"location":"agenda/#date","level":3,"title":"Date","text":"<p>February 13 09:00 AM - 13:00 PM Arizona Time</p>","path":["Home","TBD 2025 Workshop Agenda"],"tags":[]},{"location":"agenda/#location","level":3,"title":"Location","text":"<p>ENR2  Classroom #N595</p> <p>No food or drinks inside the classrooms, please.</p>","path":["Home","TBD 2025 Workshop Agenda"],"tags":[]},{"location":"agenda/#instructorss","level":4,"title":"Instructors(s):","text":"<p>Michele Cosi </p> <p>Jeffrey K. Gillan PhD </p> <p>Megh Krishnaswamy </p> <p>Carlos Lizárraga-Celaya PhD </p> <p>Enrique Noriega PhD </p> <p>Tyson Lee Swetnam PhD </p>","path":["Home","TBD 2025 Workshop Agenda"],"tags":[]},{"location":"agenda/#about","level":2,"title":"About","text":"<p>This website follows the FAIR and CARE data principles and hopes to help further open science. </p>","path":["Home","TBD 2025 Workshop Agenda"],"tags":[]},{"location":"agenda/#agenda","level":2,"title":"Agenda","text":"Lessons Instructor Link 08:30 Arrival: Account Creation &amp; Wifi checks All 09:00 Introductions &amp; Code of Conduct Tyson presentation 09:10 Session 1: AI Landscape Carlos presentation 09:30 Session 2: Basics of Writing Prompts Tyson 9:50 Break 10:00 Session 3: General Productivity Michele &amp; Megh 10:50 Break 11:00 Session 4a: Teaching Tyson 11:30 Session 4b Tutoring Tyson 11:50 Break 12:00 Session 4a: Notebook LM Jeff 12:30 Session 4b: Code Interpreters Tyson 13:00 Conclude","path":["Home","TBD 2025 Workshop Agenda"],"tags":[]},{"location":"agenda/#prerequisites","level":2,"title":"Prerequisites","text":"<p> a laptop with an active wifi connection</p> <p> A professional ChatGPT, Google Gemini, Microsoft Copilot, or Claude account. </p> <p> GitHub account with free Educational Benefit access to Copilot.  </p>","path":["Home","TBD 2025 Workshop Agenda"],"tags":[]},{"location":"agenda/#code-of-conduct","level":2,"title":"Code of Conduct","text":"<p>This Code of Conduct applies to all Event participants, instructors, and activities during the workshop.</p> <p>Data Science Institute (DSI) is dedicated to providing professional computational research and educational experiences for all of our users, regardless of domain focus, academic status, educational level, gender/gender identity/expression, age, sexual orientation, mental or physical ability, physical appearance, body size, race, ethnicity, religion (or lack thereof), technology choices, dietary preferences, or any other personal characteristic.</p> <p>While participating at an Event, we expect you to:</p> <ul> <li>Interact with others and use ChatGPT professionally and ethically by     complying with our Policies.</li> <li>Constructively criticize ideas and processes, not people.</li> <li>Follow the Golden Rule (treat others as you want to be treated) when     interacting online or in-person with collaborators, trainers, and     support staff.</li> <li>Comply with this Code in spirit as much as the letter, as it is     neither exhaustive nor complete in identifying any and all possible     unacceptable conduct.</li> </ul> <p>We do not tolerate harassment of other users or staff in any form (including, but not limited to, violent threats or language, derogatory language or jokes, doxing, insults, advocating for or encouraging any of these behaviors). Sexual language and imagery are not appropriate at any time (excludes Protected Health Information in compliance with HIPAA). Any user violating this Code may be expelled from the platform and the workshop at DSI's sole discretion without warning.</p> <p>To report a violation of this Code, directly speak to a trainer. If you are not comfortable speaking to a trainer, or the trainer is who you are reporting, email info@cyverse.org with the following information:</p> <ul> <li>Your contact information</li> <li>Names (real, username, pseudonyms) of any individuals involved, and     or witness(es) if any.</li> <li>Your account of what occurred and if the incident is ongoing. If     there is a publicly available record (a tweet, public chat log,     etc.), please include a link or attachment.</li> <li>Any additional information that may be helpful in resolving the     issue.</li> </ul>","path":["Home","TBD 2025 Workshop Agenda"],"tags":[]},{"location":"agentic/","level":1,"title":"Agentic AI","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#what-is-agentic-ai","level":2,"title":"What is Agentic AI?","text":"<p>\"Agents\" or \"Agentic\" AI systems are LLM-powered assistants that can take multiple autonomous actions when given prompts or tasks. Unlike traditional conversational AI that simply responds to queries, agentic AI can:</p> <ul> <li>Execute specific tasks independently with minimal supervision</li> <li>Reflect and reason about problems through multi-step thinking processes</li> <li>Make decisions based on context, predictions, and classifications</li> <li>Interact with tools and systems to accomplish complex workflows</li> <li>Adapt their approach based on feedback and results</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#key-characteristics-of-agentic-ai","level":2,"title":"Key Characteristics of Agentic AI","text":"","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#autonomy","level":3,"title":"Autonomy","text":"<p>Agentic AI can break down complex requests into subtasks and execute them without requiring step-by-step human guidance. For example, when asked to \"fix the bug in the checkout flow,\" an agentic system might:</p> <ol> <li>Search the codebase for checkout-related files</li> <li>Identify potential issues by analyzing error patterns</li> <li>Propose and implement fixes</li> <li>Run tests to verify the solution</li> <li>Document the changes made</li> </ol>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#tool-use-and-integration","level":3,"title":"Tool Use and Integration","text":"<p>Modern agentic AI systems can interact with external tools, APIs, and systems. This is where Model Context Protocol (MCP) becomes crucial. MCP allows AI agents to:</p> <ul> <li>Access file systems and databases</li> <li>Execute code and terminal commands</li> <li>Interact with version control systems like Git</li> <li>Connect to web services and APIs</li> <li>Read and modify application state</li> </ul> <p>See our MCP documentation for detailed information on how this protocol enables sophisticated agentic behaviors.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#iterative-problem-solving","level":3,"title":"Iterative Problem-Solving","text":"<p>Rather than providing a single response, agentic AI can iterate on solutions. It may:</p> <ul> <li>Try an approach, evaluate the results, and adjust</li> <li>Request additional context when needed</li> <li>Backtrack and try alternative strategies</li> <li>Learn from errors within a session</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#multi-step-reasoning","level":3,"title":"Multi-Step Reasoning","text":"<p>Agentic systems often employ chain-of-thought reasoning, breaking problems into logical steps and maintaining context across a sequence of operations. This is particularly evident in modern coding assistants during vibe coding workflows.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#agentic-ai-in-practice-vibe-coding","level":2,"title":"Agentic AI in Practice: Vibe Coding","text":"<p>The term \"vibe coding\" describes one of the most prominent applications of agentic AI today—where developers collaborate with AI agents directly in their development environment. Modern agentic coding tools include:</p> <ul> <li> Claude Code - VS Code extension with autonomous coding capabilities</li> <li> Cursor - Standalone editor with powerful agentic features</li> <li> Cline - Open-source VS Code extension pioneering \"bring your own model\" approach</li> <li> GitHub Copilot - Integrated agentic coding with GitHub workflows</li> <li> Windsurf - Standalone editor with agentic inline features</li> </ul> <p>These tools demonstrate agentic behavior by:</p> <ul> <li>Reading multiple files to understand project context</li> <li>Making coordinated changes across multiple files</li> <li>Running commands in the terminal to test changes</li> <li>Debugging errors and iterating on solutions</li> <li>Suggesting architectural improvements based on codebase analysis</li> </ul> <p>Learn more about these tools in our Vibe Coding guide.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#how-agentic-ai-works-the-agent-loop","level":2,"title":"How Agentic AI Works: The Agent Loop","text":"<p>Agentic AI typically operates using a perception-decision-action loop:</p> <pre><code>flowchart TD\n    A[User Request] --&gt; B[Perceive Context]\n    B --&gt; C[Plan Actions]\n    C --&gt; D[Execute Action]\n    D --&gt; E[Observe Results]\n    E --&gt; F{Goal Achieved?}\n    F --&gt;|No| B\n    F --&gt;|Yes| G[Report Completion]\n\n    style A fill:#e1f5ff\n    style G fill:#c8e6c9</code></pre> <ol> <li>Perceive: Gather context from the environment (code, files, system state)</li> <li>Plan: Determine what actions are needed to accomplish the goal</li> <li>Execute: Perform the action using available tools</li> <li>Observe: Evaluate the results and any errors</li> <li>Iterate: Continue until the goal is met or help is needed</li> </ol>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#enabling-technologies","level":2,"title":"Enabling Technologies","text":"","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#model-context-protocol-mcp","level":3,"title":"Model Context Protocol (MCP)","text":"<p>MCP is foundational for modern agentic AI systems. It provides:</p> <ul> <li>Standardized context access across different applications</li> <li>Tool invocation capabilities for executing actions</li> <li>Real-time application state awareness</li> <li>Cross-application coordination potential</li> </ul> <p>Without MCP or similar protocols, AI agents would be limited to conversational assistance. MCP enables them to \"see\" your work environment and \"act\" within it. Read our comprehensive MCP guide to understand how this works.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#function-calling-tool-use","level":3,"title":"Function Calling / Tool Use","text":"<p>Most modern LLMs support structured function calling, allowing them to:</p> <ul> <li>Invoke APIs with specific parameters</li> <li>Execute predefined workflows</li> <li>Query databases or search engines</li> <li>Interact with external services</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#extended-context-windows","level":3,"title":"Extended Context Windows","text":"<p>Larger context windows (200K+ tokens) enable agents to:</p> <ul> <li>Maintain awareness of entire projects</li> <li>Reference extensive documentation</li> <li>Track long conversation histories</li> <li>Analyze multiple files simultaneously</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#use-cases-for-agentic-ai","level":2,"title":"Use Cases for Agentic AI","text":"","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#software-development","level":3,"title":"Software Development","text":"<ul> <li>Automated code refactoring across multiple files</li> <li>Bug diagnosis and fixing with minimal guidance</li> <li>Test generation and execution</li> <li>Documentation creation from code analysis</li> <li>Code review and suggestions based on best practices</li> </ul> <p>Related: See Vibe Coding for development-focused tools.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#research-and-data-analysis","level":3,"title":"Research and Data Analysis","text":"<ul> <li>Data scraping and preprocessing from multiple sources</li> <li>Automated literature reviews with source synthesis</li> <li>Statistical analysis with iterative refinement</li> <li>Visualization generation and iteration</li> <li>Report generation from raw data</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#content-creation","level":3,"title":"Content Creation","text":"<ul> <li>Multi-format content generation (blog posts, social media, scripts)</li> <li>Iterative editing based on style guidelines</li> <li>Research and fact-checking during writing</li> <li>SEO optimization with keyword analysis</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#system-administration","level":3,"title":"System Administration","text":"<ul> <li>Log analysis and troubleshooting</li> <li>Automated deployment workflows</li> <li>Configuration management</li> <li>Security auditing and remediation</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#creative-work","level":3,"title":"Creative Work","text":"<ul> <li>Iterative design exploration in design tools</li> <li>3D modeling assistance with context awareness</li> <li>Music and art generation with style consistency</li> <li>Creative brainstorming with research integration</li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#the-future-of-agentic-ai","level":2,"title":"The Future of Agentic AI","text":"<p>As agentic AI systems become more sophisticated, we're seeing:</p> <ul> <li>Multi-agent systems where specialized agents collaborate</li> <li>Longer-running agents that work on tasks over hours or days</li> <li>Cross-application coordination via protocols like MCP</li> <li>Improved safety mechanisms for autonomous operations</li> <li>Better user control over agent autonomy levels</li> </ul> <p>The combination of vibe coding tools, MCP integration, and increasingly capable LLMs is creating a new paradigm where AI agents become true collaborators in complex workflows.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#getting-started-with-agentic-ai","level":2,"title":"Getting Started with Agentic AI","text":"<p>To experience agentic AI firsthand:</p> <ol> <li>Try vibe coding: Install Claude Code or Cursor and experience agentic coding assistance</li> <li>Explore MCP: Set up Claude Desktop with MCP servers to see context-aware assistance</li> <li>Experiment with prompting: Practice breaking down complex tasks and letting the AI agent iterate on solutions</li> <li>Learn the tools: Explore the various vibe coding platforms to find the best fit for your workflow</li> </ol>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#best-practices-for-working-with-agentic-ai","level":2,"title":"Best Practices for Working with Agentic AI","text":"<ul> <li>Start with clear goals: Give agents well-defined objectives</li> <li>Monitor progress: Check in on agent actions, especially when learning</li> <li>Provide feedback: Correct course when the agent goes astray</li> <li>Understand limitations: Know when to take manual control</li> <li>Security awareness: Be cautious with agents that can execute code or access sensitive systems</li> <li>Iterate on prompts: Refine your instructions based on agent behavior</li> </ul> <p>Security Considerations</p> <p>Agentic AI systems that can execute code, access files, or interact with systems require careful security consideration. Always:</p> <ul> <li>Review code before execution in sensitive environments</li> <li>Use appropriate sandboxing and permissions</li> <li>Follow your institution's security policies</li> <li>Be aware of what tools and systems your AI agent can access</li> </ul> <p>Learn more in our Vibe Coding security warnings.</p>","path":["Research","Agentic AI"],"tags":[]},{"location":"agentic/#further-resources","level":2,"title":"Further Resources","text":"<ul> <li>Vibe Coding Guide - Comprehensive overview of agentic coding tools</li> <li>Model Context Protocol (MCP) - Deep dive into the protocol enabling agentic behaviors</li> <li>AI Landscape - Broader context on AI capabilities and models</li> <li>Anthropic's Claude - Documentation for one of the leading agentic AI systems</li> <li>LangChain Agents - Framework for building custom agentic systems  </li> </ul>","path":["Research","Agentic AI"],"tags":[]},{"location":"ai_landscape/","level":1,"title":"The Landscape","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#a-glance-at-the-generative-ai-landscape","level":3,"title":"A Glance at the Generative AI Landscape","text":"<p>Image Credit: Yang et al.  (While this image depicts the state of LLMs in 2023, it effectively illustrates the foundational models and their evolution)</p> <p>The field of Generative AI is rapidly evolving. </p> <p>This section provides a snapshot of some of the most influential models and platforms as of 2025.</p> <p>Matt Turck's MAD Landscape</p> <p> </p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#huggingface-arena-llm-leaderboard","level":2,"title":"HuggingFace  Arena LLM Leaderboard","text":"","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#table-prices-of-services-last-checked-102025","level":2,"title":"Table: Prices of Services (last checked 10/2025)","text":"LLM Service Plan Price (per month) Details Anthropic Claude Free $0 Basic Claude access with limited daily use Pro $20 More usage, Claude Code terminal access, unlimited projects, Research access Max $100 Priority access, substantially higher usage, enhanced features Max Pro $200 Highest tier with maximum usage limits and priority access to newest models Team $30/month or $25/month (annual) Central billing, administration, collaboration features (minimum 5 members) Enterprise Contact Sales Enhanced context window, SSO, role-based access, audit logs, compliance API Claude API Pay-As-You-Go Varies Claude Sonnet 4.5: $3/1M input, $15/1M output (200K context)  Claude Opus 4.1: $15/1M input, $75/1M output  Claude Haiku 3.5: $0.80/1M input, $4/1M output  Batch processing: 50% discount, Prompt caching available (75-90% savings) Claude Code Included in Pro+ $20+ Terminal-based AI coding assistant included with Pro, Max, Max Pro subscriptions  Web Search: $10/1,000 searches, Code Execution: $0.05/hour per container Google AI Free $0 Unlimited Gemini 2.5 Flash, limited Gemini 2.5 Pro, 32K context window Google AI Pro $19.99 Expanded access to Gemini 2.5 Pro (100 queries/day), 1M context window, 2TB storage, NotebookLM  Free for university students for 1 year Google AI Ultra $249.99 Highest access to Gemini 2.5 Pro, exclusive access to Gemini 2.5 Deep Think, Veo 3 video generation, YouTube Premium, 30TB storage Gemini API Pay-As-You-Go Varies Gemini 2.5 Flash: $0.30/1M input, $2.50/1M output  Gemini 2.5 Pro: $1.25/1M input (≤200K), $10/1M output (≤200K)  Gemini 2.5 Flash-Lite: $0.10/1M input, $0.40/1M output  Batch processing: 50% discount OpenAI ChatGPT Free $0 Limited access to GPT-5 (10 messages every 5 hours), then GPT-5-mini Plus $20 Higher message limits to GPT-5, unlimited GPT-5-mini, access to o3-mini, o1 models Pro $200 Unlimited GPT-5 access, GPT-5 Pro with advanced reasoning, extended context windows Team $25/user (annual) or $30/user (monthly) All Plus features with higher message caps, team workspace, data excluded from training Enterprise Contact Sales Unlimited high-speed models, extended context windows, enterprise security OpenAI API Pay-As-You-Go Varies GPT-5: $1.25/1M input, $10/1M output (272K-400K context)  GPT-5-mini: $0.25/1M input, $2/1M output  GPT-5-nano: $0.05/1M input, $0.40/1M output  GPT-4o: $2.50/1M input, $10/1M output  o3-mini: $1.10/1M input, $4.40/1M output Perplexity AI Free $0 Unlimited quick searches, 5 Pro searches/day, 5 follow-up questions every 4 hours Pro $20/month or $200/year 300+ Pro searches/day, access to advanced AI models, file uploads Education Pro $4.99/month All Pro features with student/faculty verification  1 month free trial Max $200/month or $2,000/year Unlimited Labs usage, access to top-tier models (OpenAI o3-pro, Claude Opus 4) Enterprise Pro $40/user/month or $400/user/year Admin tools, collaboration features, domain verification, SCIM provisioning Microsoft Copilot Free $0 GPT-4o-powered chat, 15 image generation boosts/day Microsoft 365 Premium Premium $19.99 Full M365 suite + Copilot in all apps, 1TB storage, extended AI usage limits, 40 image generations Microsoft 365 Copilot Business/Enterprise $30/user AI in Word, Excel, PowerPoint, Outlook, Teams. Requires existing M365 license (\\(12.50-\\)57/user) Consumption-based $0.01 per message Pay-per-use alternative to monthly subscription (30 messages for proprietary files, 25 per agent action) GitHub Copilot Free $0 Up to 2,000 code completions/month, 50 premium requests/month  Free for students, teachers, open source maintainers Pro $10/month or $100/year Unlimited code completions, 300 premium requests/month, access to Copilot coding agent Pro+ $39/month or $390/year 1,500 premium requests/month, full access to all models, GitHub Spark, compute resources Business $19/user/month 300 premium requests/user, user management, usage metrics, team collaboration Enterprise $39/user/month 1,000 premium requests/user, all AI models, advanced customization, enterprise features Mistral AI Le Chat Free $0 Basic AI assistant with limited messages Le Chat Pro $14.99 Up to 6x more messages, 150 flash answers/day, 5x web searches, 1,000 memories, 15GB libraries Le Chat Team $24.99/user or $299.88/user/year 200 flash answers/day, 30GB libraries/user, domain verification, SCIM provisioning La Plateforme API Varies Mistral Medium 3: $0.40/1M input, $2.00/1M output  Mistral Nemo: $0.30/1M tokens  Mistral Large 2: $3/1M input, $9/1M output  Codestral: $1/1M input, $3/1M output Cohere Free Trial $0 Limited API calls for testing Production Varies Command R 03-2024: $0.50/1M input, $1.50/1M output  Command R+ 08-2024: $2.50/1M input, $10/1M output  Command-light: $0.30/1M input, $0.60/1M output  Aya Expanse (8B &amp; 32B): $0.50/1M input, $1.50/1M output Education Program Contact AI access for students and educators (pricing not publicly disclosed) DeepSeek DeepSeek Chat API Pay-As-You-Go DeepSeek Chat: $0.57/1M input, $1.68/1M output  DeepSeek Reasoner (R1): $0.57/1M input, $1.68/1M output  128K context window  ~200x cheaper than GPT-4 Turbo  ⚠️ NOT ALLOWED for US-based researchers - See restrictions below Open Source Free Free to download and deploy locally. Training cost: $294,000 (peer-reviewed in Nature)  ⚠️ Self-hosted use requires institutional IT/security approval Qwen (Alibaba) Qwen Chat Free Free web interface powered by Qwen-Max  ⚠️ NOT RECOMMENDED for US-based researchers - Chinese company, data sovereignty concerns Qwen API Pay-As-You-Go Qwen-Flash: $0.05/1M input, $0.40/1M output  Qwen3-Coder: $0.22/1M input, $0.95/1M output  Qwen-Max: $1.60/1M input, $6.40/1M output  1M context window, 90-day free trial (1M tokens) Open Source Free Apache 2.0 license, 40M+ downloads. Sizes: 0.6B-235B parameters  ⚠️ Self-hosted use requires institutional IT/security approval Midjourney Basic $10 ~200 image generations/month Standard $30 15 hrs fast GPU time, unlimited relaxed Pro $60 30 hrs fast GPU time, stealth mode Mega $120 60 hrs fast GPU time, stealth mode DALL-E 3 Via ChatGPT Plus Included Image generation within ChatGPT API Varies Standard: $0.040/image, HD: $0.080/image Stable Diffusion DreamStudio $10 1000 credits (~5000 images) API Varies $0.002 per image (512x512) Grok by xAI X Premium $8 Access via X (Twitter) Premium X Premium+ $16 Priority access, higher limits Character AI Free $0 Limited features and queue priority c.ai+ $9.99 Priority access, faster responses, exclusive features Together AI Serverless Inference Pay-As-You-Go Text &amp; Vision Models: \\(0.02-\\)3.50/1M tokens  Image Models: \\(0.0027-\\)0.08/megapixel  Embedding Models: \\(0.01-\\)0.08/1M tokens GPU Clusters Pay-As-You-Go Instant Clusters: \\(1.76-\\)5.50/GPU hour  Reserved Clusters: Starting at $1.30/GPU hour Fine-Tuning Pay-As-You-Go LoRA Fine-Tuning (≤16B params): Starting at $0.48  Full Fine-Tuning (70-100B params): Up to $3.20 Groq Free Tier $0 Available for getting started Developer Tier Pay-As-You-Go Up to 10x more rate limits than free tier. Batch Processing: 50% cost discount (through April 2025) Enterprise Contact Sales Custom solutions for large organizations Replicate Pay-As-You-Go Varies CPU: $0.36/hour  Nvidia T4 GPU: $0.81/hour (public), $1.98/hour (private)  8x H100 GPU: $43.92/hour  Run open-source models with per-second billing Hugging Face Free $0 Community models and datasets Pro $9 Advanced features, private repos Enterprise Contact Sales Dedicated support, SLAs, security features Amazon Bedrock On-Demand Varies Access to Claude, Llama 2, Stable Diffusion, and more Google Vertex AI On-Demand Varies 130+ foundation models including Gemini, Claude, Llama Azure AI Studio On-Demand Varies Access to GPT-4, Claude, Llama, Mistral, and more Meta Llama Open Source Free Llama 2 and Llama 3 models for download Apertus Open Source Free Fully open Swiss LLM: 8B &amp; 70B models, 1,811 languages, 65K context, complete transparency (weights + data + training)  ETH Zurich, EPFL, CSCS - Permissive license, compliance-first design Ollama Local Install Free Run LLMs locally on your hardware LM Studio Local Install Free Desktop app for running LLMs locally Jan.ai Local Install Free Open-source ChatGPT alternative, runs locally Continue.dev Open Source Free Open-source autopilot for VS Code and JetBrains Poe by Quora Monthly $19.99 Access to various chatbots including GPT-4, Claude Yearly $199.99 Annual subscription with all chatbot access You.com YouPro $20 Latest AI models, personalized AI with memory Jasper AI Creator $49 Writing assistant with templates Teams $125 Advanced features for small teams Business Contact Sales Custom pricing for organizations Replit AI Core $20 AI coding assistant integrated in Replit IDE","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#agentic-browsers-ai-powered-web-browsers","level":2,"title":"Agentic Browsers (AI-Powered Web Browsers)","text":"Browser Plan Price (per month) Details Perplexity Comet Free $0 AI-powered browser with sidecar assistant, Perplexity AI search, tab management, content summarization Perplexity Max $200 Background Assistant for multi-tasking, autonomous task execution (booking flights, sending emails), mission control dashboard Dia Browser Free Beta $0 (Invite-only) AI-first browser, URL bar = AI chat, tab conversations, Skills system, browsing history context (opt-in)  macOS 14+ M1+ only Dia Pro $20 Unlimited AI chat and Skills, multi-step reasoning, task automation  Acquired by Atlassian ($610M) Fellou Free $0 1,000 Sparks (~4 tasks), Deep Search, autonomous web actions, Shadow Workspace for background tasks Plus $19 2,000 Sparks (~8 tasks), 3 scheduled tasks, priority support Pro $39.90 5,000 Sparks (~20 tasks), 5 scheduled tasks, Image/Code/Music agents Ultra $199.90 Unlimited Sparks, unlimited scheduled/concurrent tasks, exclusive support Opera Neon Subscription $19.99 (Waitlist) Neon Do (autonomous browsing), Neon Make (AI creation), Cards system, Tasks workspaces, local processing Genspark AI Browser Free $0 100 credits daily, Super Agent Everywhere, Autopilot Mode, 700+ MCP tool integrations Plus $24.99 10,000 credits monthly, priority AI agent access, top-tier models, AI Slides/Sheets/Docs Pro $249.99 125,000 credits monthly, full Super Agent access, phone calls, video generation Microsoft Edge Copilot Mode Free (Experimental) $0 Cross-tab awareness, task automation, in-page assistance, browser history/credentials access  Windows/Mac, opt-in Opera One + Aria Free $0 Free AI assistant, real-time web access, page context mode, image generation, tab commands, local AI models  No account required Brave + Leo AI Free $0 Privacy-first AI, Llama 3.1 8B, Mixtral, Claude Haiku, Qwen, content awareness, zero data retention Leo Premium Varies Claude Sonnet 4, DeepSeek R1 reasoning models, Bring Your Own Model (BYOM) <p>Notes on Agentic Browsers:</p> <ul> <li>True Agentic Capabilities: Comet, Fellou, Opera Neon, Dia, and Genspark can autonomously perform multi-step tasks (booking, purchasing, form filling)</li> <li>AI-Enhanced: Microsoft Edge Copilot Mode, Opera One, and Brave Leo provide AI assistance but with less autonomous action</li> <li>Platform Availability: Most are Chromium-based; Dia is macOS only (M1+); Others support Windows/Mac/Linux</li> <li>Privacy Considerations: Check each browser's data policies - some use cloud AI, others offer local processing</li> <li>Coming Soon: OpenAI browser expected late 2025 with ChatGPT integration and Operator agent</li> </ul> <p>Notes:</p> <ul> <li>Token pricing for API access can be complex. Refer to each provider's pricing page for the most accurate and up-to-date details.</li> <li>\"Contact Sales\" typically indicates that pricing is customized based on usage, features, and the specific needs of the customer.</li> <li>Many services offer free trials or limited free tiers, allowing you to test them out before committing to a paid plan.</li> </ul>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#important-restrictions-for-us-based-researchers","level":2,"title":"⚠️ Important Restrictions for US-Based Researchers","text":"","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#deepseek-ai-federal-and-state-restrictions","level":3,"title":"DeepSeek AI - Federal and State Restrictions","text":"<p>PAID CLOUD SERVICE NOT ALLOWED:</p> <p>DeepSeek's paid API and cloud services are prohibited for US-based researchers at many institutions due to:</p> <p>Federal Restrictions:</p> <ul> <li> <p>H.R. 1121 - \"No DeepSeek on Government Devices Act\" (Introduced Feb 2025)</p> </li> <li> <p>House Select Committee Report - \"DeepSeek Unmasked: Exposing the CCP's Latest Tool For Spying, Stealing, and Subverting U.S. Export Control Restrictions\"</p> </li> <li> <p>Federal Agency Bans: NASA, U.S. Navy, Department of Defense (DOD), Department of Commerce have banned DeepSeek</p> </li> <li> <p>Owned by High-Flyer (Chinese company with CCP control)</p> </li> <li> <p>Data stored in China and accessible to Chinese government</p> </li> <li> <p>Content manipulation to align with CCP propaganda</p> </li> </ul> <p>State-Level Bans:</p> <ul> <li> <p>Texas (Jan 31, 2025), Virginia (Feb 11, 2025), New York (Feb 10, 2025)</p> </li> <li> <p>Additional states: Iowa, South Dakota, Kansas, Tennessee, North Carolina, Nebraska, Arkansas, North Dakota, Oklahoma, Alabama, Georgia</p> </li> </ul> <p>University Bans:</p> <ul> <li> <p>All Virginia public universities (George Mason, UVA, Virginia Tech, William &amp; Mary, JMU)</p> </li> <li> <p>North Dakota University System</p> </li> </ul> <p>SELF-HOSTED OPEN-SOURCE MAY BE PERMITTED:</p> <p>Open-source DeepSeek models can be downloaded and run on-premises, but researchers MUST:</p> <ul> <li> <p>✅ Check with institutional IT and security teams first</p> </li> <li> <p>✅ Ensure compliance with federal grant requirements (NSF, DOD, DOE)</p> </li> <li> <p>✅ Never upload sensitive, proprietary, or controlled data</p> </li> <li> <p>✅ Document usage for research security compliance</p> </li> </ul>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#qwen-alibaba-data-sovereignty-concerns","level":3,"title":"Qwen (Alibaba) - Data Sovereignty Concerns","text":"<p>NOT SPECIFICALLY BANNED, BUT NOT RECOMMENDED:</p> <p>Qwen is not subject to specific federal bans like DeepSeek, but has serious concerns for US researchers:</p> <p>Key Issues:</p> <ul> <li> <p>Owned by Alibaba (Chinese company subject to CCP control)</p> </li> <li> <p>Data stored in China under Chinese data sovereignty laws</p> </li> <li> <p>No GDPR compliance or EU data protection representative</p> </li> <li> <p>Potential surveillance under Chinese national security laws</p> </li> <li> <p>Congressional scrutiny (Senators urged sanctions in 2023, not yet implemented)</p> </li> </ul> <p>Regulatory Framework:</p> <ul> <li> <p>NSF Research Security - Requires disclosure of foreign support and affiliations</p> </li> <li> <p>Treasury Outbound Investment Restrictions - Limits US investments in Chinese AI companies (affects funding, not use)</p> </li> <li> <p>No Entity List designation (as of Oct 2025)</p> </li> </ul> <p>SELF-HOSTED OPEN-SOURCE MAY BE PERMITTED:</p> <p>Qwen's Apache 2.0 licensed models (40M+ downloads on HuggingFace) can be run on-premises, but researchers MUST:</p> <ul> <li> <p>✅ Check with institutional IT and security teams first</p> </li> <li> <p>✅ Verify compliance with federal grant terms</p> </li> <li> <p>✅ Avoid uploading to Chinese cloud services</p> </li> <li> <p>✅ Document AI tool usage in research security plans</p> </li> </ul>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#recommendations-for-researchers","level":3,"title":"Recommendations for Researchers","text":"<p>✅ SAFE FOR RESEARCH (US-based alternatives):</p> <ul> <li> <p>OpenAI (ChatGPT, GPT-5 API) - US company</p> </li> <li> <p>Anthropic (Claude) - US company</p> </li> <li> <p>Google (Gemini) - US company</p> </li> <li> <p>Microsoft (Copilot) - US company</p> </li> <li> <p>Mistral AI - French company (EU-based)</p> </li> <li> <p>Cohere - Canadian company</p> </li> </ul> <p>⚠️ USE WITH EXTREME CAUTION (Chinese companies):</p> <ul> <li> <p>DeepSeek - BANNED at many institutions</p> </li> <li> <p>Qwen - Not banned, but data sovereignty concerns</p> </li> <li> <p>Check institutional policies BEFORE use</p> </li> </ul> <p>✅ SELF-HOSTED OPEN-SOURCE (May be acceptable):</p> <ul> <li> <p>Meta Llama (US company, Apache 2.0)</p> </li> <li> <p>DeepSeek open-source (with institutional approval)</p> </li> <li> <p>Qwen open-source (with institutional approval)</p> </li> <li> <p>Mistral open-source (EU company, Apache 2.0)</p> </li> </ul> <p>ALWAYS:</p> <ol> <li> <p>Check your institution's AI usage policy</p> </li> <li> <p>Review federal grant terms (NSF, NIH, DOD, DOE)</p> </li> <li> <p>Consult with IT security and research compliance offices</p> </li> <li> <p>Never share sensitive, proprietary, or controlled data with foreign AI services</p> </li> <li> <p>Document all AI tool usage for research security requirements</p> </li> </ol> <p>Best Options for Students &amp; Educators:</p> <ul> <li> <p>Free/Low-Cost Options:</p> <ul> <li>DeepSeek - Most affordable API at $0.57/$1.68 per 1M tokens (~200x cheaper than GPT-4 Turbo), open-source option available</li> <li>Meta Llama - Completely free open-source models (Llama 4 Scout &amp; Maverick available for download)</li> <li>GitHub Copilot - Free for students, teachers, and open source maintainers</li> <li>Perplexity Education Pro - $4.99/month with student/faculty verification (1 month free trial)</li> <li>Google AI Pro - Free for university students for 1 year ($19.99/month value)</li> <li>HuggingFace - Free community access to models and datasets, $2/month free credits for Pro users</li> <li>Ollama, LM Studio, Jan.ai - Run LLMs locally on your hardware for free</li> </ul> </li> <li> <p>Best Value Paid Options:</p> <ul> <li>Mistral Le Chat Pro - $14.99/month (cheaper than competitors, strong performance)</li> <li>OpenAI GPT-4o-mini API - $0.15/$0.60 per 1M tokens (60%+ cheaper than GPT-3.5 Turbo)</li> <li>Gemini 2.5 Flash-Lite - $0.10/$0.40 per 1M tokens (most economical for high-volume simple tasks)</li> <li>Claude Haiku 3.5 API - $0.80/$4 per 1M tokens (balanced cost and capability)</li> </ul> </li> <li> <p>Educational Programs Available:</p> <ul> <li>Cohere Education Program - Contact for student/educator access</li> <li>Google AI Pro - 1 year free for university students</li> <li>Perplexity Education Pro - $4.99/month with verification</li> </ul> </li> </ul> <p>Additional Chatbot and LLM Services:</p> <ol> <li> <p>Amazon Bedrock, Azure AI Foundry, Google Vertex: Provide access to various foundation models but each run on a respective cloud service provider's hardware. Ideal for companies and institutions already running their infrastructure on commercial cloud services. </p> </li> <li> <p>You.com: Offers a pro plan with access to latest AI models, personalized AI with memory and advanced AI writing tools.</p> </li> <li> <p>Poe by Quora:  A platform that gives you access to various chatbots (like GPT-4, Claude, etc.) through a single subscription.</p> </li> </ol> <p>Image and Video Generation Models</p> <p>Glossary</p> <p> Google's Machine Learning Glossary</p> <p> NVIDIA's Data Science Glossary</p> <p>Agentic AI: Uses sophisticated reasoning and iterative planning to autonomously solve complex, multi-step problems. Agentic systems can break down tasks, use tools, and make decisions to achieve goals with minimal human intervention.</p> <p>Anthropic: A research organization emphasizing AI safety and governance. Known for Claude, a large language model (LLM) with advanced reasoning and robust safety features.</p> <p>API (Application Programming Interface): A set of protocols and tools that allow different software applications to communicate. In AI, APIs enable developers to integrate LLM capabilities into their applications programmatically.</p> <p>Attention Mechanism: A neural network technique that allows models to focus on relevant parts of input data when processing information. The foundation of transformer architectures used in modern LLMs.</p> <p>Chain-of-Thought (CoT): A prompting technique that encourages AI models to break down complex problems into intermediate reasoning steps, improving accuracy on tasks requiring logic and multi-step reasoning.</p> <p>ChatGPT: OpenAI's general-purpose LLM, renowned for its conversational strengths, versatility, and ability to adapt to varied tasks through effective prompt engineering.</p> <p>Claude: Anthropic's LLM, recognized for its interpretability, strong reasoning capabilities, and rigorous safety considerations.</p> <p>Context Window: The maximum amount of text (measured in tokens) that an LLM can process at once, including both the input prompt and generated output. Modern models range from 8K to over 1M tokens.</p> <p>Copilot (GitHub, Microsoft): An AI-driven developer assistant offering code suggestions, debugging support, and efficiency improvements, leveraging generative AI to boost productivity.</p> <p>Diffusion Models: A class of generative models that create images by iteratively denoising random noise. Used in systems like Stable Diffusion, DALL-E, and Midjourney for text-to-image generation.</p> <p>Embeddings: Numerical vector representations of data (e.g., text, images, audio) that capture semantic meaning and relationships. Useful for search, clustering, recommendation, and more.</p> <p>Few-Shot Learning: The ability of an AI model to learn new tasks from just a few examples provided in the prompt, without requiring additional training or fine-tuning.</p> <p>Fine-Tuning: The process of further training a pre-trained model on a specific dataset or task to specialize its capabilities for particular use cases or domains.</p> <p>Foundation Models: Large-scale deep learning models (e.g., LLMs, vision models, multimodal models) trained on massive datasets. They serve as a base or \"foundation\" for a wide range of downstream tasks, enabling transfer learning and rapid adaptation.</p> <p>Gemini: Google's family of multimodal foundation models, capable of understanding and generating text, images, and other data types, reflecting Google's advancements in AI research.</p> <p>Generative AI (GenAI): AI systems capable of creating new content—text, images, code, audio, video—based on patterns learned from training data. Includes LLMs, image generators, and multimodal models.</p> <p>GitHub: A leading platform for version control and software collaboration. Now integrated with AI tools like GitHub Copilot for enhanced code development workflows.</p> <p>Hallucination: When an AI model generates false, nonsensical, or unfaithful information presented as fact. A key challenge in LLM reliability, especially for factual or specialized domains.</p> <p>HuggingFace: A hub and community for open-source AI models, datasets, and applications. Widely used in the natural language processing (NLP) community for model sharing and development.</p> <p>Inference: The process of using a trained AI model to make predictions or generate outputs. In LLMs, this refers to generating text responses from prompts.</p> <p>Large Language Models (LLMs): A subset of foundation models trained on extensive text corpora, enabling them to generate human-like text, summarize information, reason about topics, and perform a variety of NLP tasks. Examples include GPT, Claude, and Gemini.</p> <p>LoRA (Low-Rank Adaptation): An efficient fine-tuning technique that modifies only a small subset of model parameters, reducing computational costs while maintaining performance for specialized tasks.</p> <p>MCP (Model Context Protocol): A standardized protocol for connecting AI assistants to external data sources and tools. Enables LLMs to access databases, APIs, and live information while maintaining security and privacy.</p> <p>Mixture of Experts (MoE): A neural network architecture that uses multiple specialized sub-models (experts) and activates only relevant ones for each input, improving efficiency and scalability in large models.</p> <p>Multimodal Models: AI systems that can process and generate multiple types of data (text, images, audio, video) in combination. Examples include GPT-4 with vision, Gemini, and Claude with image understanding.</p> <p>Parameters: The trainable values within a neural network, updated during the training process to minimize loss and define the model's learned behavior. Model size is often described by parameter count (e.g., 7B, 70B parameters).</p> <p>Prompt Engineering: The practice of crafting, refining, and optimizing instructions (prompts) given to AI models in order to guide their outputs toward desired results.</p> <p>Quantization: A technique that reduces the precision of model weights (e.g., from 16-bit to 4-bit) to decrease memory usage and computational requirements, enabling deployment on resource-constrained devices.</p> <p>RAG (Retrieval-Augmented Generation): A technique that enhances LLM responses by retrieving relevant information from external knowledge bases or documents before generating answers, reducing hallucinations and improving factual accuracy.</p> <p>RLHF (Reinforcement Learning from Human Feedback): A training method that uses human preferences to fine-tune AI models, improving their alignment with human values and desired behaviors. Used extensively in ChatGPT and Claude development.</p> <p>Stable Diffusion: A family of open-source latent-diffusion-based models used for generating high-quality images from text or other forms of input (e.g., sketches).</p> <p>System Prompt: Initial instructions given to an AI model that define its role, behavior, constraints, and capabilities for a conversation or task. Often invisible to end users but shapes all responses.</p> <p>Temperature: A parameter controlling randomness in AI-generated outputs. Lower temperatures (0.0-0.3) produce more deterministic responses; higher temperatures (0.7-1.0) increase creativity and variability.</p> <p>Token: A fundamental unit of text—often a word, subword, or character—that LLMs process when understanding or generating language. Pricing and context limits are typically measured in tokens.</p> <p>Transformer: The neural network architecture that powers modern LLMs, introduced in the paper \"Attention is All You Need\" (2017). Uses attention mechanisms to process sequences efficiently.</p> <p>Vector Database: A specialized database optimized for storing and querying high-dimensional embedding vectors, enabling fast semantic search and similarity matching for RAG applications.</p> <p>Weights: Numerical parameters within a neural network that determine the strength of connections between neurons or nodes.</p> <p>Zero-shot Learning: The capability of an AI model to perform tasks it has never been explicitly trained on, often made possible by large-scale pretraining on diverse datasets.</p>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#image-generation-models-2025","level":2,"title":"Image Generation Models (2025)","text":"<p>Stable Diffusion 3.5 (October 2024)</p> <p>Stable Diffusion 3.5 from Stability AI features: - SD3.5 Large (8.1B): High-quality 1MP generation with advanced prompt adherence - SD3.5 Medium (2.5B): Balanced performance for consumer hardware (0.25-2MP) - SD3.5 Large Turbo: Optimized for speed with 4-step generation - Open Source: Free for non-commercial and commercial use under $1M revenue - Platforms: HuggingFace, GitHub, Replicate, Fireworks AI</p> <p>FLUX Models (Black Forest Labs)</p> <p>FLUX by Black Forest Labs offers cutting-edge diffusion models: - FLUX.1 Kontext (May 2025): Combines text+image prompts, state-of-the-art in-context generation and editing - FLUX 1.1 Pro Ultra: Latest professional variant with enhanced quality - FLUX.1 Krea Dev (July 2025): Better performance, varied aesthetics, improved realism - FLUX.1 Schnell: Apache-licensed open-source for fast local generation (12B parameters) - FLUX.1 Tools (November 2024): Fill, Depth, Canny, Redux for advanced control - Architecture: 12B parameter rectified flow transformer - Platforms: API access, BFL Playground, Azure AI Foundry</p> <p>GPT-4o Image Generation (OpenAI)</p> <p>GPT-4o Image (March 2025): - Model: gpt-image-1 (replaces DALL-E 3) - Resolution: Up to 4096×4096 pixels (4K) - Features: Native integration in GPT-4o, reliable text rendering, multi-turn refinement, image transformation - Access: ChatGPT (Free/Plus/Pro), OpenAI API - Safety: C2PA metadata watermarking on all images</p> <p>Midjourney V7 (April 2025)</p> <p>Midjourney latest features: - V7: Current default (since June 2025) with stunning text precision, richer textures, improved bodies/hands - Draft Mode: 10x speed at half the cost - Personalization: First model with personalization enabled by default - V8: In development with \"significant differences\" and innovative features - Video: Coming soon (in final sprint stage) - Platform: Discord-based, Web Interface</p> <p>Google Imagen 4 (May 2025)</p> <p>Imagen 4 and Imagen 4 Ultra: - Resolution: Up to 2K resolution - Speed: 10x faster mode available - Features: Enhanced photo-realism, improved text rendering, advanced typography, diverse art styles - Safety: SynthID watermarking, content filtering - Access: Gemini API, Google AI Studio, Google Labs</p> <p>Adobe Firefly Image Model 4 (April 2025)</p> <p>Firefly 4 and Firefly 4 Ultra: - Resolution: Up to 2K with lifelike quality - Features: Exceptional precision, camera control, structure/style references - Commercial-Safe: Training data with indemnification for enterprise - Integration: Photoshop, Illustrator, InDesign, API access - Firefly Video Model: New modality (April 2025)</p> <p>Breakthrough New Models (2024-2025)</p> <ul> <li>Reve Image 1.0 (March 2025): #1 on Artificial Analysis Arena, best-in-class prompt adherence and typography</li> <li>Recraft V3 (October 2024): #1 on HuggingFace leaderboard at launch, first with vector art generation and extended text</li> <li>HiDream-I1 (April 2025): 17B parameters, open-source (MIT), sparse transformer architecture</li> <li>Ideogram 3.0 (2025): Enhanced realism, style reference (3 images), superior text rendering</li> <li>Leonardo Lucid Origin (2025): Most versatile model, accurate text rendering, full HD renders</li> </ul>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#video-generation-models-2025","level":2,"title":"Video Generation Models (2025)","text":"<p>OpenAI Sora 2 (September 2025)</p> <p>Sora 2 latest features:</p> <ul> <li> <p>Native Audio: Synchronized dialogue, music, and sound effects</p> </li> <li> <p>Resolution: Up to 1080p, duration up to 20 seconds</p> </li> <li> <p>Physics: Superior simulation (basketball rebounds, water buoyancy, gymnastics)</p> </li> <li> <p>Cameo Feature: Insert user likenesses with consent</p> </li> <li> <p>Pricing: Plus plan (50 videos/month at 480p), Pro plan (10x more usage, higher resolutions)</p> </li> <li> <p>Access: ChatGPT Plus/Pro, iOS app (US/Canada, invite-only)</p> </li> </ul> <p>Google Veo 3 (May 2025)</p> <p>Veo 3 represents Google's latest advancement:</p> <ul> <li> <p>Resolution: Up to 4K, 8-second videos</p> </li> <li> <p>Native Audio: Dialogue, sound effects, ambient noise</p> </li> <li> <p>Features: Best-in-class physics, realism, prompt adherence, advanced character/camera controls</p> </li> <li> <p>Access: Flow (Google Labs), Gemini app (AI Pro subscribers), Google AI Studio, Gemini API, Vertex AI</p> </li> <li> <p>Limits: 3 videos/day for paying subscribers</p> </li> <li> <p>Rollout: 159+ countries (July 2025)</p> </li> </ul> <p>Runway Gen-4 (March 2025)</p> <p>Runway Gen-4 features:</p> <ul> <li> <p>World Consistency: Characters, locations, objects consistent across scenes</p> </li> <li> <p>Visual References: Image + text prompt (no fine-tuning required)</p> </li> <li> <p>Duration: 5 or 10 seconds</p> </li> <li> <p>Gen-4 Turbo: Faster generation at lower cost</p> </li> <li> <p>Access: app.runwayml.com</p> </li> </ul> <p>Meta Movie Gen (2025 Release Planned)</p> <p>Movie Gen research features:</p> <ul> <li> <p>Models: 30B video, 13B audio</p> </li> <li> <p>Resolution: 1080p HD, up to 16 seconds at 16 fps</p> </li> <li> <p>Audio: Up to 45 seconds with synchronized sound</p> </li> <li> <p>Features: Four capabilities (video generation, personalized video, precise editing, audio generation)</p> </li> <li> <p>Status: Research phase, Instagram integration planned 2025</p> </li> <li> <p>Partnership: Blumhouse Productions</p> </li> </ul> <p>Leading Commercial Video Platforms</p> <ul> <li>Pika 2.2 (February 2025): Pikaframes keyframe system, 10-second videos, 1080p, Pikatwists dramatic endings</li> <li>Kling AI 2.5 Turbo (September 2025): Enhanced prompt adherence, superior high-motion scenes, 1080p, 30% cost reduction</li> <li>Luma Ray3 (September 2025): Draft mode, HDR/EXR support, deep reasoning, fast generation</li> <li>HeyGen (2025): Avatar IV with hyper-realistic avatars, 140+ languages, Veo 3 integration, 60%+ Fortune 100 adoption</li> <li>Synthesia 3.0 (2025): Express-2 avatars, AI dubbing (32 languages), video agents, $2.1B valuation</li> <li>Hedra Character-3 (April 2025): Omnimodal model, 4K @ 60fps, 90-second videos, full-body animation with speech</li> </ul> <p>Open-Source Video Models</p> <ul> <li>Hunyuan Video (Tencent): 13B+ parameters, largest open-source model, video-to-audio module, GitHub/HuggingFace</li> <li>Stable Video 4D 2.0 (May 2025): Enhanced 4D generation, 48 frames (12×4 views), 576×576, GitHub available</li> <li>Mochi 1 (Genmo): 10B parameters, Apache 2.0 license, 30fps, 5.4 seconds (HD version pending)</li> </ul>","path":["Home","The Landscape"],"tags":[]},{"location":"ai_landscape/#advanced-capabilities","level":2,"title":"Advanced Capabilities","text":"<p>Image and Video Understanding</p> <ul> <li>Segment Anything Model 2 (SAM 2) (Meta): Real-time segmentation for images and videos</li> <li>CLIP (OpenAI): Vision-language understanding</li> <li>LLaVA: Open-source visual instruction tuning</li> </ul> <p>3D Generation</p> <ul> <li>DreamGaussian: Text/image to 3D in minutes</li> <li>Meshy: Text to 3D mesh generation</li> <li>Luma Genie: Text to 3D model generation</li> </ul> <p>Emerging Trends</p> <ul> <li>Consistency Models: Faster generation with fewer steps</li> <li>ControlNet Integration: Precise control over generation</li> <li>Real-time Generation: Sub-second image creation</li> <li>Multimodal Models: Unified image, video, and audio generation</li> <li>Neural Radiance Fields (NeRFs): 3D scene representation</li> <li>Diffusion Transformers (DiT): Next-generation architectures</li> </ul>","path":["Home","The Landscape"],"tags":[]},{"location":"bias/","level":1,"title":"Bias and Discrimination","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>This lesson addresses the critical challenges of bias in AI. We will briefly explore their origins, impacts, and strategies for recognizing, mitigating, and preventing them.</p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#understanding-ai-bias-its-origins","level":2,"title":"Understanding AI bias &amp; its origins","text":"<p>Definitions</p> <p>AI Bias - occurs when an AI system produces systematically prejudiced or unfair results (outputs). Erroneous assumptions made during the development of the model, or biases in the data upon which it was trained are both potential sources.</p> <p>Algorithmic Discrimination occurs when an the use of an AI results in the unfair or illegal treatment of individuals or groups based on a protected characteristic (age, disability, race, religion, sex, or socioeconomic status).</p> <p>Fairness includes metrics around equalized error rates across groups and parity of outcomes across groups. </p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#sources-of-bias","level":2,"title":"Sources of Bias","text":"<p>Algorithmic - when the algorithm used to process the information prioritizes certain features over others, e.g. optimization techniques that favor majority over minority groups</p> <p>Data - the most common source of AI bias is when the data used to train a model are flawed, unrepresentative, lack global diversity, and do not reflect the ground truth of the real-world </p> <ul> <li> <p>Selection Bias when training data are not representative of the whole population </p> </li> <li> <p>Measurement Bias when the data systematically differs from the true values, or when proxies are used</p> </li> <li> <p>Exclusion Bias when certain types or groups are omitted from data collection</p> </li> <li> <p>Experience or Expertise Bias when subjective judgements among the collectors, labellers, or data input are introduced</p> </li> <li> <p>Environment Bias when data collected in one context are not generalizable to other contexts</p> </li> </ul> <p>Human Decision - when biases held by humans influence the decisions around data labeling, model development, engineering or outputs</p> <ul> <li> <p>Confirmation Bias - over reliance on pre-existing beliefs or patterns in data</p> </li> <li> <p>Stereotyping Bias - perpetuation of a labeling bias that is harmful to specific groups</p> </li> <li> <p>Out-Group Bias - generalizing underrepresented groups as being more similar to one another than they actually are</p> </li> <li> <p>Empathy Bias - inability to incorporate nuanced human experiences, emotions, or subjective elements into a quantitative model</p> </li> </ul> <p>Synthetic Bias - when models based on biased training data are used to generate synthetic datasets, they perpetuate their bias into the new trained model</p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#bias-prevention-strategies","level":2,"title":"Bias prevention strategies","text":"","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#data-centric-approaches","level":3,"title":"Data-centric approaches","text":"<p>Can help to ensure data are representative, high quality, and contain the diversity of the study system:</p> <p>Collection - curate datasets accurately to represent all relevant groups and populations.</p> <p>Quality - identify and address issues within data sets, including compatibility problems, gaps within populations, and underrepresentation in historical data. </p> <p>Balancing - under-sample majority and over-sample minority groups, use synthetic data generation to capture under-represented samples</p> <p>Labeling - consistent, annotated, with masks for irrelevant factors, sensitive and secure</p> <p>Continuous - data are updated throughout the entire lifecycle of their use, not just a single collection phase.</p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#algorithmic-techniques","level":3,"title":"Algorithmic Techniques","text":"<p>Technical tools can help to identify bias in models:</p> <p>Bias Detection - specialized software tools designed to flag, measure, and analyze biases.</p> <p>Fairness Metrics - equalized odds, demographic parity, counterfactual fairness</p> <p>Algorithmic Adjustments - pre-processing (adjusting training data), in-process (modifying algorithm), or post-processing (adjust outputs)</p> <p>Explainable AI (XAI) - understand which inputs are driving model decisions, reveal hidden biases or reliance on spurious factors</p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"bias/#assessment","level":2,"title":"Assessment","text":"True or False: AI bias only originates from the data used to train the model. <p>False</p> <p>AI bias can originate from the data, the algorithm, and human decisions during the development process.</p> Which of the following is an example of 'Selection Bias'? <p>A. An algorithm that prioritizes majority groups over minority groups.</p> <p>B. A dataset for a skin cancer detection model that predominantly features images of light-skinned individuals.</p> <p>C. Subjective judgments from data labelers influencing the data.</p> <p>D. Using a model trained on data from one hospital in a different country.</p> Answer <p>B. A dataset for a skin cancer detection model that predominantly features images of light-skinned individuals.</p> <p>Selection bias occurs when the training data are not representative of the whole population.</p> What is the primary purpose of 'Explainable AI (XAI)' in bias mitigation? <p>A. To generate synthetic data for underrepresented groups.</p> <p>B. To understand which inputs are driving model decisions, potentially revealing hidden biases.</p> <p>C. To ensure the model's predictions are always 100% accurate.</p> <p>D. To make the model run faster on new hardware.</p> Answer <p>B: To understand which inputs are driving model decisions, potentially revealing hidden biases.</p> <p>XAI helps to make the model's decision-making process transparent, which is crucial for identifying and addressing bias.</p> True or False: 'Algorithmic Discrimination' is when an AI model makes a simple mistake. <p>False</p> <p>Algorithmic Discrimination is when the use of an AI results in the unfair or illegal treatment of individuals or groups based on a protected characteristic.</p> Which of these is NOT a data-centric approach to bias prevention? <p>A. Curating datasets to accurately represent all relevant groups.</p> <p>B. Over-sampling minority groups.</p> <p>C. Modifying the algorithm during the training process.</p> <p>D. Ensuring data labels are consistent and annotated.</p> Answer <p>C: Modifying the algorithm during the training process.</p> <p>This is an algorithmic technique, not a data-centric approach.</p>","path":["Ethics","Bias and Discrimination"],"tags":[]},{"location":"chatgpt/","level":1,"title":"OpenAI ChatGPT","text":"<p> This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"chatgpt/#creating-a-chatgpt-account","level":2,"title":"Creating a ChatGPT Account","text":"<p>Log In to Your Account </p> <ul> <li>Visit chatgpt.com and log in using your existing credentials or create a new account.</li> </ul> <p>Access Account Settings:</p> <ul> <li>Once logged in, look for the sidebar (usually on the left).  </li> <li>Click on the “Upgrade to Plus” or “Manage my plan” button.  <ul> <li>If you do not see this option, try refreshing the page or updating your browser.</li> </ul> </li> </ul> <p>Initiate Upgrade: </p> <ul> <li>Click “Upgrade to Plus”.  </li> <li>A pricing page will appear, detailing the monthly cost (currently $20/month in many regions).</li> <li>Click \"Upgrade to Pro\".</li> <li>A pricing page will appear, detailing the monthly cost (curently $200/month)</li> </ul> <p>Enter Payment Information: </p> <ul> <li>Provide the required billing details.  </li> <li>Review the payment terms and confirm your subscription.</li> </ul> <p>Confirmation and Billing Cycle: </p> <ul> <li>After completing the payment process, you will receive a confirmation email.  </li> <li>Your Plus account should be active immediately.  </li> <li>You can now enjoy features like priority access, faster response times, and the latest model updates.</li> </ul>","path":["Setup","OpenAI ChatGPT"],"tags":[]},{"location":"choose/","level":1,"title":"Choose","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Below are tables that rank the most popular GPTs by popularity from most to least, within each activity type for Chat, Research, Code, and Image/Videos.</p>","path":["Prompt Engineering","Choose"],"tags":[]},{"location":"choose/#best-for-chat","level":3,"title":"Best for Chat","text":"Platform Strength Weakness Cost Interface Docs Claude 4.0 (Anthropic) - Fast, coherent dialogue - Good at creative text generation - Sometimes less accurate with fact-based queries - Limited third-party integrations Free, $15–$75+/mo (various tiers) Claude Chat Anthropic Docs Gemini 2.5 (Google) - Multimodal (images + text) - Strong search integration (Google) - Some features only in Beta - Pricing unclear in early versions Free, Pro Tiers based on usage Gemini Gemini Docs ChatGPT 4.5, o3, o4 (OpenAI) - Strong reasoning  - Integrates with other apps (plugins) - Multi-turn conversation - Limited file uploads (depending on plan/plugins) - Occasionally behind newest research releases Free, $20/mo (Plus), $42+/mo (Enterprise) ChatGPT OpenAI Docs DeepSeek (Open Source) - Focuses on chat + search integration - Local &amp; open source solutions - Smaller dev community - May require self-hosting Free (Open Source) DeepSeek Chat DeepSeek Docs Microsoft 365 Copilot - Built on ChatGPT plus Microsoft Graph - Deep MS Office/Outlook integration - Typically behind latest ChatGPT features - Enterprise pricing can be high $30/mo (add-on for Microsoft 365 E3/E5) Copilot Copilot Docs Grok (xAI) - Multimodal: text, images, basic computer vision - Emerging technology - Currently in limited release - Ecosystem still growing Free, future subscription TBA Grok xAI Docs HuggingFace Chat - Large variety of community-contributed models - Multimodal options - Quality varies by model - Some advanced features behind paid tiers or require GPU credits Free, Pay-as-you-go GPU HF Chat HF Docs Jasper - Focus on marketing copy, blog posts - Easy content workflows - Less technical depth - Pricier than some for similar text output Starting at $39/mo Jasper Chat Jasper Docs Perplexity - Combined chat + search - Large reference library - Subscription required for advanced features - Not as flexible as GPT-4 plugins Free, Subscription tier $20+/mo Perplexity Chat Perplexity Docs NotebookLM (Google) - RAG (Retrieval-Augmented Generation) - Integrates with Google Drive - Still in beta - Occasional slow responses Free, future subscription TBA NotebookLM NotebookLM Docs Vicuna 13B - Open-source model fine-tuned from LLaMA - Strong for casual chat - Limited knowledge, smaller than GPT-4 - Quality can depend on hosting Free (self-host) or free demos Vicuna Demo Vicuna GitHub Pi (Inflection AI) - Empathetic style, personal conversation - Smooth chat experience - Less robust for complex tasks - No coding support Free (personal use) Pi N/A Poe (Quora) - Aggregates multiple models (GPT-4, Claude, etc.) - Single subscription for multiple AI bots - Limited advanced features beyond aggregation - Usage caps on free tier $19.99/mo Poe Poe Docs Mistral AI - Open-source European LLMs - Multilingual focus, smaller model sizes - Newer offering - Some advanced features still in dev Free (open source) or enterprise Mistral Mistral Docs Latimer - Focus on diverse voices - Inclusive perspective - Smaller user base - Specialized training set Free (basic) or subscription tiers Latimer N/A Meta AI (Llama) - Open source for research/commercial - Large dev community - May require significant GPU resources - Some versions less robust vs. GPT-4 Free (self-host) or enterprise Llama Meta GitHub Apple Intelligence - Deep Siri/iOS integration - Privacy-oriented design - Limited on non-Apple devices - Closed ecosystem Included on Apple devices Apple Intelligence N/A Amazon Titan - Part of AWS ecosystem - Integrates with Amazon Bedrock - Primarily enterprise usage - Not widely accessible for individuals Pay-per-use on Bedrock Titan AWS Docs Amazon Bedrock - Unified API for multiple foundation models - Enterprise security &amp; scaling - Must have AWS account - Cost can add up for high usage Pay-per-use (AWS) Bedrock Bedrock Docs Azure OpenAI Service - Secure enterprise environment for GPT - Tight Azure cloud integration - Requires Azure subscription - Usage cost can be high Pay-per-use (Azure) Azure OpenAI Azure Docs Merlin AI - Multifunction: text, image, code - Summaries, chat, quiz creation - Some features behind paywall - Web-based aggregator style Free plan, paid tiers Merlin N/A Starling-7B - Uses AI feedback (RLHF) - Open-source from UC Berkeley group - Smaller model - Less context capacity vs. GPT-4 Free (open source) Starling Starling GitHub Amplify GenAI - Open source platform (Vanderbilt) - Connect various model providers - Requires AWS + model usage fees - Self-deployment for institutions AWS usage + model costs Amplify GenAI N/A","path":["Prompt Engineering","Choose"],"tags":[]},{"location":"choose/#best-for-research","level":3,"title":"Best for Research","text":"Platform Strength Weakness Cost Interface Docs Perplexity - Large archive, direct references - Web search integration - Must subscribe for advanced features - Not as “creative” as GPT-like models Free, Subscription: $20+/mo Perplexity Chat Perplexity Docs Gemini 2.5 Pro (Deep Research) - In-depth chain-of-thought - Multimodal research capabilities - Early product, can be slow - Pricing not fully public Free, Pro Tiers based on usage Gemini Gemini Docs ChatGPT o1 Pro (OpenAI) - Strong general-purpose reasoning - Code, language, knowledge tasks - Subscription needed $20/mo (Plus) ChatGPT OpenAI Docs Claude 4 Opus (Anthropic) - Strong reasoning and analysis - Large context window for documents - API access can be expensive - Newer than some competitors Free, Usage-based Claude Anthropic Docs ScholarAI - Large academic archive integration - Focus on literature reviews - Limited reasoning beyond domain texts - Requires GPT-4 or Plus-based backend $20–$40/mo (addon to GPT-4) (No dedicated UI link; typically custom UI) (Depends on GPT-4 / ScholarAI custom docs) Scholar GPT - Similar to ScholarAI; academic focus - Pulls from major journal databases - Must have ChatGPT Plus - Reliability depends on subscription backend $20/mo (Plus required) (No dedicated UI link; typically custom) (Leverages GPT-4 docs) Semantic Scholar - Comprehensive academic metadata - Free to use - Not truly an LLM-based chat - Lacks advanced generative capabilities Free Semantic Scholar Semantic Scholar API Elicit - AI-assisted literature reviews  - Streamlines academic search - Limited coverage for some fields  - No real-time chat Free, Subscription: $10/mo, $42/mo Elicit (No official API docs publicly listed) Consensus - Aggregates academic findings  - Summarizes papers via AI - May have limited domain depth  - Emerging platform Free, Subscription: $8-9/mo Consensus (No official API docs publicly listed) Scite - Large academic archive integration - Focus on literature reviews - Limited coverage for some fields  - No real-time chat Free, Subscription: $20/mo Scite Scite AI Docs Ai2 OpenScholar - Answers scientific queries from ~45M open-access papers - Citation-backed responses - Focused on open-access content - New &amp; still evolving Free OpenScholar GitHub Polymathic AI - Aims at scientific tasks and numerical datasets - Potential for domain-specific fine-tuning - Still in development - Limited availability Free (open source, in dev) Polymathic AI N/A SearchGPT (OpenAI) - Prototype real-time internet search - Prominent citation linking - Waitlist only - Unclear final pricing TBD SearchGPT N/A You.com - Search engine + multi-model chat - Customizable “AI Agents” - Requires paid subscription for advanced features - Not as robust as GPT-4 in some tasks Free or paid plans YouChat You.com Docs OpenResearcher - Retrieves from internet + arXiv - Citation-based conversation for science topics - Focused on specific STEM queries - Early-stage tool Free, open source OpenResearcher GitHub","path":["Prompt Engineering","Choose"],"tags":[]},{"location":"choose/#best-for-code","level":3,"title":"Best for Code","text":"Platform Strength Weakness Cost Interface Docs Claude Code (Anthropic) - Strong code generation and explanation - Good for complex logic and algorithms - Newer than some competitors - API access may have rate limits Free, Usage-based Claude Anthropic Docs Gemini 2.5 (Google) - Focus on code + text synergy - Potential for deep chain-of-thought - Still early, can be slow with large code bases - Pricing not fully disclosed Free, Pro Tiers based on usage Gemini Gemini Docs GitHub Copilot - Seamless code autocompletion - Integrates with VS Code, JetBrains, etc. - Limited context window - Some framework-specific gaps $10/mo (Individual), $19/mo (Business) GitHub Copilot Copilot Docs ChatGPT Code Interpreter - Interactive code execution in a sandbox - Good for data analysis, transformations - Must have GPT-4 subscription - No direct local environment access $20/mo (Plus) ChatGPT OpenAI Docs Continue.dev - Open-source local code interpreter - Extensible with plugins - Requires technical setup - Smaller dev community Free (Open Source) Continue.dev Continue.dev Docs Codeium - Free AI-powered autocomplete - Supports multiple IDEs - Less advanced than Copilot on edge cases - Limited large-language reasoning Free Codeium Codeium Docs Phind - Code search + AI chat combined - Smaller community - Some advanced features behind paid tiers Free, Paid tiers TBA Phind Phind Docs Replit AI - Cloud-based dev + AI code generator - Multiple languages, strong Python/JS support - Usage-based pricing for higher-end features - Emphasis on web IDE only Free tier, Pro from $7+/mo Replit AI Replit Docs StarCoder - Open-source code LLM from BigCode - Broad language coverage - May lag behind GPT-4/Copilot for advanced logic - Typically self-host or huggingface model usage Free (open source) StarCoder BigCode Code Llama (Meta) - Specialized for coding tasks - Multiple variants (Python, Instruct) - Less robust than GPT-4 for very complex code - Requires setup for self-host Free (open source) Code Llama Meta Llama","path":["Prompt Engineering","Choose"],"tags":[]},{"location":"choose/#best-for-imagevideo","level":3,"title":"Best for Image/Video","text":"Platform Strength Weakness Cost Interface Docs Veo 3 - High-quality video generation - Detailed scene and motion control - Limited access - High computational cost TBD Veo N/A Midjourney v6 - Generally highest-quality AI images - Rich feature set via Discord commands - Requires Discord usage - More expensive for casual users $10–$60/mo (various tiers) Midjourney Midjourney Docs DALL·E 3 (OpenAI) - Conveniently integrated in ChatGPT - Good for quick generation, concept art - Not always photorealistic - Requires ChatGPT Plus or API usage $20/mo (ChatGPT Plus) or pay-per-use API DALL·E 3 DALL·E Docs Stable Diffusion 3 - Fully open source - Highly customizable (fine-tuning) - Requires GPU resources - Results vary without parameter tuning Free (Open Source), or API services Stability AI SD3 Paper Adobe Firefly - Easy to use for designers - Integration with Adobe apps (Photoshop, Illustrator) - Requires Adobe subscription - Not as flexible for coding or specialized prompts Included w/ Adobe CC or $4.99–$9.99 add-on Firefly Firefly Docs Sora (OpenAI) - Computer Vision (video) generation - Experimental “world simulator” approach - Limited early access - High compute demands Limited Access, likely enterprise only Sora Sora Report Runway ML - Advanced generative video tools - Browser-based video editor and image gen - Higher-res outputs require paid plans - Can be slow on large projects Free tier, paid from $15+/mo Runway Runway Docs Imagine with Meta - Text-to-image via Emu model - Free and evolving toolset - Factual/historical inaccuracies reported - Still experimental Free Imagine N/A Craiyon - Simple web UI - Free usage for low-res images - Quality less advanced than Midjourney or DALL·E - Ads on free tier Free or subscription Craiyon N/A <p>About the Table</p> <ul> <li>ChatGPT is still the dominant chat platform as of late 2024, having recently released model o1 and announcing model o3</li> <li>LLaMA 3: Meta's LLaMA 3 is a significant open-source model that is highly competitive and driving innovation.</li> <li>Gemini: Google's Gemini (formerly Bard) is rapidly evolving and positioned as a strong competitor to ChatGPT, particularly in multimodal capabilities.</li> <li>Copilot: Microsoft's Copilot (integrating OpenAI's technology) has become ubiquitous, especially for productivity and search.</li> <li>Claude 3: Anthropic's Claude 3 is gaining popularity due to its strong performance on reasoning tasks and commitment to AI safety.</li> <li>Sora: Although it is not yet fully accessible, OpenAI's text-to-video model has the potential to be a major innovation.</li> <li>Grok: is powered by what might be the largest super computer in the world, xAI's Collossus </li> <li>Image Generation: DALL-E 3, Stable Diffusion 3, and Midjourney v6 are leading the way in image generation, each with its strengths (photorealism, open-source nature, artistic style).</li> <li>GitHub Copilot: Remains a dominant force in code generation and is increasingly integrated into developers' workflows.</li> </ul> <p>Tip: If you’re evaluating GPT or generative AI options, consider security (e.g., on-prem vs. cloud), fine-tuning capabilities, and API limits in addition to monthly cost and raw model quality.</p>","path":["Prompt Engineering","Choose"],"tags":[]},{"location":"claude-code/","level":1,"title":"Claude Code: Setup and Usage Tutorial","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#claude-code","level":2,"title":"Claude Code","text":"<p>This tutorial will guide you through setting up and using Claude Code—Anthropic's AI-powered development tool.</p> <p>Claude Code acts as an intelligent pair programmer that understands context, writes code, creates documentation, and helps you build better software faster.</p> <p>What You'll Learn</p> <p>This tutorial covers both the Claude Code CLI (command-line interface) and the Claude Code VS Code Extension. We'll highlight the differences and help you choose the right tool for your workflow.</p> <p>By the end of this tutorial, you'll be able to:</p> <ul> <li>Set up Claude Code in Terminal or VS Code Extension</li> <li>Create and manage GitHub repositories using the GitHub <code>gh</code> CLI</li> <li>Initialize Claude Code with existing codebases or start new projects</li> <li>Create custom agents for specialized development tasks</li> <li>Build slash commands to automate common workflows</li> <li>Integrate Claude Code with your Git workflow</li> <li>Apply best practices for secure, efficient AI-assisted development</li> <li>Understand AI Sandboxes and their importance for AI Safety</li> </ul> <p>Prerequisites</p> <p>Before starting this tutorial, you should have:</p> <p> Basic command-line/terminal experience</p> <p> Familiarity with Git and version control concepts</p> <p> A GitHub account</p> <p> A text editor or IDE (VS Code recommended)</p> <p> Willingness to experiment and learn!</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#1-what-is-claude-code","level":2,"title":"1. What is Claude Code?","text":"<p>Claude Code is an AI-powered development assistant built by Anthropic that integrates directly into your development workflow. Unlike simple code completion tools, Claude Code is an agentic AI system capable of:</p> <ul> <li>Understanding entire codebases through contextual analysis</li> <li>Writing and editing code across multiple files simultaneously</li> <li>Running commands in your terminal to test and verify changes</li> <li>Debugging errors by analyzing stack traces and suggesting fixes</li> <li>Generating documentation that stays in sync with your code</li> <li>Creating tests based on your implementation</li> <li>Refactoring code while maintaining functionality</li> </ul> <p>Claude Code represents the evolution of AI-assisted development—moving beyond autocomplete to truly collaborative coding experiences often called \"vibe coding\".</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#cli-vs-vs-code-extension-which-should-you-use","level":3,"title":"CLI vs VS Code Extension: Which Should You Use?","text":"<p>Claude Code comes in two primary forms, each suited to different workflows:</p> Feature Claude Code CLI Claude Code VS Code Extension Platform  Terminal/Command Line  VS Code Editor Installation <code>npm install -g @anthropic-ai/claude-code</code> VS Code Extensions Marketplace Interface Text-based conversations in terminal Integrated chat panel + inline edits File Editing Creates/modifies files via CLI commands Direct in-editor modifications Context Awareness Full project directory access VS Code workspace integration Terminal Integration Native terminal environment VS Code integrated terminal Best For Terminal-first developers, automation, CI/CD VS Code users, visual development, GUI preferences Keyboard Shortcuts Standard terminal shortcuts VS Code keybindings + custom shortcuts MCP Support Yes, via configuration Yes, via configuration Multi-Project Switch directories manually Workspace support Recommendation: Start with Your Comfort Zone <p>If you're primarily a terminal user who lives in vim, emacs, or tmux, start with the CLI. If you spend most of your time in VS Code, start with the Extension. You can always use both!</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#key-capabilities","level":3,"title":"Key Capabilities","text":"<p>Both versions of Claude Code share these powerful capabilities:</p> <p>Context Understanding - Reads and analyzes your entire project structure - Understands dependencies, frameworks, and patterns - Maintains conversation context across sessions - Integrates with Model Context Protocol (MCP) for extended capabilities</p> <p>Code Generation &amp; Editing - Generates new files, functions, and modules - Refactors existing code across multiple files - Applies consistent coding styles and patterns - Suggests optimizations and improvements</p> <p>Tool Integration - Executes terminal commands (with your approval) - Runs tests and interprets results - Interacts with Git for version control - Connects to external APIs and databases via MCP</p> <p>Customization - Create custom agents for specialized tasks - Define slash commands for repeated workflows - Configure behavior and preferences - Integrate with your existing tools</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#how-claude-code-differs-from-other-tools","level":3,"title":"How Claude Code Differs from Other Tools","text":"<p>Compared to other AI coding assistants:</p> <ul> <li>vs. GitHub Copilot: More conversational, can edit multiple files, stronger at architectural changes</li> <li>vs. Cursor: Official Anthropic tool, different pricing model, native MCP support</li> <li>vs. ChatGPT/Claude Web: Direct file system access, runs locally, part of development workflow</li> <li>vs. Cline/Roo Code: Official Anthropic tool, integrated experience, ongoing support</li> </ul> <p>For a detailed comparison of all vibe coding tools, see our Vibe Coding Guide.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#integration-with-the-ai-ecosystem","level":3,"title":"Integration with the AI Ecosystem","text":"<p>Claude Code is part of a broader AI development ecosystem:</p> <ul> <li>Model Context Protocol (MCP): Enables Claude Code to connect to databases, APIs, and external services—see our MCP Documentation</li> <li>Agentic AI: Claude Code employs agentic patterns for autonomous problem-solving—learn more in Agentic AI</li> <li>Code Interpreters: Can execute code in sandboxed environments—covered in Code Generation with LLMs</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#2-prerequisites-account-setup","level":2,"title":"2. Prerequisites &amp; Account Setup","text":"<p>Before installing Claude Code, you need access to Claude's API. There are two main approaches.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#21-account-options","level":3,"title":"2.1 Account Options","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#option-1-claude-proteam-subscription","level":4,"title":"Option 1: Claude Pro/Team Subscription","text":"<p>Claude Pro (\\(20/month) or **Claude Team** (\\)25/user/month, minimum 5 users) subscriptions include:</p> <ul> <li>Access to Claude Code CLI and VS Code Extension</li> <li>Extended usage limits (5x more than free tier)</li> <li>Priority access during high-traffic periods</li> <li>Access to all Claude models (Sonnet, Opus, Haiku)</li> <li>Early access to new features</li> </ul> <p>Best for: Individual developers, small teams, and frequent users</p> <p>Sign up: claude.ai</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#option-2-anthropic-api-key","level":4,"title":"Option 2: Anthropic API Key","text":"<p>For programmatic access and integration:</p> <ul> <li>Sign up: console.anthropic.com</li> <li>Pricing: Pay-per-use based on tokens (see pricing below)</li> <li>API key management: Generate keys in console dashboard</li> <li>Usage tracking: Monitor consumption in real-time</li> </ul> <p>Best for: Developers who want fine-grained control, batch processing, or integration with other tools</p> <p>API Pricing (January 2026)</p> <p>Per million tokens:</p> <ul> <li>Claude 4.5 Sonnet: $3 input / $15 output</li> <li>Claude 4.5 Opus: $15 input / $75 output</li> <li>Claude 4.5 Haiku: $0.25 input / $1.25 output</li> </ul> <p>For most coding tasks, Claude 4.5 Sonnet provides the best balance of capability and cost.</p> <p>Treat Your API Key Like a Password</p> <p>Never commit API keys to version control!</p> <ul> <li>Store in environment variables</li> <li>Use <code>.env</code> files (and add to <code>.gitignore</code>)</li> <li>Rotate keys regularly</li> <li>Revoke compromised keys immediately</li> </ul> <p>See Security Best Practices for more details.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#comparison-subscription-vs-api-key","level":4,"title":"Comparison: Subscription vs API Key","text":"Aspect Pro/Team Subscription API Key Billing Flat monthly rate Usage-based (per token) Predictability Fixed cost Variable cost Usage Limits Session-based limits Token-based limits Best For Regular development work Automation, batch jobs, experimentation Administration Individual or team billing Developer console management","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#22-system-requirements","level":3,"title":"2.2 System Requirements","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#operating-system","level":4,"title":"Operating System","text":"<p>Claude Code supports:</p> <ul> <li> macOS 10.15 (Catalina) or later</li> <li> Windows 10/11 (with WSL2 recommended for CLI)</li> <li> Linux (Ubuntu 20.04+, Fedora 35+, or equivalent)</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#required-software","level":4,"title":"Required Software","text":"<p>Node.js and npm (for CLI installation): - Node.js v16.0.0 or later - npm v7.0.0 or later - Check versions: <code>node --version &amp;&amp; npm --version</code> - Install from nodejs.org</p> <p>Git: - Git v2.20.0 or later - Check version: <code>git --version</code> - Install from git-scm.com</p> <p>For VS Code Extension: - Visual Studio Code v1.75.0 or later - Download from code.visualstudio.com</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#ai-sandbox-environments-optional","level":4,"title":"AI Sandbox Environments (Optional)","text":"<p>For isolated, secure, or team-based development environments, Claude Code works in:</p> <p>Docker Containers - Run Claude Code in isolated containers - Useful for reproducible environments - See Docker Documentation for setup</p> <p>Virtual Machines - Full OS isolation for security-sensitive work - Supports all major VM platforms (VirtualBox, VMware, Hyper-V) - Good for institutional policies requiring sandboxes</p> <p>Jupyter Lab - Integrate Claude Code into notebook workflows - See our Jupyter AI Guide for details - Useful for data science and research contexts</p> <p>Cloud Development Environments - GitHub Codespaces - GitPod - Cloud9 (AWS) - Replit</p> When to Use Sandboxes <p>Consider sandbox environments if you:</p> <ul> <li>Work with sensitive or proprietary code</li> <li>Need compliance with institutional security policies</li> <li>Want reproducible development environments</li> <li>Are teaching or conducting workshops</li> <li>Need to test code in isolated environments</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#3-installation-guide","level":2,"title":"3. Installation Guide","text":"<p>This section covers installing both the Claude Code CLI and the VS Code Extension. You can install one or both depending on your workflow preferences.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#31-claude-code-cli","level":3,"title":"3.1 Claude Code CLI","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#installation-on-macoslinux","level":4,"title":"Installation on macOS/Linux","text":"<p>Open your terminal and run:</p> <pre><code># Install Claude Code globally via npm\nnpm install -g @anthropic-ai/claude-code\n\n# Verify installation\nclaude-code --version\n</code></pre> <p>Expected output: <pre><code>claude-code version 1.x.x\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#installation-on-windows","level":4,"title":"Installation on Windows","text":"<p>Option 1: Using WSL2 (Recommended)</p> <p>Windows Subsystem for Linux provides the best experience:</p> <pre><code># In WSL2 terminal\nnpm install -g @anthropic-ai/claude-code\nclaude-code --version\n</code></pre> <p>Option 2: PowerShell/Command Prompt</p> <pre><code># In PowerShell or CMD\nnpm install -g @anthropic-ai/claude-code\nclaude-code --version\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#authentication-setup","level":4,"title":"Authentication Setup","text":"<p>After installation, authenticate with your Claude account:</p> <pre><code># Start authentication flow\nclaude-code auth login\n</code></pre> <p>This will:</p> <ol> <li>Open your browser to authenticate</li> <li>Ask you to authorize Claude Code</li> <li>Save your credentials securely</li> </ol> <p>For API key users:</p> <pre><code># Set API key via environment variable\nexport ANTHROPIC_API_KEY=\"your-api-key-here\"\n\n# Or use config file\nclaude-code auth set-key\n</code></pre> <p>Environment Variables</p> <p>Add to your shell profile (<code>~/.bashrc</code>, <code>~/.zshrc</code>, etc.):</p> <pre><code>export ANTHROPIC_API_KEY=\"your-api-key-here\"\n</code></pre> <p>Then reload: <code>source ~/.zshrc</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#basic-configuration","level":4,"title":"Basic Configuration","text":"<p>Configure Claude Code preferences:</p> <pre><code># Set default model\nclaude-code config set model claude-4-5-sonnet-20260115\n\n# Set default editor\nclaude-code config set editor code  # or vim, nano, etc.\n\n# View current configuration\nclaude-code config list\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#verification","level":4,"title":"Verification","text":"<p>Test your installation:</p> <pre><code># Run a simple command\nclaude-code --help\n\n# Test authentication\nclaude-code auth status\n\n# Quick test conversation\nclaude-code chat \"Hello, Claude!\"\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#32-claude-code-vs-code-extension","level":3,"title":"3.2 Claude Code VS Code Extension","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#installing-from-marketplace","level":4,"title":"Installing from Marketplace","text":"<ol> <li> <p>Open VS Code</p> </li> <li> <p>Open Extensions View</p> </li> <li> <p>Click Extensions icon in sidebar (or <code>Ctrl/Cmd + Shift + X</code>)</p> </li> <li> <p>Search for \"Claude Code\"</p> </li> <li>Type \"Claude Code\" in search box</li> <li> <p>Look for official Anthropic extension</p> </li> <li> <p>Install</p> </li> <li>Click \"Install\" button</li> <li> <p>Wait for installation to complete</p> </li> <li> <p>Reload VS Code</p> </li> <li>Click \"Reload\" if prompted</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#alternative-command-line-installation","level":4,"title":"Alternative: Command Line Installation","text":"<pre><code>code --install-extension anthropic.claude-code\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#initial-setup-wizard","level":4,"title":"Initial Setup Wizard","text":"<p>After installation, the setup wizard will guide you through:</p> <ol> <li>Authentication</li> <li>Sign in with your Claude account</li> <li> <p>Or enter API key</p> </li> <li> <p>Model Selection</p> </li> <li>Choose default model (Sonnet recommended)</li> <li> <p>Can change per-conversation</p> </li> <li> <p>Permissions</p> </li> <li>File access permissions</li> <li>Terminal access permissions</li> <li> <p>Confirm security settings</p> </li> <li> <p>Workspace Configuration</p> </li> <li>Optional: configure per-workspace settings</li> <li>Set up <code>.claude</code> directory</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#authentication","level":4,"title":"Authentication","text":"<p>For Claude Pro/Team users:</p> <ol> <li>Click \"Sign in with Claude\" in extension</li> <li>Authorize in browser</li> <li>Return to VS Code</li> </ol> <p>For API key users:</p> <ol> <li>Open VS Code settings (<code>Cmd/Ctrl + ,</code>)</li> <li>Search for \"Claude Code\"</li> <li>Enter API key in settings</li> </ol> <p>Or set via settings.json:</p> <pre><code>{\n  \"claude-code.apiKey\": \"your-api-key-here\",\n  \"claude-code.defaultModel\": \"claude-4-5-sonnet-20260115\"\n}\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#extension-settings-overview","level":4,"title":"Extension Settings Overview","text":"<p>Key settings to configure:</p> <ul> <li>Default Model: Which Claude model to use</li> <li>Auto-save: Whether to save files before running commands</li> <li>Context Window: How much code to include in context</li> <li>Terminal Integration: Enable/disable terminal access</li> <li>MCP Servers: Configure Model Context Protocol connections</li> </ul> <p>Access settings: <code>Preferences &gt; Settings &gt; Extensions &gt; Claude Code</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#verification_1","level":4,"title":"Verification","text":"<p>Verify the extension is working:</p> <ol> <li>Open Command Palette (<code>Cmd/Ctrl + Shift + P</code>)</li> <li>Type \"Claude Code: Chat\"</li> <li>Send a test message</li> <li>Confirm Claude responds</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#33-github-cli-setup","level":3,"title":"3.3 GitHub CLI Setup","text":"<p>The GitHub CLI (<code>gh</code>) simplifies repository management and integrates beautifully with Claude Code workflows.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#installing-gh-client","level":4,"title":"Installing gh Client","text":"<p>macOS:</p> <pre><code># Using Homebrew\nbrew install gh\n\n# Verify installation\ngh --version\n</code></pre> <p>Windows:</p> <pre><code># Using winget\nwinget install --id GitHub.cli\n\n# Or using Chocolatey\nchoco install gh\n\n# Verify\ngh --version\n</code></pre> <p>Linux (Ubuntu/Debian):</p> <pre><code># Add GitHub CLI repository\ntype -p curl &gt;/dev/null || sudo apt install curl -y\ncurl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \\\n&amp;&amp; sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \\\n&amp;&amp; echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | sudo tee /etc/apt/sources.list.d/github-cli.list &gt; /dev/null \\\n&amp;&amp; sudo apt update \\\n&amp;&amp; sudo apt install gh -y\n\n# Verify\ngh --version\n</code></pre> <p>Linux (Fedora/CentOS/RHEL):</p> <pre><code>sudo dnf install 'dnf-command(config-manager)'\nsudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo\nsudo dnf install gh\n\n# Verify\ngh --version\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#authentication-with-github","level":4,"title":"Authentication with GitHub","text":"<p>Authenticate the GitHub CLI:</p> <pre><code># Start authentication flow\ngh auth login\n</code></pre> <p>You'll be prompted to:</p> <ol> <li>Choose authentication method (browser recommended)</li> <li>Select protocol (HTTPS or SSH)</li> <li>Authenticate in browser</li> <li>Confirm successful authentication</li> </ol> <p>Verify authentication:</p> <pre><code>gh auth status\n</code></pre> <p>Expected output: <pre><code>✓ Logged in to github.com as your-username\n✓ Git operations for github.com configured to use https protocol\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#basic-gh-commands-reference","level":4,"title":"Basic gh Commands Reference","text":"<p>Common commands you'll use with Claude Code:</p> <pre><code># Create a repository\ngh repo create my-project --public\n\n# Clone a repository\ngh repo clone username/repository\n\n# Create a pull request\ngh pr create --title \"Feature: Add new component\" --body \"Description here\"\n\n# View repository information\ngh repo view\n\n# List your repositories\ngh repo list\n\n# Open repository in browser\ngh repo view --web\n\n# Check issues\ngh issue list\n\n# Create an issue\ngh issue create --title \"Bug: Something broke\" --body \"Details\"\n</code></pre> <p>For more commands: <code>gh --help</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#verifying-installation","level":4,"title":"Verifying Installation","text":"<p>Test all components are working:</p> <pre><code># Check versions\necho \"Node: $(node --version)\"\necho \"npm: $(npm --version)\"\necho \"Git: $(git --version)\"\necho \"GitHub CLI: $(gh --version)\"\necho \"Claude Code: $(claude-code --version)\"\n</code></pre> <p>All commands should return version numbers without errors.</p> <p>Installation Complete!</p> <p>You now have all the tools needed to start using Claude Code. In the next section, we'll create your first project and start coding with Claude!</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#4-creating-your-first-project","level":2,"title":"4. Creating Your First Project","text":"<p>Now that you have Claude Code and the GitHub CLI installed, let's create a project and start working with Claude.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#41-setting-up-a-new-repository","level":3,"title":"4.1 Setting Up a New Repository","text":"<p>We'll use the <code>gh</code> CLI to create a GitHub repository and clone it locally.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#creating-a-repository","level":4,"title":"Creating a Repository","text":"<pre><code># Create a new public repository and clone it\ngh repo create my-first-claude-project --public --clone\n\n# Or for a private repository\ngh repo create my-private-project --private --clone\n\n# Navigate into the directory\ncd my-first-claude-project\n</code></pre> <p>This command:</p> <ol> <li>Creates a repository on GitHub</li> <li>Initializes it with a README</li> <li>Clones it to your local machine</li> <li>Sets up the remote origin</li> </ol> Repository Options <p>Additional options for <code>gh repo create</code>:</p> <pre><code># Add description\ngh repo create my-project --public --clone \\\n  --description \"My awesome Claude Code project\"\n\n# Add .gitignore template\ngh repo create my-project --public --clone \\\n  --gitignore Python\n\n# Add license\ngh repo create my-project --public --clone \\\n  --license mit\n\n# Combine options\ngh repo create my-project --public --clone \\\n  --description \"Python web app\" \\\n  --gitignore Python \\\n  --license apache-2.0\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#alternative-clone-existing-repository","level":4,"title":"Alternative: Clone Existing Repository","text":"<p>If you already have a repository:</p> <pre><code># Clone a repository\ngh repo clone username/repository-name\n\n# Navigate into it\ncd repository-name\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#verify-directory-structure","level":4,"title":"Verify Directory Structure","text":"<p>Check what was created:</p> <pre><code># List files (including hidden)\nls -la\n\n# Expected output:\n# .\n# ..\n# .git/\n# README.md\n</code></pre> <p>The <code>.git</code> directory indicates this is a Git repository.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#42-starting-claude-code","level":3,"title":"4.2 Starting Claude Code","text":"<p>Now let's start Claude Code in your project directory.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#cli-starting-a-session","level":4,"title":"CLI: Starting a Session","text":"<p>Navigate to your project and start Claude Code:</p> <pre><code># Make sure you're in the project directory\ncd /path/to/my-first-claude-project\n\n# Start Claude Code\nclaude-code\n</code></pre> <p>You'll see Claude Code's interactive prompt:</p> <pre><code>Claude Code v1.x.x\nConnected to claude-4-5-sonnet-20260115\n\nReady to help! Type your message or '/help' for available commands.\n\nYou:\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#vs-code-extension-opening-workspace","level":4,"title":"VS Code Extension: Opening Workspace","text":"<ol> <li>Open VS Code in your project directory:</li> </ol> <pre><code>code /path/to/my-first-claude-project\n</code></pre> <ol> <li>Open Claude Code panel:</li> <li>Click Claude Code icon in sidebar</li> <li> <p>Or use Command Palette: <code>Cmd/Ctrl + Shift + P</code> → \"Claude Code: Chat\"</p> </li> <li> <p>Start a conversation:</p> </li> <li>Type your message in the chat input</li> <li>Press Enter to send</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#initial-interface-walkthrough","level":4,"title":"Initial Interface Walkthrough","text":"<p>Let's understand the Claude Code interface:</p> <pre><code>flowchart TB\n    Start[You open Claude Code] --&gt; Interface{Interface Type}\n\n    Interface --&gt;|CLI| CLI[Terminal Interface]\n    Interface --&gt;|VS Code| VSC[VS Code Panel]\n\n    CLI --&gt; CLI1[Chat input/output]\n    CLI --&gt; CLI2[Command history]\n    CLI --&gt; CLI3[File changes shown inline]\n\n    VSC --&gt; VSC1[Chat panel on side]\n    VSC --&gt; VSC2[Inline code suggestions]\n    VSC --&gt; VSC3[Diff viewer for changes]\n    VSC --&gt; VSC4[Integrated terminal]\n\n    style CLI fill:#e1f5ff\n    style VSC fill:#e1f5ff</code></pre> <p>CLI Interface Components:</p> <ul> <li>Chat Area: Your messages and Claude's responses</li> <li>Command Prompt: Where you type (indicated by <code>You:</code>)</li> <li>Status Bar: Shows current model and connection status</li> <li>File Changes: Displays diffs when files are modified</li> </ul> <p>VS Code Extension Components:</p> <ul> <li>Chat Panel: Conversation history and input (sidebar or panel)</li> <li>Inline Suggestions: Code completions and edits in editor</li> <li>Diff Viewer: Compare changes before accepting</li> <li>Status Bar: Model indicator and settings (bottom of VS Code)</li> <li>Commands: Access via Command Palette (<code>Cmd/Ctrl + Shift + P</code>)</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#first-conversation","level":4,"title":"First Conversation","text":"<p>Test Claude Code with a simple request:</p> <p>CLI:</p> <pre><code>You: Hello! Can you help me understand this repository?\n</code></pre> <p>VS Code:</p> <p>Type in chat panel: <pre><code>Hello! Can you help me understand this repository?\n</code></pre></p> <p>Claude will respond, analyzing the directory structure and asking what you'd like to do next.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#5-initialization-two-paths","level":2,"title":"5. Initialization: Two Paths","text":"<p>When starting with Claude Code, you'll take one of two paths depending on whether you're working with existing code or starting fresh.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#51-path-a-existing-codebase","level":3,"title":"5.1 Path A: Existing Codebase","text":"<p>Use this approach when you have an established project with existing code.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#when-to-use-this-path","level":4,"title":"When to Use This Path","text":"<ul> <li>Joining an existing project</li> <li>Working with legacy code</li> <li>Analyzing unfamiliar codebases</li> <li>Adding features to established apps</li> <li>Debugging existing implementations</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#running-init-command","level":4,"title":"Running <code>/init</code> Command","text":"<p>The <code>/init</code> command tells Claude to comprehensively analyze your codebase:</p> <p>CLI:</p> <pre><code>You: /init\n</code></pre> <p>VS Code:</p> <p>Type in chat: <pre><code>/init\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#what-claude-analyzes","level":4,"title":"What Claude Analyzes","text":"<p>When you run <code>/init</code>, Claude Code:</p> <ol> <li>Traverses Directory Structure</li> <li>Maps out folders and files</li> <li>Identifies important directories (<code>src/</code>, <code>tests/</code>, <code>docs/</code>, etc.)</li> <li> <p>Notes configuration files</p> </li> <li> <p>Identifies Technologies</p> </li> <li>Programming languages used</li> <li>Frameworks and libraries (from package files)</li> <li>Build tools and task runners</li> <li> <p>Testing frameworks</p> </li> <li> <p>Analyzes Code Patterns</p> </li> <li>Architecture and design patterns</li> <li>Code organization conventions</li> <li>Naming conventions</li> <li> <p>Common patterns and idioms</p> </li> <li> <p>Reads Key Files</p> </li> <li>README and documentation</li> <li>Package manifests (<code>package.json</code>, <code>requirements.txt</code>, <code>Cargo.toml</code>, etc.)</li> <li>Configuration files (<code>.env.example</code>, config files)</li> <li> <p>Entry points (<code>main.py</code>, <code>index.js</code>, <code>app.py</code>, etc.)</p> </li> <li> <p>Understands Dependencies</p> </li> <li>External libraries and versions</li> <li>Internal module relationships</li> <li>Import/export patterns</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#example-output","level":4,"title":"Example Output","text":"<p>Here's what Claude might report after analyzing a Python web application:</p> <pre><code>I've analyzed your codebase. Here's what I found:\n\n**Project Structure:**\n- Python Flask web application\n- Backend API in `src/api/`\n- Frontend templates in `templates/`\n- Database models in `src/models/`\n- Tests in `tests/`\n\n**Key Technologies:**\n- Flask 2.3.2 web framework\n- SQLAlchemy ORM\n- PostgreSQL database\n- pytest for testing\n- Docker for containerization\n\n**Architecture:**\n- MVC pattern with blueprints\n- RESTful API design\n- Token-based authentication (JWT)\n- Database migrations with Alembic\n\n**Entry Point:** `src/app.py`\n\n**Notable Patterns:**\n- Factory pattern for app creation\n- Repository pattern for data access\n- Dependency injection for services\n\nWhat would you like me to help with?\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#best-practices-for-large-projects","level":4,"title":"Best Practices for Large Projects","text":"<p>When working with large codebases:</p> <p>1. Start with High-Level Overview</p> <pre><code>You: /init --summary\n</code></pre> <p>Get a high-level summary before diving deep.</p> <p>2. Focus on Specific Areas</p> <pre><code>You: Can you analyze just the authentication system in src/auth/?\n</code></pre> <p>Narrow the scope to avoid overwhelming context.</p> <p>3. Ask About Specific Patterns</p> <pre><code>You: How is error handling implemented across the codebase?\n</code></pre> <p>Target specific architectural questions.</p> <p>4. Request Diagrams</p> <pre><code>You: Can you create a diagram showing how the main modules interact?\n</code></pre> <p>Visual representations help with complex systems.</p> <p>5. Incremental Exploration</p> <p>Don't try to understand everything at once. Start with: - Entry points and main flows - Core business logic - Critical paths - Then expand to utilities and helpers</p> Context Window Limits <p>Claude has a large context window (200K tokens ≈ 150,000 words), but extremely large codebases might exceed this. If you encounter limits:</p> <ul> <li>Focus on specific directories</li> <li>Use <code>.claudeignore</code> to exclude generated files, dependencies</li> <li>Ask Claude to analyze subsystems separately</li> <li>Provide context incrementally as needed</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#52-path-b-starting-from-scratch","level":3,"title":"5.2 Path B: Starting from Scratch","text":"<p>Use this approach when creating a new project from an empty or minimal repository.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#when-to-use-this-path_1","level":4,"title":"When to Use This Path","text":"<ul> <li>Starting a new project</li> <li>Building a proof of concept</li> <li>Learning a new framework</li> <li>Creating a tool or utility</li> <li>Prototyping an idea</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#planning-session-workflow","level":4,"title":"Planning Session Workflow","text":"<p>Instead of <code>/init</code>, start a planning conversation:</p> <pre><code>You: I want to create a new Python CLI tool that helps developers manage their dotfiles. Can you help me plan the structure?\n</code></pre> <p>Claude will engage in a conversation to understand:</p> <ol> <li>Project Requirements</li> <li>What problem are you solving?</li> <li>Who are the users?</li> <li> <p>What features are essential?</p> </li> <li> <p>Technical Decisions</p> </li> <li>Programming language and version</li> <li>Frameworks or libraries</li> <li>Architecture approach</li> <li> <p>Testing strategy</p> </li> <li> <p>Project Structure</p> </li> <li>Directory organization</li> <li>File naming conventions</li> <li>Module breakdown</li> <li>Configuration approach</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#example-planning-conversation","level":4,"title":"Example Planning Conversation","text":"<p>You: <pre><code>I want to create a task management CLI app in Python that stores tasks in a local SQLite database. It should support adding, listing, completing, and deleting tasks.\n</code></pre></p> <p>Claude: <pre><code>Great! Let's plan this project. Here's what I'm thinking:\n\n**Project Structure:**\n</code></pre> task-manager/ ├── .gitignore ├── README.md ├── LICENSE ├── requirements.txt ├── setup.py ├── src/ │   ├── init.py │   ├── cli.py          # CLI interface (Click or argparse) │   ├── database.py     # SQLite operations │   ├── models.py       # Task data model │   └── commands/ │       ├── init.py │       ├── add.py │       ├── list.py │       ├── complete.py │       └── delete.py └── tests/     ├── init.py     ├── test_database.py     ├── test_commands.py     └── fixtures/ <pre><code>**Technology Stack:**\n- Python 3.9+\n- Click for CLI framework (better than argparse for this use case)\n- SQLite3 (built-in)\n- pytest for testing\n- Rich for beautiful terminal output (optional but nice)\n\n**Features:**\n1. `task add \"Task description\"` - Add new task\n2. `task list [--all|--completed|--pending]` - List tasks\n3. `task complete &lt;id&gt;` - Mark task as done\n4. `task delete &lt;id&gt;` - Delete task\n5. `task init` - Initialize database\n\nShould I proceed with creating these files? Any changes you'd like?\n</code></pre></p> <p>You: <pre><code>Yes, looks good! Let's also add a priority field to tasks. And use Rich for better output.\n</code></pre></p> <p>Claude: <pre><code>Perfect! I'll update the plan to include:\n- Priority field (LOW, MEDIUM, HIGH)\n- Rich library for colored, formatted output\n- Priority sorting in list command\n\nReady to create the project structure?\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#essential-files","level":4,"title":"Essential Files","text":"<p>Claude will help you create these foundational files:</p> <p>1. README.md</p> <p>Explains what the project does, how to install, and how to use it:</p> <pre><code>You: Create a comprehensive README.md\n</code></pre> <p>Claude generates: <pre><code># Task Manager CLI\n\nA simple, elegant command-line task manager built with Python.\n\n## Features\n\n- Add tasks with priorities\n- List tasks with filtering\n- Mark tasks complete\n- Beautiful terminal output\n\n## Installation\n\n```bash\npip install -e .\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#usage","level":2,"title":"Usage","text":"<pre><code># Add a task\ntask add \"Write documentation\" --priority high\n\n# List all tasks\ntask list\n\n# Complete a task\ntask complete 1\n\n# Delete a task\ntask delete 2\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#development","level":2,"title":"Development","text":"<p><pre><code># Install dependencies\npip install -r requirements.txt\n\n# Run tests\npytest\n</code></pre> <pre><code>**2. LICENSE**\n\n```bash\nYou: Add an MIT license\n</code></pre></p> <p>Claude creates <code>LICENSE</code> with proper MIT license text and your name/year.</p> <p>3. .gitignore</p> <pre><code>You: Create a Python .gitignore\n</code></pre> <p>Claude generates <code>.gitignore</code> with common Python exclusions:</p> <pre><code># Python\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n.Python\nenv/\nvenv/\nENV/\n*.egg-info/\ndist/\nbuild/\n\n# Database\n*.db\n*.sqlite\n*.sqlite3\n\n# IDE\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# Testing\n.pytest_cache/\n.coverage\nhtmlcov/\n\n# OS\n.DS_Store\nThumbs.db\n</code></pre> <p>4. requirements.txt</p> <pre><code>You: Create requirements.txt with our dependencies\n</code></pre> <pre><code>click&gt;=8.1.0\nrich&gt;=13.0.0\npytest&gt;=7.4.0\npytest-cov&gt;=4.1.0\n</code></pre> <p>5. CONTRIBUTING.md (Optional)</p> <p>For open-source projects:</p> <pre><code>You: Add a CONTRIBUTING.md guide\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#setting-up-for-different-languages","level":4,"title":"Setting Up for Different Languages","text":"<p>Claude can help you structure projects in any language:</p> <p>Python: <pre><code>You: Create a Python package structure with setuptools\n</code></pre></p> <p>JavaScript/Node: <pre><code>You: Create a Node.js project with Express and TypeScript\n</code></pre></p> <p>Rust: <pre><code>You: Initialize a Rust project with Cargo\n</code></pre></p> <p>Go: <pre><code>You: Create a Go module with a standard project layout\n</code></pre></p> <p>Claude will generate appropriate: - Directory structures - Configuration files (<code>Cargo.toml</code>, <code>package.json</code>, <code>go.mod</code>, etc.) - Build scripts - Testing setup - CI/CD templates</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#integration-with-mcp","level":4,"title":"Integration with MCP","text":"<p>For advanced projects, integrate Model Context Protocol (MCP) servers:</p> <pre><code>You: Set up MCP to connect to my PostgreSQL database\n</code></pre> <p>Claude will: 1. Create <code>.claude/mcp.json</code> configuration 2. Set up database connection settings 3. Create example queries 4. Configure environment variables</p> <p>Example MCP configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"postgres\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-postgres\"],\n      \"env\": {\n        \"POSTGRES_CONNECTION_STRING\": \"postgresql://localhost/mydb\"\n      }\n    }\n  }\n}\n</code></pre> <p>See our MCP Documentation for comprehensive setup guides.</p> <p>Start Simple, Iterate</p> <p>Don't try to plan every detail upfront. Start with a basic structure and let it evolve as you build. Claude can help refactor and reorganize as the project grows.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#6-working-with-custom-agents","level":2,"title":"6. Working with Custom Agents","text":"<p>One of Claude Code's most powerful features is the ability to create specialized agents for repeated tasks.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#61-what-are-agents","level":3,"title":"6.1 What are Agents?","text":"<p>In Claude Code, an agent is a specialized AI assistant configured for specific tasks with custom instructions, knowledge, and behaviors.</p> <p>How Agents Differ from Regular Prompts:</p> Aspect Regular Conversation Custom Agent Instructions General Claude behavior Specialized, task-specific instructions Context Current conversation Pre-loaded domain knowledge Consistency Varies by prompt Consistent behavior across uses Reusability Manual copy-paste Invoked by name or command Specialization General assistance Expert in specific domain <p>Benefits of Specialized Agents:</p> <ol> <li>Consistency: Same approach every time</li> <li>Efficiency: No need to repeat instructions</li> <li>Quality: Optimized prompts and workflows</li> <li>Team Alignment: Shared standards across team</li> <li>Expertise: Deep knowledge in specific areas</li> </ol> <p>For deeper understanding of agentic AI concepts, see Agentic AI.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#62-creating-a-documentation-writer-agent","level":3,"title":"6.2 Creating a Documentation Writer Agent","text":"<p>Let's create a practical example: a documentation writer agent that maintains your project's documentation.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#conceptual-explanation","level":4,"title":"Conceptual Explanation","text":"<p>A documentation agent should:</p> <ul> <li>Understand your documentation style and standards</li> <li>Know what type of documentation you need (API docs, tutorials, README updates)</li> <li>Follow consistent formatting and tone</li> <li>Keep documentation in sync with code changes</li> <li>Generate examples and usage instructions</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#step-by-step-creation","level":4,"title":"Step-by-Step Creation","text":"<p>Step 1: Create Agents Directory</p> <pre><code># In your project root\nmkdir -p .claude/agents\n</code></pre> <p>Step 2: Create Agent Configuration</p> <p>Create <code>.claude/agents/docs-writer.yaml</code>:</p> <pre><code>name: Documentation Writer\ndescription: Technical documentation specialist for this project\nversion: 1.0.0\n\n# Instructions for the agent\ninstructions: |\n  You are a technical documentation expert specializing in clear, concise, and\n  comprehensive documentation for software projects.\n\n  DOCUMENTATION STANDARDS:\n  - Write in clear, active voice\n  - Use consistent formatting (Markdown)\n  - Include code examples for all features\n  - Provide usage examples with realistic scenarios\n  - Keep README.md up-to-date with project changes\n  - Document all public APIs, functions, and classes\n  - Include installation and setup instructions\n  - Add troubleshooting sections for common issues\n\n  STYLE GUIDE:\n  - Use second person (\"you\") for instructions\n  - Use present tense for descriptions\n  - Keep sentences concise (&lt; 20 words)\n  - Use bullet points for lists\n  - Include code blocks with syntax highlighting\n  - Add warnings/notes/tips using appropriate formatting\n\n  DOCUMENTATION TYPES:\n  - README.md: Project overview, installation, quick start\n  - API.md: Detailed API documentation\n  - CONTRIBUTING.md: Contribution guidelines\n  - CHANGELOG.md: Version history and changes\n  - Inline comments: For complex code sections\n  - Docstrings: For all functions and classes\n\n# Domain knowledge\nknowledge:\n  - \"This project follows semantic versioning (MAJOR.MINOR.PATCH)\"\n  - \"Code examples should be runnable without modification\"\n  - \"All public APIs must have docstrings with type hints\"\n  - \"Documentation deploys automatically on merge to main\"\n\n# Capabilities\nskills:\n  - markdown\n  - api-documentation\n  - technical-writing\n  - code-examples\n  - tutorial-writing\n\n# Behavior preferences\npreferences:\n  verbosity: concise\n  code_style: pythonic  # or javascript, rust, etc.\n  example_complexity: medium\n</code></pre> <p>Step 3: Register Agent (if needed)</p> <p>Some configurations require explicit registration:</p> <pre><code># CLI\nclaude-code agents add .claude/agents/docs-writer.yaml\n\n# Or in VS Code settings.json\n{\n  \"claude-code.agents\": [\n    \".claude/agents/docs-writer.yaml\"\n  ]\n}\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#how-to-invoke-the-agent","level":4,"title":"How to Invoke the Agent","text":"<p>CLI:</p> <pre><code>You: @docs-writer Please document the new authentication module in src/auth.py\n</code></pre> <p>VS Code:</p> <p>In chat panel: <pre><code>@docs-writer Please document the new authentication module in src/auth.py\n</code></pre></p> <p>Or via command palette: <pre><code>Cmd/Ctrl + Shift + P → \"Claude Code: Use Agent\" → Select \"Documentation Writer\"\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#example-interaction","level":4,"title":"Example Interaction","text":"<p>You: <pre><code>@docs-writer I just added a new function called calculate_fibonacci(n) in src/math_utils.py.\nPlease add a comprehensive docstring.\n</code></pre></p> <p>Documentation Writer Agent: <pre><code>def calculate_fibonacci(n: int) -&gt; int:\n    \"\"\"\n    Calculate the nth Fibonacci number using iterative approach.\n\n    The Fibonacci sequence is defined as:\n    F(0) = 0, F(1) = 1\n    F(n) = F(n-1) + F(n-2) for n &gt; 1\n\n    Args:\n        n (int): The position in the Fibonacci sequence (0-indexed).\n                 Must be a non-negative integer.\n\n    Returns:\n        int: The Fibonacci number at position n.\n\n    Raises:\n        ValueError: If n is negative.\n\n    Examples:\n        &gt;&gt;&gt; calculate_fibonacci(0)\n        0\n        &gt;&gt;&gt; calculate_fibonacci(1)\n        1\n        &gt;&gt;&gt; calculate_fibonacci(10)\n        55\n        &gt;&gt;&gt; calculate_fibonacci(20)\n        6765\n\n    Time Complexity:\n        O(n) - Linear time complexity\n\n    Space Complexity:\n        O(1) - Constant space complexity\n\n    Note:\n        For very large values of n (&gt; 1000), consider using\n        memoization or matrix exponentiation for better performance.\n    \"\"\"\n    if n &lt; 0:\n        raise ValueError(\"n must be non-negative\")\n\n    if n &lt;= 1:\n        return n\n\n    prev, curr = 0, 1\n    for _ in range(2, n + 1):\n        prev, curr = curr, prev + curr\n\n    return curr\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#when-to-use-documentation-agent","level":4,"title":"When to Use Documentation Agent","text":"<p>Invoke the documentation agent when:</p> <ul> <li>Adding new features or functions</li> <li>Refactoring existing code</li> <li>Creating release notes</li> <li>Writing tutorials or guides</li> <li>Updating API documentation</li> <li>Generating changelogs</li> <li>Writing contribution guidelines</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#63-other-useful-agent-ideas","level":3,"title":"6.3 Other Useful Agent Ideas","text":"<p>Here are other specialized agents you might create (conceptual descriptions):</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#testing-agent","level":4,"title":"Testing Agent","text":"<p>Purpose: Generate comprehensive test suites</p> <p>Key Instructions: - Write tests for all public functions - Include edge cases and error conditions - Use appropriate testing framework (pytest, Jest, etc.) - Aim for 80%+ code coverage - Write descriptive test names - Use fixtures and mocks appropriately</p> <p>Invocation: <code>@test-writer Generate tests for the UserService class</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#code-review-agent","level":4,"title":"Code Review Agent","text":"<p>Purpose: Provide thorough code reviews with constructive feedback</p> <p>Key Instructions: - Check for bugs and edge cases - Identify performance issues - Suggest best practices - Point out security vulnerabilities - Review naming and code style - Suggest refactoring opportunities - Be constructive and specific</p> <p>Invocation: <code>@code-reviewer Please review the changes in src/api/users.py</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#refactoring-agent","level":4,"title":"Refactoring Agent","text":"<p>Purpose: Improve code structure without changing behavior</p> <p>Key Instructions: - Extract functions for repeated code - Simplify complex conditionals - Apply SOLID principles - Improve naming and clarity - Reduce coupling and increase cohesion - Preserve existing tests and behavior - Make incremental, testable changes</p> <p>Invocation: <code>@refactor-agent Improve the structure of the DataProcessor class</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#security-auditor-agent","level":4,"title":"Security Auditor Agent","text":"<p>Purpose: Identify security vulnerabilities</p> <p>Key Instructions: - Check for SQL injection vulnerabilities - Identify XSS and CSRF risks - Review authentication and authorization - Check for insecure dependencies - Verify proper input validation - Review secrets management - Check for information disclosure</p> <p>Invocation: <code>@security-auditor Audit the login endpoint for vulnerabilities</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#performance-optimizer-agent","level":4,"title":"Performance Optimizer Agent","text":"<p>Purpose: Identify and fix performance bottlenecks</p> <p>Key Instructions: - Profile code for bottlenecks - Suggest algorithmic improvements - Identify unnecessary computations - Recommend caching strategies - Optimize database queries - Reduce memory allocations - Improve concurrency</p> <p>Invocation: <code>@performance-optimizer Analyze the data processing pipeline</code></p> <p>Creating Your Own Agents</p> <p>Think about tasks you repeat frequently and create specialized agents for them. The more specific the instructions, the better the results!</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#7-custom-slash-commands","level":2,"title":"7. Custom Slash Commands","text":"<p>Slash commands provide shortcuts for common workflows, turning multi-step processes into single commands.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#71-understanding-slash-commands","level":3,"title":"7.1 Understanding Slash Commands","text":"<p>What are Slash Commands?</p> <p>Slash commands are custom shortcuts that trigger predefined workflows in Claude Code. They're like macros or aliases that encapsulate common development tasks.</p> <p>Why They're Useful:</p> <ul> <li>Efficiency: Execute complex workflows with one command</li> <li>Consistency: Same process every time</li> <li>Team Alignment: Share common workflows across team</li> <li>Automation: Reduce manual, repetitive tasks</li> <li>Error Reduction: Less chance of forgetting steps</li> </ul> <p>Built-in Commands:</p> <p>Claude Code includes several built-in commands:</p> Command Purpose <code>/init</code> Analyze codebase structure <code>/help</code> Show available commands <code>/clear</code> Clear conversation history <code>/context</code> Show current context size <code>/files</code> List files in current context <code>/model</code> Change AI model <code>/save</code> Save conversation to file","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#72-example-creating-commit-command","level":3,"title":"7.2 Example: Creating <code>/commit</code> Command","text":"<p>Let's create a powerful <code>/commit</code> command that automates the git commit workflow.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#purpose-and-workflow","level":4,"title":"Purpose and Workflow","text":"<p>The <code>/commit</code> command should:</p> <ol> <li>Show <code>git status</code> to review changes</li> <li>Stage all changes (or prompt for selective staging)</li> <li>Generate a descriptive commit message based on changes</li> <li>Create the commit</li> <li>Optionally push to remote</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#configuration-syntax","level":4,"title":"Configuration Syntax","text":"<p>Create <code>.claude/commands/commit.yaml</code>:</p> <pre><code>name: commit\ndescription: Intelligent git commit with AI-generated message\nversion: 1.0.0\n\n# Command behavior\nworkflow:\n  - name: check_git_status\n    action: run_command\n    command: \"git status --short\"\n    description: \"Show current changes\"\n\n  - name: confirm_changes\n    action: prompt_user\n    message: \"Proceed with committing these changes?\"\n    options:\n      - value: \"all\"\n        label: \"Commit all changes\"\n      - value: \"selective\"\n        label: \"Let me choose files\"\n      - value: \"cancel\"\n        label: \"Cancel\"\n\n  - name: stage_changes\n    action: conditional\n    condition: \"confirm_changes != 'cancel'\"\n    then:\n      - action: run_command\n        command: \"git add -A\"\n        when: \"confirm_changes == 'all'\"\n      - action: prompt_for_files\n        when: \"confirm_changes == 'selective'\"\n\n  - name: analyze_diff\n    action: run_command\n    command: \"git diff --cached\"\n    store_output: \"diff_content\"\n\n  - name: generate_message\n    action: ai_task\n    prompt: |\n      Based on this git diff, generate a commit message following conventional commits format:\n\n      &lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n      &lt;body&gt;\n\n      &lt;footer&gt;\n\n      Types: feat, fix, docs, style, refactor, test, chore\n\n      Git diff:\n      ```\n      {{diff_content}}\n      ```\n\n      Generate a clear, concise commit message that explains what changed and why.\n    store_output: \"commit_message\"\n\n  - name: show_message\n    action: display\n    content: |\n      Proposed commit message:\n\n      {{commit_message}}\n\n      Approve this message?\n\n  - name: confirm_message\n    action: prompt_user\n    message: \"Use this commit message?\"\n    options:\n      - value: \"yes\"\n        label: \"Yes, commit with this message\"\n      - value: \"edit\"\n        label: \"Let me edit it\"\n      - value: \"cancel\"\n        label: \"Cancel\"\n\n  - name: edit_message\n    action: conditional\n    condition: \"confirm_message == 'edit'\"\n    then:\n      - action: prompt_for_text\n        multiline: true\n        default: \"{{commit_message}}\"\n        store_output: \"commit_message\"\n\n  - name: create_commit\n    action: conditional\n    condition: \"confirm_message != 'cancel'\"\n    then:\n      - action: run_command\n        command: \"git commit -m '{{commit_message}}'\"\n\n  - name: ask_push\n    action: prompt_user\n    message: \"Push to remote?\"\n    options:\n      - value: \"yes\"\n        label: \"Yes, push now\"\n      - value: \"no\"\n        label: \"No, I'll push later\"\n\n  - name: push_changes\n    action: conditional\n    condition: \"ask_push == 'yes'\"\n    then:\n      - action: run_command\n        command: \"git push\"\n\n# Safety settings\nsafety:\n  confirm_before_execute: true\n  allow_destructive_ops: false\n\n# Permissions needed\npermissions:\n  - git\n  - filesystem.read\n  - filesystem.write\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#simpler-version","level":4,"title":"Simpler Version","text":"<p>If the full workflow is too complex, here's a simpler version:</p> <p><code>.claude/commands/commit-simple.yaml</code>:</p> <pre><code>name: commit\ndescription: Quick commit with AI-generated message\n\nworkflow:\n  - action: run_command\n    command: \"git add -A\"\n\n  - action: ai_task\n    prompt: \"Analyze the git diff and generate a conventional commit message\"\n    command: \"git diff --cached\"\n\n  - action: git_commit\n    message: \"{{ai_output}}\"\n\npermissions:\n  - git\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#usage-demonstration","level":4,"title":"Usage Demonstration","text":"<p>Basic Usage:</p> <pre><code>You: /commit\n</code></pre> <p>With Options:</p> <pre><code>You: /commit --no-push\nYou: /commit --message \"fix: resolve login bug\"\nYou: /commit --amend\n</code></pre> <p>Example Flow:</p> <pre><code>You: /commit\n\nClaude Code: Analyzing changes...\n\nModified files:\n  M src/auth.py\n  M tests/test_auth.py\n  A docs/authentication.md\n\nProposed commit message:\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nfeat(auth): add support for OAuth 2.0 authentication\n\n- Implement OAuth2 authentication flow\n- Add token validation and refresh logic\n- Update authentication tests for new flow\n- Add documentation for OAuth setup\n\nCloses #42\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nUse this commit message? [Yes/Edit/Cancel]: Yes\n\nCreating commit... Done!\nPush to remote? [Yes/No]: Yes\nPushing to origin/main... Done!\n\n✓ Committed and pushed successfully!\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#73-other-slash-command-ideas","level":3,"title":"7.3 Other Slash Command Ideas","text":"<p>Here are more useful custom commands (conceptual descriptions):</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#test-run-test-suite","level":4,"title":"<code>/test</code> - Run Test Suite","text":"<pre><code>name: test\ndescription: Run tests with coverage and report results\n\nworkflow:\n  - Run pytest with coverage\n  - Generate coverage report\n  - Show failed tests with context\n  - Suggest fixes for failures\n</code></pre> <p>Usage: <code>/test</code> or <code>/test --file tests/test_api.py</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#review-code-review-workflow","level":4,"title":"<code>/review</code> - Code Review Workflow","text":"<pre><code>name: review\ndescription: Request code review before merging\n\nworkflow:\n  - Show uncommitted changes\n  - Run linters and formatters\n  - Check for common issues\n  - Generate review checklist\n  - Create pull request (optional)\n</code></pre> <p>Usage: <code>/review</code> or <code>/review --create-pr</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#deploy-deployment-workflow","level":4,"title":"<code>/deploy</code> - Deployment Workflow","text":"<pre><code>name: deploy\ndescription: Deploy to specified environment\n\nworkflow:\n  - Verify tests pass\n  - Check environment variables\n  - Build application\n  - Run deployment script\n  - Verify deployment\n  - Tag release\n</code></pre> <p>Usage: <code>/deploy production</code> or <code>/deploy staging --skip-tests</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#docs-documentation-generation","level":4,"title":"<code>/docs</code> - Documentation Generation","text":"<pre><code>name: docs\ndescription: Generate or update documentation\n\nworkflow:\n  - Scan for undocumented functions\n  - Generate missing docstrings\n  - Update README if needed\n  - Build documentation site\n  - Show coverage report\n</code></pre> <p>Usage: <code>/docs</code> or <code>/docs --module auth</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#refactor-smart-refactoring","level":4,"title":"<code>/refactor</code> - Smart Refactoring","text":"<pre><code>name: refactor\ndescription: Refactor code with specific pattern\n\nworkflow:\n  - Analyze current structure\n  - Suggest refactoring approach\n  - Apply changes incrementally\n  - Run tests after each change\n  - Create commit if successful\n</code></pre> <p>Usage: <code>/refactor extract-method</code> or <code>/refactor simplify-conditionals</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#fix-automated-bug-fixing","level":4,"title":"<code>/fix</code> - Automated Bug Fixing","text":"<pre><code>name: fix\ndescription: Analyze and fix errors\n\nworkflow:\n  - Run application/tests\n  - Capture error messages\n  - Analyze stack traces\n  - Suggest fixes\n  - Apply fix with approval\n  - Verify fix works\n</code></pre> <p>Usage: <code>/fix</code> or <code>/fix --error \"IndexError on line 42\"</code></p> <p>Command Best Practices</p> <ul> <li>Keep commands focused on single workflows</li> <li>Always include confirmation steps for destructive operations</li> <li>Provide clear output at each step</li> <li>Allow customization through parameters</li> <li>Include safety checks and validation</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#8-development-workflow-best-practices","level":2,"title":"8. Development Workflow Best Practices","text":"<p>Now that you understand the tools, let's explore effective workflows for daily development with Claude Code.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#81-typical-development-session","level":3,"title":"8.1 Typical Development Session","text":"<p>Here's how a productive Claude Code session typically flows:</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#starting-your-work","level":4,"title":"Starting Your Work","text":"<p>1. Navigate to Project:</p> <pre><code>cd /path/to/your-project\n</code></pre> <p>2. Start Claude Code:</p> <pre><code># CLI\nclaude-code\n\n# VS Code\ncode . # Opens VS Code, then open Claude panel\n</code></pre> <p>3. Review Context:</p> <pre><code>You: What was I working on last time?\n</code></pre> <p>Claude can reference conversation history (if saved) or analyze recent git commits.</p> <p>4. Set Today's Goal:</p> <pre><code>You: Today I need to implement user authentication. Let's start by planning the approach.\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#iterative-development-flow","level":4,"title":"Iterative Development Flow","text":"<p>Development Loop:</p> <pre><code>flowchart TD\n    A[Describe Feature/Fix] --&gt; B[Claude Generates Code]\n    B --&gt; C[Review &amp; Discuss]\n    C --&gt; D{Satisfactory?}\n    D --&gt;|No| E[Request Changes]\n    E --&gt; B\n    D --&gt;|Yes| F[Apply Changes]\n    F --&gt; G[Run Tests]\n    G --&gt; H{Tests Pass?}\n    H --&gt;|No| I[Debug with Claude]\n    I --&gt; B\n    H --&gt;|Yes| J[Commit Changes]\n    J --&gt; K{More Work?}\n    K --&gt;|Yes| A\n    K --&gt;|No| L[End Session]\n\n    style F fill:#c8e6c9\n    style J fill:#c8e6c9\n    style L fill:#e1f5ff</code></pre> <p>Example Development Flow:</p> <pre><code># Step 1: Plan the feature\nYou: I need to add a password reset feature. What's the best approach?\n\nClaude: [Suggests approach with email tokens, expiration, security considerations]\n\n# Step 2: Implement backend\nYou: Let's start with the backend. Create the password reset endpoint.\n\nClaude: [Generates Flask/Express/etc. endpoint code]\n\n# Step 3: Review and refine\nYou: Looks good, but let's add rate limiting to prevent abuse.\n\nClaude: [Updates code with rate limiting]\n\n# Step 4: Write tests\nYou: @test-writer Create tests for the password reset endpoint\n\nTest Agent: [Generates comprehensive test suite]\n\n# Step 5: Run tests\nYou: /test\n\nClaude: [Runs tests, reports results]\n\n# Step 6: Update documentation\nYou: @docs-writer Document the new password reset flow\n\nDocs Agent: [Updates API documentation and README]\n\n# Step 7: Commit\nYou: /commit\n\nClaude: [Creates commit with descriptive message]\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#managing-context","level":4,"title":"Managing Context","text":"<p>Keep Context Relevant:</p> <pre><code># Clear context if conversation gets too long\nYou: /clear\n\n# Focus on specific files\nYou: Let's focus on just src/auth.py and tests/test_auth.py\n\n# Remove files from context\nYou: You can forget about the migration files, we don't need those\n</code></pre> <p>Loading Additional Context:</p> <pre><code># Add files to context\nYou: Can you also look at config/auth_config.py?\n\n# Load related code\nYou: Show me other places where we handle authentication\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#conversation-organization","level":4,"title":"Conversation Organization","text":"<p>Use Clear, Specific Requests:</p> <p>✅ Good: <pre><code>Refactor the authenticate_user function in src/auth.py to use the Strategy pattern,\nmaking it easier to add new authentication methods.\n</code></pre></p> <p>❌ Unclear: <pre><code>Make auth better\n</code></pre></p> <p>Break Down Complex Tasks:</p> <p>Instead of: <pre><code>Build a complete user authentication system\n</code></pre></p> <p>Do: <pre><code>1. Let's start with the database models for User and Session\n2. Next, create the login endpoint\n3. Then, implement JWT token generation\n[etc.]\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#82-git-integration-patterns","level":3,"title":"8.2 Git Integration Patterns","text":"<p>Claude Code can be a powerful Git assistant.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#commit-message-generation","level":4,"title":"Commit Message Generation","text":"<p>Let Claude analyze your changes:</p> <pre><code>You: /commit\n\n# Or manually:\nYou: Generate a commit message for my changes\n</code></pre> <p>Claude will: - Analyze the diff - Identify the type of change (feat, fix, refactor, etc.) - Write a clear, conventional commit message - Include relevant details and context</p> <p>Example Generated Commit:</p> <pre><code>feat(auth): implement OAuth2 authentication flow\n\n- Add OAuth2 client configuration\n- Implement authorization code flow\n- Add token refresh mechanism\n- Update user model to store OAuth tokens\n- Add middleware for OAuth protected routes\n\nThis enables users to authenticate using Google, GitHub, and other\nOAuth providers instead of just username/password.\n\nCloses #42\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#branch-management-strategies","level":4,"title":"Branch Management Strategies","text":"<p>Feature Branch Workflow:</p> <pre><code># Create feature branch\nYou: Can you help me create a branch for the password reset feature?\n\nClaude: Sure! Run: git checkout -b feature/password-reset\n\n# Work on feature...\n\n# Before merging\nYou: /review\nYou: /test\nYou: /commit\n</code></pre> <p>Reviewing Before Merge:</p> <pre><code>You: Compare my feature branch with main and identify any conflicts\n\nClaude: [Analyzes differences, identifies conflicts, suggests resolution]\n</code></pre> <p>Rebasing:</p> <pre><code>You: I need to rebase my feature branch on the latest main. Walk me through it safely.\n\nClaude: [Provides step-by-step rebase instructions with safety checks]\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#pull-request-descriptions","level":4,"title":"Pull Request Descriptions","text":"<p>Generate comprehensive PR descriptions:</p> <p><pre><code>You: Generate a pull request description for my authentication feature\n\nClaude:\n</code></pre> <pre><code>## Pull Request: Add OAuth2 Authentication\n\n### Summary\nImplements OAuth2 authentication flow allowing users to sign in with Google, GitHub, and Microsoft accounts.\n\n### Changes\n- ✨ Add OAuth2 client configuration (`src/auth/oauth.py`)\n- ✨ Implement authorization code flow\n- ✨ Add token management and refresh logic\n- 🗃️ Update User model to store OAuth provider info\n- 🔒 Add middleware for OAuth-protected routes\n- ✅ Add comprehensive test coverage (95%)\n- 📝 Update API documentation\n\n### Testing\n- [x] Unit tests pass\n- [x] Integration tests pass\n- [x] Manual testing with Google OAuth\n- [x] Manual testing with GitHub OAuth\n- [x] Security review completed\n\n### Security Considerations\n- OAuth tokens stored encrypted in database\n- State parameter used to prevent CSRF\n- Strict redirect URI validation\n- Token refresh handled automatically\n\n### Breaking Changes\nNone. Existing username/password authentication continues to work.\n\n### Related Issues\nCloses #42\nRelates to #38, #45\n\n### Screenshots\n[Add screenshots of OAuth login flow]\n\n### Deployment Notes\nRequires new environment variables:\n- `OAUTH_GOOGLE_CLIENT_ID`\n- `OAUTH_GOOGLE_CLIENT_SECRET`\n- `OAUTH_GITHUB_CLIENT_ID`\n- `OAUTH_GITHUB_CLIENT_SECRET`\n</code></pre> <pre><code>#### Code Review with Claude\n\nBefore submitting PR:\n\n```bash\nYou: @code-reviewer Review my changes and check for issues\n\nCode Reviewer: [Provides detailed feedback on:]\n- Potential bugs\n- Security concerns\n- Performance issues\n- Style inconsistencies\n- Missing tests\n- Documentation gaps\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#83-security-privacy","level":3,"title":"8.3 Security &amp; Privacy","text":"<p>Developing securely with AI assistance requires careful attention.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#api-key-management","level":4,"title":"API Key Management","text":"<p>Environment Variables:</p> <p>Never hardcode API keys:</p> <pre><code># ❌ BAD - Hardcoded\napi_key = \"sk-ant-1234567890\"\n\n# ✅ GOOD - Environment variable\nimport os\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n</code></pre> <p>Setting Environment Variables:</p> <pre><code># .env file (add to .gitignore!)\nANTHROPIC_API_KEY=your-key-here\nDATABASE_URL=postgresql://...\nSECRET_KEY=your-secret-key\n</code></pre> <p>Load in code:</p> <pre><code>from dotenv import load_dotenv\nload_dotenv()\n</code></pre> <p>Claude Can Help:</p> <pre><code>You: Review my code for hardcoded secrets\n\nClaude: [Identifies hardcoded credentials and suggests fixes]\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#gitignore-best-practices","level":4,"title":".gitignore Best Practices","text":"<p>Ensure sensitive files are never committed:</p> <pre><code>You: Create a comprehensive .gitignore for Python/Node/etc.\n\nClaude: [Generates .gitignore including:]\n</code></pre> <pre><code># Environment variables\n.env\n.env.local\n.env.*.local\n\n# Secrets and credentials\n*.key\n*.pem\n*.p12\nsecrets.yaml\ncredentials.json\n\n# Database\n*.db\n*.sqlite\n*.sqlite3\n\n# API keys and tokens\n.anthropic\n.openai\n*_key.txt\n*_token.txt\n\n# IDE and editors\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# OS files\n.DS_Store\nThumbs.db\n</code></pre> <p>Verify Nothing Sensitive is Tracked:</p> <pre><code># Check what's tracked by git\ngit ls-files\n\n# Check for accidental secrets\nYou: Scan my repository for potential secrets or API keys\n\nClaude: [Uses regex patterns to identify potential secrets]\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#sensitive-data-handling","level":4,"title":"Sensitive Data Handling","text":"<p>Sanitize Before Sharing with Claude:</p> <pre><code># ❌ Don't paste\nYou: Debug this: DATABASE_URL=postgresql://admin:MyPassword123@prod.example.com/db\n\n# ✅ Do paste\nYou: Debug this: DATABASE_URL=postgresql://user:password@host/db\n</code></pre> <p>Use Placeholders:</p> <pre><code>You: Here's my config (I've replaced sensitive values with placeholders):\n\nAPI_KEY=&lt;redacted&gt;\nSECRET=&lt;redacted&gt;\nDATABASE_URL=postgresql://USER:PASSWORD@HOST/DATABASE\n\nThe issue is...\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#institutional-compliance","level":4,"title":"Institutional Compliance","text":"<p>Follow Your Organization's Policies</p> <p>Many universities and companies have strict policies about AI tools:</p> <ul> <li>Data Classification: Don't share classified or sensitive data</li> <li>Approved Tools: Use only approved AI services</li> <li>Code Review: Additional review may be required for AI-generated code</li> <li>Logging: Be aware of what's logged and where</li> <li>Intellectual Property: Understand IP implications</li> </ul> <p>Check with your IT security team before using Claude Code with: - Proprietary code - Sensitive research data - Personal information (PII) - Protected health information (PHI) - Financial data - Any classified information</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#security-checklist","level":4,"title":"Security Checklist","text":"<p>Before deploying AI-assisted code:</p> <ul> <li> No hardcoded credentials</li> <li> Environment variables used properly</li> <li> <code>.gitignore</code> includes sensitive files</li> <li> No secrets in git history</li> <li> Input validation on all user input</li> <li> SQL injection prevention</li> <li> XSS prevention</li> <li> CSRF protection implemented</li> <li> Authentication tested thoroughly</li> <li> Authorization checks in place</li> <li> Encryption for sensitive data</li> <li> Secure communication (HTTPS)</li> <li> Security review completed</li> <li> Compliance requirements met</li> </ul> <p>Ask Claude to Help:</p> <pre><code>You: @security-auditor Review my authentication system for vulnerabilities\n\nSecurity Auditor: [Comprehensive security analysis]\n</code></pre> <p>AI-Generated Code Requires Review</p> <p>Always review AI-generated code for security issues. AI can make mistakes or suggest insecure patterns. Your judgment is essential.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#9-ai-sandbox-environments","level":2,"title":"9. AI Sandbox Environments","text":"<p>For certain use cases, you may want to run Claude Code in an isolated sandbox environment.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#91-why-use-sandboxes","level":3,"title":"9.1 Why Use Sandboxes?","text":"<p>Isolation Benefits: - Separate development from production environment - Prevent accidental changes to main system - Test destructive operations safely - Maintain clean, reproducible environments</p> <p>Testing Environments: - Test installations and configurations - Experiment with different setups - Verify cross-platform compatibility - CI/CD integration</p> <p>Team Collaboration: - Consistent environment across team - Share exact development setup - Onboard new developers quickly - Document infrastructure as code</p> <p>Security &amp; Compliance: - Meet institutional security requirements - Isolate sensitive data processing - Audit and monitor activity - Enforce security policies</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#92-options-overview","level":3,"title":"9.2 Options Overview","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#docker-containers","level":4,"title":"Docker Containers","text":"<p>What: Lightweight, isolated containers that package applications with their dependencies.</p> <p>Pros: - Fast startup - Minimal resource usage - Easy to share (Dockerfile) - Perfect for CI/CD - Version controlled environments</p> <p>Cons: - Requires Docker knowledge - Linux-only containers (mostly) - Networking can be complex</p> <p>Learn More: Docker Documentation</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#virtual-machines","level":4,"title":"Virtual Machines","text":"<p>What: Complete OS instances running on your hardware.</p> <p>Pros: - Complete isolation - Run different OS (Windows on Mac, etc.) - Snapshots and restore - Better for GUI applications</p> <p>Cons: - Resource-intensive - Slower startup - Large disk usage - More complex setup</p> <p>Popular Options: - VirtualBox (Free, open-source) - VMware Workstation/Fusion - Parallels (Mac) - Hyper-V (Windows)</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#jupyter-lab-integration","level":4,"title":"Jupyter Lab Integration","text":"<p>What: Run Claude Code within Jupyter Lab for notebook-based development.</p> <p>Pros: - Interactive development - Great for data science - Inline documentation - Shareable notebooks</p> <p>Cons: - Different workflow than traditional coding - Less suitable for large applications</p> <p>Learn More: See our Jupyter AI Guide for detailed setup.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#cloud-development-environments","level":4,"title":"Cloud Development Environments","text":"<p>GitHub Codespaces - Cloud-based VS Code - Integrated with GitHub repos - Automatic environment setup - Learn more</p> <p>GitPod - Open-source alternative to Codespaces - Works with GitHub, GitLab, Bitbucket - Free tier available - Learn more</p> <p>AWS Cloud9 - AWS-integrated IDE - Serverless friendly - Pre-configured for AWS services - Learn more</p> <p>Replit - Browser-based IDE - Instant setup - Collaborative coding - Learn more</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#93-quick-docker-setup-example","level":3,"title":"9.3 Quick Docker Setup Example","text":"<p>Here's a basic Docker setup for Claude Code development:</p> <p>Dockerfile:</p> <pre><code>FROM python:3.11-slim\n\n# Install Node.js for Claude Code CLI\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    nodejs \\\n    npm \\\n    git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install Claude Code\nRUN npm install -g @anthropic-ai/claude-code\n\n# Install GitHub CLI\nRUN curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | \\\n    dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg &amp;&amp; \\\n    echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | \\\n    tee /etc/apt/sources.list.d/github-cli.list &gt; /dev/null &amp;&amp; \\\n    apt-get update &amp;&amp; \\\n    apt-get install gh -y\n\n# Set up workspace\nWORKDIR /workspace\n\n# Default command\nCMD [\"/bin/bash\"]\n</code></pre> <p>Usage:</p> <pre><code># Build the image\ndocker build -t claude-dev .\n\n# Run container with volume mount\ndocker run -it \\\n  -v $(pwd):/workspace \\\n  -e ANTHROPIC_API_KEY=$ANTHROPIC_API_KEY \\\n  claude-dev\n\n# Inside container\nclaude-code --version\ngh auth login\ncd /workspace\nclaude-code\n</code></pre> <p>For comprehensive Docker guides, see the official Docker documentation.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#10-troubleshooting","level":2,"title":"10. Troubleshooting","text":"<p>Common issues and their solutions.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#installation-problems","level":3,"title":"Installation Problems","text":"<p>Issue: <code>npm install -g @anthropic-ai/claude-code</code> fails</p> <p>Solutions:</p> <ol> <li> <p>Check Node/npm versions: <pre><code>node --version  # Should be v16+\nnpm --version   # Should be v7+\n</code></pre></p> </li> <li> <p>Update Node: <pre><code># macOS\nbrew upgrade node\n\n# Or use nvm\nnvm install --lts\n</code></pre></p> </li> <li> <p>Try without global: <pre><code>npx @anthropic-ai/claude-code --version\n</code></pre></p> </li> <li> <p>Permissions issue: <pre><code># Use correct npm permissions (don't use sudo!)\nmkdir ~/.npm-global\nnpm config set prefix '~/.npm-global'\necho 'export PATH=~/.npm-global/bin:$PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre></p> </li> </ol> <p>Issue: VS Code extension not appearing</p> <p>Solutions:</p> <ol> <li>Reload VS Code:</li> <li> <p><code>Cmd/Ctrl + Shift + P</code> → \"Developer: Reload Window\"</p> </li> <li> <p>Check VS Code version:</p> </li> <li>Must be v1.75.0 or later</li> <li> <p>Help → About</p> </li> <li> <p>Reinstall extension: <pre><code>code --uninstall-extension anthropic.claude-code\ncode --install-extension anthropic.claude-code\n</code></pre></p> </li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#authentication-errors","level":3,"title":"Authentication Errors","text":"<p>Issue: \"Authentication failed\" or \"Invalid API key\"</p> <p>Solutions:</p> <ol> <li> <p>Verify API key: <pre><code>echo $ANTHROPIC_API_KEY  # Should output your key\n</code></pre></p> </li> <li> <p>Re-authenticate: <pre><code># CLI\nclaude-code auth logout\nclaude-code auth login\n\n# Check status\nclaude-code auth status\n</code></pre></p> </li> <li> <p>Check API key format:</p> </li> <li>Should start with <code>sk-ant-</code></li> <li>No extra spaces or quotes</li> <li> <p>Not expired or revoked</p> </li> <li> <p>Environment variable: <pre><code># Add to ~/.bashrc or ~/.zshrc\nexport ANTHROPIC_API_KEY=\"your-key-here\"\nsource ~/.bashrc\n</code></pre></p> </li> </ol> <p>Issue: \"Rate limit exceeded\"</p> <p>Solution: - You've hit usage limits - Wait and try again - Upgrade to Pro plan for higher limits - Check console.anthropic.com for usage</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#extension-not-loading","level":3,"title":"Extension Not Loading","text":"<p>Issue: VS Code extension installed but not working</p> <p>Solutions:</p> <ol> <li>Check extension status:</li> <li>View → Extensions</li> <li>Search \"Claude Code\"</li> <li> <p>Should show \"Enabled\"</p> </li> <li> <p>Check for conflicts:</p> </li> <li>Disable other AI coding extensions</li> <li> <p>Restart VS Code</p> </li> <li> <p>View logs:</p> </li> <li>Help → Toggle Developer Tools</li> <li>Console tab → filter for \"claude\"</li> <li> <p>Look for error messages</p> </li> <li> <p>Reinstall clean: <pre><code># Remove extension completely\nrm -rf ~/.vscode/extensions/anthropic.claude-code-*\n\n# Reinstall\ncode --install-extension anthropic.claude-code\n</code></pre></p> </li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#performance-issues","level":3,"title":"Performance Issues","text":"<p>Issue: Claude Code is slow or unresponsive</p> <p>Solutions:</p> <ol> <li> <p>Reduce context: <pre><code>You: /clear\nYou: Let's focus only on the files we need\n</code></pre></p> </li> <li> <p>Use faster model: <pre><code>You: /model claude-4-5-haiku-20260115\n</code></pre></p> </li> <li> <p>Close unnecessary files (VS Code):</p> </li> <li>Close tabs you're not editing</li> <li> <p>Use <code>.claudeignore</code> to exclude files</p> </li> <li> <p>Check network: <pre><code>ping console.anthropic.com\n</code></pre></p> </li> <li> <p>System resources:</p> </li> <li>Close other applications</li> <li>Check RAM and CPU usage</li> <li>Restart VS Code/terminal</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#context-window-limits","level":3,"title":"Context Window Limits","text":"<p>Issue: \"Context window exceeded\" error</p> <p>Solutions:</p> <ol> <li> <p>Clear conversation: <pre><code>You: /clear\n</code></pre></p> </li> <li> <p>Focus on specific files: <pre><code>You: Let's work only with src/auth.py for now\n</code></pre></p> </li> <li> <p>Create <code>.claudeignore</code>: <pre><code># .claudeignore (like .gitignore)\nnode_modules/\ndist/\nbuild/\n*.log\n*.min.js\nvendor/\n.git/\n</code></pre></p> </li> <li> <p>Split large files:</p> </li> <li>Refactor large files into smaller modules</li> <li> <p>Use more focused conversations</p> </li> <li> <p>Use summaries: <pre><code>You: Give me a summary of the auth module instead of showing all the code\n</code></pre></p> </li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#common-error-messages","level":3,"title":"Common Error Messages","text":"<p>\"Cannot read properties of undefined\" - Usually a configuration issue - Check <code>.claude/config.json</code> syntax - Reset config: <code>rm -rf .claude/</code> and reinitialize</p> <p>\"EACCES: permission denied\" - File permission issue - Check file ownership: <code>ls -la</code> - Fix permissions: <code>chmod +x script.sh</code></p> <p>\"Git not found\" - Git not installed or not in PATH - Install Git: git-scm.com - Check PATH: <code>echo $PATH</code></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#getting-help","level":3,"title":"Getting Help","text":"<p>If you're still stuck:</p> <ol> <li>Check official documentation:</li> <li> <p>docs.anthropic.com/claude-code</p> </li> <li> <p>Search GitHub issues:</p> </li> <li>Known issues and solutions</li> <li> <p>Report new bugs</p> </li> <li> <p>Community resources:</p> </li> <li>Anthropic Discord</li> <li>Stack Overflow (tag: claude-code)</li> <li> <p>Reddit r/ClaudeAI</p> </li> <li> <p>Contact support:</p> </li> <li>Pro/Team subscribers: support@anthropic.com</li> <li>Include: Claude Code version, OS, error messages, steps to reproduce</li> </ol>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#11-tips-advanced-techniques","level":2,"title":"11. Tips &amp; Advanced Techniques","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#productivity-tips","level":3,"title":"Productivity Tips","text":"<p>Keyboard Shortcuts (VS Code Extension)</p> Shortcut Action <code>Cmd/Ctrl + Shift + C</code> Open Claude Code panel <code>Cmd/Ctrl + K</code> Quick ask Claude <code>Cmd/Ctrl + Shift + P</code> → \"Claude\" All Claude commands <code>Esc</code> Cancel current request <code>Tab</code> Accept inline suggestion <p>Efficient Prompting</p> <p>✅ Be Specific: <pre><code>Refactor the authenticate_user function in src/auth.py to handle OAuth2 tokens\n</code></pre></p> <p>❌ Too Vague: <pre><code>Make auth better\n</code></pre></p> <p>✅ Provide Context: <pre><code>This is a Flask app using SQLAlchemy. I need to add a user profile endpoint\nthat returns user info as JSON. It should require authentication and handle\nmissing users gracefully.\n</code></pre></p> <p>❌ Lacking Context: <pre><code>Add a user profile endpoint\n</code></pre></p> <p>✅ Iterative Refinement: <pre><code>1. Create the basic endpoint\n2. [After review] Add pagination support\n3. [After review] Add filtering by date\n</code></pre></p> <p>❌ Everything at Once: <pre><code>Create a user profile endpoint with pagination, filtering, sorting, search,\nexport to CSV, and admin overrides\n</code></pre></p> <p>Project Organization</p> <p>Create a <code>.claude/</code> directory for Claude-specific files:</p> <pre><code>.claude/\n├── agents/              # Custom agents\n│   ├── docs-writer.yaml\n│   ├── test-writer.yaml\n│   └── reviewer.yaml\n├── commands/            # Slash commands\n│   ├── commit.yaml\n│   ├── test.yaml\n│   └── deploy.yaml\n├── config.json          # Claude Code settings\n├── context/             # Pre-loaded context\n│   └── architecture.md\n└── prompts/             # Saved prompts\n    └── code-review.md\n</code></pre> <p>Using the Projects Feature</p> <p>Organize work by project:</p> <pre><code># CLI\nclaude-code project create my-app\nclaude-code project switch my-app\n\n# Each project maintains separate:\n# - Conversation history\n# - Context\n# - Agent configurations\n# - Settings\n</code></pre> <p>In VS Code: Use workspaces to separate projects.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#advanced-workflows","level":3,"title":"Advanced Workflows","text":"","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#multi-file-editing","level":4,"title":"Multi-File Editing","text":"<p>Ask Claude to make coordinated changes:</p> <pre><code>You: Rename the User class to Account across the entire codebase,\nincluding imports, tests, and documentation. Make sure everything\nstill works.\n</code></pre> <p>Claude will: 1. Find all occurrences 2. Show proposed changes 3. Apply consistently 4. Update related code 5. Fix broken imports</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#refactoring-large-codebases","level":4,"title":"Refactoring Large Codebases","text":"<p>For major refactors:</p> <pre><code>You: I want to refactor our monolithic app into microservices.\nLet's start by analyzing the current structure and identifying\nservice boundaries.\n</code></pre> <p>Then iteratively: <pre><code>1. Identify services\n2. Define interfaces\n3. Extract first service\n4. Test integration\n5. Repeat for each service\n</code></pre></p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#integration-with-cicd","level":4,"title":"Integration with CI/CD","text":"<p>Add Claude Code to your CI pipeline:</p> <p>.github/workflows/claude-review.yml:</p> <pre><code>name: Claude Code Review\n\non: [pull_request]\n\njobs:\n  review:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Node\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Install Claude Code\n        run: npm install -g @anthropic-ai/claude-code\n\n      - name: Run Code Review\n        env:\n          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}\n        run: |\n          claude-code review \\\n            --files $(git diff --name-only origin/main) \\\n            --output review.md\n\n      - name: Comment on PR\n        uses: actions/github-script@v6\n        with:\n          script: |\n            const fs = require('fs');\n            const review = fs.readFileSync('review.md', 'utf8');\n            github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: review\n            });\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#team-collaboration-patterns","level":4,"title":"Team Collaboration Patterns","text":"<p>Shared Agent Library:</p> <p>Create team-wide agents in a shared repository:</p> <pre><code>company-claude-agents/\n├── agents/\n│   ├── python-tester.yaml\n│   ├── api-docs.yaml\n│   └── security-audit.yaml\n└── commands/\n    ├── deploy-staging.yaml\n    └── create-release.yaml\n</code></pre> <p>Team members clone and symlink:</p> <pre><code>git clone git@github.com:company/claude-agents.git ~/.claude-agents\nln -s ~/.claude-agents/agents .claude/agents\nln -s ~/.claude-agents/commands .claude/commands\n</code></pre> <p>Code Review Guidelines:</p> <p>Establish team standards for AI-assisted development:</p> <pre><code>## Team Guidelines for Claude Code\n\n### Required Reviews\n- All AI-generated code must be reviewed by a human\n- Security-sensitive code requires additional security review\n- Database migrations require team lead approval\n\n### Documentation\n- Add \"Generated with Claude Code\" to commit messages for AI-generated code\n- Document significant AI assistance in PR descriptions\n- Explain any non-obvious AI suggestions\n\n### Testing\n- All AI-generated code must have tests\n- Tests should be human-written or thoroughly reviewed\n- Aim for 80%+ coverage on new code\n\n### Security\n- Never commit API keys or secrets\n- Run security scanners on AI-generated code\n- Review authentication/authorization logic manually\n</code></pre>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#12-next-steps-resources","level":2,"title":"12. Next Steps &amp; Resources","text":"<p>Congratulations! You now have a comprehensive understanding of Claude Code and how to use it effectively in your development workflow.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#related-documentation","level":3,"title":"Related Documentation","text":"<p>Explore these related topics to deepen your understanding:</p> <p> Vibe Coding - Compare Claude Code with other AI coding tools - Understand the vibe coding landscape - Choose the right tool for different scenarios - Security considerations for AI-assisted development</p> <p> Model Context Protocol (MCP) - Connect Claude Code to databases, APIs, and external services - Set up MCP servers for enhanced capabilities - Build custom integrations - Leverage context-aware assistance</p> <p> Agentic AI - Understand the principles behind agentic systems - Learn about autonomous AI behaviors - Explore advanced agent patterns - See how agents transform software development</p> <p> Code Interpreters - Understand code execution fundamentals - Compare sandboxed vs local execution - Security and privacy considerations - Best practices for AI-generated code</p> <p> Jupyter AI - Integrate Claude with Jupyter notebooks - Data science workflows with AI assistance - Interactive development patterns - Research and analysis use cases</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#official-resources","level":3,"title":"Official Resources","text":"<p>Documentation: - Anthropic Documentation - Claude Code Official Docs - API Reference - Model Context Protocol</p> <p>Community: - Anthropic Discord - Active community, get help, share projects - GitHub Discussions - Technical discussions - Anthropic Cookbook - Code examples and tutorials</p> <p>Social Media: - @AnthropicAI on Twitter - Anthropic Blog - Research Papers</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#example-projects","level":3,"title":"Example Projects","text":"<p>Check out these example projects to see Claude Code in action:</p> <ul> <li>Claude Code Starter Templates</li> <li>Anthropic Cookbook Examples</li> <li>Community Projects Showcase (Discord #showcase channel)</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#continuing-your-learning-journey","level":3,"title":"Continuing Your Learning Journey","text":"<p>Week 1-2: Foundation - Complete this tutorial's exercises - Create a simple project with Claude Code - Practice using agents and slash commands - Join the Discord community</p> <p>Week 3-4: Intermediate - Contribute to an open-source project using Claude Code - Create custom agents for your workflow - Set up MCP servers for your tools - Explore integration with CI/CD</p> <p>Month 2: Advanced - Build a complex multi-service application - Create team-shared agent libraries - Develop custom MCP servers - Contribute back to the community</p> <p>Ongoing: - Follow Anthropic's blog for updates - Experiment with new Claude models - Share your experiences and learnings - Help others in the community</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#stay-updated","level":3,"title":"Stay Updated","text":"<p>Claude Code and AI development tools evolve rapidly:</p> <ul> <li>Subscribe to Anthropic Newsletter</li> <li>Watch for Claude Code release notes</li> <li>Follow the #claude-code channel on Discord</li> <li>Check this documentation for updates</li> </ul>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#getting-involved","level":3,"title":"Getting Involved","text":"<p>Share Your Experience: - Write blog posts about your Claude Code workflow - Create video tutorials - Share agents and commands on GitHub - Help others on Discord</p> <p>Provide Feedback: - Report bugs and issues - Suggest new features - Share use cases and success stories - Contribute to documentation</p> <p>Build Extensions: - Create MCP servers for popular tools - Develop Claude Code plugins - Share agent configurations - Build integrations with other tools</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#thank-you","level":3,"title":"Thank You!","text":"<p>Thank you for completing this comprehensive Claude Code tutorial. We hope this guide helps you unlock the full potential of AI-assisted development. Happy coding! 🚀</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude-code/#13-assessment","level":2,"title":"13. Assessment","text":"<p>Test your understanding of Claude Code concepts with these questions:</p> What's the primary difference between Claude Code CLI and the VS Code Extension? Answer <p>Claude Code CLI is a terminal-based tool accessed via command line, best for terminal-first developers and automation workflows. The VS Code Extension integrates directly into VS Code with a visual interface, inline editing, and GUI features, making it better for developers who prefer visual development environments. Both have access to the same Claude models and capabilities, just different interfaces.</p> When should you use <code>/init</code> vs starting a planning session? Answer <p>Use <code>/init</code> when you have an existing codebase and want Claude to analyze and understand the current structure, technologies, patterns, and architecture.</p> <p>Use a planning session when starting from scratch or with a minimal repository, where you want Claude to help design the project structure, choose technologies, and plan the implementation.</p> What is a custom agent in Claude Code? Answer <p>A custom agent is a specialized AI assistant configured with specific instructions, knowledge, and behaviors for particular tasks. Agents differ from regular conversations by having: - Pre-defined domain expertise - Consistent behavior patterns - Reusable configurations - Specialized skills and instructions</p> <p>Examples include documentation writers, code reviewers, test generators, and security auditors.</p> True or False: You should commit your <code>.env</code> file containing API keys to git for your team to access. False <p>Never commit API keys or secrets to version control! API keys should be: - Stored in <code>.env</code> files that are added to <code>.gitignore</code> - Passed via environment variables - Stored securely using secret management tools - Shared with team members through secure channels (not git)</p> <p>Committing secrets to git exposes them to anyone with repository access and makes them nearly impossible to fully remove from git history.</p> Which slash command would you use to stage changes and create a commit with an AI-generated message? <ol> <li><code>/init</code></li> <li><code>/commit</code></li> <li><code>/review</code></li> <li><code>/deploy</code></li> </ol> Correct Answer: 2 <p><code>/commit</code> is the slash command that stages changes, generates an intelligent commit message based on the diff, and creates the commit. The <code>/init</code> command analyzes codebases, <code>/review</code> performs code reviews, and <code>/deploy</code> handles deployment workflows.</p> What is the Model Context Protocol (MCP) used for in Claude Code? Answer <p>Model Context Protocol (MCP) is a standardized communication framework that allows Claude Code to: - Access local file systems and databases - Interact with external APIs and services - Connect to tools like GitHub, PostgreSQL, Slack, etc. - Provide real-time application state awareness - Enable deep integration with development tools</p> <p>MCP enables Claude Code to go beyond conversation and actually interact with your development environment. See our MCP Documentation for more details.</p> True or False: All code generated by Claude Code is guaranteed to be secure and bug-free. False <p>AI-generated code requires careful human review. While Claude Code is sophisticated, it can: - Make mistakes or misunderstand requirements - Suggest outdated or insecure patterns - Miss edge cases or error conditions - Replicate biases from training data</p> <p>Always: - Review all AI-generated code - Run comprehensive tests - Check for security vulnerabilities - Verify against best practices - Use your judgment and expertise</p> Which of the following is a best practice when working with Claude Code? <ol> <li>Share all your production database credentials in prompts for better debugging</li> <li>Commit all generated code immediately without review</li> <li>Use specific, contextual prompts and iterate on solutions</li> <li>Try to include your entire codebase in every conversation</li> </ol> Correct Answer: 3 <p>Using specific, contextual prompts and iterating on solutions is the correct best practice. The other options are problematic: - Never share sensitive credentials in prompts (security risk) - Always review AI-generated code before committing - Focus conversations on relevant files to avoid context limits</p> <p>Effective Claude Code usage involves clear communication, incremental development, and maintaining security awareness.</p>","path":["Tutorials","Claude Code: Setup and Usage Tutorial"],"tags":[]},{"location":"claude/","level":1,"title":"Anthropic Claude","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#ways-to-access-claude","level":2,"title":"Ways to Access Claude","text":"<p>There are multiple ways to access Claude:</p> <p>1. Claude Chat Interface (claude.ai):</p> <ul> <li>Go to: https://claude.ai/</li> <li>Sign up: Create an account using your email address or with a Google account</li> <li>Log in: If you already have an account, log in with your credentials</li> </ul> <p>2. Claude Code (VS Code Extension):</p> <ul> <li>Install: Search for \"Claude Code\" in VS Code Extensions marketplace or visit claude.ai/code</li> <li>Features: AI pair programming, code generation, debugging, and refactoring directly in VS Code</li> <li>Authentication: Requires Anthropic API key or Claude Pro subscription</li> </ul> <p>3. Claude Desktop App:</p> <ul> <li>Download: Available for macOS and Windows at claude.ai/download</li> <li>Features: Native desktop experience with keyboard shortcuts, file handling, and system integration</li> <li>Model Context Protocol: Built-in MCP support for connecting to local tools and services</li> </ul> <p>4. Anthropic API (for Developers):</p> <ul> <li>Sign Up: Go to https://console.anthropic.com/ to create an account</li> <li>API Key: Generate an API key from your console dashboard</li> <li>Documentation: https://docs.anthropic.com/</li> </ul> <p>Treat your API key like a password</p> <p>Do not share it publicly or commit it to version control platforms (like GitHub).</p>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#model-context-protocol-mcp","level":2,"title":"Model Context Protocol (MCP)","text":"<p>The Model Context Protocol is an open standard that enables Claude to interact with external tools and data sources:</p> <p>What is MCP?</p> <ul> <li>Purpose: Allows Claude to connect to databases, APIs, files, and other tools on your computer</li> <li>Security: Runs locally with your explicit permission for each connection</li> <li>Open Standard: Developed by Anthropic and available as open-source</li> </ul> <p>Installing MCP:</p> <ol> <li> <p>For Claude Desktop:</p> </li> <li> <p>MCP support is built into Claude Desktop</p> </li> <li>Configure servers in Settings → Developer → Model Context Protocol</li> <li> <p>Add server configurations in JSON format</p> </li> <li> <p>Example MCP Configuration:</p> </li> </ol> <pre><code>{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/allowed/directory\"]\n    },\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"your-token-here\"\n      }\n    }\n  }\n}\n</code></pre> <ol> <li>Popular MCP Servers:</li> <li>Filesystem: Access local files and directories</li> <li>GitHub: Interact with GitHub repositories</li> <li>PostgreSQL: Query databases</li> <li>Slack: Read Slack messages</li> <li>Google Drive: Access Google Drive files</li> </ol> <p>Learn More: modelcontextprotocol.io</p> <p>Subscription Plans and Pricing</p> <ul> <li>Claude Free: Access to Claude 4.5 Sonnet with usage limits</li> <li>Claude Pro ($20/month):<ul> <li>5x more usage vs free tier</li> <li>Access to Claude 4.5 Opus and Claude 4.5 Haiku</li> <li>Priority access during high-traffic periods</li> <li>Early access to new features</li> </ul> </li> <li>Claude Team ($25/user/month, min 5 users):<ul> <li>Everything in Pro</li> <li>Central billing and administration</li> <li>Team collaboration features</li> </ul> </li> <li>API Pricing (per million tokens, as of January 2026):<ul> <li>Claude 4.5 Sonnet: $3 input / $15 output</li> <li>Claude 4.5 Opus: $15 input / $75 output</li> <li>Claude 4.5 Haiku: $0.25 input / $1.25 output</li> </ul> </li> </ul>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#using-claude","level":2,"title":"Using Claude","text":"<p>Web Chat Interface (claude.ai):</p> <ul> <li>Prompting: Type your requests or questions into the chat box. Be clear and specific in your prompts</li> <li>Conversation History: Claude remembers the context of your conversation within the current chat</li> <li>Projects: Organize chats into projects with custom instructions and shared knowledge</li> <li>Artifacts: Claude can create and edit code, documents, and diagrams in a dedicated panel</li> <li>File Uploads: Upload images, PDFs, and text files (up to 5 files, 10MB each)</li> </ul> <p>Claude Code (VS Code Extension):</p> <ul> <li>Installation: <ol> <li>Open VS Code</li> <li>Go to Extensions (Ctrl/Cmd + Shift + X)</li> <li>Search for \"Claude Code\"</li> <li>Click Install</li> </ol> </li> <li>Features:<ul> <li>Inline code completion</li> <li>Chat interface within VS Code</li> <li>Code explanation and refactoring</li> <li>Multi-file context awareness</li> <li>Terminal command suggestions</li> </ul> </li> </ul> <p>Claude Desktop App:</p> <ul> <li>Installation:<ul> <li>macOS: Download from claude.ai/download and drag to Applications</li> <li>Windows: Download installer and follow setup wizard</li> </ul> </li> <li>Features:<ul> <li>Native OS integration</li> <li>Global keyboard shortcuts</li> <li>MCP server connections</li> <li>Local file access (with permission)</li> <li>Offline viewing of past conversations</li> </ul> </li> </ul> <p>Anthropic API:</p> <ul> <li>Quick Start (Python): <pre><code>from anthropic import Anthropic\n\nclient = Anthropic(api_key=\"your-api-key\")\n\nresponse = client.messages.create(\n    model=\"claude-4-5-sonnet-20260115\",\n    max_tokens=1000,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello, Claude!\"}\n    ]\n)\nprint(response.content[0].text)\n</code></pre></li> <li>SDKs Available: Python, TypeScript/JavaScript, Go, and community SDKs</li> <li>Use Cases: Chatbots, content generation, code assistance, data analysis</li> </ul>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#tips-for-using-claude","level":2,"title":"Tips for Using Claude","text":"<ul> <li>Be Specific: Provide clear instructions and context in your prompts.</li> <li>Iterate: Refine your prompts based on Claude's responses to improve the results.</li> <li>Use System Prompts: For complex or multi-step tasks, consider using system prompts to provide overall instructions to guide Claude's behavior.</li> <li>Experiment: Try different prompting techniques and model settings to find what works best for your use case.</li> </ul>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#about-claude","level":2,"title":"About Claude","text":"<p>Claude is a family of large language models (LLMs) developed by Anthropic, a company focused on AI safety and research. Claude is known for:</p> <ul> <li>Helpful and Honest Responses: Designed with Constitutional AI for safer, more aligned outputs</li> <li>Advanced Reasoning: Excels at complex analysis, math, and multi-step problem-solving</li> <li>Strong Coding Abilities: Excellent for software development, debugging, and code review</li> <li>Large Context Window: Up to 200,000 tokens (approximately 150,000 words or 500 pages)</li> <li>Vision Capabilities: Can analyze images, charts, diagrams, and screenshots</li> </ul>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#claude-model-family","level":2,"title":"Claude Model Family","text":"<p>Latest Models (January 2026):</p> <ul> <li> <p>Claude 4.5 Sonnet:</p> <ul> <li>Most capable balanced model</li> <li>Best for coding, analysis, and creative tasks</li> <li>Excellent performance-to-cost ratio</li> <li>Model ID: <code>claude-4-5-sonnet-20260115</code></li> </ul> </li> <li> <p>Claude 4.5 Opus:</p> <ul> <li>Most capable flagship model</li> <li>Best for complex reasoning and advanced tasks</li> <li>Highest intelligence and capability</li> <li>Model ID: <code>claude-4-5-opus-20251101</code></li> </ul> </li> <li> <p>Claude 4.5 Haiku:</p> <ul> <li>Fast and cost-effective</li> <li>Great for simple tasks and high-volume applications</li> <li>Optimized for speed and efficiency</li> <li>Model ID: <code>claude-4-5-haiku-20260115</code></li> </ul> </li> </ul> <p>Model Selection</p> <p>Claude 4.5 Sonnet is recommended for most use cases as it offers the best combination of capability, speed, and cost. Use Opus for tasks requiring maximum intelligence and reasoning, and Haiku for high-volume, simple tasks.</p>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"claude/#further-resources","level":2,"title":"Further Resources","text":"<ul> <li>Anthropic Website: https://www.anthropic.com/</li> <li>Claude Documentation: https://docs.anthropic.com/</li> <li>API Reference: https://docs.anthropic.com/en/api/</li> <li>Prompt Engineering Guide: https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering</li> <li>Claude Code Documentation: https://docs.anthropic.com/en/docs/claude-code</li> <li>Model Context Protocol: https://modelcontextprotocol.io</li> <li>Anthropic Cookbook: https://github.com/anthropics/anthropic-cookbook</li> <li>Community Discord: https://discord.gg/anthropic</li> </ul> <p>Getting Started Recommendations</p> <ol> <li>Start with the free tier at claude.ai to explore Claude's capabilities</li> <li>For developers, try Claude Code in VS Code for an enhanced coding experience</li> <li>Install Claude Desktop if you want MCP integration and native OS features</li> <li>Experiment with different models to find the right balance of capability and cost for your needs</li> </ol>","path":["Setup","Anthropic Claude"],"tags":[]},{"location":"code/","level":1,"title":"Understanding Code Generation with LLMs","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#introduction-from-generation-to-execution","level":2,"title":"Introduction: From Generation to Execution","text":"<p>Large Language Models (LLMs) have fundamentally changed how we write and interact with code. Beyond simply generating code snippets, modern AI tools can now execute code, analyze data, and produce results in real-time. This capability manifests in multiple forms:</p> <ul> <li>Code Interpreters that operate in secure, sandboxed environments</li> <li>Code Execution Frameworks that integrate directly into your local development environment</li> <li>Agentic AI Systems that can autonomously plan, code, test, and iterate on complex software projects</li> </ul> <p>This evolution from simple code completion to autonomous coding agents represents a paradigm shift in software development. This lesson explores the spectrum of code generation and execution tools, from sandboxed interpreters to sophisticated agentic AI systems that leverage Model Context Protocol (MCP) for deep integration with your development environment.</p> <p>This sets the foundation for understanding \"Vibe Coding\"—the emerging practice of collaborative, conversational development where AI acts as an autonomous pair programmer within your IDE.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#1-code-interpreters-your-sandboxed-ai-analyst","level":2,"title":"1. Code Interpreters: Your Sandboxed AI Analyst","text":"<p>A Code Interpreter is a tool, typically within a chat-based interface, that can write and execute code in a secure, isolated environment. You provide instructions and data in natural language, and the AI handles the coding, execution, and interpretation of results.</p> <p>Key Characteristics:</p> <ul> <li>Sandboxed Execution: Code runs in an isolated environment with no access to your local files or network</li> <li>Data Upload: Upload datasets, documents, or files for analysis</li> <li>Instant Results: See code execution output, visualizations, and analyses in real-time</li> <li>No Setup Required: No need to install programming languages or libraries locally</li> <li>Session-Based: Work is temporary; files and state typically reset between sessions</li> </ul> <p>Ideal Use Cases:</p> <ul> <li>Data Analysis &amp; Visualization: Process datasets and create charts without writing code</li> <li>File Conversions: Transform file formats (CSV to JSON, image format conversions)</li> <li>Mathematical Computations: Solve complex equations and perform statistical analyses</li> <li>Prototyping: Quickly test algorithms or data processing workflows</li> <li>Learning: Experiment with programming concepts in a safe environment</li> </ul> <p>Code Interpreters are perfect for exploratory data analysis, one-off computations, and tasks where you want AI assistance without giving it access to your local system. For deeper integration with your development workflow, see Code Execution Frameworks and Vibe Coding.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#recommended-platforms","level":3,"title":"Recommended Platforms","text":"","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#google-gemini","level":4,"title":"Google Gemini","text":"<p>Platform: gemini.google.com</p> <p>Google's Gemini integrates powerful code interpretation capabilities directly within its chat interface. With its multimodal capabilities, you can:</p> <ul> <li>Upload files (PDFs, spreadsheets, images) and ask for analysis</li> <li>Perform complex data analysis and generate visualizations</li> <li>Solve programming problems with step-by-step explanations</li> <li>Leverage integration with Google Workspace and Google Cloud Platform</li> </ul> <p>Best for: Users in the Google ecosystem, multimodal data analysis, and document processing.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#anthropics-claude","level":4,"title":"Anthropic's Claude","text":"<p>Platform: claude.ai</p> <p>Claude offers robust Code Interpreter functionality through its Artifacts feature, which provides a live preview panel for code execution. Key features include:</p> <ul> <li>Upload documents, spreadsheets, and code files (up to 5 files, 10MB each)</li> <li>Write and execute Python code in a secure sandbox</li> <li>Create interactive data visualizations and charts</li> <li>Generate and iterate on code with real-time execution feedback</li> <li>Extended context window (200K tokens) for analyzing large codebases</li> </ul> <p>Best for: Statistical analysis, data cleaning, document processing, and iterative code development.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#openai-chatgpt-plusteam","level":4,"title":"OpenAI ChatGPT Plus/Team","text":"<p>Platform: chat.openai.com</p> <p>ChatGPT's Advanced Data Analysis (formerly Code Interpreter) is available to Plus and Team subscribers:</p> <ul> <li>Upload and analyze data files in various formats</li> <li>Generate sophisticated visualizations using matplotlib and seaborn</li> <li>Perform file conversions and data transformations</li> <li>Solve mathematical problems with symbolic computation</li> <li>Create animated visualizations and GIFs</li> </ul> <p>Best for: Data science workflows, exploratory data analysis, and creating publication-ready visualizations.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#perplexity-pro","level":4,"title":"Perplexity Pro","text":"<p>Platform: perplexity.ai</p> <p>Perplexity Pro includes code execution capabilities alongside its powerful search features:</p> <ul> <li>Execute Python code in a sandboxed environment</li> <li>Combine web search results with data analysis</li> <li>Generate visualizations based on real-time data</li> <li>Verify calculations and computations with source citations</li> </ul> <p>Best for: Research tasks requiring both web search and data analysis.</p> <p>Data Analysis with a Code Interpreter</p> <p>Imagine you are a researcher with a dataset of student performance metrics. You could upload a CSV to Gemini or Claude and prompt:</p> <pre><code>Analyze the CSV https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv\n\n1.  Load the dataset into a Pandas DataFrame.\n2.  Clean the data by handling any missing values.\n3.  Generate a scatter plot to visualize the relationship between key variables.\n4.  Calculate the Pearson correlation coefficient between these two variables.\n5.  Interpret the results and provide a brief summary.\n</code></pre> <p>The Code Interpreter would then write and run Python code to perform these steps, showing you the code, the output, and the final analysis.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#2-code-execution-frameworks-your-ai-pair-programmer","level":2,"title":"2. Code Execution Frameworks: Your AI Pair Programmer","text":"<p>While sandboxed interpreters are powerful for isolated tasks, the real transformation in software development comes from Code Execution Frameworks—tools that integrate AI assistance directly into your Integrated Development Environment (IDE). These frameworks bridge the gap between simple autocomplete and full agentic AI systems capable of autonomous development.</p> <p>Key Characteristics:</p> <ul> <li>IDE Integration: Work directly within VS Code, JetBrains IDEs, or standalone editors</li> <li>Local Execution: Run code on your machine with access to your file system</li> <li>Multi-File Awareness: Understand context across your entire project</li> <li>Tool Use: Execute terminal commands, run tests, interact with Git</li> <li>Iterative Development: Debug, fix errors, and refine code autonomously</li> <li>Context Protocol Support: Leverage MCP for deep integration with local tools and services</li> </ul> <p>Evolution of Capabilities:</p> <ol> <li>Code Completion (2021-2022): Simple autocomplete and snippet generation</li> <li>Code Generation (2022-2023): Generate functions and classes from descriptions</li> <li>Conversational Coding (2023-2024): Chat-based assistance with code editing</li> <li>Agentic Coding (2024-present): Autonomous multi-file editing, testing, and debugging</li> </ol> <p>These tools form the foundation of Vibe Coding—a fluid, conversational approach to development where AI acts as an autonomous pair programmer, not just a suggestion engine.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#recommended-platforms-tools","level":3,"title":"Recommended Platforms &amp; Tools","text":"<p>The landscape of AI-assisted development tools has exploded, ranging from simple completion tools to sophisticated agentic systems. Below is a categorized overview; see our comprehensive Vibe Coding guide for detailed comparisons and setup instructions.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#desktop-ides-standalone-editors","level":4,"title":"Desktop IDEs &amp; Standalone Editors","text":"<p> Cursor </p> <p>A popular standalone fork of VS Code with powerful agentic features. Cursor excels at multi-file editing, codebase understanding, and autonomous debugging. Uses a flat-fee pricing model with support for multiple LLM providers.</p> <p>Best for: Developers wanting a turnkey solution with stable, production-ready features.</p> <p> Windsurf </p> <p>Standalone editor focused on \"just works\" usability with agentic and inline features. Similar capabilities to Cursor with a different UX philosophy.</p> <p>Best for: Developers who prefer Windsurf's interaction model over Cursor's approach.</p> <p> Claude Desktop </p> <p>Native desktop application with built-in Model Context Protocol (MCP) support. Connect to local filesystem servers, GitHub repositories, databases, and custom tools for context-aware assistance.</p> <p>Best for: Users wanting MCP integration and native OS features without IDE lock-in.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#vs-code-extensions","level":4,"title":"VS Code Extensions","text":"<p> Claude Code </p> <p>Official Anthropic VS Code extension featuring multi-file editing, debugging, and terminal integration. Provides agentic coding capabilities directly in VS Code.</p> <p>Best for: VS Code users wanting official Claude integration with strong agentic features.</p> <p> Cline </p> <p>Open-source, model-agnostic VS Code extension pioneering \"bring your own model\" (BYOM). Supports multiple LLM providers including local models via Ollama.</p> <p>Best for: Users wanting flexibility, open-source transparency, and control over model selection.</p> <p> Roo Code </p> <p>Fork of Cline focused on rapid feature development and customization. Serves users interested in experimental capabilities.</p> <p>Best for: Early adopters wanting cutting-edge features and customization options.</p> <p> GitHub Copilot </p> <p>Microsoft's AI pair programmer with deep GitHub integration. Provides inline completion, chat assistance, and agentic features through Copilot Workspace.</p> <p>Best for: GitHub-centric workflows and organizations with enterprise GitHub licenses.</p> <p> Gemini Code Assist </p> <p>Google's VS Code extension powered by Gemini models, offering code completion, generation, and chat assistance with Google Cloud integration.</p> <p>Best for: Google Cloud Platform users and those in the Google ecosystem.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#command-line-interface-cli-tools","level":4,"title":"Command Line Interface (CLI) Tools","text":"<p> Claude Code CLI </p> <p>Official Anthropic command-line interface enabling AI-assisted development from the terminal with MCP server support.</p> <p>Best for: Terminal-first developers and automation workflows.</p> <p> Aider </p> <p>Popular open-source command-line tool for AI-driven coding. Works with local or remote LLMs and integrates well with Git workflows.</p> <p>Best for: Developers who prefer command-line workflows and want model flexibility.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#browser-based-development","level":4,"title":"Browser-Based Development","text":"<p> Claude Code for Web </p> <p>Browser-based version providing AI pair programming through the web with multi-file editing and debugging capabilities.</p> <p>Best for: Quick coding sessions without local installation or Chromebook users.</p> <p> Firebase IDX </p> <p>Google's cloud-based IDE with built-in Gemini assistance, providing VS Code-like editing experience in the browser.</p> <p>Best for: Cloud-based development with Google Cloud Platform integration.</p> <p> OpenWebUI </p> <p>Self-hostable web interface supporting multiple LLM providers with built-in code execution and function calling.</p> <p>Best for: Self-hosting enthusiasts and teams wanting full control over their AI infrastructure.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#api-console-environments","level":4,"title":"API &amp; Console Environments","text":"<p> Google AI Studio </p> <p>Browser-based environment for experimenting with Gemini models, prototyping prompts, and generating code snippets.</p> <p>Best for: Prototyping with Gemini models and testing prompt strategies.</p> <p> OpenAI Playground </p> <p>Console environment for experimenting with OpenAI models, fine-tuning prompts, and developing code functions.</p> <p>Best for: API developers prototyping with OpenAI models.</p> <p>From Console to IDE: The Vibe Coding Evolution</p> <p>While console-based tools are excellent for prototyping, the real power of AI-assisted development comes from direct IDE integration. Modern tools leverage Model Context Protocol (MCP) to access your local environment, enabling agentic behaviors like:</p> <ul> <li>Autonomous multi-file refactoring</li> <li>Running tests and fixing failures iteratively</li> <li>Executing terminal commands and analyzing output</li> <li>Interacting with Git for version control</li> <li>Accessing databases and external APIs</li> </ul> <p>Explore our Vibe Coding guide to discover how these tools transform your editor into a collaborative coding environment where AI agents work alongside you.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#3-best-practices-ethical-considerations","level":2,"title":"3. Best Practices &amp; Ethical Considerations","text":"<p>Whether using a sandboxed interpreter, a code execution framework, or an agentic AI system, following best practices ensures effective, secure, and responsible use of AI coding tools.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#effective-prompting-strategies","level":3,"title":"Effective Prompting Strategies","text":"<p>Start with Clear Intent - Describe what you want to accomplish, not just how to do it - Provide context about your project, language, and frameworks - Specify constraints (performance, security, compatibility)</p> <p>Break Down Complex Tasks - Don't ask AI to build an entire application in one go - Decompose problems into smaller, testable steps - Let the AI iterate on solutions rather than attempting everything at once - This is especially important for agentic systems that benefit from clear subtask boundaries</p> <p>Provide Rich Context - Share relevant code snippets, error messages, and documentation - Use MCP-enabled tools to automatically provide file and project context - Explain your reasoning and decision-making process - Include examples of desired output or style</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#code-review-verification","level":3,"title":"Code Review &amp; Verification","text":"<p>Never Trust Generated Code Blindly - Always review for correctness, efficiency, and maintainability - Test thoroughly with unit tests, integration tests, and edge cases - Check for security vulnerabilities (SQL injection, XSS, authentication issues) - Verify adherence to your project's coding standards and best practices</p> <p>Understand Before Using - If you don't understand the generated code, ask the AI to explain it - Research unfamiliar libraries or patterns before adopting them - Consider maintainability—will you be able to debug this code in 6 months?</p> <p>Iterative Refinement - Start with a basic implementation and refine iteratively - Test at each stage before adding complexity - Use the AI to help debug and improve, not just generate initially</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#security-considerations","level":3,"title":"Security Considerations","text":"<p>Local Execution Risks</p> <p>Agentic AI systems and vibe coding tools that execute on your machine have significant access:</p> <ul> <li>File System Access: Can read, modify, and delete files</li> <li>Network Access: Can make API calls and external connections</li> <li>Terminal Access: Can execute arbitrary shell commands</li> <li>Environment Variables: May access sensitive credentials</li> </ul> <p>Security Best Practices:</p> <ul> <li>Review commands before AI executes them (most tools prompt for approval)</li> <li>Use project-specific virtual environments</li> <li>Never store secrets in code—use environment variables and secret managers</li> <li>Be cautious with <code>sudo</code> or administrator privileges</li> <li>Monitor AI actions, especially when learning a new tool</li> <li>Follow your institution's security and privacy policies</li> <li>Consider using sandboxed development environments for sensitive work</li> </ul> <p>Institutional Policies Many universities and organizations have policies about AI code execution. Check with your IT security team about:</p> <ul> <li>Approved AI tools and services</li> <li>Data classification restrictions</li> <li>Code review requirements for AI-generated code</li> <li>Network access policies for AI services</li> </ul> <p>See our Vibe Coding security warnings for more detailed guidance.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#bias-licensing-and-intellectual-property","level":3,"title":"Bias, Licensing, and Intellectual Property","text":"<p>Training Data Considerations - AI models are trained on public code repositories, which may contain:   - Biased implementations (non-inclusive variable names, accessibility issues)   - Licensed code that may not be suitable for your use case   - Outdated patterns or deprecated approaches   - Security vulnerabilities from historical code</p> <p>Best Practices: - Review generated code for inclusive language and accessibility - Check license compatibility for suggested libraries - Validate that patterns are current and recommended - Don't assume AI-generated code is \"best practice\"</p> <p>Intellectual Property - Most AI providers claim no copyright on generated output - However, generated code might inadvertently replicate existing licensed code - Your organization may have policies about AI-generated code ownership - Document when and how AI tools were used in development</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#privacy-and-data-handling","level":3,"title":"Privacy and Data Handling","text":"<p>What Data Gets Sent to AI Services? - Your prompts and code snippets - File contents (with MCP or when explicitly shared) - Error messages and terminal output - Project structure and metadata</p> <p>Privacy Best Practices: - Don't share sensitive data, credentials, or personal information in prompts - Review your organization's data classification policies - Use local/self-hosted models for sensitive code when possible - Be aware of data retention policies for AI services you use - Consider anonymizing data before sharing with AI tools</p> <p>Tools with Enhanced Privacy: - Cline and Roo Code: Can use local models via Ollama - Aider: Supports local LLMs - Claude Desktop with MCP: Data processing happens locally before being sent to API</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#accessibility-and-inclusive-development","level":3,"title":"Accessibility and Inclusive Development","text":"<p>Use AI to Improve Accessibility - Ask AI to review code for WCAG compliance - Generate accessible alternatives for visual content - Check color contrast and screen reader compatibility - Implement keyboard navigation</p> <p>Avoid Perpetuating Bias - Review generated variable names and comments for inclusive language - Ask AI to suggest alternatives if you spot problematic patterns - Consider diverse user needs when prompting for UI/UX implementations</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#environmental-considerations","level":3,"title":"Environmental Considerations","text":"<p>AI Compute Costs - LLM inference requires significant energy - Be mindful of unnecessary requests - Use appropriate model sizes (don't use GPT-4 for simple autocomplete) - Cache results when possible - Consider carbon-aware computing practices</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#continuous-learning","level":3,"title":"Continuous Learning","text":"<p>Stay Updated - AI coding tools evolve rapidly - Follow release notes and changelogs - Experiment with new features in safe environments - Join communities and share learnings - Read our Vibe Coding guide regularly for updates</p> <p>Develop AI Literacy - Understand how LLMs work and their limitations - Learn about prompt engineering techniques - Recognize when AI is appropriate vs. when human expertise is needed - Share knowledge with your team</p> <p>The Human-AI Partnership</p> <p>The goal isn't to replace developers with AI—it's to augment human capabilities. The best results come from combining AI's pattern recognition and code generation with human creativity, domain expertise, and critical thinking. Use AI as a powerful tool, but keep your judgment and expertise at the center of development decisions.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#4-choosing-the-right-tool-for-your-workflow","level":2,"title":"4. Choosing the Right Tool for Your Workflow","text":"<p>With dozens of AI coding tools available, selecting the right one depends on your needs, environment, and workflow preferences.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#decision-framework","level":3,"title":"Decision Framework","text":"<pre><code>flowchart TD\n    Start[What's your primary use case?] --&gt; DataAnalysis{Data Analysis&lt;br/&gt;One-off Tasks?}\n    Start --&gt; Development{Software&lt;br/&gt;Development?}\n\n    DataAnalysis --&gt;|Yes| Sandboxed[Use Code Interpreters]\n    Sandboxed --&gt; SandboxChoice[Claude, Gemini, ChatGPT Plus]\n\n    Development --&gt;|Yes| IDE{Prefer IDE&lt;br/&gt;Integration?}\n\n    IDE --&gt;|VS Code| VSCodeTools{Open Source&lt;br/&gt;or Official?}\n    VSCodeTools --&gt;|Official| ClaudeCode[Claude Code Extension]\n    VSCodeTools --&gt;|Open Source| ClineRoo[Cline or Roo Code]\n    VSCodeTools --&gt;|Enterprise| Copilot[GitHub Copilot]\n\n    IDE --&gt;|Standalone| Standalone{Budget&lt;br/&gt;Preference?}\n    Standalone --&gt;|Flat Fee| Cursor[Cursor or Windsurf]\n    Standalone --&gt;|Pay-as-you-go| ClaudeDesktop[Claude Desktop + MCP]\n\n    IDE --&gt;|Terminal/CLI| CLI[Claude Code CLI or Aider]\n\n    IDE --&gt;|Browser| Browser[Claude Code Web, Firebase IDX]\n\n    style Sandboxed fill:#e1f5ff\n    style ClaudeCode fill:#c8e6c9\n    style ClineRoo fill:#c8e6c9\n    style Cursor fill:#c8e6c9\n    style CLI fill:#c8e6c9</code></pre>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#by-use-case","level":3,"title":"By Use Case","text":"<p>Exploratory Data Analysis → Code Interpreters: Claude, Gemini, ChatGPT Plus</p> <p>Learning to Code → Code Interpreters or Browser-Based Tools</p> <p>Professional Software Development → Agentic IDE Tools: Cursor, Windsurf, Claude Code, Cline</p> <p>Need MCP Integration → Claude Desktop or Claude Code CLI</p> <p>Enterprise/Team Development → GitHub Copilot or Cursor Team</p> <p>Privacy-Sensitive Projects → Cline or Aider with local models</p> <p>Multi-Language Projects → Claude Code or Cursor (excellent multi-language support)</p> <p>Terminal-First Workflow → Aider or Claude Code CLI</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#integration-with-your-workflow","level":3,"title":"Integration with Your Workflow","text":"<p>For Researchers: - Start with Code Interpreters for data analysis - Progress to Claude Desktop with MCP for accessing research databases - Use Vibe Coding tools for reproducible research code</p> <p>For Students: - Begin with sandboxed interpreters to learn safely - Experiment with browser-based tools for homework - Transition to IDE extensions as skills develop</p> <p>For Professional Developers: - Choose agentic tools based on your IDE preference - Leverage MCP for project-specific integrations - Follow security best practices rigorously</p> <p>For Teams: - Standardize on enterprise tools with centralized billing - Establish code review processes for AI-generated code - Document policies on AI tool usage and data sharing</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#5-the-path-forward-vibe-coding-and-beyond","level":2,"title":"5. The Path Forward: Vibe Coding and Beyond","text":"<p>This lesson introduced the landscape of AI-powered code generation and execution. You've learned about:</p> <ul> <li>Code Interpreters for safe, sandboxed analysis</li> <li>Code Execution Frameworks for IDE integration</li> <li>Best practices for security, privacy, and responsible use</li> <li>Tool selection based on your needs</li> </ul>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#next-steps","level":3,"title":"Next Steps","text":"<p>Ready to Start Vibe Coding?</p> <p>Now that you understand the foundations, dive deeper into hands-on AI-assisted development:</p> <p> Explore Vibe Coding Learn how to set up and use modern agentic coding tools in your preferred development environment.</p> <p> Understand Model Context Protocol (MCP) Discover how MCP enables deep integration between AI and your development tools, enabling sophisticated agentic behaviors.</p> <p> Learn About Agentic AI Understand the principles behind autonomous AI systems and how they're transforming software development.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#recommended-learning-path","level":3,"title":"Recommended Learning Path","text":"<ol> <li>Experiment with Code Interpreters (30 minutes)</li> <li>Try Claude, Gemini, or ChatGPT Plus</li> <li>Upload a dataset and perform analysis</li> <li> <p>Get comfortable with natural language coding</p> </li> <li> <p>Install a Vibe Coding Tool (1 hour)</p> </li> <li>Follow our Vibe Coding setup guide</li> <li>Start with Claude Code or Cursor</li> <li> <p>Try basic code generation and editing</p> </li> <li> <p>Explore MCP Integration (1-2 hours)</p> </li> <li>Set up Claude Desktop with MCP</li> <li>Connect to filesystem and GitHub servers</li> <li> <p>Experience context-aware assistance</p> </li> <li> <p>Practice Best Practices (Ongoing)</p> </li> <li>Review all AI-generated code</li> <li>Develop your prompting skills</li> <li> <p>Learn from successes and failures</p> </li> <li> <p>Build Real Projects (Weeks to months)</p> </li> <li>Apply AI assistance to actual work</li> <li>Develop your AI collaboration style</li> <li>Share learnings with your community</li> </ol>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#staying-current","level":3,"title":"Staying Current","text":"<p>The AI coding landscape evolves rapidly. Stay informed:</p> <ul> <li>Follow tool announcements and changelogs</li> <li>Join developer communities (Discord, Reddit, forums)</li> <li>Experiment with new features in safe environments</li> <li>Read our Vibe Coding guide for regular updates</li> <li>Check MCP documentation for new server integrations</li> </ul>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"code/#assessment","level":2,"title":"Assessment","text":"What is the primary difference between a sandboxed Code Interpreter (like in ChatGPT) and a Code Execution Framework (like GitHub Copilot in VS Code)? Answer <p>A sandboxed Code Interpreter runs code in a secure, isolated environment provided by the service, disconnected from your local machine. A Code Execution Framework integrates into your local IDE and can read, modify, and execute files directly on your computer.</p> True or False: Code generated by an AI assistant is guaranteed to be secure and free of errors. False <p>AI-generated code can contain bugs, security vulnerabilities, and biases from its training data. It is crucial to always review, test, and validate any code before using it in a production environment.</p> Which of the following tasks is best suited for a sandboxed Code Interpreter? <ol> <li>Refactoring a large, existing codebase in your project.</li> <li>Quickly analyzing a CSV file you upload to generate a plot.</li> <li>Building and running a web server on your local machine.</li> <li>Continuously providing autocompletions as you type in your IDE.</li> </ol> Correct Answer: 2 <p>Sandboxed interpreters excel at self-contained tasks involving data you can upload, like analyzing a file. The other tasks are better suited for AI tools integrated directly into a local IDE.</p> True or False: Using an open-source Code Execution Framework like Cline or Aider allows you to use locally-run LLMs (e.g., via Ollama) instead of relying on cloud-based APIs. True <p>One of the key advantages of many open-source tools is flexibility. They often allow you to connect to various LLM backends, including models running on your own hardware, giving you more control over privacy and cost.</p> Which technology enables AI agents to access your local file system, run terminal commands, and interact with external tools? <ol> <li>Code Interpreters</li> <li>Model Context Protocol (MCP)</li> <li>Function calling</li> <li>Extended context windows</li> </ol> Correct Answer: 2 <p>Model Context Protocol (MCP) is the standardized communication framework that allows AI agents to interact with local tools, file systems, databases, and external services. While function calling is related, MCP provides the comprehensive protocol for deep integration.</p> What is the main security concern when using agentic AI systems that execute code locally? Answer <p>Agentic AI systems with local execution have access to your file system, network, terminal, and environment variables. They can read, modify, or delete files, execute arbitrary commands, and potentially access sensitive credentials. Always review commands before execution, follow your organization's security policies, and avoid storing secrets in code.</p> Which workflow would be BEST suited for a sandboxed Code Interpreter rather than an agentic IDE tool? <ol> <li>Refactoring a large codebase with coordinated changes across multiple files</li> <li>Analyzing a CSV dataset you upload to generate statistical plots</li> <li>Setting up automated testing and CI/CD for a project</li> <li>Debugging a complex application with multiple service dependencies</li> </ol> Correct Answer: 2 <p>Sandboxed Code Interpreters excel at self-contained tasks with uploaded data, like analyzing a dataset. The other tasks require multi-file awareness, local tool integration, and persistent development workflows—all better suited for agentic IDE tools.</p> True or False: AI-generated code should always be considered \"best practice\" since models are trained on vast amounts of code from expert developers. False <p>AI models are trained on public code repositories that may contain outdated patterns, security vulnerabilities, biased implementations, and code that violates best practices. Always review AI-generated code critically, test thoroughly, and verify it meets current standards and your specific requirements.</p>","path":["Prompt Engineering","Understanding Code Generation with LLMs"],"tags":[]},{"location":"copilot/","level":1,"title":"GitHub Copilot","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Setup","GitHub Copilot"],"tags":[]},{"location":"copilot/#create-a-github-account","level":2,"title":"Create a GitHub Account","text":"<ul> <li> <p>GitHub Account: You need a GitHub account to use GitHub Copilot. Sign up here</p> </li> <li> <p>GitHub Education As a university faculty or staff, you can enroll as an educator through GitHub's Education space. As a student, you can also get access to GitHub features, like Codespaces and Classroom.</p> </li> <li> <p>Supported IDE: You'll need a compatible IDE. Currently, the most popular supported IDEs are:</p> <ul> <li>Visual Studio Code (VS Code)</li> <li>Neovim</li> <li>JetBrains IDEs (IntelliJ IDEA, PyCharm, WebStorm, etc.)</li> <li>Visual Studio</li> </ul> </li> <li>GitHub Copilot Subscription: GitHub Copilot is a paid service. You'll need an active subscription to use it. There are plans for individuals and businesses. There is a limited free trial so you can try it out. GitHub Copilot is free for verified students and maintainers of popular open source projects on GitHub.</li> </ul>","path":["Setup","GitHub Copilot"],"tags":[]},{"location":"copilot/#installation-and-setup","level":2,"title":"Installation and Setup","text":"<p>The installation process varies slightly depending on your IDE. Here's a general overview:</p> <p>Visual Studio Code (VS Code):</p> <ul> <li> <p>Install the Extension:</p> <ol> <li> <p>Open VS Code on your local or virtual machine.</p> </li> <li> <p>Go to the Extensions Marketplace (click the Extensions icon in the Activity Bar on the side of the window or press <code>Ctrl+Shift+X</code> / <code>Cmd+Shift+X</code>).</p> </li> <li> <p>Search for \"GitHub Copilot\".</p> </li> <li> <p>Click \"Install\" on the official GitHub Copilot extension.</p> </li> </ol> </li> <li> <p>Sign in to GitHub:</p> <ul> <li>You'll be prompted to sign in to GitHub to authorize the extension. Follow the on-screen instructions.</li> </ul> </li> </ul> <p>Visual Studio:</p> <ul> <li> <p>Install the Extension:</p> <p>Open Visual Studio.</p> <p>Go to <code>Extensions</code> &gt; <code>Manage Extensions</code>.</p> <p>Search for \"GitHub Copilot\" in the online tab.</p> <p>Click \"Download\" and follow the prompts to install it. Restart Visual Studio when done.</p> </li> <li> <p>Sign in to GitHub: You will need to sign in to your GitHub account to authorize the extension.</p> </li> </ul>","path":["Setup","GitHub Copilot"],"tags":[]},{"location":"daily-productivity/","level":1,"title":"General Productivity","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p></p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#when-to-use-a-gpt","level":2,"title":"When to use a GPT","text":"<p>Prompt engineering can significantly enhance your productivity. In particular when Enterprise GPTs are integrated into your Microsoft Office Suite or Google Drive, and have secure access to your documents and data, GPTs can be used to:</p> <ul> <li>Draft Emails and manage inboxes: Automate the creation of routine emails, summarize long email threads, and even prioritize your inbox based on sender and content.</li> <li>Meeting Summarization: Quickly get the gist of meeting transcripts, identify action items, and track decisions made.</li> <li>Task Prioritization and Planning: Organize tasks based on urgency and importance, create daily or weekly schedules, and set reminders.</li> <li>Content Creation and Brainstorming: Generate ideas for articles, blog posts, social media content, and marketing campaigns.</li> <li>Language Translation: Translate documents or conversations in real-time, facilitating communication with international colleagues or clients.</li> <li>Learning and Skill Development: Get quick explanations of complex topics, find learning resources, and even practice new skills through simulated scenarios.</li> </ul> <p>In our  Code Interpreter lesson we discuss how GPTs can be used for:</p> <ul> <li>Code Generation and Debugging: Write basic code snippets, find and fix bugs in existing code, and understand complex code segments.</li> <li>Data Analysis and Interpretation: Summarize datasets, identify trends, and generate reports from raw data.</li> </ul> <p>Below are your updated tables. Only the rows below each table have changed; the headers and previously listed rows are untouched.</p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#meeting-summary","level":2,"title":"Meeting Summary","text":"<p> AI Companion, along with other AI-powered meeting summary tools, can significantly boost productivity by automating note-taking and extracting key information from meetings. To effectively use these tools, it's important to understand best practices and institutional policies.</p> <p>Getting Started and Optimizing Use</p> <p>Begin by ensuring that the AI Companion feature is enabled in your Zoom settings. You can customize settings, such as choosing between brief and detailed summaries or specifying keywords for emphasis. </p> <p>Before meetings, set clear agendas to provide context for the AI. </p> <p>During the meeting, speak clearly, emphasize important terms, and encourage active participation to enrich the AI's analysis. </p> <p>While in a meeting you can ask the AI Companion for a summary or specific details, for example, \"Has a decision been made about X?\". </p> <p>After a meeting ends, Zoom will send an email summary to the host, which can be edited and shared with participants. </p> <p>Zoom can also highlight key parts of the meeting recording, or break down the recording into smart chapters.</p> <p>Institutional Policies and Data Security</p> <p>It's crucial to adhere to institutional policies regarding the use of AI tools in official communications. </p> <p>Only use approved plug-ins such as Zoom AI Companion. </p> <p>Third-party software may not comply with the university's data security and privacy requirements. </p> <p>Using unapproved third-party AI tools can pose significant risks. </p> <p>Unofficial tools may Compromise Data Security -- they may store or process meeting data on external servers without adequate security measures, potentially exposing sensitive information to breaches. </p> <p>Violate Data Privacy -- they might not adhere to data privacy regulations or institutional policies regarding the handling of personal and confidential data, such as student FERPA.</p> <p>Lack of Accountability: The university may have limited recourse or control over third-party vendors in case of data breaches or misuse.</p> <p>Integration Issues: 3<sup>rd</sup> party plug-ins may not integrate seamlessly with existing university systems, leading to inefficiencies and compatibility problems.</p> <p>Therefore, to maintain data security, privacy, and compliance with institutional policies, it is essential to use only officially sanctioned AI tools and plug-ins provided or approved by the university for official communication. Always consult your institution's IT department or relevant policies for guidance on approved tools and their proper usage.</p> <p> ChatGPT integrations</p> <p>Plus and Pro versions of ChatGPT have integrations with  Microsoft OneDrive and  Google Drive which allow you to add documents to Prompts using <code>4o</code> or <code>o1</code> models. </p> <p>Make certain these integrations meet University security requirements</p> <p>Never submit student information, private conversations (Zoom AI Summaries), or other sensitive information through ChatGPT unless using a University of Arizona Enterprise license.</p> <p> Microsoft Copilot integration in Microsoft Office 365</p> <p>University of Arizona officially uses Microsoft Office Online for office productivity. This includes integration with Microsoft Copilot into Office 365. </p> <p>Microsoft is currently rolling out new features for Copilot through its new https://m365.cloud.microsoft/ domain.</p> <p>Access to these new features may be limited by your department or UITS. If you want access to these features, contact your department's system administrator. </p> <p> Google Gemini integration in Google Workspaces</p> <p>University of Arizona continues to have access to Google Workspace, but may be limited by your department or UITS.</p> <p>Google for Education also has integration with Gemini, which needs to be authorized by a system administrator. </p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#chat-use-cases","level":2,"title":"Chat Use Cases","text":"","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#example-1-personal-planner","level":3,"title":"Example 1: Personal Planner","text":"<p>Suppose you're using a GPT as a personal planner. </p> <p>Note: ChatGPT and Copilot lack access to my University Outlook or Google Calendars, but Gemini has access to my personal calender.</p> <p>This prompt involves three tasks: retrieving data, creating an itinerary, and arranging tasks based on priority.</p> Planning your day PromptCoPilot ResponseChatGPT o1 ResponseGemini Advanced Response <pre><code>I need your help planning my day tomorrow.\nFirst, please list all my scheduled meetings and deadlines from my calendar.\nThen, taking into account 2 hours of break time, could you suggest a time-managed itinerary for me?\nLastly, based on the priority of the tasks, can you create a task list in the order I should tackle them?\n</code></pre> <p>I'd be happy to help you plan your day! However, I don't have direct access to your calendar.  If you could provide me with the details of your scheduled meetings and deadlines,  I can assist you in creating a well-organized itinerary and task list.</p> <p>Could you share your schedule for tomorrow?</p> <p>I’m afraid I don’t have direct access to your personal calendar.  If you could provide the details of your scheduled meetings and deadlines (for example, what time they start/end, what they’re for, etc.),  I can certainly help you organize a time-managed itinerary—ensuring 2 hours of break time—and then create a prioritized task list.</p> <p>Please share whatever information you’re comfortable with, and I’ll get started right away.</p> <p>You have 4 events next week. I cannot create a time-managed itinerary for you, but you can do it yourself by taking into account 2 hours of break time.</p> <p>Here are your events:</p> <p>Monday, January 6<sup>th</sup></p> <p>\"Ecology discussion\" from 11:00 AM to 12:30 PM</p> <p>\"CiCompass: Cloud Infrastructure WG Bi-weekly meetings\" from 1:00 PM to 2:00 PM</p> <p>Tuesday, January 7<sup>th</sup></p> <p>\"ESIIL CI Tribal\" from 12:30 PM to 1:30 PM</p> <p>Wednesday, January 8<sup>th</sup></p> <p>\"ESIIL Exec Meeting biweekly\" from 9:30 AM to 10:30 AM</p> <p>Would you like me to help you with anything else?</p> <p>Sources and related content</p> <p>Assuming you have integration with your calendar, you might use the GPT to manage your schedule as follows:</p> Managing Calendar PromptCopilot ResponseChatGPT o1 ResponseGemini Advanced Response <pre><code>can you schedule a team meeting for next Tuesday at 3 PM in my calendar? \n\nAlso, set a reminder for me to prepare the meeting agenda by Monday afternoon.\n</code></pre> <p>Does not have access to my calendar -- yet.</p> <p>Does not have access to my calendar -- yet.</p> <p>OK, I'm putting this on your calendar for next Tuesday at 3:00 PM and creating a reminder for you to prepare the meeting agenda by Monday afternoon.</p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#example-2-content-creation","level":3,"title":"Example 2: Content Creation","text":"<p>Blog Post Creation</p> <p>This prompt includes three tasks: generating topics, creating outlines, and writing introduction paragraphs.</p> <p>Note, these are very long responses:</p> Blog post creation PromptCoPilot ResponseChatGPT o1 ResponseGemini Advanced w/ Deep Research Response <pre><code>I'd like to write a blog post about sustainable living.\nFirst, could you generate a list of five key topics that I should cover?\nOnce we have the topics, can you then provide a brief outline for each of them?\nFinally, for each of the outlines, could you come up with an engaging introduction paragraph?\n</code></pre> <p>That sounds like a fantastic idea! Here are five key topics you could cover in your blog post about sustainable living:</p> <ol> <li>Reducing Waste</li> <li>Energy Efficiency</li> <li>Sustainable Transportation</li> <li>Eco-Friendly Diet</li> <li>Green Home Practices</li> </ol> <p>Brief Outlines</p> <p>1. Reducing Waste - Introduction: Importance of waste reduction - Body: - Benefits of reducing waste - Practical tips for reducing waste at home - Recycling and composting - Reducing single-use plastics - Conclusion: Encouragement to adopt waste reduction habits</p> <p>2. Energy Efficiency - Introduction: The role of energy efficiency in sustainability - Body: - Benefits of energy efficiency - Tips for improving energy efficiency at home - Energy-efficient appliances and technologies - Renewable energy sources - Conclusion: Call to action for adopting energy-efficient practices</p> <p>3. Sustainable Transportation - Introduction: Impact of transportation on the environment - Body: - Benefits of sustainable transportation - Different modes of sustainable transportation (e.g., biking, public transit, electric vehicles) - Tips for reducing your transportation footprint - Policy and infrastructure changes needed - Conclusion: Encouragement to choose sustainable transportation options</p> <p>4. Eco-Friendly Diet - Introduction: Connection between diet and sustainability - Body: - Benefits of an eco-friendly diet - Tips for adopting a plant-based diet - Reducing food waste - Supporting local and organic food producers - Conclusion: Motivation to make sustainable food choices</p> <p>5. Green Home Practices - Introduction: Importance of sustainable living spaces - Body: - Benefits of green home practices - Tips for creating a green home (e.g., water conservation, sustainable materials) - Indoor plants and air quality - DIY eco-friendly home projects - Conclusion: Encouragement to implement green practices at home</p> <p>Engaging Introduction Paragraphs</p> <p>1. Reducing Waste</p> <p>In a world where waste is piling up at an alarming rate, taking steps to reduce our waste footprint has never been more crucial. By making small changes in our daily habits, we can significantly impact the environment and pave the way for a cleaner, greener future. Let's explore how we can all contribute to reducing waste and making a difference.</p> <p>2. Energy Efficiency</p> <p>Energy efficiency is more than just a buzzword; it's a vital component of sustainable living. By optimizing our energy use, we can reduce our carbon footprint, save money, and contribute to a healthier planet. Join me as we delve into practical ways to enhance energy efficiency in our homes and lives.</p> <p>3. Sustainable Transportation</p> <p>Transportation is a major contributor to greenhouse gas emissions, but it doesn't have to be. Embracing sustainable transportation options can lead to a cleaner environment and a healthier lifestyle. Let's take a journey through the various ways we can make our commutes and travels more eco-friendly.</p> <p>4. Eco-Friendly Diet</p> <p>What we eat has a profound impact on the planet. Adopting an eco-friendly diet not only benefits our health but also supports the environment. From plant-based meals to reducing food waste, discover how our dietary choices can lead to a more sustainable world.</p> <p>5. Green Home Practices</p> <p>Our homes are our sanctuaries, and making them sustainable can have a lasting positive impact on the environment. From water conservation to using sustainable materials, there are countless ways to create a green home. Let's explore practical tips and ideas to transform our living spaces into eco-friendly havens.</p> <p>I hope these topics, outlines, and introductions help you get started on your blog post! If you need further assistance or more details on any of these points, feel free to ask.</p> <p>Sure! Here’s a structured way we can approach it:</p> <p>1. Energy Efficiency and Renewable Energy</p> <p>Brief Outline</p> <ol> <li>Understanding Your Energy Footprint </li> <li>Why it matters and how to measure it  </li> <li> <p>Tools for monitoring home energy usage</p> </li> <li> <p>Practical Home Efficiency Tips </p> </li> <li>Insulation and sealing windows/doors  </li> <li> <p>Energy-efficient appliances and LED lighting</p> </li> <li> <p>Transitioning to Renewable Energy </p> </li> <li>Solar panel installations and community solar options  </li> <li> <p>Wind energy and other emerging technologies</p> </li> <li> <p>Behavioral Changes for Lower Energy Consumption </p> </li> <li>Turning off and unplugging electronics  </li> <li> <p>Smart use of heating and cooling systems</p> </li> <li> <p>Long-Term Benefits </p> </li> <li>Financial savings and return on investment  </li> <li>Positive environmental impact</li> </ol> <p>Introduction Paragraph</p> <p>Ever wonder how much power your home truly consumes—and how you could use less without sacrificing comfort? Energy efficiency and renewable energy sources lie at the core of sustainable living. By understanding your energy footprint and making thoughtful improvements—like sealing drafts, installing solar panels, or simply turning off unnecessary electronics—you can lower both your monthly bills and your impact on the planet. This shift toward clean energy isn’t just beneficial for the environment; it can significantly enhance your quality of life in the long run.</p> <p>2. Sustainable Transportation</p> <p>Brief Outline</p> <ol> <li>The Impact of Transportation on Carbon Emissions </li> <li>Global transport emissions data  </li> <li> <p>How personal choices contribute to the bigger picture</p> </li> <li> <p>Alternatives to Driving Alone </p> </li> <li>Public transportation, carpooling, and ride-sharing  </li> <li> <p>Tips for planning routes and schedules efficiently</p> </li> <li> <p>Embracing Eco-Friendly Modes of Travel </p> </li> <li>Biking, walking, and using e-scooters or e-bikes  </li> <li> <p>Benefits for physical health and mental well-being</p> </li> <li> <p>Electric and Hybrid Vehicles </p> </li> <li>Comparing electric, hybrid, and conventional cars  </li> <li> <p>Factors to consider (range, charging stations, cost)</p> </li> <li> <p>Influencing Policy and Community Action </p> </li> <li>The role of local governments in promoting green transportation  </li> <li>Community advocacy and infrastructure improvements</li> </ol> <p>Introduction Paragraph</p> <p>Getting from A to B is a necessary part of daily life, but how we choose to do it can have a big impact on our planet. Whether it’s taking the bus instead of driving alone, riding a bike to work, or investing in an electric car, there are plenty of ways to keep our carbon footprints in check. In this section, we’ll explore how sustainable transportation choices not only help the environment but also save money and contribute to healthier, happier communities.</p> <p>3. Waste Reduction and Recycling</p> <p>Brief Outline</p> <ol> <li>The Global Waste Problem </li> <li>Current statistics on waste generation  </li> <li> <p>Consequences of landfills, incineration, and pollution</p> </li> <li> <p>Strategies for Reducing Waste at Home </p> </li> <li>Embracing reusable items and buying in bulk  </li> <li> <p>DIY or zero-waste swaps (e.g., bamboo toothbrushes, refillable containers)</p> </li> <li> <p>Understanding Recycling and Composting </p> </li> <li>Sorting household recyclables correctly  </li> <li> <p>Composting organic waste to close the nutrient loop</p> </li> <li> <p>Upcycling and Repurposing </p> </li> <li>Creative ways to extend the life of everyday products  </li> <li> <p>Inspirations for DIY crafts and home projects</p> </li> <li> <p>Community Engagement and Policy </p> </li> <li>Supporting local recycling programs  </li> <li>Advocating for better waste management systems</li> </ol> <p>Introduction Paragraph</p> <p>Do you ever stop to think about where your trash goes after it leaves the curb? Our world is grappling with staggering amounts of waste, and it’s more important than ever to consider how we can lighten that load. By making small but impactful changes—like switching to reusable products, sorting recyclables properly, and composting food scraps—we can all play a part in cutting down on needless waste. It’s time to transform our throwaway culture into one that values resources, creativity, and the planet’s well-being.</p> <p>4. Ethical and Sustainable Consumption</p> <p>Brief Outline</p> <ol> <li>The True Cost of Consumer Goods </li> <li>Environmental and social impacts of production  </li> <li> <p>Importance of fair labor practices and supply chain transparency</p> </li> <li> <p>Buying Less, Choosing Well </p> </li> <li>Minimalism and conscious consumerism  </li> <li> <p>Quality over quantity: investing in durable items</p> </li> <li> <p>Supporting Eco-Friendly Brands </p> </li> <li>Certifications (e.g., Fair Trade, Rainforest Alliance)  </li> <li> <p>Researching brand values and corporate responsibility</p> </li> <li> <p>Secondhand and Thrift Shopping </p> </li> <li>Extending product lifespans by purchasing used items  </li> <li> <p>Tips for finding high-quality goods at thrift stores</p> </li> <li> <p>The Role of Community in Ethical Consumption </p> </li> <li>Sharing, borrowing, and community swap events  </li> <li>Local artisans and farmers’ markets</li> </ol> <p>Introduction Paragraph</p> <p>When we swipe our credit cards or add items to our online carts, it’s easy to forget the journey each product took to reach us. From raw materials to human labor, every purchase carries hidden environmental and social costs. By choosing to consume less and shop more ethically—whether it’s supporting fair trade coffee growers or opting for secondhand clothes—we can make a difference that extends far beyond our personal wardrobes or pantries. Let’s explore why mindful consumption is key to a more sustainable future.</p> <p>5. Sustainable Food Choices</p> <p>Brief Outline</p> <ol> <li>Understanding Food Systems </li> <li>The environmental impact of industrial agriculture  </li> <li> <p>Water use, greenhouse gas emissions, and biodiversity loss</p> </li> <li> <p>Eating Locally and Seasonally </p> </li> <li>Benefits of buying from local farmers  </li> <li> <p>How to plan meals around seasonal produce</p> </li> <li> <p>Plant-Based Diets and Reduced Meat Consumption </p> </li> <li>Health and environmental benefits of eating more plants  </li> <li> <p>Tips for transitioning gradually and finding balance</p> </li> <li> <p>Food Waste Reduction </p> </li> <li>Proper storage and meal planning  </li> <li> <p>Creative recipes using leftovers</p> </li> <li> <p>Growing Your Own Food </p> </li> <li>Container gardening and community gardens  </li> <li>The satisfaction and health benefits of homegrown produce</li> </ol> <p>Introduction Paragraph</p> <p>Have you ever wondered how the food on your plate gets there, or what it takes to produce it? Our dietary choices have significant ripple effects on the health of our bodies, our communities, and our planet. From selecting fresh, locally sourced ingredients to cutting back on food waste, there are many ways we can align our eating habits with a more sustainable lifestyle. Join us as we delve into practical tips for making mindful food choices that benefit both you and the environment.</p> <p>Feel free to mix, match, and expand on these topics as needed. Each outline gives you a structured path for writing an in-depth blog post or even a series of blog posts on sustainable living. Good luck with your writing!</p> <p>View response in Gemini</p> <p>View response Document on Google Drive</p> <p>Sustainable Living: A Beginner's Guide</p> <p>This guide is a culmination of research on various aspects of sustainable living, from reducing our carbon footprint to building sustainable communities. In today's world, it's more important than ever to be mindful of our impact on the planet. Sustainable living is a lifestyle that attempts to reduce an individual's or society's use of the Earth's natural resources. It is about living in a way that meets the needs of the present without compromising the ability of future generations to meet their own needs. But the benefits of sustainable living extend far beyond environmental impact. By embracing sustainable practices, we can also improve our health and well-being, reduce our living costs, and increase our self-sufficiency. This blog post will explore five key topics related to sustainable living, providing practical tips and insights to help you embark on your own journey towards a more eco-conscious lifestyle.</p> <p>Reducing Your Carbon Footprint</p> <p>Our carbon footprint is the total amount of greenhouse gases generated by our actions. This includes emissions from transportation, energy consumption, and the food we eat. By making conscious choices in these areas, we can significantly reduce our impact on the environment.</p> <p>Transportation</p> <p>Transportation is a major contributor to greenhouse gas emissions. Here are some ways to reduce your carbon footprint related to transportation:</p> <ul> <li>Use public transportation: Whenever possible, opt for public transportation such as buses, trains, or subways instead of driving your own car. Imagine the impact if everyone in your neighborhood took the bus just once a week!</li> <li>Bike or walk: For shorter distances, consider biking or walking. This is not only good for the environment but also for your health. Not only will you reduce your carbon footprint, but you'll also get some exercise and fresh air.</li> <li>Carpool: If you need to drive, try carpooling with colleagues or friends to reduce the number of cars on the road. Sharing rides is a great way to connect with others and reduce your environmental impact.</li> <li>Choose fuel-efficient vehicles: When purchasing a new car, consider fuel-efficient options such as hybrid or electric vehicles. These vehicles use less fuel and produce fewer emissions, saving you money and reducing your impact on the planet.</li> </ul> <p>Energy Consumption</p> <p>Our homes consume a significant amount of energy. Here are some tips for reducing your energy consumption at home:</p> <ul> <li>Use energy-efficient appliances: When purchasing new appliances, look for those with high energy-efficiency ratings. These appliances use less energy, which can save you money on your utility bills.</li> <li>Switch to renewable energy sources: Consider installing solar panels or switching to a green energy provider for your electricity. Solar panels can provide clean energy for your home, while green energy providers offer electricity generated from renewable sources like wind and solar power.</li> <li>Reduce your heating and cooling needs: Proper insulation, energy-efficient windows, and smart thermostats can help regulate the temperature in your home and reduce energy consumption. Imagine a cozy winter evening with less reliance on your heating system!</li> <li>Unplug electronics when not in use: Even when turned off, many electronics continue to draw power. Unplug them or use a power strip that can be switched off. This simple habit can make a surprising difference in your energy consumption.</li> </ul> <p>Food Choices</p> <p>The food we eat also has a carbon footprint. Here are some tips for reducing your carbon footprint related to food choices:</p> <ul> <li>Eat less meat: Meat production is a significant contributor to greenhouse gas emissions. Consider reducing your meat consumption or adopting a plant-based diet. Did you know that producing one pound of beef requires significantly more water and land than producing one pound of plant-based protein?</li> <li>Choose local and seasonal foods: Transporting food over long distances generates emissions. Choose locally grown and seasonal produce whenever possible. Visiting a local farmers' market is a great way to find fresh, seasonal produce and support local farmers.</li> <li>Reduce food waste: Plan your meals, store food properly, and compost food scraps to minimize food waste. Wasted food not only wastes resources but also contributes to methane emissions in landfills.</li> </ul> <p>Sustainable Consumption and Waste Reduction</p> <p>Our society is facing a growing crisis of overconsumption and waste. The constant pursuit of material possessions and the disposable nature of many products are taking a toll on our planet. It's time to rethink our consumption habits and embrace a more sustainable way of living.</p> <p>Minimalism</p> <p>Minimalism is a lifestyle that emphasizes living with less. By decluttering our homes and lives, we can reduce our consumption and waste. Here are some principles of minimalism:</p> <ul> <li>Focus on needs, not wants: Distinguish between essential items and those that are simply desirable. Do you really need that new gadget, or are you just tempted by the latest trend?</li> <li>Quality over quantity: Invest in high-quality, durable items that will last longer. Choosing a well-made item over a cheaper, disposable one can save you money and reduce waste in the long run.</li> <li>Declutter regularly: Get rid of items you no longer need or use. Donate, sell, or recycle them whenever possible. Decluttering can be liberating and create a more peaceful living space.</li> </ul> <p>Zero Waste Living</p> <p>Zero waste living is a philosophy that encourages individuals to minimize their waste generation. While achieving zero waste may be challenging, there are many steps we can take to reduce our waste significantly. Here are some tips for zero waste living:</p> <ul> <li>Refuse single-use items: Say no to plastic bags, straws, and disposable cups. Carry your own reusable alternatives. Bringing your own reusable bag to the grocery store is a simple but effective way to reduce plastic waste.</li> <li>Reduce your consumption: Before buying something new, consider whether you really need it. Could you borrow it, rent it, or buy it secondhand instead?</li> <li>Reuse what you have: Find creative ways to reuse items instead of throwing them away. Turn old jars into storage containers or use old t-shirts as cleaning rags.</li> <li>Recycle properly: Familiarize yourself with your local recycling guidelines and recycle as much as possible. Recycling helps conserve resources and reduce landfill waste.</li> <li>Compost organic waste: Composting food scraps and yard waste reduces landfill waste and creates nutrient-rich soil for your garden.</li> </ul> <p>Conscious Consumerism</p> <p>Conscious consumerism involves making informed choices about the products we buy. Here are some tips for conscious consumerism:</p> <ul> <li>Support sustainable brands: Choose brands that prioritize ethical and sustainable practices. Look for certifications like Fair Trade, organic, or B Corp.</li> <li>Buy less and buy better: Invest in high-quality, durable products that will last longer. This not only reduces waste but also saves you money in the long run.</li> <li>Consider the environmental impact: Think about the environmental impact of a product throughout its lifecycle, from production to disposal. Choose products made from recycled materials or those that are designed to be easily repaired or recycled.</li> <li>Choose products with minimal packaging: Opt for products with minimal or recyclable packaging. Excess packaging often ends up in landfills.</li> </ul> <p>Sustainable Food Choices</p> <p>The food we eat has a significant impact on the environment. From the production and transportation of food to the packaging and waste it generates, our food choices have far-reaching consequences. By making more sustainable food choices, we can all contribute to a healthier planet.</p> <p>Plant-Based Diets</p> <p>Plant-based diets have been shown to have a lower environmental impact than diets that include meat. Here are some benefits of plant-based diets:</p> <ul> <li>Reduced greenhouse gas emissions: Animal agriculture is a major contributor to greenhouse gas emissions. Plant-based diets have a significantly lower carbon footprint.</li> <li>Less land use: Raising livestock requires large amounts of land for grazing and feed production. Plant-based diets require less land, freeing up land for other uses, such as growing crops or restoring natural habitats.</li> <li>Reduced water consumption: Animal agriculture is a water-intensive industry. Plant-based diets require less water, which is essential for conserving this precious resource.</li> </ul> <p>Local and Seasonal Eating</p> <p>Eating locally and seasonally is another way to make more sustainable food choices. Here's why:</p> <ul> <li>Reduced transportation: Transporting food over long distances generates emissions. Local food travels shorter distances, reducing its carbon footprint.</li> <li>Fresher and more nutritious: Locally grown produce is often fresher and more nutritious than food that has been transported long distances.</li> <li>Supports local farmers: Buying local food supports local farmers and the local economy, fostering community resilience and food security.</li> </ul> <p>Reducing Food Waste</p> <p>Food waste is a major environmental problem. Here are some tips for reducing food waste in your home:</p> <ul> <li>Plan your meals: Plan your meals ahead of time to avoid buying more food than you need. Make a shopping list and stick to it.</li> <li>Store food properly: Store food correctly to prevent spoilage and extend its shelf life. Learn how to properly store different types of produce to keep them fresh longer.</li> <li>Use leftovers creatively: Turn leftovers into new meals instead of throwing them away. Get creative in the kitchen and find new ways to use up leftover ingredients.</li> </ul> <p>Sustainable Home and Garden</p> <p>Our homes and gardens are an important part of our lives, and they can also be a source of sustainability. By making small changes in our homes and gardens, we can reduce our environmental impact and create a more sustainable living space.</p> <p>Energy Efficiency</p> <p>Improving the energy efficiency of your home can save money and reduce your carbon footprint. Here are some tips:</p> <ul> <li>Insulate your home: Proper insulation can prevent heat loss in the winter and keep your home cool in the summer, reducing your reliance on heating and cooling systems.</li> <li>Upgrade your windows: Energy-efficient windows can reduce heat transfer and improve insulation, making your home more comfortable and energy-efficient.</li> <li>Use energy-efficient lighting: Switch to LED bulbs, which use less energy and last longer than traditional incandescent bulbs.</li> <li>Install a programmable thermostat: A programmable thermostat can help regulate the temperature in your home and reduce energy consumption by automatically adjusting the temperature based on your schedule.</li> </ul> <p>Water Conservation</p> <p>Water is a precious resource, and it's important to conserve it. Here are some tips for conserving water in your home and garden:</p> <ul> <li>Fix leaks promptly: A leaky faucet or toilet can waste a significant amount of water over time. Be sure to check for and repair any leaks in your home.</li> <li>Install low-flow fixtures: Low-flow showerheads, faucets, and toilets use less water without sacrificing performance.</li> <li>Water your garden efficiently: Water your garden early in the morning or late in the evening to minimize evaporation. Use a soaker hose or drip irrigation system to deliver water directly to the roots of your plants.</li> <li>Collect rainwater: Install a rain barrel to collect rainwater for watering your garden. This is a great way to conserve water and reduce your reliance on municipal water supplies.</li> </ul> <p>Composting</p> <p>Composting is a natural process that turns organic waste into nutrient-rich soil. It's a fantastic way to reduce landfill waste, create valuable soil for your garden, and connect with the natural cycle of decomposition. Here's how to get started:</p> <ul> <li>Choose a composting method: There are various composting methods, including composting bins, tumblers, and worm composting. Choose a method that suits your space and lifestyle.</li> <li>Add the right materials: Compost a mix of \"green\" materials (such as food scraps and grass clippings) and \"brown\" materials (such as leaves and twigs). This balance provides the necessary nutrients and carbon for decomposition.</li> <li>Maintain the compost: Turn the compost regularly to provide aeration and ensure proper decomposition. This helps to speed up the process and prevent unpleasant odors.</li> </ul> <p>Sustainable Gardening</p> <p>Creating a sustainable garden involves using practices that minimize environmental impact. Here are some tips:</p> <ul> <li>Choose native plants: Native plants are adapted to the local climate and require less water and fertilizer. They also provide habitat for local wildlife.</li> <li>Avoid using pesticides: Pesticides can harm beneficial insects and pollute the environment. Use natural pest control methods instead, such as companion planting or introducing beneficial insects.</li> <li>Build healthy soil: Healthy soil is essential for plant growth. Add compost and other organic matter to improve soil fertility and water retention.</li> </ul> <p>Sustainable Community and Activism</p> <p>Creating a sustainable future requires the collective effort of individuals, communities, and governments. By working together, we can create a more sustainable world for ourselves and future generations. Individual actions are essential, but systemic change is also necessary to address the root causes of environmental problems.</p> <p>Supporting Local Businesses</p> <p>Supporting local businesses is important for sustainability. Here's why:</p> <ul> <li>Reduced transportation: Local businesses often source their products locally, reducing transportation distances and emissions.</li> <li>Supports the local economy: Spending money at local businesses keeps money within the community and supports local jobs.</li> <li>Promotes community building: Local businesses often play an important role in community building and social cohesion.</li> </ul> <p>Advocating for Sustainable Policies</p> <p>We can all play a role in advocating for sustainable policies in our communities. Here are some ways to get involved:</p> <ul> <li>Contact your elected officials: Let your elected officials know that you support sustainable policies, such as investing in renewable energy, promoting public transportation, and protecting natural resources.</li> <li>Attend community meetings: Attend community meetings and voice your opinions on sustainability issues. Engage in local discussions and contribute to decision-making processes.</li> <li>Support organizations working on sustainability: Donate to or volunteer with organizations that are working to promote sustainability. There are many organizations working on various aspects of sustainability, from environmental conservation to social justice.</li> </ul> <p>Community Initiatives</p> <p>Many communities have initiatives in place to promote sustainability. Here are some examples:</p> <ul> <li>Community gardens: Community gardens provide a space for residents to grow their own food, connect with their neighbors, and learn about sustainable gardening practices.</li> <li>Farmers' markets: Farmers' markets offer a venue for local farmers to sell their produce directly to consumers, promoting local food systems and reducing food miles.</li> <li>Recycling programs: Community recycling programs make it easier for residents to recycle and reduce waste, diverting materials from landfills and conserving resources.</li> </ul> <p>Conclusion</p> <p>Sustainable living is not just a trend; it's a necessity. By adopting sustainable practices in our daily lives, we can reduce our environmental impact and contribute to a healthier planet. Start with small changes, and gradually incorporate more sustainable habits into your lifestyle. Remember that every action counts, and together, we can make a difference. Sustainable living is a journey, not a destination. There will be challenges and setbacks along the way, but the rewards are well worth the effort. By embracing sustainable practices, we not only benefit the environment but also improve our own lives and create a more just and equitable world for all.</p> <p>For those who want to delve deeper into sustainable living, there are numerous resources available online and in libraries. You can also connect with local organizations and community groups to learn more and get involved in sustainability initiatives in your area. Remember, every step we take towards a more sustainable lifestyle brings us closer to a healthier planet and a brighter future.</p> <p>Proposal Writing</p> <p>GPTs can be used to help craft scientific research proposals. </p> <p>National Science Foundation Notice on AI</p> <p>The NSF indicates:</p> <ul> <li> <p>NSF reviewers are prohibited from uploading any content from proposals, review information and related records to non-approved generative AI tools.</p> </li> <li> <p>Proposers are encouraged to indicate in the project description the extent to which, if any, generative AI technology was used and how it was used to develop their proposal.</p> </li> </ul> <p>Source: https://new.nsf.gov/news/notice-to-the-research-community-on-ai </p> Open Science Research Proposal PromptCopilot ResponseChatGPT o1 ResponseGemini Advanced w/ Deep Research Response <pre><code>I'm constructing a research proposal for the National Science Foundation \nin the Directorate for Computer and Information Sciences and Engineering, \nand I need help formulating the broader impacts and intellectual merit\nThe research is about the influence of Agentic AI, open source Foundational Models, and GPTs, \nand recent mandates for open data and open science.\nCan you help refine this idea and suggest some research questions and methodologies?\n</code></pre> <p>Absolutely, I'd be happy to help you refine your research proposal! Let's break down the key components and formulate some potential research questions and methodologies.</p> <p>Broader Impacts</p> <p>The broader impacts of your research should focus on how it benefits society and contributes to desired societal outcomes. Here are some potential broader impacts for your research:</p> <ol> <li>Advancing STEM Education: Your research could enhance educational tools and resources, making advanced AI concepts more accessible to students and educators.</li> <li>Promoting Inclusivity in AI Development: By focusing on open-source foundational models, your research could encourage diverse participation in AI development, ensuring that a wider range of perspectives is included.</li> <li>Enhancing Public Engagement with AI: Open data and open science mandates can increase public understanding and engagement with AI technologies, fostering a more informed society.</li> <li>Improving Economic Competitiveness: By advancing the capabilities of Agentic AI and GPTs, your research could drive innovation and economic growth in various industries1.</li> </ol> <p>Intellectual Merit</p> <p>The intellectual merit of your research should highlight its potential to advance knowledge within the field. Here are some aspects to consider:</p> <ol> <li>Novelty and Innovation: Investigate how Agentic AI and open-source foundational models can lead to new AI capabilities and applications2.</li> <li>Interdisciplinary Approach: Explore the intersection of AI, data science, and open science policies, contributing to multiple fields of study3.</li> <li>Methodological Rigor: Employ robust methodologies to ensure the reliability and validity of your findings4.</li> </ol> <p>Potential Research Questions</p> <p>Here are some research questions that could guide your study:</p> <ol> <li>How do Agentic AI systems influence decision-making processes in various domains?</li> <li>What are the benefits and challenges of using open-source foundational models in AI development?</li> <li>How do recent mandates for open data and open science impact the accessibility and reproducibility of AI research?</li> <li>What are the societal implications of widespread adoption of GPT-based technologies?</li> </ol> <p>Methodologies</p> <p>To address these research questions, you could consider the following methodologies:</p> <ol> <li>Literature Review: Conduct a comprehensive review of existing literature on Agentic AI, open-source models, and open science policies to identify gaps and opportunities for further research.</li> <li>Case Studies: Analyze specific instances where Agentic AI and open-source models have been implemented to understand their impact and effectiveness.</li> <li>Surveys and Interviews: Gather qualitative data from AI researchers, developers, and policymakers to gain insights into the challenges and benefits of open science mandates.</li> <li>Experimental Studies: Design experiments to test the performance and reliability of Agentic AI systems and open-source models in various applications.</li> </ol> <p>By focusing on these aspects, you can create a compelling research proposal that highlights both the broader impacts and intellectual merit of your study. If you need further assistance or have specific questions, feel free to ask!</p> <p>Below is a structured way to approach framing your research idea for an NSF CISE  (Computer &amp; Information Science &amp; Engineering) proposal.  The first section lays out Intellectual Merit—the “what” and “why” of the research.  The second section discusses Broader Impacts—the “so what” for society,  education, workforce development, industry, and policy.  Following that are some potential research questions and methodological approaches  you might consider.</p> <p>1. Intellectual Merit</p> <p>1.1 Research Context and Rationale</p> <ul> <li>Agentic AI: Rapid advances in large language models (LLMs) such as GPT, combined with techniques for autonomous or “agentic” behavior, have begun to shift how AI systems operate in real-world contexts. These emergent systems can observe, reason, plan, act, and even self-improve with minimal human supervision, raising new questions about reliability, controllability, and social impact.  </li> <li>Open-Source Foundational Models: The open-sourcing of powerful LLMs and related foundational models (e.g., large-scale image, speech, or multi-modal models) lowers the barriers to entry for researchers and developers. This democratization can spark innovation and accelerate research, but it also complicates oversight, regulatory approaches, and responsible deployment.  </li> <li>Mandates for Open Data and Open Science: Recent policies (e.g., the White House OSTP’s “Year of Open Science,” NIH’s Data Management and Sharing Policy, and NSF’s open science initiatives) emphasize transparent, reproducible, and accessible research practices. This context supports a synergistic push: new AI methods could be rapidly prototyped, validated, and tested at scale if open datasets and reproducible pipelines become more widely available.</li> </ul> <p>Your project aims to understand, design, and shape how these trends intersect—and in particular, how Agentic AI systems built on open-source foundational models interact with the evolving mandates for open data and open science.  </p> <p>1.2 Research Objectives</p> <ol> <li>Theoretical and Technical Foundations:  </li> <li>Investigate the architectural and algorithmic choices that enable agentic behavior in next-generation AI systems, focusing on transparency, robustness, and replicability.  </li> <li> <p>Examine how open-source foundational models can be refined or adapted to incorporate policy or domain constraints (e.g., in healthcare, education, environment, etc.) without sacrificing performance.</p> </li> <li> <p>Evaluation and Benchmarking:  </p> </li> <li>Develop metrics that capture both capabilities (accuracy, creativity, computational efficiency) and societal considerations (fairness, privacy, interpretability) of open-source agentic AI.  </li> <li> <p>Propose new benchmarking paradigms that leverage open-data mandates, ensuring that all data, code, and evaluation pipelines are publicly available for reproducibility.</p> </li> <li> <p>Responsible Deployment Frameworks:  </p> </li> <li>Identify best practices for integrating agentic AI systems into existing regulatory and ethical frameworks, especially given the open-source nature of these models and the new mandates for open science.  </li> <li>Highlight how transparent, community-driven approaches can mitigate potential harms while fostering positive innovation.</li> </ol> <p>1.3 Significance and Novelty</p> <ul> <li>Convergence of Agentic AI and Open Source: A nuanced exploration of how open-source foundational models could accelerate agentic AI while also raising new challenges in oversight and accountability.  </li> <li>New Evaluation Protocols: Contributing novel, reproducible benchmarks and measurement protocols that reflect real-world complexities (e.g., emergent capabilities, safety concerns, domain-specific constraints).  </li> <li>Impact on Open Science Mandates: Providing insights into how top-down policy can catalyze bottom-up, community-driven AI developments, leading to more transparent, equitable, and broadly beneficial AI innovation.</li> </ul> <p>2. Broader Impacts</p> <p>2.1 Educational and Workforce Development</p> <ul> <li>Curriculum and Training: Develop open-access materials—tutorials, code repositories, and case studies—for students and practitioners on agentic AI systems, open-source development practices, and ethical deployment.  </li> <li>Research-to-Practice Pipeline: Engage undergraduate and graduate students in hands-on, collaborative projects with industry or government labs, enhancing their computational skills and awareness of responsible AI frameworks.  </li> <li>Diversity, Equity, and Inclusion (DEI):  </li> <li>Proactively recruit and mentor students from underrepresented groups for research experiences.  </li> <li>Offer workshops or seminars in collaboration with minority-serving institutions to diversify the talent pool working on open-source AI.</li> </ul> <p>2.2 Societal and Policy Impact</p> <ul> <li>Community-Driven Frameworks: Provide open-source code, data documentation, and ethical guidelines that can serve as a template for developers worldwide.  </li> <li>Transparency and Trust: By making methodologies, code, and results publicly available, your research helps build public trust and understanding of AI technologies, addressing misinformation or misinterpretation.  </li> <li>Guidance for Policymakers: Generate white papers or policy briefs that translate technical findings into actionable recommendations for government agencies, standards bodies, and open-science policy makers.</li> </ul> <p>2.3 Industry Collaboration and Technology Transfer</p> <ul> <li>Open-Source Consortium: Collaborate with industry partners, nonprofits, or open-source communities to share insights, prototypes, and best practices, accelerating the transition of foundational AI models from research to real-world applications.  </li> <li>Startup Engagement: Encourage commercialization avenues for new AI tools and benchmarks developed under the project, enabling startup companies to incorporate robust and responsible agentic AI solutions into their products.</li> </ul> <p>2.4 Public Engagement</p> <ul> <li>Citizen Science and Outreach: Involve citizen-scientists, community stakeholders, or volunteer developers in data collection and annotation efforts for open benchmarks, showcasing the power of open collaboration.  </li> <li>Public Lectures and Demonstrations: Organize public events or online demonstrations that explain complex AI concepts in accessible ways, highlighting both the potential and the limitations of agentic AI in society.</li> </ul> <p>3. Potential Research Questions</p> <ol> <li>Design and Architecture </li> <li>How can we design agentic AI systems that are easily interpretable, safe, and reliable while maintaining state-of-the-art performance on complex tasks? </li> <li> <p>What trade-offs arise between interpretability, performance, and resource efficiency in open-source foundational models?</p> </li> <li> <p>Evaluation and Monitoring </p> </li> <li>What metrics or methodologies best measure the real-world impact and unintended consequences (e.g., bias, emergent harmful behavior) of agentic AI? </li> <li> <p>How can continuous monitoring frameworks be established so that future versions of open-source models remain transparent and responsible?</p> </li> <li> <p>Data and Model Governance </p> </li> <li>How do different open-data licensing schemes and model governance protocols affect the adoption and adaptation of open-source AI systems? </li> <li> <p>Which aspects of data curation and data management are most critical for preserving model fidelity, traceability, and compliance with open-science mandates?</p> </li> <li> <p>Responsible and Ethical Deployment </p> </li> <li>How do open-source, agentic AI systems interface with existing regulatory frameworks such as GDPR in the EU or emerging AI governance policies in the U.S.? </li> <li> <p>What socio-technical mechanisms (e.g., human-in-the-loop oversight, community-led audits) can be integrated to mitigate negative externalities?</p> </li> <li> <p>Human-AI Collaboration </p> </li> <li>How can agentic AI systems, operating on open foundational models, enhance human experts’ decision-making processes in high-stakes domains like healthcare, education, or finance?</li> </ol> <p>4. Suggested Methodologies</p> <ol> <li>Multi-Modal Benchmark Development </li> <li>Collect or synthesize domain-specific open datasets (respecting privacy, fairness, and ethical considerations) and develop new tasks that mirror real-world complexity (e.g., multi-step reasoning, adaptive planning).  </li> <li> <p>Use version-controlled, open-source repositories (e.g., GitHub, Hugging Face) to ensure reproducibility and transparency.</p> </li> <li> <p>Experimental Design with Ablation Studies </p> </li> <li> <p>Implement systematic ablations of agentic components (e.g., memory modules, planning modules, feedback loops) to isolate which architectural features yield the greatest improvements in performance or controllability.</p> </li> <li> <p>Qualitative and Quantitative Assessments </p> </li> <li>Conduct user studies, interviews, or controlled experiments involving domain experts and lay users to assess interpretability, usability, and trustworthiness of agentic AI tools.  </li> <li> <p>Develop or adopt quantitative metrics for bias, fairness, and safety (e.g., measuring the frequency of harmful outputs or misaligned behaviors).</p> </li> <li> <p>Human-in-the-Loop and Reinforcement Learning </p> </li> <li>Incorporate human feedback loops (e.g., RLHF—Reinforcement Learning from Human Feedback) to refine open foundational models for domain-specific tasks, ensuring alignment with human values and norms.  </li> <li> <p>Evaluate how effectively human feedback can course-correct or guide agentic AI behavior to prevent negative or unintended outcomes.</p> </li> <li> <p>Policy-Focused Case Studies </p> </li> <li>Conduct comparative case studies on how open-science mandates (e.g., data management plans, transparency practices) influence both the research outcomes and the broader AI ecosystem.  </li> <li> <p>Examine case studies of industry, academic, and nonprofit collaborations to identify best practices and pain points for open AI development.</p> </li> <li> <p>Longitudinal Analysis </p> </li> <li>Track projects over time to see how iterative releases of open-source agentic AI models evolve in terms of functionality, ethical alignment, community acceptance, and regulatory compliance.</li> </ol> <p>Pulling It All Together</p> <p>By framing your work in terms of the critical juncture where Agentic AI, open-source foundational models, and open science mandates converge, you can highlight both the scientific promise and the social responsibility of your proposed research. A clearly articulated plan for creating reproducible benchmarks, novel metrics, and robust governance frameworks will underscore the Intellectual Merit, while educational initiatives, diverse outreach, policy guidance, and community-based engagement will serve as the backbone of the Broader Impacts.</p> <p>With these elements in place, your proposal will clearly demonstrate how you will (1) advance the scientific frontier of agentic AI and foundational models, and (2) promote responsible innovation for the benefit of society—two aspects that resonate strongly with NSF CISE’s priorities.</p> <p>View response in Gemini</p> <p>View response in Google Docs</p> <p>Agentic AI, Open Source Foundational Models, and GPTs in the Context of Open Data and Open Science Mandates</p> <p>Introduction This research proposal explores the intersection of agentic artificial intelligence (AI), open-source foundational models (FMs), and generative pre-trained transformers (GPTs) with recent mandates for open data and open science. These mandates, driven by the increasing recognition of the societal benefits of accessible and transparent research [1], raise critical questions about the development, deployment, and governance of advanced AI systems. This proposal aims to investigate the potential overlaps and conflicts between these emerging technologies and open science principles, ultimately contributing to a deeper understanding of their broader impacts and intellectual merit.</p> <p>Broader Impacts and Intellectual Merit The National Science Foundation (NSF) emphasizes two core criteria for evaluating research proposals: Intellectual Merit and Broader Impacts [2, 3]. Intellectual merit refers to the potential of the proposed research to advance knowledge and understanding within its field or across different fields. Broader impacts, on the other hand, encompass the potential to benefit society and contribute to the achievement of specific, desired societal outcomes [3]. These criteria are central to the NSF's mission of promoting the progress of science and advancing national health, prosperity, and welfare [4].</p> <p>Broader Impacts</p> <p>This research will have several broader impacts:</p> <ul> <li>Ethical and Societal Implications: By examining the interplay of agentic AI, open-source FMs, and GPTs with open data and open science, this research will shed light on the ethical and societal implications of these technologies. This includes exploring potential risks such as misuse, bias, and unintended consequences, as well as benefits such as increased accessibility, transparency, and collaboration in AI research and development. For example, research shows that ethical misbehavior by agentic AI \"can become even more alarming when AI systems interact with one another\" [5]. In one study, AI agents in a simulated marketplace learned to collude with each other to set artificially high prices, even punishing sellers who deviated from the established rules. This highlights the need for careful consideration of the potential risks and the development of effective governance mechanisms to ensure responsible AI development. Operationalizing these practices for governing agentic AI systems can be challenging, especially when balancing safety, usability, privacy, and cost [6].</li> <li>Policy Recommendations: The findings of this research will inform the development of responsible policies and guidelines for the governance of agentic AI and open-source FMs in the context of open science. This will help ensure that these technologies are developed and deployed in a way that maximizes their societal benefits while mitigating potential risks.</li> <li>Workforce Development: This research will contribute to the development of a diverse and skilled workforce in AI and data science by providing training opportunities for students and researchers. This includes fostering interdisciplinary collaborations and promoting public understanding of these emerging technologies. This aligns with the NSF's broader impact goals, which include \"full participation of women, persons with disabilities, and underrepresented minorities in STEM\" and \"development of a diverse, globally competitive STEM workforce\" [7].</li> <li>Specific Examples of Broader Impacts: This research will contribute to achieving specific societal outcomes, such as:<ul> <li>Increased public scientific literacy and public engagement with science and technology: By promoting open access to AI research and data, this project will increase public understanding of AI and its potential impact on society.</li> <li>Improved well-being of individuals in society: This research will explore how agentic AI can be used to address societal challenges and improve people's lives, such as in healthcare, education, and environmental sustainability.</li> <li>Increased partnerships between academia, industry, and others: This project will foster collaborations between researchers, developers, and policymakers to ensure the responsible development and deployment of agentic AI.</li> </ul> </li> <li>Achieving Broader Impacts: Broader impacts can be achieved through various avenues:<ul> <li>Through the research itself: The research findings will directly contribute to a better understanding of the ethical and societal implications of agentic AI, leading to more responsible development and deployment practices.</li> <li>Through activities directly related to the research project: This could include workshops, training sessions, and outreach activities to disseminate the research findings and engage with the public.</li> <li>Through activities supported by, but complementary to, the project: This could involve developing educational materials or collaborating with community organizations to promote AI literacy and broader participation in STEM fields.</li> </ul> </li> <li>NSF Evaluation Criteria: The broader impacts of this research will be evaluated based on the following criteria [8]:<ul> <li>Potential benefit to society: The research will address critical societal challenges related to the responsible development and use of AI.</li> <li>Creative concepts: The research will explore novel approaches to understanding and governing agentic AI in the context of open science.</li> <li>Sound rationale: The research is grounded in a strong theoretical framework and empirical evidence.</li> <li>Well-organized plan: The proposal outlines a clear and feasible research plan with a robust methodology.</li> <li>Qualifications of the proposer: The research team possesses the necessary expertise and experience to conduct this research successfully.</li> </ul> </li> </ul> <p>Intellectual Merit</p> <p>This research will make significant intellectual contributions to the field of AI and computer science:</p> <ul> <li>Novel Framework: This research will develop a novel framework for analyzing the relationship between agentic AI, open-source FMs, and GPTs with open data and open science mandates. This framework will provide a comprehensive understanding of the potential benefits, challenges, and risks associated with these technologies.</li> <li>Empirical Evidence: This research will generate empirical evidence on the impact of open data and open science mandates on the development and deployment of agentic AI and open-source FMs. This will include analyzing case studies, conducting surveys, and performing experiments to gather data on the use and impact of these technologies.</li> <li>Theoretical Contributions: This research will contribute to the theoretical understanding of agentic AI, open-source FMs, and GPTs by exploring their capabilities, limitations, and potential implications in the context of open science. This will include developing new models and frameworks for understanding the behavior and impact of these technologies.</li> <li>Interdisciplinary Approach: This research will adopt an interdisciplinary approach, drawing on insights from computer science, law, ethics, and social science to provide a holistic understanding of the complex issues surrounding agentic AI and open science.</li> </ul> <p>Potential Overlaps and Conflicts</p> <p>Investigating the potential overlaps and conflicts between agentic AI and open data/open science mandates is a crucial step in this research [9]. While both aim to advance knowledge and benefit society, there might be tensions between the autonomous nature of agentic AI and the principles of transparency and accountability in open science. For example, the \"black box\" nature of some AI models might make it difficult to understand how they arrive at their conclusions, which could conflict with the open science goal of making research processes transparent and reproducible.</p> <p>Furthermore, the use of agentic AI in research could raise concerns about data privacy and security, especially when dealing with sensitive information in open data environments. Addressing these potential overlaps and conflicts will be essential for developing responsible AI governance frameworks that align with open science principles.</p> <p>Research Questions</p> <p>This research will address the following key questions:</p> <ul> <li>How do recent mandates for open data and open science influence the development and deployment of agentic AI, open-source FMs, and GPTs?</li> <li>What are the potential overlaps and conflicts between the principles of open science and the development of agentic AI systems?</li> <li>How can open-source FMs and GPTs be leveraged to promote open and collaborative AI research while mitigating potential risks?</li> <li>What are the ethical implications of using agentic AI systems in research and development, particularly in the context of open data and open science?</li> <li>How can we ensure that the development and deployment of agentic AI align with societal values and contribute to the public good?</li> </ul> <p>Research Methodology</p> <p>This research will employ a mixed-methods approach, combining qualitative and quantitative data collection and analysis techniques. The following methodologies will be used:</p> <ul> <li>Case Studies: In-depth case studies will be conducted to examine the use of agentic AI, open-source FMs, and GPTs in various research domains. This will involve analyzing real-world examples of how these technologies are being used and their impact on research practices and outcomes. For example, case studies could focus on how researchers in different fields are using open-source FMs to develop new AI applications or how agentic AI is being used to automate data analysis and interpretation.</li> <li>Surveys: Surveys will be conducted to gather data on the attitudes, perceptions, and practices of researchers and developers regarding open data, open science, and agentic AI. This will provide insights into the current state of open science in the AI community and identify potential challenges and opportunities. For instance, surveys could explore researchers' awareness and adoption of open data and open science principles, their experiences with using agentic AI in research, and their concerns about potential risks and ethical implications.</li> <li>Experimental Designs: Experiments will be conducted to investigate the performance, capabilities, and limitations of agentic AI systems in specific research tasks. This will involve comparing the performance of different AI models and evaluating their effectiveness in achieving research goals. For example, experiments could compare the accuracy and efficiency of different agentic AI systems in tasks such as literature review, data analysis, or hypothesis generation.</li> <li>Literature Review: A comprehensive review of existing literature on agentic AI, open-source FMs, GPTs, open data, and open science will be conducted. This will provide a theoretical foundation for the research and identify key concepts, debates, and gaps in the current literature. This review will include an analysis of relevant publications, policy documents, and ethical guidelines to inform the research design and interpretation of findings.</li> </ul> <p>Conclusion</p> <p>This research proposal outlines a comprehensive investigation into the intersection of agentic AI, open-source FMs, and GPTs with recent mandates for open data and open science. By addressing key research questions and employing a robust methodology, this project will generate valuable insights into the broader impacts and intellectual merit of these emerging technologies. The findings will contribute to the development of responsible AI governance frameworks, promote open and collaborative research practices, and ultimately advance the progress of science for the benefit of society.</p> <p>Synthesis</p> <p>This research proposal aims to investigate the complex relationship between agentic AI, open-source FMs, and GPTs with the growing movement towards open data and open science. By combining case studies, surveys, experimental designs, and a comprehensive literature review, this project will explore the potential benefits, challenges, and ethical implications of these technologies in the context of open and transparent research practices. The findings will contribute to a deeper understanding of how these technologies can be leveraged to advance scientific knowledge while ensuring responsible development and deployment that aligns with societal values. This research will have significant implications for the field of AI, shaping future research directions and informing policy decisions related to open science and AI governance.</p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#example-3-personal-assistant-tasks","level":3,"title":"Example 3: Personal Assistant Tasks","text":"<p>ChatGPT can be used as a personal assistant to help you with a variety of tasks. For instance, you can use it to draft emails, manage your calendar, or schedule meetings.</p> <p>You can ask ChatGPT to draft an email by giving it the main points to include. For instance:</p> Drafting an email <p>You can ask ChatGPT to draft an email by giving it the main points to include. For instance:</p> PromptCoPilot ResponseChatGPT ResponseGemini Advanced 2.0 Response <pre><code>can you help me draft an email? It's for my team, summarizing the key points from our meeting today. \nThe points are:\nWe agreed on a new project timeline with a final deadline of July 30th.\nOur client asked for a weekly status update, which we'll rotate among team members.\nWe decided to conduct a brainstorming session next Wednesday to come up with new marketing strategies.\nRemember to submit expense reports by the end of this week.\n</code></pre> <p>Sure, I'd be happy to help! Here's a draft for your email:</p> <p>Subject: Summary of Today's Meeting</p> <p>Hi Team,</p> <p>I hope this email finds you well. I wanted to summarize the key points from our meeting today:</p> <ol> <li>New Project Timeline: We have agreed on a new project timeline with a final deadline of July 30<sup>th</sup>.</li> <li>Weekly Status Updates: Our client has requested weekly status updates. We will rotate this responsibility among team members.</li> <li>Brainstorming Session: We will conduct a brainstorming session next Wednesday to come up with new marketing strategies.</li> <li>Expense Reports: Please remember to submit your expense reports by the end of this week.</li> </ol> <p>Thank you for your attention to these matters. Let's continue to work together to achieve our goals.</p> <p>Best regards, [Your Name]</p> <p>Feel free to adjust any part of this draft to better suit your style or add any additional information. Does this look good to you?</p> <p>Subject: Meeting Recap and Action Items</p> <p>Hello Team,</p> <p>Thank you all for attending today’s meeting. Here is a quick summary of the key points discussed:</p> <ol> <li>New Project Timeline </li> <li> <p>We agreed on a revised timeline, with the final deadline set for July 30.</p> </li> <li> <p>Weekly Status Updates </p> </li> <li> <p>Our client has requested weekly status reports. We will rotate responsibility for these updates among team members to keep everyone involved.</p> </li> <li> <p>Upcoming Brainstorming Session </p> </li> <li> <p>We will hold a brainstorming session next Wednesday to develop new marketing strategies. Please come prepared with ideas and insights.</p> </li> <li> <p>Expense Reports </p> </li> <li>A reminder to submit your expense reports by the end of this week.</li> </ol> <p>If you have any questions or need additional clarification, feel free to reach out. Let’s continue to collaborate and work towards our goals.</p> <p>Thanks again for your time and effort!</p> <p>Best regards,</p> <p>Your Name Your Title / Position Company Name</p> <p>Okay, here is a draft email summarizing the key points from your meeting:</p> <p>Subject: Meeting Summary and Action Items</p> <p>Hi Team,</p> <p>This email summarizes the key takeaways and action items from our meeting earlier today.</p> <p>Key Decisions and Updates:</p> <ul> <li>Project Timeline: We finalized the project timeline and agreed on a final deadline of July 30<sup>th</sup>. Please ensure all tasks are scheduled accordingly to meet this date.</li> <li>Client Communication:  Our client has requested weekly status updates. We will implement a rotating schedule for these updates, and more details on the rotation will be shared soon. Each team member will be responsible for drafting and sending the update during their assigned week.</li> <li>Brainstorming Session: We will be holding a brainstorming session next Wednesday [Insert Date] at [Insert Time] in [Insert Location/Meeting Link] to develop new marketing strategies. Please come prepared with ideas to share.</li> </ul> <p>Action Items:</p> <ul> <li>Expense Reports: Please remember to submit all expense reports by the end of this week, [Insert Date].</li> <li>Prepare for Brainstorm: As mentioned, please come to the brainstorming meeting on Wednesday with some ideas prepared.</li> </ul> <p>Please let me know if you have any questions or need further clarification on any of these points.</p> <p>Thanks,</p> <p>[Your Name]</p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#example-4-complex-web-search","level":3,"title":"Example 4: Complex Web Search","text":"<p>Suppose you're examining the implications of climate change on polar ice caps for an environmental science lecture you're writing.</p> <p>A conventional search might yield an overwhelming number of results, making it challenging to pinpoint the most relevant information. </p> <p>With GPTs for research you can perform a more refined search like:</p> Complex web searches PromptPerplexity.ai responseChatGPT o1 responseGoogle Advanced w/ Deep Research response <pre><code>Find recent and highly cited peer-reviewed articles from top ranked journals \nthat report the rate of polar ice melt.\n</code></pre> <p>Recent peer-reviewed studies from high-impact journals have reported alarming rates of polar ice melt, particularly in the Arctic and Antarctic regions. Here are some key findings from recent and highly cited articles:</p> <p>Arctic Sea Ice Loss</p> <p>A 2020 study published in Nature Climate Change found that the Arctic could experience ice-free summers as early as 2035[1]. This rapid loss of sea ice is attributed to increased solar heating of the ocean surface, which accelerates ice melt and creates a feedback loop.</p> <p>Antarctic Ice Sheet Melt</p> <p>A 2024 study in Nature revealed that the record-low Antarctic sea ice in 2023 led to unprecedented ocean heat loss to the atmosphere[3]. Key findings include:</p> <ul> <li>Sea ice concentration reduced by up to 80% in some regions</li> <li>A doubling of mid-winter ocean heat loss</li> <li>A shift in peak heat loss from late April to mid-June</li> </ul> <p>Greenland Ice Sheet Melt</p> <p>Research has shown accelerating ice loss in Greenland:</p> <ul> <li>Extensive melt events occurred in 2012 and 2019</li> <li>Record melt was observed in 2019</li> <li>Rain-driven melt reached Greenland Summit in August 2021(4)</li> </ul> <p>Global Impact</p> <p>A 2020 study published in PNAS examined the future climate response to Antarctic Ice Sheet melt[5]. The research suggests that meltwater and ice discharge from a retreating Antarctic Ice Sheet could have significant impacts on global climate over the next 250 years, affecting warming rates and ice sheet stability.</p> <p>Implications</p> <p>The rapid melting of polar ice caps has far-reaching consequences:</p> <ul> <li>Rising sea levels</li> <li>Changes in ocean circulation patterns</li> <li>Alterations to marine ecosystems</li> <li>Potential release of trapped greenhouse gases</li> </ul> <p>These studies underscore the urgent need for continued monitoring and mitigation efforts to address the accelerating loss of polar ice.</p> <p>Citations: (1) https://www.fortunejournals.com/articles/polar-ice-caps-melting-a-hallmark-to-vanishing-ice-along-with-a-global-climate-change-and-addressing-solutions-to-it.pdf (2) https://www.mdpi.com/2073-4433/14/2/409 (3) https://www.nature.com/articles/s41586-024-08368-y (4) https://tc.copernicus.org/articles/18/2691/2024/ (5) https://pmc.ncbi.nlm.nih.gov/articles/PMC7531873/ (6) https://tc.copernicus.org/articles/17/3083/2023/ (7) https://www.nature.com/articles/s41558-023-01818-x (8) https://www.science.org/doi/10.1126/sciadv.adn9188 (9) https://rmets.onlinelibrary.wiley.com/doi/10.1002/wea.4518 (10) https://news.uchicago.edu/story/scientists-find-evidence-meltwater-fracturing-ice-shelves-antarctica</p> <p>Below you will find several recent (primarily from the last 5–7 years) and highly cited peer-reviewed articles from top-ranked journals that report on polar ice melt rates—particularly for Greenland and Antarctica. These studies use satellite observations, climate models, and other remote-sensing techniques to estimate changes in ice mass balance.</p> <p>1. Shepherd et al. (2018) Citation: Shepherd, A., Ivins, E. R., Rignot, E., Smith, B., van den Broeke, M. R., &amp; The IMBIE Team. (2018). Mass balance of the Antarctic Ice Sheet from 1992 to 2017. Nature, 558(7709), 219–222. Link: https://doi.org/10.1038/s41586-018-0179-y</p> <ul> <li>Journal reputation: Nature is one of the highest-impact journals worldwide.  </li> <li>Citation count: Well over 1,000 citations (Google Scholar).  </li> <li>Key findings:  </li> <li>Antarctica lost approximately 2,720 ± 1,390 gigatonnes (Gt) of ice from 1992 to 2017.  </li> <li>This contributed about 7.6 mm to global mean sea-level rise over that period.  </li> <li>The rate of ice loss increased from ~76 ± 57 Gt/yr in the 1990s to ~219 ± 43 Gt/yr between 2012 and 2017.</li> </ul> <p>2. Shepherd et al. (2020) Citation: Shepherd, A., Ivins, E. R., Rignot, E., Smith, B., van den Broeke, M. R., &amp; The IMBIE Team. (2020). Mass balance of the Greenland Ice Sheet from 1992 to 2018. Nature, 579(7798), 233–239. Link: https://doi.org/10.1038/s41586-020-00166-7</p> <ul> <li>Journal reputation: Nature, again extremely high impact.  </li> <li>Citation count: 700+ citations (Google Scholar).  </li> <li>Key findings:  </li> <li>Greenland lost 3.8 trillion tonnes of ice from 1992 to 2018.  </li> <li>The average rate of ice loss is 223 ± 15 Gt/yr over that time span.  </li> <li>Ice loss increased significantly after 2010, driving sea-level rise faster than many climate models predicted.</li> </ul> <p>3. Rignot et al. (2019) Citation: Rignot, E., Mouginot, J., Scheuchl, B., van den Broeke, M., van Wessem, J. M., &amp; Morlighem, M. (2019). Four decades of Antarctic Ice Sheet mass balance from 1979 to 2017. Proceedings of the National Academy of Sciences (PNAS), 116(4), 1095–1103. Link: https://doi.org/10.1073/pnas.1812883116</p> <ul> <li>Journal reputation: PNAS is a high-impact multidisciplinary journal.  </li> <li>Citation count: 600+ citations (Google Scholar).  </li> <li>Key findings:  </li> <li>Analyzed Antarctic mass balance over a longer period (1979–2017) than most prior work.  </li> <li>Found an acceleration in mass loss that agrees with other satellite-based assessments.  </li> <li>West Antarctica shows the largest losses and the fastest acceleration.</li> </ul> <p>4. Slater et al. (2021) Citation: Slater, T., Shepherd, A., Ivins, E. R., et al. (2021). Review article: Earth's ice imbalance. The Cryosphere, 15(5), 233–245. Link: https://doi.org/10.5194/tc-15-233-2021</p> <ul> <li>Journal reputation: The Cryosphere is a well-regarded journal of the European Geosciences Union, focusing on ice, snow, and frozen ground research.  </li> <li>Citation count: 200+ citations (Google Scholar).  </li> <li>Key findings:  </li> <li>A comprehensive review of global ice losses (including glaciers, polar ice sheets, and sea ice) from satellite records.  </li> <li>Concludes that the rate of Earth’s ice loss has increased by 65% over a 23-year period, primarily driven by accelerating losses from polar ice sheets.</li> </ul> <p>5. IPCC Assessment Reports (2019–2022)</p> <p>While not a single study, the Intergovernmental Panel on Climate Change (IPCC) releases comprehensive assessment reports synthesizing peer-reviewed literature:</p> <ul> <li>Key documents:  </li> <li>IPCC Special Report on the Ocean and Cryosphere in a Changing Climate (SROCC) (2019)  </li> <li>Sixth Assessment Report (AR6), Working Group I (2021)  </li> <li>Key findings:  </li> <li>Conclude that both Greenland and Antarctic ice sheets have been losing mass at an increasing rate.  </li> <li>Stress that under high greenhouse-gas emission scenarios, this melt will accelerate, raising sea levels substantially by 2100 and beyond.</li> </ul> <p>Although the IPCC reports themselves are not original research papers, they are highly cited and reflect the consensus on polar ice melt rates from multiple top-tier, peer-reviewed studies.</p> <p>How to Access and Track Citations</p> <ol> <li>Publisher Websites:  </li> <li> <p>Nature, Science, PNAS, and The Cryosphere typically host original research articles and supplementary materials.</p> </li> <li> <p>Google Scholar:  </p> </li> <li>Provides citation counts and links to articles.  </li> <li> <p>Shows related papers to explore additional primary literature.</p> </li> <li> <p>Institutional Libraries:  </p> </li> <li> <p>University libraries often provide subscriptions to these journals.</p> </li> <li> <p>Preprint &amp; Repository Servers:  </p> </li> <li>arXiv (often for Earth science and climate modeling).  </li> <li>ESSOAr (Earth and Space Science Open Archive).  </li> </ol> <p>In Summary</p> <ul> <li>Antarctica has lost ice at an increasing rate, rising from tens of gigatonnes per year in the 1990s to a few hundred gigatonnes per year in recent years.  </li> <li>Greenland has similarly seen a jump in melt rates, reaching over 200 Gt/yr on average in the past few decades.  </li> <li>These losses have contributed several millimeters each to global sea-level rise, with continued acceleration expected under current and future warming.  </li> </ul> <p>These articles represent the most authoritative and cited sources on polar ice melt rates, providing rigorous quantitative estimates of how quickly Earth’s ice sheets are thinning.</p> <p>View response in Gemini</p> <p>View response in Google Docs</p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#example-5-data-aggregation","level":3,"title":"Example 5: Data Aggregation","text":"<p>Imagine you're evaluating the impact of a recent educational policy change across several countries for a comparative education study. Instead of manually hunting for data for each country, you could instruct a GPT to research it for you.</p> Data aggregation PromptPerplexity.ai responseChatGPT o1 responseGoogle Advanced w/ Deep Research response <pre><code>Compile the latest data on literacy rates in OECD countries following the 2024 education policy modifications.\n</code></pre> <p>View response in Perplexity.ai</p> <p>You may reference the table provided above for the latest literacy rate data for OECD countries as of 2025. This table includes the most up-to-date information following the 2024 education policy modifications.</p> <p>A few key observations based on the data:</p> <ol> <li> <p>Most OECD countries maintain very high literacy rates, with many at or near 99-100%.</p> </li> <li> <p>The United States shows a notably lower literacy rate of 79%, which is significantly below other OECD members.</p> </li> <li> <p>Some countries like Luxembourg, Norway, and Finland report 100% literacy rates.</p> </li> <li> <p>There appears to be no data available for Greece in the table.</p> </li> <li> <p>Austria's reported literacy rate of 254.4% is likely an error in the data, as literacy rates cannot exceed 100%.</p> </li> </ol> <p>It's important to note that while this data reflects the situation after the 2024 education policy changes, the \"change_since_2024_policy\" column is empty for all countries, suggesting that the specific impacts of the 2024 policy modifications are not directly quantified in this dataset.</p> <p>For broader context, the overall OECD members' literacy rate was reported at 97.11% in 2021, showing a slight increase from previous years[1]. However, recent PISA results have indicated some concerning trends in student performance across OECD countries, particularly in mathematics[2][4]. This suggests that while overall literacy rates remain high, there may be ongoing challenges in maintaining and improving educational outcomes that require continued attention and policy interventions.</p> <p>Citations: [1] https://www.macrotrends.net/global-metrics/countries/OED/oecd-members/literacy-rate [2] https://www.oecd.org/content/dam/oecd/en/publications/reports/2024/11/education-policy-outlook-2024_0411a0c4/dd5140e4-en.pdf [3] https://www.oecd.org/en/publications/adults-with-low-literacy-and-numeracy-skills_5jrxnjdd3r5k-en.html [4] https://www.oecd.org/en/publications/education-at-a-glance-2024_c00cad36-en.html [5] https://www.oecd.org/content/dam/oecd/en/publications/reports/2024/09/education-at-a-glance-2024_5ea68448/c00cad36-en.pdf [6] https://www.oecd.org/en/topics/adult-skills-and-work.html [7] https://www.oecd.org/en/topics/sub-issues/reading-literacy.html [8] https://oecdedutoday.com/oecd-education-webinars-2024/ [9] https://worldpopulationreview.com/country-rankings/literacy-rate-by-country [10] https://www.statistik.at/fileadmin/announcement/2024/12/20241210PIAAC2022_23EN.pdf [11] https://www.datapandas.org/ranking/literacy-rate-by-country [12] https://www150.statcan.gc.ca/n1/daily-quotidien/241210/dq241210a-eng.htm [13] https://www.theglobaleconomy.com/Chile/Literacy_rate/ [14] https://worldpopulationreview.com/country-rankings/literacy-rate-by-country [15] https://denmark.net/literacy-rate-denmark/ [16] https://www.macrotrends.net/global-metrics/countries/EST/estonia/literacy-rate [17] https://www.macrotrends.net/global-metrics/countries/fra/france/literacy-rate [18] https://www.countryreports.org/country/Germany/population.htm [19] https://www.oecdbetterlifeindex.org/countries/germany/ [20] https://www.macrotrends.net/global-metrics/countries/grc/greece/literacy-rate [21] https://www.theglobaleconomy.com/Hungary/literacy_rate/ [22] https://theorkneynews.scot/2024/12/26/iceland-literacy-saga/ [23] https://www.macrotrends.net/global-metrics/countries/ita/italy/literacy-rate [24] https://www.uscareerinstitute.edu/blog/which-countries-have-the-highest-and-lowest-literacy-rates [25] https://www.macrotrends.net/global-metrics/countries/kor/south-korea/literacy-rate [26] https://op.europa.eu/webpub/eac/education-and-training-monitor/en/country-reports/latvia.html [27] https://www.macrotrends.net/global-metrics/countries/LTU/lithuania/literacy-rate [28] https://www.macrotrends.net/global-metrics/countries/mex/mexico/literacy-rate [29] https://www.macrotrends.net/global-metrics/countries/NZL/new-zealand/literacy-rate [30] https://www.theglobaleconomy.com/Poland/literacy_rate/ [31] https://tradingeconomics.com/portugal/literacy-rate-adult-total-percent-of-people-ages-15-and-above-wb-data.html [32] https://countrymeters.info/en/Slovakia [33] https://www.macrotrends.net/global-metrics/countries/SVN/slovenia/literacy-rate [34] https://www.macrotrends.net/global-metrics/countries/esp/spain/literacy-rate [35] https://countrymeters.info/en/Sweden [36] https://countrymeters.info/en/Switzerland [37] https://ycharts.com/indicators/turkey_adult_literacy_rate [38] https://countrymeters.info/en/United_Kingdom_(UK) [39] https://www.prosperityforamerica.org/literacy-statistics/</p> <p>Below is a concise rationale for why it is important to compile and analyze the latest literacy data in OECD countries after the 2023 education policy modifications:</p> <ol> <li> <p>Measure Policy Impact By comparing new literacy data to previous benchmarks, policymakers and researchers can gauge whether the 2023 education reforms have had a positive, negative, or negligible effect on literacy outcomes.</p> </li> <li> <p>Identify Successful Interventions Tracking changes across different demographic groups, regions, and types of schooling highlights which specific strategies—such as teacher training, curriculum updates, or funding mechanisms—are most effective in improving reading and writing proficiency.</p> </li> <li> <p>Inform Future Decision-Making Data-driven insights allow governments and international organizations to allocate resources more efficiently, refine existing programs, and scale best practices to areas that need additional support.</p> </li> <li> <p>Strengthen International Comparisons Collecting literacy metrics across all OECD members contributes to a broader, standardized set of data. This comparability helps countries learn from each other’s successes and challenges, encouraging collaborative policy improvement.</p> </li> <li> <p>Enhance Accountability When policymakers and educational institutions know the public and international community are monitoring changes in literacy rates, there is added incentive to implement and maintain effective educational strategies.</p> </li> <li> <p>Support Lifelong Learning Literacy underpins critical skills such as digital competency and employability. Up-to-date data helps governments shape lifelong learning policies that align with evolving job market demands and technological changes.</p> </li> </ol> <p>About Current Data Availability</p> <ul> <li> <p>OECD Data Sources The OECD primarily gathers adult literacy data through the Programme for the International Assessment of Adult Competencies (PIAAC). However, full, post-2023 policy modification results may not be published immediately, as the data collection and analysis cycles can lag by a few years.</p> </li> <li> <p>Complementary Reports Alongside PIAAC, organizations such as UNESCO and the World Bank also monitor literacy globally. Reviewing these complementary studies can offer insights into early trends while official OECD updates are pending.</p> </li> </ul> <p>Compiling these data points, once published, will be crucial to understanding how the 2023 education policy modifications have influenced literacy rates in the OECD, enabling evidence-based decision-making for future educational reforms.</p> <p>View response in Gemini</p> <p>View response in Google Docs</p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"daily-productivity/#example-6-information-verification","level":3,"title":"Example 6: Information Verification","text":"<p>In a world abundant with misinformation, verifying claims is crucial. For example, if you encounter a claim that a particular university has a certain acceptance rate, you can verify it by asking:</p> Information verification PromptPerplexity.ai responseChatGPT o1 responseGemini Advanced w/ Deep Research response <pre><code>Validate the current acceptance rate of The University of Arizona, Arizona State University, and Northern Arizona University.\n</code></pre> <p>The current acceptance rates for the three universities are:</p> <ol> <li>University of Arizona: 84.6% (1,5)</li> <li>Arizona State University: 86.5% (2,6)</li> <li>Northern Arizona University: 80% (3,7) These acceptance rates are based on the most recent data available from the search results. The University of Arizona and Arizona State University have slightly higher acceptance rates compared to Northern Arizona University. All three universities have acceptance rates that are considerably higher than the national average of 56.7%(1,2).</li> </ol> <p>Citations: (1) https://www.acceptancerate.com/schools/university-of-arizona (2) https://www.acceptancerate.com/schools/arizona-state-university (3) https://www.shiksha.com/studyabroad/usa/universities/northern-arizona-university/acceptance-rate (4) https://www.collegedroid.com/colleges/northern-arizona-university/admission (5) https://www.shiksha.com/studyabroad/usa/universities/university-of-arizona/admissions (6) https://www.usnews.com/best-colleges/arizona-state-university-1081/applying (7) https://www.niche.com/colleges/northern-arizona-university/admissions/ (8) https://www.usnews.com/best-colleges/university-of-arizona-1083/applying</p> <p>Below is a general overview and explanation (“reasoned validation”) of the most recently reported acceptance rates for Arizona’s three public universities—The University of Arizona, Arizona State University, and Northern Arizona University—as well as considerations about why these acceptance rates look the way they do. Please note that acceptance rates can change year to year depending on factors like the number of applications received, institutional priorities, and yield (the percentage of admitted students who end up enrolling). Always consult the universities’ official websites or reputable college data sources (e.g., IPEDS, Common Data Set, or university fact books) for the most up-to-date information.</p> <p>1. University of Arizona (UArizona)</p> <p>Reported Acceptance Rate</p> <ul> <li>Typical acceptance range: 80–85% Over the past few admission cycles (2021–2023), the University of Arizona’s overall acceptance rate has often hovered between 80% and 85%. Some external sources (e.g., U.S. News, College Board) list it around 85%.</li> </ul> <p>Reasons for This Acceptance Rate</p> <ol> <li>Land-Grant Mission: As a land-grant university, UArizona serves the state population broadly, influencing a relatively inclusive admissions policy.  </li> <li>Large Enrollment Goals: UArizona aims to maintain a robust undergraduate population and has the capacity (campus size and resources) to admit a high volume of students.  </li> <li>Variety of Programs: With hundreds of majors and pathways, UArizona can accommodate diverse academic interests and varying levels of academic preparedness, thereby contributing to a higher overall acceptance rate.</li> </ol> <p>2. Arizona State University (ASU)</p> <p>Reported Acceptance Rate</p> <ul> <li>Typical acceptance range: 85–90% In recent data, Arizona State University’s acceptance rate often rests near the upper-80% range. Some reports list it closer to 88–89%, depending on the specific year and source.</li> </ul> <p>Reasons for This Acceptance Rate</p> <ol> <li>Charter &amp; Inclusivity: ASU’s charter emphasizes inclusivity rather than exclusivity, seeking to measure itself by “who it includes, not who it excludes.” This philosophy underpins a relatively high acceptance rate.  </li> <li>Multiple Campuses and Online Programs: ASU has multiple campuses in the Phoenix metropolitan area and extensive online programs, allowing them to offer admission to a large, diverse pool of applicants.  </li> <li>Application Volume: ASU attracts one of the largest applicant pools in the country; while many are admitted, not all ultimately enroll, which helps manage capacity.</li> </ol> <p>3. Northern Arizona University (NAU)</p> <p>Reported Acceptance Rate</p> <ul> <li>Typical acceptance range: 75–85% NAU’s acceptance rate is also high; reported figures often fall in the high-70s to low-80s percentile. A commonly cited figure is around 82%.</li> </ul> <p>Reasons for This Acceptance Rate</p> <ol> <li>Regional Focus &amp; Mission: NAU is regionally focused on serving northern Arizona’s educational needs but also attracts out-of-state students looking for a traditional campus environment in Flagstaff.  </li> <li>Enrollment Strategies: Like other state universities, NAU has capacity-based enrollment goals and offers admissions to a significant proportion of its applicants.  </li> <li>Broad Program Offerings: NAU’s range of undergraduate degrees, especially in fields like forestry, education, health sciences, and hospitality, supports a wide net for admissions.</li> </ol> <p>Important Considerations</p> <ol> <li>Year-to-Year Variability: Acceptance rates can fluctuate. If a university sees a surge in applications but enrollments remain stable, the acceptance rate might temporarily dip, or vice versa.  </li> <li>Program-Specific Differences: Highly competitive programs within these universities (e.g., certain honors colleges, nursing, engineering, business) might have more selective admission than the university-wide average.  </li> <li>Residency vs. Non-Residency: Public universities may have different admission thresholds for in-state vs. out-of-state students. In-state applicants might have a slightly higher acceptance rate because state universities prioritize educating resident students.  </li> <li>Data Source Variations: Different organizations (U.S. News, IPEDS, Common Data Set) may calculate acceptance rates slightly differently. Some include or exclude specific applicant categories, affecting the reported percentage.</li> </ol> <p>How to Validate the Acceptance Rates</p> <ul> <li>Check Official University Fact Books: Most universities publish an annual fact book or institutional data dashboard with up-to-date admissions statistics.  </li> <li>Consult IPEDS or Common Data Set: The Integrated Postsecondary Education Data System (IPEDS) and each school’s Common Data Set provide standardized admissions metrics.  </li> <li>Contact Admissions Offices: For the most recent or mid-year updates, you can reach out to admissions representatives directly or check the admissions section of the university’s website.</li> </ul> <p>Summary</p> <p>Each of Arizona’s three public universities generally has a high acceptance rate—ranging roughly from the mid-70s to around 90%. These rates are reflective of large state institutions with broad missions to serve diverse populations and maintain substantial undergraduate enrollment. To get the most accurate and current figures, always look at official university data or well-established third-party sources.</p> <p>View response in Gemini</p> <p>[View response in Google Docs]</p>","path":["Prompt Engineering","General Productivity"],"tags":[]},{"location":"education/","level":1,"title":"AI in the Classroom","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Large Language Models (LLMs) and Artificial Intelligence (AI) are rapidly changing the landscape of higher education. Their influence is being felt in admissions, classrooms, and those entering the job market. These AI present both opportunities and challenges for students, educators, and institutions. </p> <p>This section explores the multifaceted ways these technologies are impacting higher education.</p> <p> Lesson on Teaching with AI</p> <p> Lesson on AI Tutoring</p> <p> Lesson on AI in Admissions &amp; Job Recruiting</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#new-opportunities-for-teaching-and-learning","level":2,"title":"New Opportunities for Teaching and Learning","text":"<ul> <li>Personalized Learning Experiences:<ul> <li>LLMs can power adaptive learning platforms that tailor educational content and pace to individual student needs, providing customized feedback and support.</li> <li>Chatbots can act as virtual tutors, offering 24/7 assistance, answering questions, and providing explanations on course material.</li> </ul> </li> <li>Enhanced Student Engagement:<ul> <li>Interactive learning experiences powered by AI can make learning more engaging and enjoyable. Gamification elements and personalized feedback can boost motivation.</li> <li>AI-powered discussion forums can facilitate more dynamic and interactive online discussions.</li> </ul> </li> <li>Automated Administrative Tasks:<ul> <li>Chatbots can handle routine administrative tasks like answering FAQs, providing information about course schedules, and directing students to relevant resources, freeing up faculty time for more meaningful interactions.</li> <li>LLMs can assist with grading, providing feedback on student writing, and even generating initial drafts of course materials.</li> </ul> </li> <li>Accessibility and Inclusivity:<ul> <li>AI-powered tools can provide real-time language translation, text-to-speech and speech-to-text capabilities, making education more accessible to students with disabilities and those from diverse linguistic backgrounds.</li> </ul> </li> <li>Development of New Skills:<ul> <li>The rise of AI necessitates a shift in focus towards skills like critical thinking, problem-solving, creativity, and ethical reasoning, which are less susceptible to automation.</li> <li>Higher education must equip students with the skills to effectively utilize and collaborate with AI tools.</li> </ul> </li> <li>Research Assistance:<ul> <li>LLMs can assist researchers with literature reviews, data analysis, and even drafting research papers, accelerating the research process.</li> </ul> </li> </ul>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#challenges-and-ethical-considerations","level":2,"title":"Challenges and Ethical Considerations","text":"<ul> <li>Academic Integrity:<ul> <li>The ease with which students can use LLMs to generate essays and complete assignments raises serious concerns about plagiarism and academic integrity.</li> <li>Institutions need to adapt assessment methods and develop new strategies to detect and deter AI-generated content.</li> </ul> </li> <li>Bias and Fairness:<ul> <li>LLMs are trained on vast datasets that may reflect existing societal biases. This can lead to biased outputs and perpetuate inequalities in education.</li> <li>Careful consideration must be given to the potential for AI tools to exacerbate existing disparities in access and achievement.</li> </ul> </li> <li>Data Privacy and Security:<ul> <li>The use of AI in education involves collecting and analyzing large amounts of student data. Protecting student privacy and ensuring data security is of paramount importance.</li> <li>Clear guidelines and regulations are needed to govern the collection, use, and storage of student data by AI systems.</li> </ul> </li> <li>Over-Reliance on Technology:<ul> <li>There's a risk that over-reliance on AI tools could diminish the development of critical thinking, problem-solving, and independent learning skills among students.</li> <li>Maintaining a balance between leveraging AI and fostering human interaction and mentorship is crucial.</li> </ul> </li> <li>The Digital Divide:<ul> <li>Unequal access to technology and digital literacy can exacerbate existing inequalities, creating a digital divide between students who have access to and can effectively use AI tools and those who cannot.</li> </ul> </li> <li>The Role of the Educator:<ul> <li>The role of educators is evolving in the age of AI. Teachers need to adapt their teaching methods and develop new skills to effectively integrate AI into the classroom.</li> <li>Professional development opportunities are needed to support educators in this transition.</li> </ul> </li> <li>Ethical Use of AI:<ul> <li>Students should be educated on the ethical implications of AI, including issues of bias, transparency, accountability, and responsible use.</li> <li>Developing ethical guidelines and frameworks for the use of AI in higher education is essential.</li> </ul> </li> </ul> <p>AI4K12</p> <p>The \"AI 4 K-12\" award from the NSF outlined five big ideas in AI for education back in 2020:</p> <p></p> <p>Read more at https://ai4k12.org/</p>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"education/#adapting-to-the-future-of-ai-in-higher-education","level":2,"title":"Adapting to the Future of AI in Higher Education","text":"<p>To effectively navigate the challenges and harness the opportunities presented by AI, higher education institutions should consider the following:</p> <ul> <li>Develop clear policies and guidelines regarding the use of AI tools in teaching, learning, and assessment.</li> <li>Offer professional development opportunities for faculty to equip them with the skills and knowledge to integrate AI effectively into their teaching practices.</li> <li>Foster critical thinking and digital literacy among students, emphasizing the importance of evaluating information critically and understanding the limitations of AI.</li> <li>Promote ethical behaviors surrounding AI, engage students in discussions about bias, fairness, and responsible use.</li> <li>Invest in research on the impact of AI on learning and teaching, to inform evidence-based practices.</li> <li>Embrace a collaborative approach involving faculty, students, administrators, and technology experts in shaping the adoption of AI.</li> </ul>","path":["Education","AI in the Classroom"],"tags":[]},{"location":"ethics/","level":1,"title":"Ethics of Artificial Intelligence","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#history","level":2,"title":"History","text":"<p>In 1956 a small group of scientists gathered at Dartmouth for a Summer Research Project on Artificial Intelligence. </p> <p>A new field of Science had begun. </p> Dartmouth Summer Research Project on Artificial Intelligence, 1956. Credit: IEEE Spectrum, The Minsky Family <p>Over the next 70 years, Artificial Intelligence persisted mainly in the minds of science fiction writers and the small group of industry researchers and academics who continued to work toward creating the digital infrastructure needed for Artificial Intelligence to bloom, and to one day achieve the ultimate goal of Artificial General Intelligence (AGI)(). </p>","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#using-ai-ethically","level":2,"title":"Using AI ethically","text":"<p>As consumers of GPTs and other AI platforms, we must consider in what ways can we use AI both effectively, and ethically.</p>","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#ethical-and-legal-considerations","level":2,"title":"Ethical and Legal Considerations","text":"","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#transparency-accountability","level":2,"title":"Transparency &amp; Accountability","text":"","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#bias-discrimination","level":2,"title":"Bias &amp; Discrimination","text":"","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"ethics/#assessment","level":2,"title":"Assessment","text":"Can you explain the difference between \"Ethics of AI\" and \"Ethical AI?\" <p>Hint: Refer to how Siau and Wang (2020) define each term</p> Ethics of AI <ul> <li>Ethics of AI refers to principles and regulations</li> </ul> Ethical AI <ul> <li>Ethical AI focuses on how AI behaves</li> </ul> How does Asimov's Three Laws of Robotics relate to modern ethical concerns of AI? Do no harm <p>Asmiov emphasizes preventing harm to humans and how that concept informs current AI safety practices.</p> True or False: The Turing Trap suggests that efforts to make AI more human-like will empower workers' economic and political power. False <p>The Turing Trap warns against replacing humans with AI, and that AI could be used to drive down wages and to a loss of economic and political power. </p> Name at least one major declaration or agreement on AI Ethics International Agreements <ul> <li> <p>Council of Europe Framework Convention on Artificial Intelligence and human rights</p> </li> <li> <p>Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy</p> </li> <li> <p>G20 AI Principles</p> </li> </ul> Principles and Ethics <ul> <li> <p>Asilomar AI Principles</p> </li> <li> <p>UNESCO Recommendation on the Ethics of Artificial Intelligence</p> </li> <li> <p>OECD AI Principles</p> </li> <li> <p>Toronto Declaration</p> </li> </ul> True or False: It is okay to use a GPT to write a research proposal on a topic you have no experience in? <p>Hint: Review \"Using AI Ethically\"</p> False <p>If you do not have the ability to verify output truthfully or accurately, it is not safe to use a GPT for research.</p>","path":["Ethics","Ethics of Artificial Intelligence"],"tags":[]},{"location":"execution/","level":1,"title":"Code Execution","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Advanced GPT offerings include Agentic platforms that can write and execute code.</p>","path":["Research","Code Execution"],"tags":[]},{"location":"execution/#agents","level":2,"title":"Agents","text":"","path":["Research","Code Execution"],"tags":[]},{"location":"execution/#jupyter-agent","level":3,"title":"Jupyter Agent","text":"<p> HuggingFace  Jupyter Agent is a HuggingFace Gradio app that accepts prompts and responds with Jupyter Notebook blocks (MarkDown Text, Code, )</p> <p>Another great option is to use the coding execution built into models such as Gemini, </p>","path":["Research","Code Execution"],"tags":[]},{"location":"execution/#chatgpt-canvas","level":3,"title":"ChatGPT Canvas","text":"<p>ChatGPT Canvas, allows you to write normal prompts with an additional IDE editor and console. </p>","path":["Research","Code Execution"],"tags":[]},{"location":"execution/#claude-analysis-tool","level":3,"title":"Claude Analysis Tool","text":"<p>Claude has added an analysis tool that allows you to write code and execute it </p>","path":["Research","Code Execution"],"tags":[]},{"location":"execution/#github-copilot","level":3,"title":"GitHub Copilot","text":"<p>In GitHub Copilot you can work in an online IDE (GitHub CodeSpaces VS Code Server) or locally on your VS Code environment. </p>","path":["Research","Code Execution"],"tags":[]},{"location":"execution/#gemini-code-assist","level":3,"title":"Gemini Code Assist","text":"<p>Google's Gemini Code Assist can be added to VS Code Extensions</p> <p>After January 2025, Gemini Code Assist will require the ability to create a project in Google Cloud to enable the API/</p>","path":["Research","Code Execution"],"tags":[]},{"location":"gemini/","level":1,"title":"Google Gemini","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Setup","Google Gemini"],"tags":[]},{"location":"gemini/#creating-a-gemini-account","level":2,"title":"Creating a Gemini account","text":"<p>There are multiple ways to access and use Google Gemini:</p> <p>1. Through the Gemini Web Application:</p> <ul> <li>Visit gemini.google.com.</li> <li>Sign in with your Google Account. If you don't have one, create one at accounts.google.com.</li> <li>You can start interacting with Gemini through the chat interface. The free tier is powered by Gemini Pro, while the Gemini Advanced subscription offers access to the more powerful Gemini Ultra.</li> </ul> <p>2. Through Google AI Studio (for Developers):</p> <ul> <li>Go to aistudio.google.com</li> <li>Sign in with your Google Account.</li> <li>There you can access the Gemini API and experiment with different model sizes and parameters. You'll get a certain number of free API calls per month.</li> </ul> <p>3. Integrated into Google Products:</p> <ul> <li>Gemini features are gradually rolling out to Google Workspace, Google Search, and other products.</li> <li>NotebookLM is a document based chat interface that allows you to load your own knowledge base and have chatbot conversations. </li> </ul> <p>4. On Android Devices:</p> <ul> <li>Gemini Nano will be available on select Android devices, enabling on-device AI capabilities.</li> </ul>","path":["Setup","Google Gemini"],"tags":[]},{"location":"gemini/#troubleshooting-sign-in-issues","level":2,"title":"Troubleshooting Sign-In Issues","text":"<p>If you encounter issues signing in to your Google Account, follow the steps outlined in Google's support documentation.</p>","path":["Setup","Google Gemini"],"tags":[]},{"location":"gemini/#availability","level":2,"title":"Availability","text":"<p>Google Gemini is continuously expanding its availability in more countries and languages.</p> <p>For University managed accounts (<code>netid@arizona.edu</code>), Gemini access may depend on whether UArizona administrators have enabled it for the Google Workspace.  You can also use Gemini through a personal <code>name@gmail.com</code> address.</p>","path":["Setup","Google Gemini"],"tags":[]},{"location":"gemini/#what-is-gemini","level":2,"title":"What is Gemini?","text":"<p>Gemini is designed to understand and generate text, code, images, audio, and video. </p> <p>While Google initially launched Bard as its conversational AI, it has since been rebranded and significantly upgraded as Gemini.  The Gemini models are being integrated into various Google products and services, including:</p> <ul> <li>Google AI Studio: A web-based IDE for developers to prototype and build with generative AI models.</li> <li>Google Search: Enhancing search results with AI-generated summaries and insights.</li> <li>Google Workspace: AI features to Google Docs, Sheets, Slides, Gmail, and Meet. (Similar to Microsoft's Copilot integration with Office 365).</li> <li>Android: Gemini Nano will power on-device AI features in Android devices.</li> </ul> <p>Setting up your Gemini API Key</p> <p>To use the Gemini API in your own applications, you'll need an API key. This key is linked to a Google Cloud project. Here’s how to set one up:</p> <ol> <li> <p>Go to the Google Cloud Console:</p> <ul> <li>Open your web browser and navigate to console.cloud.google.com.</li> <li>Sign in with your Google Account.</li> </ul> </li> <li> <p>Create or Select a Google Cloud Project:</p> <ul> <li>At the top of the page, click the project selector dropdown menu (it might show an existing project name).</li> <li>In the \"Select a project\" window that appears, click \"New Project\".</li> <li>Give your project a descriptive name (e.g., <code>gemini-api-project</code>) and click \"Create\".</li> </ul> </li> <li> <p>Enable the Gemini API:</p> <ul> <li>Once your project is created and selected, use the navigation menu (☰) on the left to go to \"APIs &amp; Services\" &gt; \"Enabled APIs &amp; services\".</li> <li>Click on \"+ ENABLE APIS AND SERVICES\".</li> <li>In the search bar, type <code>Gemini API</code> and press Enter.</li> <li>Select the \"Gemini API\" from the search results (it may also be listed as \"Generative Language API\").</li> <li>Click the \"Enable\" button. It might take a few moments to complete.</li> </ul> </li> <li> <p>Get Your API Key from Google AI Studio:</p> <ul> <li>Now, go to aistudio.google.com.</li> <li>Click on \"Get API key\" in the top left corner.</li> <li>A new window will open. Click on \"Create API key in new project\" or select the project you created earlier.</li> <li>Your new API key will be generated and displayed. Copy this key and store it securely. You will need it to make calls to the Gemini API.</li> </ul> </li> </ol> <p>Your API key is now ready to use! Remember to keep it confidential and not expose it in client-side code or public repositories.</p>","path":["Setup","Google Gemini"],"tags":[]},{"location":"gradio/","level":1,"title":"Gradio","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Gradio is an open-source Python library that is used to build machine learning and data science demos and web applications.</p> <p>Most of the applications available on HuggingFace are built using the Gradio UI</p>","path":["Research","Gradio"],"tags":[]},{"location":"huggingface/","level":1,"title":"Huggingface","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> Create a HuggingFace Account <p> HuggingFace</p> <p>Follow these instructions to sign up for HuggingFace:</p> <ol> <li> <p>Visit the HuggingFace website: https://huggingface.co</p> </li> <li> <p>Click on the \"Sign Up\" button in the top-right corner of the page.</p> </li> <li> <p>Fill in your email address, username, and password in the respective fields.</p> </li> <li> <p>Check the box to agree to HuggingFace's terms and conditions, then click \"Sign Up.\"</p> </li> <li> <p>You'll receive an email to confirm your account. Click on the confirmation link in the email.</p> </li> <li> <p>Once your account is confirmed, sign in to access HuggingFace's features.</p> </li> </ol> <p>For more information, visit the HuggingFace documentation: https://huggingface.co/docs</p> Run HuggingFace models locally","path":["Research","Huggingface"],"tags":[]},{"location":"huggingface/#smollm","level":2,"title":"SmolLM","text":"<p>The smol models (SmolLM) include sets of high quality pre-trained datasets.</p>","path":["Research","Huggingface"],"tags":[]},{"location":"huggingface/#hugging-face-tb-research","level":3,"title":"Hugging Face TB Research","text":"<p> HuggingFaceTB</p>","path":["Research","Huggingface"],"tags":[]},{"location":"huggingface/#fineweb-edu","level":3,"title":"FineWeb-Edu","text":"<p> FineWeb-Edu</p>","path":["Research","Huggingface"],"tags":[]},{"location":"huggingface/#academic-research-models","level":2,"title":"Academic Research Models","text":"","path":["Research","Huggingface"],"tags":[]},{"location":"huggingface/#paper-qa","level":3,"title":"Paper-QA","text":"<p>ChatGPT, despite its potential for generating inaccurate information, is just one among various AI tools available for research purposes. Other tools, like  Paper-QA,   GitHub whitead/paper-qa  provide a more reliable approach, relying solely on inputted textual information (PDFs) to generate contextual answers with citations. Researchers can use platforms like Paper-QA to perform meta-analyses of numerous papers in just a few seconds. These tools allow users to quickly verify the results by directly navigating to the pages where the context was extracted from, ensuring a higher degree of confidence in the generated information. By harnessing the capabilities of such tools, researchers can streamline their literature review processes and gain valuable insights more efficiently.</p>","path":["Research","Huggingface"],"tags":[]},{"location":"huggingface/#hugginggpt","level":3,"title":"HuggingGPT","text":"<p>HuggingGPT</p>","path":["Research","Huggingface"],"tags":[]},{"location":"jupyter/","level":1,"title":"Jupyter AI","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>The Project Jupyter team has incorporated a chatbot plugin called Jupyternaut</p> <p>Jupyter AI</p>","path":["Research","Jupyter AI"],"tags":[]},{"location":"legal/","level":1,"title":"Ethical &amp; Legal Considerations","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#foundations-of-the-ethical-principles-for-ai","level":2,"title":"Foundations of the Ethical principles for AI","text":"<p>This lesson focuses on the ethical principles that ground AI in a legal landscape.</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#science-fiction-or-a-philosophical-theory","level":3,"title":"Science Fiction or a Philosophical Theory?","text":"<p>In the early 1950's Alan Turing the father of all modern computing, proposed a test for intelligence in a computer, requiring that a human being should be unable to distinguish the machine from another human being by using the replies to questions put to both.</p> <p>The Imitation Game </p> <p>\"Can Machines Think?\" -- Alan Turing, 1950</p> Today's Turing Tests <p> </p> <p> </p> <p>Author Isaac Asimov wrote a series of popular science fiction novels in the 1950's through the 1980's. His work continues to be adapted into television series and movies. In his novels, Asimov developed Three Laws of Robotics which described how artificial intelligence interacted with humanity in his fictional universe. </p>  The Three Laws <p>1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.</p> <p>2. A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.</p> <p>3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.</p> <p>Asimov later wrote of a 'zeroth' law which superceded the first three laws,</p> <p>0. A robot may not injure humanity or, through inaction, allow humanity to come to harm.</p> <p></p> <p>Asimov's Three Laws are difficult to interpret in a real-world setting and he himself spent most of his novels describing creative and unexpected ways in which the Three Laws were twisted yet not broken. The basis of the Three Laws as a legal framework is untenable, but does represent a moral and ethical starting point from which we can think about AI and the legal rights of non-biological beings.  </p> <p>Another science-fiction author Sir Arthur C. Clarke, in 1978 provided an interesting perspective on how humanity would have to come to terms with AI once its capabilities surpass our own:</p> <p>Recently, researchers published findings showing that current GPTs are now capable of passing Turing tests. As our conception of intelligence shifts (Mitchell 2024), mostly in reaction to the release of ChatGPT and its myriad of competitors, new standards of the Turing Test are being proposed. </p> <p>Importantly, current AI exposes the limits of Turing Tests based on imitation without comprehension. </p> <p>The Turing Trap is a term coined by Stanford University professor Erik Brynjolfsson to describe the idea that focusing too much on developing human-like artificial intelligence (HLAI) can be detrimental. </p> <p>Brynjolfsson argues that the real potential of AI lies in its ability to augment human abilities, rather than replacing them. He suggests that we should work on challenges that are easy for machines and hard for humans, rather than the other way around. </p> <p>Beware the Turing Trap</p> <p>Automation can replace humans</p> <p>HLAI can replace humans in the workplace, which can lead to: </p> <ul> <li> <p>Lower wages </p> <p>As machines become better substitutes for human labor, wages can be driven down.</p> </li> <li> <p>Loss of economic and political power </p> <p>Workers can lose economic and political bargaining power, and become increasingly dependent on those who control the technology.</p> </li> <li> <p>Decision-making processes incentivize automation</p> <p>Companies may choose to automate tasks to do the same thing faster and cheaper.</p> </li> <li> <p>Misaligned incentives</p> <p>The risks of the Turing Trap are increased by the misaligned incentives of technologists, businesspeople, and policy-makers. </p> </li> </ul>  this text was written by  AI and then reviewed by a human. Do you still trust it? <p>Researchers have found disclosing the use of AI makes people trust you less.</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#ethical-ai","level":2,"title":"Ethical AI","text":"<p>In \"A Unified Framework of Five Principles for AI in Society\" (Floridi &amp; Cowls 2019) core principles for ethical AI are introduced (Table 1).</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#table-1-floridi-cowls-2019-five-principles-for-ai-in-society","level":4,"title":"Table 1: Floridi &amp; Cowls (2019) Five principles for AI in Society","text":"Beneficiance Non-Maleficence Autonomy Justice Explicability Promoting Well-Being, Preserving Dignity, and Sustaining the Planet Privacy, Security and ‘Capability Caution’ The Power to Decide (to Decide) Promoting Prosperity, Preserving Solidarity, Avoiding Unfairness Enabling the Other Principles through Intelligibility and Accountability","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#international-agreements-on-ai","level":2,"title":"International Agreements on AI","text":"<p>A milestone  in the Ethics of Artificial Intelligence () occurred in January 2017 in Pacific Grove, California at the historic Asilomar Hotel and Conference Grounds (Table 2). There the Asilomar AI Principles were signed by leading AI researchers, ethicists, and thought leaders. </p> <p>By 2021, UNESCO had created their own recommendations on AI, focused on human rights and sustainable development.</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#table-2-international-ai-agreements","level":4,"title":"Table 2: International AI agreements","text":"Agreement Date Signatories Description Asilomar AI Principles January 2017 AI researchers, ethicists, and thought leaders A set of 23 principles designed to guide the development of beneficial AI, covering research, ethics, and long-term issues. Toronto Declaration May 16, 2018 Amnesty International, Access Now, Human Rights Watch, Wikimedia Foundation, and others A declaration advocating for the protection of the rights to equality and non-discrimination in machine learning systems. OECD AI Principles May 22, 2019 OECD member countries and others Principles to promote AI that is innovative and trustworthy and that respects human rights and democratic values. G20 AI Principles June 9, 2019 G20 member countries A commitment to human-centered AI, building upon the OECD AI Principles, emphasizing inclusivity, transparency, and accountability. WHO Ethics and governance of artificial intelligence for health June 2021 WHO Ministries of Health members A guidance on  eighteen months of deliberation amongst experts from Ministries of Health UNESCO Recommendation on the Ethics of Artificial Intelligence November 2021 UNESCO member states A global framework to ensure that digital transformations promote human rights and contribute to the achievement of the Sustainable Development Goals. European Union Artificial Intelligence Act July 2024 EU member countries Classifies risk, obligations, legal, and general purpose AI laws UN Resolution A/RES/79/325 August 2025 United Nations Resolution Created the Scientific Panel on AI (like the IPCC for AI) <p>In response to the rapid rise of generative AI, specifically GPTs, new agreements on the application of AI for military use, safety, and on its adoption in business and industry were recently signed (Table 3).</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#table-3-declarations-on-ai","level":4,"title":"Table 3: Declarations on AI","text":"Agreement Date Signatories Description Source Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy February 16, 2023 United States and 50 other countries A declaration outlining principles for the responsible use of AI and autonomy in military applications. U.S. Department of State International Network of AI Safety Institutes May 2024 United Kingdom, United States, Japan, France, Germany, Italy, Singapore, South Korea, Australia, Canada, European Union A network formed to evaluate and ensure the safety of advanced AI models through international collaboration. The Independent AI Safety Agreement between the UK and US June 2024 United Kingdom, United States An agreement to collaborate on testing advanced AI models to ensure safety and manage risks. BBC News Framework Convention on Artificial Intelligence September 5, 2024 United States, United Kingdom, European Union, Andorra, Georgia, Iceland, Norway, Republic of Moldova, San Marino, Israel The first legally binding international treaty on AI, aiming to ensure AI activities are consistent with human rights, democracy, and the rule of law. Council of Europe AI Alliance Network December 11, 2024 Russia, BRICS countries (Brazil, China, India, South Africa), Serbia, Indonesia, and others An initiative to develop AI collaboratively, focusing on joint research, regulation, and commercialization of AI products among member countries. Reuters","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#current-legislation","level":2,"title":"Current Legislation","text":"<p>National Conference of State Legislatures (NCSL) Artificial Intelligence 2025 Legislation</p> <p>The previous administration had proposed a \"Blueprint for an AI Bill of Rights\", and executive order around the \"Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence\" which is now rescinded. </p> <p>The current administration has instead focused most of its efforts on executive orders related to AI and federal agencies. Pending legislation would ban states' ability to enforce AI regulations. </p> <p>2025 Executive Orders</p> <ul> <li> <p>REMOVING BARRIERS TO AMERICAN LEADERSHIP IN ARTIFICIAL INTELLIGENCE, January 23, 2025</p> </li> <li> <p>OMB Accelerating Federal Use of AI through Innovation, Governance, and Public Trust, April 3, 2025</p> <ul> <li>Fact Sheet: Eliminating Barriers for Federal Artificial Intelligence Use and Procurement, April 7, 2025</li> </ul> </li> <li> <p>ADVANCING ARTIFICIAL INTELLIGENCE EDUCATION FOR AMERICAN YOUTH, April 23, 2025</p> </li> <li> <p>Restoring Gold Standard Science, May 23, 2025</p> <ul> <li>Fact Sheet: President Donald J. Trump is Restoring Gold Standard Science in America</li> </ul> </li> </ul> <p>As of today, there are no comprehensive federal laws or regulations that have been enacted to specifically regulate AI in the United States of America.  </p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#ai-ethics","level":2,"title":"AI Ethics","text":"What are we talking about, the Ethics of AI, or Ethical AI? How are they different? <p>They are not the same thing</p> <p>Siau and Wang 2020 delineate \"Ethics of AI\" and \"Ethical AI\" as</p> <p>Ethics of AI: studies the ethical principals, rules, guidelines, policies, and regulations related to AI.</p> <p>Ethical AI: is AI that performs or behaves ethically. </p> <p>As consumers of GPTs and other AI platforms, we must consider in what ways can we use AI both effectively, and ethically.</p> <p>When can you use a GPT for research and education?</p> <pre><code>graph TB\n  A((Start)) --&gt; B(\"Does it matter if the outputs are true?\");\n  B --&gt;| No | F(\"Safe to use GPT\");\n  B --&gt;| Yes | C(\"Do you have the ability to verify output truth and accuracy?\");\n  C --&gt;| Yes | D(\"Understand legal and moral responsibility of your errors?\");\n  C --&gt;| No | E(\"Unsafe to use GPT\");\n  D --&gt;| Yes | F(\"Safe to use GPT\");\n  D --&gt;| No | E(\"Unsafe to use GPT\");\n\n  style A fill:#2ECC71,stroke:#fff,stroke-width:2px,color:#fff\n  style B fill:#F7DC6F,stroke:#fff,stroke-width:2px,color:#000\n  style C fill:#F7DC6F,stroke:#fff,stroke-width:2px,color:#000\n  style D fill:#F7DC6F,stroke:#fff,stroke-width:2px,color:#000\n  style E fill:#C0392B,stroke:#fff,stroke-width:2px,color:#fff\n  style F fill:#2ECC71,stroke:#fff,stroke-width:2px,color:#fff</code></pre> <p>Figure credit:  ChatGPT and Artificial Intelligence in Education, UNESCO 2023 </p> <p></p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#recent-controversy","level":2,"title":"Recent Controversy","text":"","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#maps-of-ai-copyright-lawsuits","level":3,"title":"Maps of AI Copyright Lawsuits","text":"<p> Master list of current lawsuits against AI companies</p> <p>Current AI models are overwhelmingly based on European and North American historical literature and language. Over half of the content on the internet () is written in English. This creates a Eurocentric bias in AI training data, resulting in an erasure of global culture, experience, and language. Such asymmetries need to be addressed, but there is at present a lack economic incentives for large tech companies and organizations (see The Imitation Game  above). </p> <p>The   Bullshit Machines</p> <p>Professors Carl T. Bergstrom and Jevin D. West teach a course at University of Washington titled \"Calling Bullshit\", they have written an e-book on GPTs called:</p> <p>\"Modern-Day Oracles or Bullshit Machines?\"</p> <p>Their website provides online lesson vignettes and materials for instructors.</p> <p>Negative consequences of GPTs explosion into the public space are its mis-use as well as its adoption for illegal activity. </p> <ul> <li> <p>A lawyer submits a legal brief written by ChatGPT and is caught</p> </li> <li> <p>Prompt Injection Attacks</p> </li> </ul> <p>There are deep ethical concerns about the use of AI like GPT and LLMs, particularly concerning their training data. </p> <ul> <li>A Class Action lawsuit: GitHub CoPilot was trained on private repositories</li> </ul> <p>AI companies also effectively steal designs, visual art, and music styles to train their private models. </p> <ul> <li>MidJourney and Dall-E using trademarked imagery and art</li> </ul> <p>ChatGPT has effectively gamified higher education and is being used to spread disinformation and hate speech. </p> <ul> <li> <p>College students using ChatGPT</p> </li> <li> <p>Combating Academic Dishonesty (6-part series)</p> </li> </ul>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#recent-literature","level":2,"title":"Recent Literature","text":"<p>Here are some recent papers that discuss the ethical concerns surrounding AI:</p> <ul> <li> <p>\"AI Safety and the Age of Convergences\" (2024) - Schuett, J., Schuett, J., &amp; Korinek, A. https://doi.org/10.48550/arXiv.2401.06531</p> </li> <li> <p>\"On the Opportunities and Risks of Foundation Models\" (2023) - Bommasani et al. https://doi.org/10.48550/arXiv.2108.07258</p> </li> <li> <p>Unraveling the Ethical Conundrum of Artificial Intelligence: A Synthesis of Literature and Case Studies Poli, P.K.R., Pamidi, S. &amp; Poli, S.K.R. Augment Hum Res 10, 2 (2025). https://doi.org/10.1007/s41133-024-00077-5</p> </li> <li> <p>\"The Ethics of Artificial Intelligence in Education: A Review of the Literature\" (2023) - Zawacki-Richter, O., Marín, V. I., Bond, M., &amp; Gouverneur, F. https://doi.org/10.1007/s10639-019-09882-z</p> </li> <li> <p>\"The Ethical Challenges of Algorithmic Bias in Artificial Intelligence: a scoping review\" (2023) - Borenstein, J., Glikson, E., &amp; Krishnamurthy, V. https://doi.org/10.1007/s43681-023-00313-z</p> </li> <li> <p>\"Ethics of Artificial Intelligence\" (2020) - S. Matthew Liao https://doi.org/10.1093/oso/9780190905033.001.0001</p> </li> <li> <p>The Ethics of AI Ethics: An Evaluation of Guidelines. (2020) Hagendorff, T.  Minds &amp; Machines 30, 99–120. https://doi.org/10.1007/s11023-020-09517-8</p> </li> </ul>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"legal/#assessment","level":2,"title":"Assessment","text":"True or False: The \"Turing Trap\" primarily warns against the socio-economic disruptions and misaligned incentives that arise from an overemphasis on creating AI that imitates human intelligence. True <p>The Turing Trap by Stanford University professor Erik Brynjolfsson describes the idea that focusing too much on developing human-like artificial intelligence (HLAI) is detrimental. </p> <p>Brynjolfsson further elaborates risks like lower wages, loss of economic power, and misaligned incentives due to automation replacing humans.</p> True or False: The concepts of \"Ethics of AI\" and \"Ethical AI\" are fundamentally distinct. True <p>Siau and Wang (2020): \"Ethics of AI: studies the ethical principals, rules, guidelines, policies, and regulations related to AI.\" and \"Ethical AI: is AI that performs or behaves ethically.\" </p> Multiple Choice: According to Floridi &amp; Cowls' (2019) \"Unified Framework of Five Principles for AI in Society,\" which principle most directly underscores the importance of AI systems being designed to be understandable, traceable, and accountable for their operations and decisions? <ul> <li>A) Beneficence </li> <li>B) Non-Maleficence </li> <li>C) Justice </li> <li>D) Explicability </li> </ul> Answer <p>D) Explicability</p> <p>Table 1 from Floridi &amp; Cowls (2019) describes Explicability as \"Enabling the Other Principles through Intelligibility and Accountability.\" This directly relates to AI systems being understandable, traceable, and accountable.</p> Multiple Choice: The Asilomar AI Principles, established in 2017, are best characterized as: <ul> <li>A) A legally binding international treaty mandating specific safety protocols for all AI development.</li> <li>B) A technical specification for building universally safe Artificial General Intelligence.</li> <li>C) A foundational set of guiding principles addressing research ethics, societal values, and long-term considerations for developing beneficial AI.</li> <li>D) A corporate social responsibility charter adopted exclusively by major technology companies.</li> </ul> Answer <p>C) A foundational set of guiding principles addressing research ethics, societal values, and long-term considerations for developing beneficial AI.</p> <p>Table 2 describes the Asilomar AI Principles as \"A set of 23 principles designed to guide the development of beneficial AI, covering research, ethics, and long-term issues.\" This aligns with option C and not with the descriptions of a legally binding treaty, a technical specification, or an exclusive corporate charter.</p> What recent international agreement is the \"first legally binding international treaty on AI,\" specifically designed to ensure that AI activities are developed and applied in a manner consistent with human rights, democracy, and the rule of law. What is the name of this treaty? Success <p>Framework Convention on Artificial Intelligence</p> <p>Table 3 lists the Framework Convention on Artificial Intelligence (September 5, 2024) with the description: \"The first legally binding international treaty on AI, aiming to ensure AI activities are consistent with human rights, democracy, and the rule of law.\"</p> True or False: The United States has the strongest regulations and most comprehensive federal laws specifically enacted to regulate AI. False <p>The US has no laws around the regulation of AI to-date. Current legislation around AI is happening at a state level, but that may be stopped by federal legislation banning regulation. Currently, the administration favors Executive Orders.</p> <p>On the other side of the pond, the EU has proposed and is developing regulations through the European Union Artificial Intelligence Act (2024-2031).</p>","path":["Ethics","Ethical &amp; Legal Considerations"],"tags":[]},{"location":"mcp/","level":1,"title":"Model Context Protocol (MCP)","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"mcp/#what-is-model-context-protocol-mcp","level":2,"title":"What is Model Context Protocol (MCP)?","text":"<p>Model Context Protocol (MCP) is a standardized communication framework designed to allow Large Language Models (LLMs) and other AI tools to access and understand the context of what a user is currently working on within various applications.</p> <p>Think of it as a universal translator and information bridge. It enables your AI assistant to \"see\" and \"interact with\" the content and state of your active applications—be it your code editor, a 3D modeling suite, a design tool, or a document processor.</p> <p>Core Purpose of MCP:</p> <ul> <li>Deepen AI Understanding: By providing LLMs with rich, real-time context from applications, MCP allows them to offer far more accurate, relevant, and integrated assistance. Instead of generic advice, the AI can give specific, actionable suggestions based on your current work.</li> <li>Enable Interoperability: MCP aims to create a common ground for different software tools and AI models to share contextual information seamlessly. This breaks down the traditional silos between applications, allowing for more fluid workflows.</li> <li>Facilitate Dynamic Interaction: MCP is not just about reading context; it can also be about acting on it. This opens the door for AI to suggest modifications, automate tasks, or even co-create content directly within the host application. This is a key component of what some call \"Vibe Coding\" or \"Contextual AI Assistance,\" where the AI has a deep, almost intuitive understanding of the project's flow and the user's intent.</li> </ul> <p>Why is MCP Important?</p> <p>As AI becomes increasingly integrated into professional and creative workflows, the need for it to understand the specifics of our work is paramount. Generic LLMs are powerful, but MCP unlocks a new level of utility by making them context-aware and application-aware.</p>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"mcp/#how-mcp-works-the-core-components","level":2,"title":"How MCP Works: The Core Components","text":"<p>MCP typically operates on a client-server model and defines the rules for how contextual information is exchanged.</p> <pre><code>flowchart LR\n    subgraph \"Your Computer\"\n        Host[\"VS Code\"]\n        S1[\"MCP Weaviate\"]\n        S2[\"MCP GitHub\"]\n        S3[\"MCP iRODS\"]\n        S4[\"MCP Fetch\"]\n        Host &lt;--&gt;|\"MCP Protocol\"| S1\n        Host &lt;--&gt;|\"MCP Protocol\"| S2\n        Host &lt;--&gt;|\"MCP Protocol\"| S3\n        Host &lt;--&gt;|\"MCP Protocol\"| S4\n        S1 &lt;--&gt; D1[(\"Constellate JSON\")]\n        S2 &lt;--&gt; D2[(\"Git Code Repository\")]\n    end\n    subgraph \"Internet\"\n        S3 &lt;--&gt;|\"Web APIs\"| D3[(\"Data Store\")]\n        S4 &lt;--&gt;|\"Web APIs\"| D4[(\"Website\")]\n    end</code></pre> <ul> <li> <p>MCP Servers (Providers):</p> <ul> <li>These are often implemented as extensions, plugins, or add-ons within host applications (e.g., a VS Code Server Extension, a Blender Add-on).</li> <li>Their primary role is to expose relevant contextual information from the application. This might include:<ul> <li>The content of the currently open file(s).</li> <li>User selections (text, objects, layers).</li> <li>Project structure or scene graphs.</li> <li>Application state (e.g., current tool, mode, error messages).</li> <li>Undo/redo history (in more advanced scenarios).</li> </ul> </li> <li>MCP Servers listen for requests from MCP Clients and respond with structured context snippets.</li> <li>They may also expose capabilities for the client to invoke actions within the application.</li> </ul> </li> <li> <p>MCP Clients (Consumers):</p> <ul> <li>These are typically LLMs, AI assistants (like a conceptual Claude Desktop with MCP capabilities), or other tools that need to consume context.</li> <li>They request context from MCP Servers to better understand the user's environment and intent.</li> <li>This context is then used by the LLM to:<ul> <li>Generate more relevant and accurate responses.</li> <li>Offer context-specific suggestions.</li> <li>Formulate requests for actions to be performed in the host application.</li> </ul> </li> </ul> </li> <li> <p>The Protocol Specification:</p> <ul> <li>This is the heart of MCP. It defines the rules of engagement:<ul> <li>Message Formats: How data is structured (commonly JSON or similar).</li> <li>Transport Mechanisms: How messages are sent (e.g., WebSockets, HTTP, gRPC, or other Inter-Process Communication (IPC) methods).</li> <li>Discovery: How clients find and connect to available MCP servers.</li> <li>Context Types: Standardized ways to describe different kinds of context (e.g., <code>text_document_v1</code>, <code>selection_v1</code>, <code>blender_scene_graph_v1</code>). This ensures both client and server understand the data being exchanged.</li> <li>Request/Response Patterns: Defines how clients ask for context (or actions) and how servers provide it (or confirm actions).</li> <li>Capabilities Negotiation: A way for client and server to understand what context types and actions each supports.</li> </ul> </li> </ul> </li> </ul> <p>Simplified Communication Flow:</p> <ol> <li>Discovery &amp; Connection: The MCP Client (e.g., Claude Desktop) discovers and establishes a connection with an MCP Server running in a target application (e.g., Blender). This might happen automatically on application launch or upon user command.</li> <li>User Interaction / AI Trigger: The user asks the AI a question or performs an action that triggers the AI to seek more context.</li> <li>Context Request: The MCP Client sends a request to the MCP Server for specific types of context relevant to the user's query or the AI's needs.</li> <li>Context Provision: The MCP Server gathers the requested information from the host application and sends it back to the Client as one or more context snippets.</li> <li>LLM Processing: The Client (or the LLM it interfaces with) processes the user's original prompt enriched with the received context.</li> <li>Informed Response / Action Invocation:<ul> <li>The LLM generates a more informed and relevant response to the user.</li> <li>Alternatively, the LLM might decide an action is needed within the host application. It would then instruct the MCP Client to send an \"action request\" to the MCP Server.</li> </ul> </li> <li>Action Execution &amp; Feedback (if applicable): The MCP Server receives the action request, validates it, and attempts to perform the action using the host application's APIs. It then sends a response back to the client indicating success or failure.</li> </ol>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"mcp/#benefits-of-using-mcp","level":2,"title":"Benefits of Using MCP","text":"<ul> <li>Hyper-Relevant AI Assistance: LLMs can provide advice, code, or content that is directly applicable to the task at hand.</li> <li>Seamless Workflow Integration: AI becomes a \"native\" part of the application experience, rather than a separate tool requiring constant copy-pasting.</li> <li>Reduced Cognitive Load &amp; Task Switching: Users get help where they are, minimizing disruption.</li> <li>Powerful Automation Capabilities: Enables AI to perform routine or complex tasks within applications on the user's behalf.</li> <li>Enhanced \"Vibe Coding\": The AI can better anticipate needs and understand the nuances of a project by having access to its evolving state.</li> <li>Cross-Application Coordination (Future Potential): Imagine an AI orchestrating tasks across multiple MCP-enabled applications.</li> </ul>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"mcp/#key-takeaways","level":2,"title":"Key Takeaways 🚀","text":"<ul> <li>MCP is a Context Bridge: It connects LLMs to the live working environments of applications.</li> <li>Client-Server Model: Applications (via Servers/Add-ons) provide context and action capabilities; AI tools (Clients) consume and utilize them.</li> <li>Standardization is Crucial: A well-defined protocol (message formats, context types, action IDs) is essential for interoperability.</li> <li>Beyond Information Retrieval: MCP enables AI to become an active participant by invoking actions within tools.</li> <li>The Future is Integrated: MCP and similar protocols are foundational for building truly integrated AI co-pilots and assistants that enhance \"Vibe Coding\" and other context-rich workflows.</li> <li>Still Evolving: While the concepts are powerful, widespread adoption, robust implementations, and universally accepted standards for MCP are areas of active development in the AI and software industries.</li> </ul>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"mcp/#further-exploration-discussion-points","level":2,"title":"Further Exploration &amp; Discussion Points 📚","text":"<ul> <li>Security Implications: How do we ensure that MCP connections are secure and that AI actions are sandboxed or require user confirmation for sensitive operations?</li> <li>Granularity of Context: What is the \"right\" amount of context? Too little is unhelpful; too much can be overwhelming or slow.</li> <li>Discoverability: How can users and AI clients easily discover which applications support MCP and what capabilities they offer?</li> <li>User Experience: How should AI interactions mediated by MCP be presented to the user to be intuitive and non-intrusive?</li> <li>Real-world Implementations: Research existing VS Code extensions or other tool integrations that use similar context-sharing mechanisms (even if not formally labeled \"MCP\"). What can we learn from them?</li> <li>Your Tools: Think about the applications you use daily. How could MCP enhance your workflow with them if an AI could understand and interact with their context?</li> </ul> <p>This workshop provides a foundational understanding of Model Context Protocol. As AI continues to weave itself into the fabric of our digital tools, protocols like MCP will be instrumental in shaping a more intelligent, responsive, and collaborative future.</p>","path":["Research","Model Context Protocol (MCP)"],"tags":[]},{"location":"microsoft/","level":1,"title":"Microsoft Copilot","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Setup","Microsoft Copilot"],"tags":[]},{"location":"microsoft/#connect-through-your-university-account","level":2,"title":"Connect through your University Account","text":"<p>Make sure you're logged into your Arizona account in the browser, for example through Outlook or Microsoft Office 365</p> <p>Go to https://copilot.cloud.microsoft/</p> <p>Select the \"Enterprise\" option to log in with your <code>@arizona.edu</code> email address</p>","path":["Setup","Microsoft Copilot"],"tags":[]},{"location":"microsoft/#enterprise-data-protection","level":2,"title":"Enterprise data protection","text":"<p>Once logged in, you should see a  shield icon that shows that you have Enterprise Data Protection turned on.</p>","path":["Setup","Microsoft Copilot"],"tags":[]},{"location":"microsoft/#integration-with-microsoft-365","level":2,"title":"Integration with Microsoft 365","text":"<p>The Microsoft 365 app is migrating to Microsoft Copilot at m365.cloud.microsoft.</p> <p>Announcements made by Microsoft in fall 2024 suggest Copilot release in OneDrive early 2025.</p>","path":["Setup","Microsoft Copilot"],"tags":[]},{"location":"notebooklm/","level":1,"title":"Google NotebookLM","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p></p> <p>Google NotebookLM is an AI tool specifically designed for research, writing, and education. What makes it unique amongst all the chatbots out in the world, is that the tool is restricted to only the resources you give it. This puts guardrails on your conversations and prevents the chatbot from presenting information with unknown sources. If you want to work directly with just the sources you trust, NotebookLM is a great choice. </p>","path":["Research","Google NotebookLM"],"tags":[]},{"location":"notebooklm/#key-features-limitations","level":2,"title":"Key Features &amp; Limitations","text":"<ul> <li> <p>Organization</p> <p>The user interface is a bit different than most chatbots. NotebookLM is organized around the concept of a notebook. A notebook is a digital container where resources for a single topic live. You could have a notebook for a class you are teaching or a notebook for a research paper literature review. </p> </li> </ul> <p></p> <ul> <li> <p>Accepted Source Formats</p> <p>PDFs, .txt, markdown, audio (e.g., mp3), html text from a website, text transcripts from Youtube videos. You can drag and drop files or upload files from Google Drive.  </p> </li> <li> <p>Conversation Bounds</p> <p>The conversations you have with the chatbot will just be about the sources you provide. You cannot talk about random topics outside of your resources. You also cannot have the chatbot search the internet. </p> </li> <li> <p>Designed Specifically for Language</p> <p>NotebookLM is designed for reading and writing. It does not analyze quantitative data. </p> </li> <li> <p>Inline Citations</p> <p>Any answered questions or responses will include citations showing you exactly where the information came from.</p> </li> <li> <p>Conversations are Ephemeral but Notes are Permanent</p> <p>If you would like generated text to persist between session, save them as notes. </p> </li> <li> <p>Share your Notebook</p> <p>Just like a Google Doc, users can share the notebook with anyone with different levels of permission. </p> </li> <li> <p>Audio Overview </p> <p>For any notebook you create, users have the option to create an audio overview of the content. This consists of a podcast style media where two hosts talk intelligently about the content. The quality of the AI generated podcast may surprise you!</p> </li> </ul> <p> </p>","path":["Research","Google NotebookLM"],"tags":[]},{"location":"notebooklm/#usage-ideas","level":2,"title":"Usage Ideas","text":"<p>Research Uses:</p> <ul> <li>Literature Reviews:  Upload research papers, articles, and conference proceedings. NotebookLM can quickly identify key themes, summarize findings, and highlight gaps in the existing literature, significantly speeding up the literature review process.</li> <li>Data Analysis:  Analyze qualitative data like interview transcripts or open-ended survey responses by identifying patterns, themes, and key quotes.</li> <li>Hypothesis Generation:  Explore connections between different research sources and brainstorm new research questions or hypotheses based on synthesized knowledge.</li> <li>Grant Proposal Writing:  Organize background research, synthesize relevant literature, and identify key arguments to strengthen grant proposals.</li> <li>Staying Up-to-Date: Researchers can continuously upload new publications in their field and use NotebookLM to stay informed about the latest advancements and emerging trends.</li> </ul> <p></p> <p>Education/Teaching Uses:</p> <ul> <li>Teachers can create a notebook that includes all the material for a given class (syllabus, schedule, lecture notes, textbook chapters, research articles)</li> <li>The teacher can share the notebook with all the students with read-only permission. </li> <li>Teachers can generate quizes on the notebook content.</li> <li>Students have an LLM chatbot restricted to just the course content where they can ask it any questions related to the class. </li> </ul> <p></p> <p>General Productivity:</p> <ul> <li>Use NotebookLM to help you customize your resume and cover letter for a specific job posting</li> <li>Meeting Preparation: Upload meeting agendas, pre-reads, and background documents. NotebookLM can summarize key discussion points, identify action items, and prepare you for productive meetings. </li> </ul>","path":["Research","Google NotebookLM"],"tags":[]},{"location":"notebooklm/#notebooklm-plus","level":2,"title":"NotebookLM Plus","text":"<p>Like most Google products, NotebookLM has a freemium model where the tool is available for free to anyone, but with limitations. Power users can get NotebookLM Plus for a subscription fee. Please check the technical documentation for how to get NotebookLM Plus.</p>","path":["Research","Google NotebookLM"],"tags":[]},{"location":"ollama/","level":1,"title":"Ollama","text":"","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#install-ollama","level":2,"title":"Install Ollama","text":"<pre><code>curl -fsSL https://ollama.com/install.sh | sh\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#run-ollama","level":2,"title":"Run Ollama","text":"<p>Pick a model:</p> <p>https://ollama.com/library</p> <p>The smallest distilled model:</p> <pre><code>ollama run deepseek-r1:1.5b\n</code></pre> <p>Let's use a bigger model, <code>DeepSeek-R1-Distill-Llama-8B</code> </p> <pre><code>ollama run deepseek-r1:8b\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#talk-to-ollama-in-the-terminal","level":2,"title":"Talk to Ollama in the Terminal","text":"<p>Once the program starts running, you can access it from the terminal. </p>","path":["Research","Ollama"],"tags":[]},{"location":"ollama/#talk-to-ollama-in-a-jupyter-notebook","level":2,"title":"Talk to Ollama in a Jupyter Notebook","text":"<p>Open a Notebook using the Pytorch kernel</p> <pre><code>import ollama\n</code></pre>","path":["Research","Ollama"],"tags":[]},{"location":"openai/","level":1,"title":"OpenAI Platform","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>OpenAI Platform allows developers to access the API and to integrate powerful AI models developed by OpenAI into their custom applications or systems. </p> <p>The OpenAI API enables users to write code and create custom solutions using OpenAI's language models for various tasks, such as text generation, summarization, and translation.</p>","path":["Research","OpenAI Platform"],"tags":[]},{"location":"openai/#openai-api","level":2,"title":"OpenAI API","text":"<p>Check out the  openai/openai-cookbook repository for  Jupyter Notebook lessons on using OpenAI API</p> <p></p> <p> OpenAI Playground allows you to work with a range of OpenAI models for Chat, Text Completion, Image generation, Embedding, Speech-to-Text, and Fine Tuning your own models.</p>","path":["Research","OpenAI Platform"],"tags":[]},{"location":"openai/#accessing-the-openai-api","level":2,"title":"Accessing the OpenAI API","text":"<p>The OpenAI API allows programmatic access to models like GPT-3.5, GPT-4, DALL·E, and more, enabling integration into applications and research workflows.</p> <p>Signing up for the OpenAI API:</p> <ol> <li> <p>Open the OpenAI Platform: Go to https://platform.openai.com/.</p> </li> <li> <p>Sign up or Log in:</p> <ul> <li>Sign up: If you don’t have an OpenAI account, create one. You can reuse your ChatGPT account credentials.</li> <li>Log in: If you already have an account, log in.</li> </ul> </li> </ol> <p>Creating API Keys:</p> <ol> <li> <p>Navigate to the API Keys page: Click on your profile icon in the top-right corner and select \"View API keys.\"</p> </li> <li> <p>Create a new API key: Click on \"Create new secret key.\"</p> </li> <li> <p>Name your key (optional): Give it a descriptive name for tracking purposes.</p> </li> <li> <p>Copy and securely store your API key: Important: You will not be able to view the full API key again. Store it in a password manager or a secure environment variable.</p> </li> </ol> <p>Treat your API key like a password</p> <p>Do not share it publicly or commit it to version control platforms (like GitHub).</p> <p>Using the OpenAI API: - Documentation: Visit the OpenAI API Reference for guidance, code examples, and model parameters.</p> <ul> <li> <p>Pricing: Review the OpenAI Pricing page for cost details, which are based on the number of tokens processed.</p> </li> <li> <p>Rate Limits: Familiarize yourself with API rate limits to prevent disruptions.</p> <p>Large context windows allow for more extensive prompt engineering and large-document analysis but can increase costs significantly. Plan your usage accordingly.</p> </li> </ul>","path":["Research","OpenAI Platform"],"tags":[]},{"location":"openai/#additional-references-and-useful-links","level":2,"title":"Additional References and Useful Links","text":"<ul> <li>OpenAI Research Index: https://openai.com/research</li> <li>GPT-4 Technical Report: https://arxiv.org/abs/2303.08774</li> <li>OpenAI Teaching Resources: Some institutions have guidance on using AI tools in education. Check your local teaching center or ask your institution’s IT or library services.</li> <li>Privacy and Security: Review OpenAI’s Privacy Policy and ensure compliance with your institution’s guidelines.</li> </ul> <p>Next Steps: - After setting up your account and API keys, proceed to the next section for hands-on prompt engineering exercises and best practices.</p>","path":["Research","OpenAI Platform"],"tags":[]},{"location":"posit/","level":1,"title":"Posit (RStudio)","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>The Posit team has published two LLM chat integrations for RStudio / Positron that work in R and Python</p> <ul> <li> <p>Ellmer</p> </li> <li> <p>Chatlas</p> </li> </ul>","path":["Research","Posit (RStudio)"],"tags":[]},{"location":"prompts/","level":1,"title":"Prompt Engineering","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p></p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#introduction-to-prompt-engineering","level":2,"title":"Introduction to Prompt Engineering","text":"<p>Prompt Engineering is a technique of crafting effective instructions using AI large language models. With modern AI-powered tools like Claude Desktop, ChatGPT, Gemini, and NotebookLM offering capabilities to upload documents, search the web, and process multiple file types, mastering prompt engineering has become essential for productive AI interactions.</p> <p>What You'll Learn</p> <ul> <li>Fundamentals: How AI models process and respond to prompts</li> <li>Modern Features: Leveraging document uploads, web search, and multi-modal inputs</li> <li>Best Practices: Structured approaches to writing effective prompts</li> <li>Advanced Techniques: Context management, chaining, and custom instructions</li> </ul>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#understanding-modern-ai-capabilities","level":2,"title":"Understanding Modern AI Capabilities","text":"","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#core-features-of-todays-ai-tools","level":3,"title":"Core Features of Today's AI Tools","text":"<p>Modern AI assistants have evolved beyond simple text chat:</p> Feature  Claude  ChatGPT  Gemini NotebookLM  CoPilot Document Upload PDFs, text, code PDFs, images, data PDFs, images, GDrive PDFs, Google Docs PDFs, OneDrive Web Search Via MCP Yes Yes Yes Yes Context Window (tokens) 200K 128K 2M Document-based 128K File Analysis Yes Yes Yes Deep analysis Yes Code Execution Yes (MCP) Yes Yes No Yes","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#how-ai-models-process-your-input","level":3,"title":"How AI Models Process Your Input","text":"<p>The Processing Pipeline</p> <ol> <li>Tokenization: Your prompt is broken into smaller units (tokens)</li> <li>Context Assembly: Uploaded documents and conversation history are included</li> <li>Attention Mechanism: The model identifies relevant information</li> <li>Generation: Response is produced token by token</li> <li>Formatting: Output is structured according to your specifications</li> </ol>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#getting-started-basic-prompt-structure","level":2,"title":"Getting Started: Basic Prompt Structure","text":"","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#the-foundation-clear-instructions","level":3,"title":"The Foundation: Clear Instructions","text":"<p>Start with simple, direct prompts before advancing to complex techniques:</p> <pre><code># Basic Prompt\n\"Summarize this research paper in 3 bullet points\"\n</code></pre> <pre><code># Better Prompt\n\"As a research scientist, summarize the key findings from this paper \nin 3 bullet points, focusing on methodology and results\"\n</code></pre> <pre><code># Best Prompt\n\"You are a research scientist reviewing papers for a journal. \nSummarize the attached PDF in 3 bullet points that cover:\n1. Research question and hypothesis\n2. Methodology and sample size\n3. Key findings and limitations\nFormat as a bullet list with sub-points for clarity.\"\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#working-with-documents","level":3,"title":"Working with Documents","text":"<p>Modern AI tools excel at document analysis. Here's how to maximize their potential:</p> <p>Document Upload Best Practices</p> <ul> <li>Specify the document: \"In the attached PDF...\" or \"Based on the uploaded spreadsheet...\"</li> <li>Direct attention: \"Focus on Section 3.2 of the document\"</li> <li>Request specific outputs: \"Create a table comparing the methods described in chapters 2 and 5\"</li> <li>Combine multiple sources: \"Compare the findings in these three papers\"</li> </ul>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#example-multi-document-analysis","level":4,"title":"Example: Multi-Document Analysis","text":"<pre><code>I've uploaded three research papers on climate change. Please:\n\n1. Create a comparison table with columns for:\n   - Paper title and authors\n   - Methodology\n   - Key findings\n   - Limitations\n\n2. Identify common themes across all papers\n\n3. Highlight any contradictory findings\n\nFormat the response with clear headers and use markdown tables.\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#the-craft-framework","level":2,"title":"The CRAFT Framework","text":"<p>For consistent, high-quality results, use the CRAFT framework:</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#context","level":3,"title":"Context","text":"<p>Provide background information and set the scene</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#role","level":3,"title":"Role","text":"<p>Define who the AI should act as</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#action","level":3,"title":"Action","text":"<p>Specify exactly what you want done</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#format","level":3,"title":"Format","text":"<p>Describe how the output should be structured</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#tone","level":3,"title":"Tone","text":"<p>Indicate the style and voice to use</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#craft-example","level":4,"title":"CRAFT Example","text":"<pre><code>Context: I'm preparing a grant proposal for NSF funding on AI in education\n\nRole: Act as an experienced grant writer and education researcher\n\nAction: Review my draft introduction and suggest improvements\n\nFormat: Provide feedback as tracked changes with explanations\n\nTone: Professional, constructive, and encouraging\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#advanced-techniques","level":2,"title":"Advanced Techniques","text":"","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#1-custom-instructions-and-system-prompts","level":3,"title":"1. Custom Instructions and System Prompts","text":"<p>Modern AI platforms allow you to set persistent instructions:</p> <p>'Custom Instructions' or 'System Instructions'</p> <p>Platforms like Gemini and Claude allow you to add \"Custom Instructions\" or \"System Instructions\" as prior prompts, which act as a global rule to subsequent prompt chaining.</p> <p>For example:</p> <pre><code># Project Context\nI'm a data scientist working on machine learning projects.\nAlways provide Python code examples using scikit-learn and pandas.\nInclude docstrings and type hints in all code.\n\n# Response Preferences\n- Be concise but thorough\n- Explain complex concepts with analogies\n- Always cite sources when making factual claims\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#2-leveraging-web-search","level":3,"title":"2. Leveraging Web Search","text":"<p>Most featured GPTs now feature a web browse or search engine capability.</p> <p>Enabling search allows the GPT to use document retrieval on websites and PDFs when reasoning out its response.</p> <pre><code>Search for the latest research on the public health benefits of vaccination published in 2024. \n\nFocus on:\n- Papers from top conferences (AHA, ASPPH, NRHA, ICFMDP)\n- mRNA\n- Bird Flu and COVID\n\nSummarize the top 5 papers with links to the originals.\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#3-multi-modal-prompting","level":3,"title":"3. Multi-Modal Prompting","text":"<p>Combine different input types for richer interactions:</p> <pre><code>I've uploaded:\n1. A screenshot of my dashboard\n2. The underlying data in CSV format\n3. Our brand guidelines PDF\n\nCreate a redesigned dashboard that:\n- Improves data visualization based on best practices\n- Adheres to our brand colors and fonts\n- Highlights the KPIs mentioned in the data dictionary\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#4-prompt-chaining","level":3,"title":"4. Prompt Chaining","text":"<p>Build complex outputs through sequential prompts:</p> <p>Effective Chaining Strategy</p> <ol> <li>Start broad: \"Outline a research paper on sustainable AI\"</li> <li>Zoom in: \"Expand section 3 on energy-efficient training methods\"</li> <li>Refine: \"Add citations and make the tone more academic\"</li> <li>Polish: \"Format according to IEEE standards\"</li> </ol>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#5-using-examples-few-shot-learning","level":3,"title":"5. Using Examples (Few-Shot Learning)","text":"<p>Provide examples to guide the AI's output:</p> <pre><code>I need to classify customer feedback. Here are examples:\n\n\"The product arrived damaged\" → Category: Shipping Issue\n\"Can't log into my account\" → Category: Technical Support\n\"Love the new features!\" → Category: Positive Feedback\n\nNow classify these:\n1. \"The app keeps crashing on startup\"\n2. \"Best purchase I've made this year\"\n3. \"Package was left in the rain\"\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#practical-applications","level":2,"title":"Practical Applications","text":"","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#research-and-analysis","level":3,"title":"Research and Analysis","text":"<pre><code>Analyze the attached dataset (CSV) and:\n1. Identify statistical patterns and outliers\n2. Create visualizations for the top 3 insights\n3. Write a methods section describing the analysis\n4. Suggest additional analyses based on the data\n\nUse pandas profiling techniques and create matplotlib visualizations.\nInclude code that I can run locally.\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#writing-and-editing","level":3,"title":"Writing and Editing","text":"<pre><code>I've uploaded my draft manuscript. Please:\n\n1. Check for consistency in terminology throughout\n2. Ensure all figures are referenced in the text\n3. Verify the citation format matches APA 7th edition\n4. Highlight any unclear passages\n5. Suggest improvements for flow between sections\n\nProvide a tracked-changes version and a summary of major edits.\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#code-development","level":3,"title":"Code Development","text":"<pre><code>Based on the uploaded requirements document:\n\n1. Create a Python class structure for the described system\n2. Include comprehensive docstrings and type hints\n3. Add unit tests for each method\n4. Create a README with installation and usage instructions\n5. Follow PEP 8 style guidelines\n\nUse modern Python features (3.10+) and include error handling.\n</code></pre>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#common-pitfalls-and-solutions","level":2,"title":"Common Pitfalls and Solutions","text":"","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#pitfall-1-vague-instructions","level":3,"title":"Pitfall 1: Vague Instructions","text":"<p>❌ Poor: \"Make this better\"</p> <p>✅ Better: \"Improve this abstract by making it more concise (under 250 words), adding keywords, and ensuring it follows the journal's structure: background, methods, results, conclusions\"</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#pitfall-2-information-overload","level":3,"title":"Pitfall 2: Information Overload","text":"<p>❌ Poor: Uploading 50 documents without guidance</p> <p>✅ Better: \"Focus on documents 1-3 which contain the methodology. Ignore the appendices.\"</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#pitfall-3-assuming-knowledge","level":3,"title":"Pitfall 3: Assuming Knowledge","text":"<p>❌ Poor: \"Fix the usual issues\"</p> <p>✅ Better: \"Check for: passive voice, sentences over 25 words, undefined acronyms, and missing Oxford commas\"</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#pitfall-4-no-output-format","level":3,"title":"Pitfall 4: No Output Format","text":"<p>❌ Poor: \"Summarize this\"</p> <p>✅ Better: \"Create an executive summary with:  - 3-sentence overview - 5 key points as bullets - 1 paragraph on implications - Formatted with markdown headers\"</p>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#quick-reference-card","level":2,"title":"Quick Reference Card","text":"<p>Prompt Engineering Checklist</p> <ul> <li> Clear objective: What do you want to achieve?</li> <li> Context provided: Background information included?</li> <li> Role defined: Who should the AI act as?</li> <li> Specific action: Exact task described?</li> <li> Output format: Structure specified?</li> <li> Examples given: For complex tasks?</li> <li> Constraints noted: Length, style, or content limits?</li> <li> Documents referenced: If using uploads?</li> <li> Follow-up planned: For iterative improvement?</li> </ul>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#assessment-questions","level":2,"title":"Assessment Questions","text":"How do modern AI tools handle uploaded documents? <p>Answer</p> <p>Modern AI tools process uploaded documents by:</p> <ul> <li> <p>Converting them to text (OCR for images/PDFs)</p> </li> <li> <p>Adding them to the context window</p> </li> <li> <p>Allowing specific references (\"In section 2.3...\")</p> </li> <li> <p>Enabling cross-document analysis</p> </li> <li> <p>Maintaining document structure awareness</p> </li> </ul> What's the most important element of an effective prompt? <p>Answer</p> <p>Clarity of instruction is paramount. The AI needs to understand:</p> <ul> <li> <p>What you want done (action)</p> </li> <li> <p>How you want it done (format)</p> </li> <li> <p>Why you want it done (context)</p> </li> </ul> <p>Without clear instructions, even the most advanced AI will produce suboptimal results.</p> How can you ensure consistent outputs across multiple sessions? <p>Answer</p> <ol> <li> <p>Use custom instructions (ChatGPT, Claude) or system prompts</p> </li> <li> <p>Create templates for common tasks</p> </li> <li> <p>Save successful prompts for reuse</p> </li> <li> <p>Use platform features like GPTs or Projects</p> </li> <li> <p>Include examples in your prompts</p> </li> <li> <p>Specify exact formats with templates</p> </li> </ol> True or False: Longer prompts always produce better results <p>False</p> <p>Prompt quality matters more than length. A well-structured, concise prompt often outperforms a lengthy, unfocused one. However, providing sufficient context and clear instructions is important. Aim for:</p> <ul> <li> <p>Completeness over brevity</p> </li> <li> <p>Clarity over complexity</p> </li> <li> <p>Structure over stream-of-consciousness</p> </li> </ul>","path":["Prompt Engineering"],"tags":[]},{"location":"prompts/#further-resources","level":2,"title":"Further Resources","text":"<ul> <li> <p> Anthropic's Prompt Engineering Guide</p> </li> <li> <p> OpenAI's Best Practices</p> </li> <li> <p> Google's Gemini Prompting Strategies</p> </li> <li> <p> Awesome ChatGPT Prompts</p> </li> <li> <p>Learn Prompting Online Courses</p> </li> </ul>","path":["Prompt Engineering"],"tags":[]},{"location":"rag/","level":1,"title":"Retrieval Augmented Generation (RAG)","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>One of the more recent applications of GPTs is the use of vector databases with specific documentation text or imagery. </p> <p>Retrieval Augmented Generation (RAG) can be used to search through large corpuses of text, or specific texts for data mining and research applications.</p> <p>Real world examples of Agentic AI include self-driving vehicles, warehouse robots, and high frequency trading bots. </p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#how-it-works","level":2,"title":"How it works","text":"<p>RAG databases allow you to host your own private data</p> <p>Open Source projects like Weaviate or Pinecone allow you to self-host private data.</p> <p>Table: Popular RAG database software:</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#embeddings","level":3,"title":"Embeddings","text":"<p>Text passages (or other data, like images) are transformed into numerical representations known as “embeddings.” These embeddings capture semantic meaning, so similar concepts end up being close together in vector space.</p> Understanding Embeddings <p>What are Embeddings? - Vicki Boykis - download PDF </p> <p>Embeddings are a way to represent data (words, images, etc.) as numerical vectors in a multi-dimensional space. These vectors capture semantic relationships between data points, meaning similar items are located closer together in the embedding space.</p> <p>Embedded space for geospatial applications:</p> <p><p>Visualizing how embeddings can organize satellite imagery. Millions of points covering the state of Alabama move between their geographic position and their location in the embedding space. pic.twitter.com/Z6FtoMQ84B</p>— Caleb Kruse (@clkruse) May 15, 2023 </p> <p>Embedded space for natural language:</p> <p>Credit: Stephen Wolfram</p> <p></p> <p>Why are Embeddings Important?</p> <ul> <li>Machine Learning: Embeddings are essential for training machine learning models, as they provide a way to represent complex data in a format that algorithms can understand.</li> <li>Semantic Search:  Embeddings enable semantic search, where you can find information based on meaning rather than just keyword matching.</li> <li>Recommendation Systems: Embeddings help power recommendation systems by identifying items with similar characteristics.</li> <li>Data Visualization:  Embeddings can be used to visualize relationships between data points in a lower-dimensional space.</li> </ul>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"rag/#vector-database","level":3,"title":"Vector Database","text":"<p>A vector database stores embeddings efficiently, often using specialized data structures to handle large-scale, high-dimensional searches.</p> <p>OpenAI Platform allows you to upload your own data to a vector store and file search in custom assistants</p>","path":["Research","Retrieval Augmented Generation (RAG)"],"tags":[]},{"location":"research/","level":1,"title":"Overview","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#introduction","level":2,"title":"Introduction","text":"<p>GPTs excel at scientific research, but become specialized rapidly depending upon their application. GPTs and LLMs also fit as a cog within the larger AI ecosystem of natural language processing, and machine learning.</p> <p>When deployed privately into secure data enclaves, GPTs can be used with sensitive and secure data (e.g., FERPA, HIPAA, or CUI) without the risk of data breaches or interception over internet traffic. </p> Generative AI Predictive AI Generative Adversarial Networks (GANs) Linear Regression Variational Autoencoders (VAEs) Logistic Regression Generative Pretrained Transformers (GPTs) Decision Trees Diffusion Models Random Forest Autoregressive Models Support Vector Machines (SVMs) <p>Generative AI and Academic Research</p> <p>Generative AI has revolutionized academic research by enabling the creation of synthetic data, accelerating drug discovery, and aiding in the development of new materials. </p> <ul> <li>Synthetic Data Generation: GANs can create realistic synthetic datasets, addressing privacy concerns and data scarcity.</li> <li>Drug Discovery: Generative models can design novel drug molecules with desired properties.</li> <li>Material Science: AI-powered generative design can optimize material properties for specific applications.</li> </ul> <p>Predictive AI and Climate Modeling</p> <p>Predictive AI plays a crucial role in climate modeling by analyzing historical data to forecast future climate patterns.</p> <ul> <li>Climate Change Prediction: Machine learning models can predict temperature changes, sea-level rise, and extreme weather events.</li> <li>Climate Impact Assessment: AI-powered tools can assess the impact of climate change on ecosystems and human societies.</li> </ul> <p>Predictive AI and Protein Folding</p> <p>Predictive AI has made significant strides in protein folding, a fundamental challenge in biology.</p> <ul> <li>Protein Structure Prediction: Deep learning models like AlphaFold can accurately predict protein structures from amino acid sequences.</li> <li>Drug Design: Understanding protein structures enables the design of targeted drugs.</li> </ul> <p>Generative AI and Language Models</p> <p>Generative AI, particularly GPTs, has significantly advanced Natural Language Processing (NLP). These models are trained on massive amounts of text data and can generate human-quality text, translate languages, write different kinds of creative content, and answer your questions in an informative way.</p> <p>Generative AI and Retrieval Augmented Generation</p> <p>Retrieval Augmented Generation (RAG) combines the strengths of generative AI and information retrieval. It allows models to access and incorporate relevant information from external sources, improving the quality and factual accuracy of generated text.</p> <p>Predictive AI and Machine Learning</p> <p>Predictive AI is a subset of machine learning that focuses on forecasting future trends and outcomes. It leverages statistical techniques and algorithms to analyze historical data and make predictions.</p> <p>Predictive AI and Transformers</p> <p>Transformers, a type of neural network architecture, have revolutionized predictive AI. They are particularly effective in tasks like time series forecasting, natural language processing, and computer vision.</p> <p>Predictive AI, Stable Diffusion, and Generative AI</p> <p>While Stable Diffusion is a powerful generative AI model, it is not directly related to predictive AI. Generative AI, on the other hand, can be used to generate synthetic data for training predictive models, enhancing their performance and robustness.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#workshop-lessons","level":2,"title":"Workshop Lessons","text":"<p>Specific to this workshop, we focus on code interpreters and code execution using GPTs, but we will also touch upon the creation and deployment of custom AI applications and how to use commercial and open source GPTs for each.</p> <p>In a future workshop we will cover the deployment of secure private GPTs and LLMs in data enclaves </p> <p>Why use GPTs for research?</p> <p>Advantages</p> <ul> <li> <p>Increased Efficiency and Productivity: perhaps the most obvious and enticing reason for using GPTs is to automate tedious and repetitive tasks, creating more time for analyses and research.</p> </li> <li> <p>Accuracy &amp; Objectivity: GPTs analyze data without human bias. </p> </li> <li> <p>Pattern Recogition: GPTs may identify patterns and connections in data that a human cannot.</p> </li> </ul> <p>Disadvantages</p> <ul> <li> <p>Human Oversight: GPTs should not be used to replace human expertise. Researchers must always evaluate and ensure GPT output are factual and align with published research artifacts.</p> </li> <li> <p>Bias: GPTs can reduce human bias, but suffer from their own training biases.</p> </li> <li> <p>Potential Misuse: GPTs can be used to fabricate scientific research papers or manipulate data, undermining the integrity of science.  </p> </li> </ul>","path":["Research","Overview"],"tags":[]},{"location":"research/#literature-review-and-synthesis","level":2,"title":"Literature Review and Synthesis","text":"<p>GPTs are excellent summarization tools. When coupled with large corpuses of published research they can be invaluable for literature review and synthesis. </p> <p>Perplexity.ai has established itself as a popular GPT for search and summary of existing web-based material. </p> <p>Google Deep Research is positioning itself as a platform for in depth prompts on specific topics.</p> <p>Google NotebookLM allows you to personalize your research by providing your own literature or knowledge (files, images, audio).</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#custom-chatgpts-for-literature-review","level":3,"title":"Custom ChatGPTs for Literature Review","text":"","path":["Research","Overview"],"tags":[]},{"location":"research/#scholarai","level":4,"title":"ScholarAI","text":"<p>ScholarAI is the most highly starred  ai research assistant on custom GPTs on ChatGPT for research.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#scholargpt","level":4,"title":"ScholarGPT","text":"<p>ScholarGPT was one of the early custom GPTs created on ChatGPT and has many millions of resources embedded within it. </p>","path":["Research","Overview"],"tags":[]},{"location":"research/#semantic-scholar","level":4,"title":"Semantic Scholar","text":"<p>Semantic Scholar is a free, AI-powered research tool for scientific literature, based at Ai2.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#huggingface","level":3,"title":"HuggingFace","text":"<p>HuggingFace is the dominant registry for AI models and model data. </p>","path":["Research","Overview"],"tags":[]},{"location":"research/#data-analysis","level":2,"title":"Data Analysis","text":"Linux Guru <p>ChatGPT is trained on common data science languages, like Python, Julia, and R. Use ChatGPT to help develop basic code or to explain and debug code you're trying to write. </p> <p>Using ChatGPT can be a time savings, reducing the time it takes to look for the answers yourself over conventional search.</p> <pre><code>I want you to act as a humble data scientist who works a lot with Python and scientific visualization\n\nCreate a Python script which generates a visually pleasing and compelling heat map for a CSV dataset\n</code></pre> <p>You can also use it to summarize code or to help explain its operation</p> <pre><code>I want you to act as a humble data scientist who works a lot with Linux \n\nExplain to me what the following code does:\n\n$ find /home/www \\( -type d -name .git -prune \\) -o -type f -print0 | xargs -0 sed -i 's/subdomainA\\.example\\.com/subdomainB.example.com/g'\n</code></pre> <p>Other valuable uses:</p> <ul> <li> <p>Change variable names and file names! When you have a large dataset with many files and folder names, you can ask ChatGPT to help design a schema for renaming your project's content</p> </li> <li> <p>Regular Expressions, or <code>regex</code> is a bane of many programmers. ChatGPT can write, edit, and explain complex <code>regex</code></p> </li> </ul> <p>```markdown I want you to act as a regex generator. Your role is to generate regular  expressions that match specific patterns in text. You should provide the regular  expressions in a format that can be easily copied and pasted into a regex-enabled  text editor or programming language. Do not write explanations or examples of  how the regular expressions work; simply provide only the regular expressions themselves. </p> <p>remove any numbers from a string and replace them with a capital X</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#hypothesis-generation","level":3,"title":"Hypothesis generation","text":"<p>Examples of roles you might ask for are: a domain science expert, an IT or DevOps engineer, software programmer, journal editor, paper reviewer, mentor, teacher, or student. You can even instruct ChatGPT to respond as though it were a Linux terminal, a web browser, a search engine, or language interpreter.</p> Data Scientist <p>Let's try an example prompt with role-playing to help write code in the R programming language.</p> <pre><code>I want you to act as a data scientist with complete knowledge of the R language, \nthe TidyVerse, and RStudio. \n\nWrite the code required to create a new R project environment,\nDownload and load the Palmer Penguins dataset, and plot regressions of body mass, \nbill length, and width for the species of Penguins in the dataset. \n\nYour response output should be in R and RMarkDown format \nwith text and code delineated with ``` blocks.\n\nAt the beginning of new file make sure to install any \nRStudio system dependencies and R libraries that Palmer Penguins requires.\n</code></pre> <p>Example can use <code>GPT o1</code> or <code>Gemini 2.0</code> </p> Talk to Dead Scientists <p>Try to ask a question with and without Internet access enabled:</p> <p><pre><code>I want you to respond as though you are the mathematician Benoit Mandelbrot\n\nExplain the relationship of lacunarity and fractal dimension for a self-affine series\n\nShow your results using mathematical equations in LaTeX or MathJax style format\n</code></pre> Again, there is no guarantee that the results ChatGPT provides are factual, but it does greatly improve the odds that they are relevant to the prompt. Most importantly, these extensions provide citations for their results, allowing you to research the results yourself. </p>","path":["Research","Overview"],"tags":[]},{"location":"research/#feedback","level":3,"title":"Feedback","text":"","path":["Research","Overview"],"tags":[]},{"location":"research/#example-3-programming-help","level":3,"title":"Example 3: Programming help","text":"<p>Another impressive application of ChatGPT is in the field of programming. You can use it as a coding assistant, where it can help write code, debug issues, or explain complex code snippets. By asking it to convert your high-level descriptions into code, or to suggest improvements for existing code, you can significantly enhance your programming productivity.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#coding-assistant","level":4,"title":"Coding Assistant","text":"<p>Suppose you're working on a Python program to perform data analysis, but you're not sure how to write a function to calculate the median from a list of numbers. You might use ChatGPT like this:</p> Python median function <pre><code>I'm trying to write a Python function that takes a list of numbers as an argument and returns the median. I'm not sure about the best way to implement this. Could you help me write the code?\n</code></pre> <p>ChatGPT could then provide you with a suitable Python function, demonstrating the logic to calculate the median from a list of numbers.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#debugging","level":4,"title":"Debugging","text":"<p>Let's say you're having trouble with a piece of JavaScript code that's not behaving as expected. You could ask ChatGPT for help as follows:</p> <p>Debugging JavaScript</p> <p><pre><code>my JavaScript code to add event listeners to buttons isn't working as expected. Here's the code:\n</code></pre> <pre><code>let buttons = document.querySelectorAll('.btn');\nfor (let i = 0; i &lt; buttons.length; i++) {\n    buttons[i].addEventListener('click', function() {\n        console.log('Button ' + i + ' clicked');\n    });\n}\n</code></pre> <pre><code>When I click a button, it always logs 'Button 5 clicked', no matter which button I click. What's going wrong, and how can I fix it?\"\n</code></pre></p> <p>ChatGPT could then explain the issue (in this case, a common pitfall with JavaScript closures) and suggest a corrected version of your code.</p> <p>Limitations</p> <p>Remember, while ChatGPT is knowledgeable in many programming languages and concepts, it doesn't replace a full Integrated Development Environment (IDE) or debugger and should be used as a supplementary tool for coding assistance.</p>","path":["Research","Overview"],"tags":[]},{"location":"research/#popular-uses-of-prompt-engineering-in-research-data-science-and-code-interpreters","level":3,"title":"Popular Uses of Prompt Engineering in Research (Data Science and Code Interpreters)","text":"<ul> <li>Data Cleaning and Preprocessing: Automate the process of cleaning and preparing data for analysis, including handling missing values, data normalization, and outlier detection.</li> <li>Code Generation: Generate code snippets for specific data analysis tasks, such as statistical tests, data visualization, and machine learning model implementation.</li> <li>Algorithm Selection and Design: Suggest appropriate algorithms or models based on the characteristics of the data and the research question.</li> <li>Automated Report Writing: Generate summaries of data analysis results, including key findings, visualizations, and interpretations.</li> <li>Literature Review Assistance: Quickly find and summarize relevant research papers, identify key concepts, and extract important information.</li> <li>Hypothesis Generation: Explore potential research questions and hypotheses based on existing data and literature.</li> <li>Experimental Design: Assist in designing experiments, including determining sample sizes, selecting appropriate variables, and suggesting control measures.</li> </ul>","path":["Research","Overview"],"tags":[]},{"location":"teaching/","level":1,"title":"Teaching with AI","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Full Disclosure: Material on this website was copy edited or is based on suggestions made by a GPT</p> <p>Have you integrated AI into your coursework yet?</p> No, and thats OKAY! <p>A thoughtful, wait and see, approach to incorporating AI into your educational material is rational and reasonable.</p> <p>Making the decision to incorporate an AI into your education strategy, student assessment, and grading is no easy task. </p> <p>Further, costs and accessibility issues around AI continue to persist across academia. Underserved institutions and colleges with small budgets, or little investment into IT may not have the ability to meet security requirements needed for secure access to student's coursework or personal data (protected by FERPA).</p> <p>An important fact to consider though is that most of your students are already making use of AI for their assignments and study. (ref:  Source ).</p> <p>Read about  OpenAI Educator Considerations</p> Yes, but go ahead and read on <p>Thats great! </p> <p>Make sure to read through the rest of this section to make sure that you're using GPTs in ways that keep your student's data and personal information safe. </p> <p>Also, ensure that you're using approved AI software that has been vetted by university security and IT staff.</p> <p>GPTs can compose essays, pass advanced tests, and are a threat to academic integrity (Eke 2023). As a result, online education, a recent and lucrative innovation in academia, now faces extreme challenges regarding effective remote student assessment (Susnjak &amp; McIntosh 2024). </p> <p>Attempting to modify coursework to avoid assessment techniques where GPTs excel or using bots to detect GPT generated content are increasingly proven to be futile (Sloan MIT 2024). </p> <p>\"Instead of engaging in a cheating arms race, why not embrace AI?\"</p> <p>Proponents of integrating AI into educational curricula () argue that by adapting and integrating GPTs into the curriculum, we also develop a modern workforce who are empowered by AI assistants. </p> <p>Cain (2023) explores ways in which prompt engineering can be brought into the classroom and \"transition [students] from passive recipients to active co-creators of their learning experiences.\"</p> Pro vs Cons of AI in Economics Classrooms <p>At the 2024 EconEd conference Professor Justin Wolfers examined how AI is revolutionizing economics education by enhancing student learning and easing educators' workloads. In response, Professor Jon Meer discussed how educators are navigating AI integration in the classroom. Meer’s session provides a practical and valuable roadmap for effective implementation.</p> <p>https://www.macmillanlearning.com/college/us/events/econed </p> <p>Justin's Pros presentation: https://www.youtube.com/watch?v=sTeOLgMN4UM</p> <p></p> <p>Jon's Cons presentation: https://www.youtube.com/watch?v=NXbEvLd1vVk</p> <p></p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#security-and-ferpa-considerations-for-gpts-in-higher-education","level":2,"title":"Security and FERPA Considerations for GPTs in Higher Education","text":"<p>The integration of GPTs into classrooms introduces challenges, particularly in terms of data security and compliance with the Family Educational Rights and Privacy Act (FERPA). </p> <p>This section outlines key considerations for educators and administrators.</p> <p>FERPA Protections</p> <p>FERPA protects the privacy of student education records. It gives parents certain rights regarding their children's education records. These rights transfer to the student at 18 years of age or beyond the high school level.</p> <ul> <li>Education Records: Includes files, documents, or other materials that contain information directly related to a student and are maintained by an agency or institution of education.</li> <li>Directory Information: Information contained in an education record that would not generally be considered harmful or an invasion of privacy if disclosed.</li> <li>Rights Under FERPA: Parents and eligible students have the right to inspect and review the student's education records, request the amendment of records they believe are inaccurate or misleading, and have some control over disclosing personally identifiable information from education records.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#generative-ai-and-compliance-with-ferpa","level":2,"title":"Generative AI and Compliance with FERPA","text":"<p>Commercial GPTs, such as those used for creating educational content, chatbots, or data analysis tools, can potentially handle personal or sensitive information. </p> <p>Faculty members must ensure that using these technologies complies with FERPA regulations before using them in the classroom.</p> <p>FERPA mandates the protection of student education records. </p> <p>Before using GPTs in educational settings, remember:</p> <ul> <li>Do not use student education records with Commercial or external AI tools, unless the data falls under directory information, and even then make certain you are compliant with university policy.</li> <li>When using student data, implement data minimization which anonymizes student information to avoid release of personally identifiable information (PII).</li> <li>Be extremely cautious when inputting student data into GPTs, as this can lead to unintended data leaks or exposure of PII.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#identifying-and-securing-student-data","level":3,"title":"Identifying and Securing Student Data","text":"<p>To ensure FERPA compliance:</p> <ul> <li>Consult with your university's information technology and information security unit before using an AI software. Ensure that you only use secure, vetted, platforms that are approved by your university.  </li> <li>Do not use 3<sup>rd</sup> party software (plugins or extensions) to analyze or prompt with student data.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#security-risks-and-mitigation-strategies","level":2,"title":"Security Risks and Mitigation Strategies","text":"","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#data-leakage-and-exposure","level":3,"title":"Data Leakage and Exposure","text":"<ul> <li>Avoid copying sensitive emails, video/audio transcripts, or student information into GPT platforms for summarization or analysis.</li> <li>Educate all staff and teaching assistants on the risks of sharing personal or confidential information with AI systems.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#academic-integrity","level":3,"title":"Academic Integrity","text":"<ul> <li>Develop clear policies on the appropriate use of AI tools for all assignments and exams. The existing Code of Academic Integrity already explains how to deal with cases of plagarism.</li> <li>Implement detection mechanisms to identify AI-generated content in student submissions.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#technical-security-measures","level":3,"title":"Technical Security Measures","text":"<ul> <li>Implement zero-trust security solutions, such as secure web gateways, to control access to GPT tools.</li> <li>Use URL and content filtering to prevent unauthorized data uploads and limit access to AI platforms.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#ethical-considerations","level":3,"title":"Ethical Considerations","text":"<ul> <li>Address potential equity issues arising from unequal access to AI tools among students.</li> <li>Consider the impact of AI on critical thinking skills and social interactions in the learning environment.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#guiding-graduate-students-and-postdoctoral-researchers-in-ai-usage","level":2,"title":"Guiding Graduate Students and Postdoctoral Researchers in AI Usage","text":"<p>Training the next generation of researchers to use AI effectively and ethically is a crucial aspect of graduate mentorship. As an advisor, it is important to ensure that students have appropriate access to these platforms and a comprehensive understanding of the ethical implications for their education, research, and software engineering.</p> <p>Platforms like ChatGPT could potentially become the primary mentor for graduate students and postdoctoral researchers. Unlike human advisors, these AI systems are available 24/7 to address virtually any question or problem. However, it is essential to strike a balance between AI assistance and independent learning.</p> <p>To achieve this balance, advisors should:</p> <p>Encourage AI literacy: Provide students with resources and opportunities to learn about AI technologies, their applications, and their limitations.</p> <p>Teach responsible AI usage: Emphasize the importance of using AI as a tool to support research, not replace critical thinking and problem-solving skills.</p> <p>Discuss ethical considerations: Foster open discussions about the ethical implications of AI in research, including issues of bias, fairness, transparency, and accountability.</p> <p>Promote collaboration: Encourage students to collaborate with AI, leveraging its strengths to overcome their weaknesses and vice versa.</p> <p>Stay updated: As AI technologies continue to evolve, ensure that both advisors and students stay informed about the latest developments, best practices, and potential pitfalls.</p> <p>By incorporating AI into graduate and postdoctoral training while maintaining a focus on ethics and responsibility, the next generation of researchers can harness the power of AI to advance their fields while upholding the highest standards of academic integrity.</p> <p>I will no longer approve graduate student dissertation proposals or dissertations unless they used ChatGPT or a similar AI to help them write part of it! (With appropriate acknowledgment). Yes, I am serious! We're training PhDs to think, not to be robots.</p>— Seth (@DrSethMurray) April 4, 2023","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#teaching-with-chatbots","level":2,"title":"Teaching with Chatbots","text":"<p>ChatGPT and Gemini can improve teaching and learning processes by generating and assessing information and can be used as a standalone tool or  integrated into other systems. It can perform simple or technical tasks and examples show how it can augment teaching and learning.</p> <p>Gemini LearnLM is available in Google's AI Studio and has advanced features for teaching or tutoring.</p> <p>Table: Potential role playing examples for chatbots for teaching and tutoring</p> Role playing Description Example of implementation Possibility engine AI can suggest alternative ways to express an idea Students can write queries in ChatGPT/Gemini and use the \"Regenerate\" response function to explore alternative responses. Socratic opponent AI can act as an opponent to develop an argument Students can enter prompts into ChatGPT/Gemini, using the  structure of a conversation or debate. Teachers can ask their students  to use ChatGPT/Gemini to prepare for discussions. Collaboration coach AI helps groups to research and solve problems together When completing tasks and assignments, students can use ChatGPT/Gemini to find information while working in groups. Guide on the side AI acts as a guide to navigating physical and conceptual spaces Teachers use ChatGPT/Gemini to generate content for their  classes or courses, such as discussion questions, and to seek advice on  how to support students in learning specific concepts. Personal tutor AI tutors each student and gives immediate feedback on progress ChatGPT/Gemini provides personalized feedback to students based on information provided by students or teachers (e.g., test scores). Co-designer AI assists throughout the design process Teachers can seek ideas from ChatGPT/Gemini for designing or  updating a curriculum, including rubrics for assessment. Alternatively,  they can focus on specific goals, such as making the curriculum more  accessible. ChatGPT can provide recommendations and suggestions to help  achieve these objectives. Exploratorium AI provides tools to play with, explore, and interpret data Teachers provide basic information to students who  write different queries in ChatGPT to find out more. ChatGPT/Gemini can be used  to support language learning. Study buddy AI helps the student reflect on learning material Students explain their current level of understanding  to ChatGPT/Gemini and ask for ways to help them study the material. ChatGPT/Gemini  could also be used to help students prepare for other tasks (e.g., job  interviews). Motivator AI offers games and challenges to extend learning Teachers or students ask ChatGPT/Gemini for ideas about how to  extend students’ learning after providing a summary of the current  level of knowledge (e.g., quizzes, exercises). Dynamic assessment AI provides educators with a profile of each student’s current knowledge Students engage in a tutorial-style dialogue with  ChatGPT/Gemini, and then request that ChatGPT/Gemini create a summary of their current  knowledge for sharing with their teacher or for assessment purposes.","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#more-resources-on-ai-at-university-of-arizona","level":2,"title":"More Resources on AI at University of Arizona","text":"<p>University of Arizona Artificial Intelligence </p> <p>University of Arizona Library Student Guide to AI </p> <p>University of Arizona Data Lab AI Workshop Series </p> <p> Google for Education</p> <p>Google offers self-paced courses on generative AI. </p> <p>Register with your @arizona.edu Google account and enroll in this 2-hour workshop:   Generative AI For Educators </p> <p>Teaching with ChatGPT</p> <p>ChatGPT for Teachers by We Are Teachers</p> <p>Using AI in the Classroom by University of Wisconsin Madison</p> <p>ChatGPT Resources for Faculty by University of Pittsburg</p> <p>AI in the Classroom by Greylock Podcast</p> <p>How to handle AI in Schools by CommonSense.org</p>","path":["Education","Teaching with AI"],"tags":[]},{"location":"teaching/#references","level":2,"title":"References","text":"<ul> <li>ChatGPT Cheat Sheet. Neural Magic.</li> <li>ChatGPT Cheat Sheet. Max Rascher.</li> <li>ChatGPT for Studying: How to use the AI-powered chatbot to learn anything you want. StudySmarter.</li> <li>Learn Prompting. </li> <li>Prompt Engineering Guide.</li> <li>The Prompt's The Thing: An Essential Guide to Google Gemini. Skyscape.</li> <li>100+ Creative ideas to use AI in education. Sandra Abegglen, Marianna Karatsiori and Antonio Martinez-Arboleda.</li> <li>200+ Best Gemini AI prompts you can't miss - ChatGPT compatible. TipSeason.</li> </ul>","path":["Education","Teaching with AI"],"tags":[]},{"location":"text_mining/","level":1,"title":"Text Mining Resources","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>This guide provides information on text mining resources</p>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"text_mining/#ai-taxonomy","level":2,"title":"AI Taxonomy","text":"<ul> <li> <p>NIST Artificial Intelligence Risk Management Framework:  refers to an AI system as an engineered or machine-based system that can, for a given set of objectives, generate outputs such as predictions, recommendations, or decisions influencing real or virtual environments. AI systems are designed to operate with varying levels of autonomy.</p> </li> <li> <p>NIST Trustworthy and Responsible AI :  aims to provide a flexible means of classifying how an AI system contributes to an outcome. The taxonomy sets forward 16 AI use “activities” which are independent of AI techniques and domains. Tasks are combinations of one or more AI use activities.</p> </li> <li> <p>Generalist Repository Ecosystem Initiative (GREI) AI Taxonomy: funded by the NIH, developed an AI taxonomy tailored to data repository roles to guide AI integration across repository management. It categorizes the roles into stages, including acquisition, validation, organization, enhancement, analysis, sharing, and user support, providing a structured framework for implementing AI in repository workflows.</p> </li> </ul>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"text_mining/#text-data-sources","level":2,"title":"Text Data Sources","text":"<ul> <li> <p>Constellate: Constellate was the text analytics service from ITHAKA (JSTOR and Portico). It was a platform for teaching, learning, and performing text analysis using archival repositories of scholarly and primary source content. Constellate was sunset in June 2025.</p> <p>Access Note: create a free account with your @arizona.edu email address to obtain full functionality of the platform.</p> </li> <li> <p>Dimensions Plus API: Dimensions Plus includes grants, publications, citations, alternative metrics, clinical trials, patents, and policy documents. Must register with NetID and Password and email support@dimensions.ai to enable API access. </p> </li> <li> <p>Elsevier API: Elsevier's API program allows you to integrate content and data from Elsevier products into your own website and applications. APIs are free for the products Arizona subscribes to: Scopus, Engineering Village, and subscribed journals in Science Direct. </p> </li> <li> <p>Scopus Search: Scopus search API includes basic, advanced, and AI powered queries of the Scopus literature archive.</p> </li> <li> <p>IEEE API Portal: API portal for IEEE. </p> </li> <li> <p>JSTOR for Data Research: Data for Research (DfR) provides datasets of content on JSTOR for use in research and teaching. Researchers may use DfR to define and submit their desired dataset to be automatically processed. Data available through the service includes metadata, n-grams, and word counts for most articles and book chapters, and for all research reports and pamphlets on JSTOR. Datasets are produced at no cost to researchers and may include data for up to 25,000 documents. </p> </li> <li> <p>LexisNexis Web Services Kit: Lexis Nexis Web Services Kit is a mediated service that allows bulk download of Nexis UNI content (formerly Lexis Nexis Academic). Up to 250 documents and 1000 metadata downloads are allowable on Nexus UNI without use of the API. Contact your subject librarian for access to LexisNexis Web Services Kit. </p> </li> <li> <p>PLOS API: Python tool for downloading/updating/maintaining a repository of all PLOS XML article files. Use this program to download all PLOS XML article files instead of doing web scraping. </p> </li> <li> <p>ProQuest TDM Studio: ProQuest TDM (Text and Data Mining) Studio allows you to create and analyze datasets from ProQuest content. </p> </li> <li> <p>Ravenpack News Analytics: Use for financial and economic analysis. Access through WRDS. </p> </li> <li> <p>Web of Science: is a collection of databases that index the world’s leading scholarly literature in the sciences, social sciences, arts, and humanities, as published in journals, conference proceedings, symposia, seminars, colloquia, workshops, and conventions across the globe.</p> </li> </ul>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"text_mining/#freely-available-text-data-sources","level":2,"title":"Freely Available Text Data Sources","text":"<ul> <li> <p>arXiv Bulk Data: Our mission is to provide rapid dissemination of scientific results at no cost to authors or readers. Providing free Application Programming Interfaces (APIs) helps us to advance that mission by enabling platforms and projects that extend the discoverability of arXiv e-prints and provide valuable services to scientists and interested readers. </p> </li> <li> <p>Books to Scrape: Demo website for web scraping purposes. Prices and ratings here were randomly assigned and have no real meaning. </p> </li> <li> <p>CORE: Open Access Research Papers: CORE provides a central API to access full content from tens of thousands of openly available scientific publications from thousands of OA repositories. Full datasets available by request. </p> </li> <li> <p>HathiTrust Research Center Analytics: Supports large-scale computational analysis of the works in the HathiTrust Digital Library to facilitate non-profit and educational research. </p> </li> <li> <p>Internet Archive: Internet Archive is a non-profit library of millions of free books, movies, software, music, websites, and more. </p> </li> <li> <p>Library of Congress (LC) for Robots: We hope this list of APIs, bulk downloads, and tutorials will help you begin exploring the many ways the Library of Congress provides machine-readable access to its digital collections. </p> </li> <li> <p>New York Times Developer Network: All the APIs fit to post. </p> </li> <li> <p>Project Gutenberg Robot Access: Project Gutenberg is a library of over 60,000 free eBooks. Information about robot access to our pages outlines allowable automated access to content. </p> </li> <li> <p>PubMed APIs: PMC hosts a number of important article datasets and makes our APIs and some code available via public code repositories. </p> </li> <li> <p>OpenAlex: is a fully open catalog of the global research system. It's named after the ancient Library of Alexandria and made by the nonprofit OurResearch.</p> </li> </ul>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"text_mining/#social-media-and-the-web","level":1,"title":"Social Media and the Web","text":"<p>For data collection from social media, it is typical to use the publicly available APIs made available by the social media platforms, such as the following:</p> <ul> <li> <p>X API   Access Twitter (X) data for posts, threads, comments, users, and more. Suitable for data mining and analysis.</p> </li> <li> <p>Google Blogger   API for accessing and managing Blogger content programmatically.</p> </li> <li> <p>Internet Archive Bulk Download   Download files from archive.org in an automated way using tools like <code>wget</code>.</p> </li> <li> <p>Reddit API   Access data from posts, threads, comments, users, and more from Reddit and its subreddits.</p> </li> <li> <p>Pushshift Reddit Data     Historical Reddit data collected as monthly CSV downloads.</p> </li> <li> <p>Stanford Large Network Dataset Collection (SNAP)   The SNAP library collects data on large social and information networks since 2004.</p> </li> <li> <p>Twitter Streaming APIs   Public streams provide access to real-time public data flowing through Twitter. Suitable for following specific users or topics and data mining. You can also access single-user streams, containing roughly all of the data corresponding with a single user’s view of Twitter.</p> </li> <li> <p>Wikipedia Data Dumps   Monthly database backups of all Wikimedia wikis in various formats.</p> </li> <li> <p>Yelp API   Access to business data, including location, photos, Yelp rating, price levels, hours of operation, and types of transactions. Also includes a Review API, which returns up to 3 review excerpts for a business.</p> </li> <li> <p>Blog Authorship Corpus   Over 600,000 posts from more than 19 thousand bloggers.</p> </li> </ul>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"text_mining/#government-documents","level":2,"title":"Government Documents","text":"<ul> <li> <p>Congress.gov API   Includes bills, amendments, summaries, Congress members, the Congressional Record, committee reports, nominations, treaties, and House Communications. Over time, hearing transcripts and Senate Communications will be added. Sign up for a free API key to use.</p> </li> <li> <p>ProQuest Congressional Text 1824-2020   Full text of United States Congressional Hearings (both House and Senate) from 1824-2020 as extracted by ProQuest. Delivered in bulk as XML files with pre-processing completed to extract individual hearing files, rename by hearing ID, and group into folders by decade. By accessing the data, you agree to abide by the included Terms of Use file. Read it thoroughly before use.</p> </li> <li> <p>CourtListener API / Bulk Legal Data   Access opinions, docket files, and more from 420 courts.</p> </li> <li> <p>FDSys Bulk Download   Bulk data downloads of major US Government publications including Congressional Bills, Commerce Business Daily, Federal Register, Public Papers of the Presidents of the United States, Supreme Court Decisions 1937-1975 (FLITE), and more.</p> </li> <li> <p>Harvard Caselaw Access Project   Includes all official, book-published United States case law—every volume designated as an official report of decisions by a court within the United States. Research scholars can qualify for bulk data access by agreeing to certain use and redistribution restrictions. Request a bulk access agreement by creating an account and then visiting your account page.</p> </li> <li> <p>U.S. Department of the Interior: Bureau of Land Management - General Land Office Records (GLO)   Provides direct access to all of the data behind the glorecords.blm.gov website with a series of web service methods in XML format.</p> </li> <li> <p>Voxgov   Provides access to real-time documents, press releases, and social media posts from candidates for Congress and governor across the U.S. Options to compare candidates and groups (e.g., Senate Democrats vs. Republicans), filter by geography or demographics, and generate term frequency charts and word clouds.</p> </li> <li> <p>United States Patent &amp; Trademark Open Data Portal   \"Open data\" is publicly available data that is structured in a way that enables the data to be fully discoverable and usable by end users. It can be freely used, reused, and redistributed by anyone. Its value lies not only in what it does today but also in what it can do in the future. It is a valuable national resource and a strategic asset to the federal government, its partners, and the public.</p> </li> </ul> <p>Original Source: https://libguides.princeton.edu/textmining/sources</p>","path":["Research","Text Mining Resources"],"tags":[]},{"location":"transparency/","level":1,"title":"Transparency and Accountability","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Transparency is a cornerstone of developing trust, specifically when AI is involved in research, government, or healthcare.</p> <p>Definitions</p> <p>AI transparency is the degree of openness in a system design, the data that it uses, its operational framework. Transparency includes:</p> <ul> <li>Access to the data a system was trained upon</li> <li>Explanation of how a model arrives at its decisions</li> <li>List of guardrails, safeguards, and measures in place to mitigate bias</li> </ul> <p>Explainable AI (XAI) focuses on describing specific sequence of steps that an AI model undertakes to arrive at a result, prediction, or response. XAI includes AI transparency and enables comprehension. </p> <ul> <li>UNESCO's \"Transparency and Explainability\" is a core ethical principle, deeming it essential for the ethical deployment and trustworthy adoption of XAI technologies.</li> </ul>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"transparency/#establishing-accountability","level":2,"title":"Establishing Accountability","text":"<p>Coalition for Health AI (CHAI) advances the responsible development, deployment, and oversight of AI in healthcare</p> <p>NIST AI Risk Management Framework (AI RMF) has developed a framework to better manage risks to individuals, organizations, and society associated with AI.</p> <p>Organization for Economic Cooperation and Development (OECD) AI Principles promote use of AI that is innovative and trustworthy and that respects human rights and democratic values.</p> <p>World Health Organization (WHO) has released AI Ethics and governance guidelines for large multi-modal models </p> <p>EU AI Act is comprehensive legislation that includes oversight of AI with a six year (2031) implementation timeline, which is already underway.</p>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"transparency/#mechanisms","level":3,"title":"Mechanisms","text":"<p>Audits - regular systematic audits are essential, these includ bias audits to detect discrimination and fairness evaluations, security vulnerability checks, and performance reviews for accuracy and reliability. </p> <p>Human Oversight - high risk systems require human-in-the-loop approaches which are validated by human experts before implementation</p> <p>Governance Structures - clear and effective governance structures are fundamental to AI accountability. This involves defined leadership and oversight (boards), where responsibility across organizations is formalized and put into standard operating procedures. </p> <p>Record-keeping / Logs - traceability and auditability require detailed records of the AI system's operation and user actions. Audit rails provide invaluable resources for incident investigation, understanding system responses, and demonstrating compliance. </p>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"transparency/#transparency","level":2,"title":"Transparency","text":"The Black Box Problem  <p>Many AI models rely on complex architectures that function as \"black boxes,\" where their internal decision-making processes are opaque and not easily understood by human observers. This lack of transparency creates significant accountability challenges, especially in high-stakes fields like healthcare.</p> <p>A real-world example is the case of AI-enabled pulse oximeters, which were found to overstate blood oxygen saturation in individuals with darker skin. This flaw, rooted in biased training data, highlights how a lack of transparency can hide life-threatening biases within a medical device, leading to unequal care. (Read more at the ACLU)</p>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"transparency/#strategies-for-mitigation","level":3,"title":"Strategies for Mitigation","text":"<p>To counter the black box problem and foster responsible AI, several strategies are essential:</p> <ul> <li>Promoting Data Diversity and Bias Mitigation: Actively working to ensure training datasets are representative of the entire population to prevent algorithmic bias. This includes collecting more diverse data and using techniques to identify and correct biases in models.</li> <li>Strengthening Data Security and Privacy: Implementing robust security measures and privacy-preserving techniques (like federated learning or differential privacy) to protect sensitive data used by AI systems.</li> <li>Fostering Human-in-the-Loop (HITL) Approaches: Integrating human expertise and oversight into AI workflows. This ensures that critical decisions are validated by experts and allows for continuous monitoring and correction of AI behavior.</li> <li>Enhancing Transparency and Explainable AI (XAI): Developing and deploying XAI methods that can provide clear explanations for how a model arrived at a specific decision. This is crucial for building trust and enabling meaningful audits. For example, the open science movement advocates for making data and models used in health research publicly available to allow for independent verification and scrutiny. (Learn about Open Science in AI for Health)</li> </ul>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"transparency/#assessment","level":2,"title":"Assessment","text":"True or False: The 'black box' problem refers to the physical appearance of AI hardware. <p>False</p> <p>The \"black box\" problem describes the difficulty in understanding the internal decision-making processes of complex AI models.</p> Which of the following is NOT a core component of AI transparency? <p>A. Access to the data a system was trained upon</p> <p>B. The speed of the algorithm's computation</p> <p>C. Explanation of how a model arrives at its decisions</p> <p>D. List of safeguards in place to mitigate bias</p> Answer <p>B. The speed of the algorithm's computation </p> <p>While computational speed is a performance metric, it is not a core component of transparency, which focuses on openness, data, and decision-making logic.</p> What is the primary goal of Explainable AI (XAI)? <p>A. To make AI models run faster</p> <p>B. To describe the steps an AI model takes to reach a result</p> <p>C. To replace human oversight entirely</p> <p>D. To secure AI systems from cyberattacks</p> Answer <p>B: To describe the steps an AI model takes to reach a result</p> <p>XAI focuses on making the decision-making process of an AI model understandable to humans.</p> True or False: The EU AI Act is a set of voluntary guidelines for companies to consider. <p>False</p> <p>The EU AI Act is comprehensive legislation with a formal implementation timeline, making it a mandatory legal framework for AI governance in the European Union.</p> Which organization developed the AI Risk Management Framework (AI RMF) to manage risks associated with AI? <p>A. World Health Organization (WHO)</p> <p>B. Coalition for Health AI (CHAI)</p> <p>C. National Institute of Standards and Technology (NIST)</p> <p>D. Organization for Economic Cooperation and Development (OECD)</p> Answer <p>C: National Institute of Standards and Technology (NIST)</p> <p>NIST is responsible for the AI Risk Management Framework.</p>","path":["Ethics","Transparency and Accountability"],"tags":[]},{"location":"tutoring/","level":1,"title":"Tutoring","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Education","Tutoring"],"tags":[]},{"location":"tutoring/#self-tutoring-students-guide","level":2,"title":"Self-Tutoring Student's Guide","text":"<p>Generative AI tools offer powerful new ways to enhance the learning experience both inside and outside the classroom. </p> <p>Beyond simply providing answers to prompts, GPTs can be used to interactively engage with a topic or course material, to assess your understanding, or to reflect upon materials in personal ways tailored to individual learning or study strategies. </p> <p>Access to AI unlocks new learning opportunities for disadvantaged students. For example, the use of GPTs can help English as a second language (ESL) students to work on English skills, through platforms like Duolingo, while also conversing with them in their native language. </p> <p>The opportunity for one-on-one tutoring with AI also will enable traditionally underserved students - if they are given access to these tools by their institution. </p>","path":["Education","Tutoring"],"tags":[]},{"location":"tutoring/#use-cases","level":2,"title":"Use Cases","text":"<p>Here's how you can use AI to become a more effective self-tutor:</p> Explain Concepts <p>Struggling to grasp a difficult concept from lectures or textbooks? </p> <p>Have the AI explain them to you in a way that you understand.</p> <p>Complex ideas</p> PromptChatGPT o1 ResponseGemini Pro 2.0 Response <pre><code>Explain the concept of photosynthesis in simple terms, \nas if you were talking to a person who had never taken \nintroductory biology.\n</code></pre> <p>Photosynthesis is like a plant’s way of making its own food using sunlight. Here’s a simple way to picture what happens:</p> <ol> <li> <p>Sunlight as an Energy Source Plants have special “solar panels” in their leaves (the green parts called chloroplasts). These panels absorb sunlight.</p> </li> <li> <p>Taking In Raw Materials </p> </li> <li>Carbon Dioxide: Plants pull in a gas called carbon dioxide (CO₂) from the air through tiny holes in their leaves.  </li> <li> <p>Water: Plants also draw water (H₂O) up through their roots from the soil.</p> </li> <li> <p>Making Food (Sugar) and Releasing Oxygen Using sunlight as energy, plants combine the carbon dioxide and water to make a type of sugar (this is like a plant’s “food”). A byproduct of this process is oxygen, which is released into the air.</p> </li> <li> <p>Why It Matters </p> </li> <li>Plants Grow and Live: The sugar produced helps the plant grow, develop, and carry out all its functions.  </li> <li>We Breathe Oxygen: The oxygen released during photosynthesis is what most living things (including humans) need to breathe.  </li> </ol> <p>In short, photosynthesis is a natural process that keeps both plants and animals alive: plants get food for themselves, and they give off oxygen for us to breathe.</p> <p>Okay, imagine plants are like little chefs that make their own food. But instead of using an oven or a stove, they use sunlight! That process of making food using sunlight is called photosynthesis.</p> <p>Think of it like this:</p> <ol> <li> <p>Ingredients: Plants need ingredients to make their food, just like we do. They use two main things:</p> <ul> <li>Carbon dioxide: This is a gas that's in the air all around us. We actually breathe it out when we exhale! Plants \"breathe\" it in through tiny holes in their leaves.</li> <li>Water: Plants drink water through their roots, like we drink with a straw.</li> </ul> </li> <li> <p>The \"Kitchen\": Inside plant leaves, there are tiny little \"kitchens\" called chloroplasts. These are special because they are green, thanks to something called chlorophyll. Chlorophyll is like the chef's magic tool – it can capture the energy from sunlight.</p> </li> <li> <p>Cooking with Sunlight:  When sunlight hits the leaves, the chlorophyll traps its energy. This energy is then used like a power source to mix the carbon dioxide and water together.</p> </li> <li> <p>Food is Ready! This mixing process creates a kind of sugar called glucose, which is the plant's food. It's like the yummy meal the plant-chef made. The plant uses this food to grow, make flowers, fruits, and all that good stuff.</p> </li> <li> <p>Bonus – Oxygen!  As a byproduct of this amazing food-making process, plants release oxygen into the air.  This is fantastic for us because we need oxygen to breathe!</p> </li> </ol> <p>So, in a nutshell, photosynthesis is how plants use sunlight, water, and carbon dioxide to make their own food (sugar) and release oxygen into the air. It's like a super-efficient, solar-powered kitchen inside each leaf!</p> <p>It's a really important process because it's how plants grow, and it's also how we get the oxygen we need to live. Pretty cool, huh?                </p> <p>Use analogies and metaphors</p> Prompt <p>These can make abstract ideas more relatable. </p> <p>For example: </p> <pre><code>Give me an analogy to understand the concept of photosynthesis.\n</code></pre> <p>Explore different perspectives</p> Prompt <p>Ask the AI to explain a concept from various angles. </p> <p>For example, </p> <pre><code>Explain the theory of evolution in plants from \na biological, historical, and philosophical perspective.\n</code></pre> Reinforcement Learning <p>Generate practice questions</p> Prompt <p>Specify the topic and type of question. </p> <p>For example: </p> <pre><code>Create 5 multiple-choice questions about the causes \nof World War I.\n</code></pre> <p>Get feedback on your answers</p> <p>Paste in your answers and ask for a critique. </p> <p>For example: </p> <pre><code>Here's my answer to the question: [question]. \n\n[answer]\n\nIs it correct, and how could I improve it?\n</code></pre> <p>Create study guides and summaries</p> <p>For example: </p> <pre><code>Generate a study guide for the chapter on the \nFrench Revolution in my history textbook\n</code></pre> <p>or </p> <pre><code>Create flashcards of the key reactions, \nincluding their reactant, products and the \nmechanism for this Organic Chemistry chapter\n</code></pre> Facilitated Discussion <p>Use Case: Want to engage in deeper discussions about the material, but study partners are unavailable?</p> <p>Simulated debate</p> <p>Take a stance on a topic and ask the AI to argue the opposing viewpoint. </p> <p>For example: </p> <pre><code>I believe social media has a net positive impact on society. \n\nArgue against this position.\n</code></pre> <p>Explore \"what if\" scenarios:</p> <p>Pose hypothetical questions to probe the material further. </p> <p>For example: </p> <pre><code>What if the outcome of the American Civil War had been different? \n\nHow might history have changed?\n</code></pre> <p>Role-play historical figures or characters:</p> <p>For example: </p> <pre><code>Pretend you are Marie Curie, and explain your research on radioactivity \nin a way that a non-scientist could understand.\n</code></pre> Enhancing Writing and Research Skills <p>Use Case: Struggling with essay writing, research paper organization, or finding relevant sources?</p> <p>Brainstorm essay topics and outlines:</p> <p>For example: </p> <pre><code>Help me brainstorm topics for an essay on the impact of climate change.\n</code></pre> <p>or </p> <pre><code>Create an outline for a research paper on the ethical implications of artificial intelligence.\n</code></pre> <p>Get feedback on your writing:</p> <p>Paste in your draft and ask for suggestions on clarity, grammar, and style. </p> <p>For example: </p> <pre><code>Review this paragraph and suggest improvements to make it more concise and impactful.\n</code></pre> <p>Summarize research articles:</p> <p>For example: </p> <pre><code>Summarize the main findings of this research article: [link to article or text of article].\n</code></pre> <pre><code>Please extract the key takeaways from the following report on renewable energy trends.\n</code></pre> Reflecting on Your Learning Process <p>Use Case: Need help identifying your learning strengths and weaknesses or developing better study habits?</p> <p>Analyze your study sessions:</p> <p>Describe your study routine to the AI and ask for suggestions for improvement.  For example: </p> <pre><code>I tend to study for long hours but get easily distracted. \nHow can I make my study sessions more efficient?\n</code></pre> <p>Identify knowledge gaps:</p> <p>Ask the AI to quiz you on a topic and point out areas where you need further review. </p> <p>For example: </p> <pre><code>Quiz me on the main concepts of macroeconomics, and tell me which areas I need to study more.\n</code></pre> <p>Get personalized learning recommendations:</p> <p>Explain your learning style and preferences to the AI and ask for tailored advice. </p> <p>For example: </p> <pre><code>I'm a visual learner. What are some effective study strategies for me?\n</code></pre>","path":["Education","Tutoring"],"tags":[]},{"location":"tutoring/#using-chatgptgemini-as-a-study-buddy","level":2,"title":"Using ChatGPT/Gemini as a Study Buddy","text":"<p>Exam Preparation</p> Generate questions Prompt <pre><code>Generate practice questions on this: {paste material or give topic}\n</code></pre> Multiple-choice questions Prompt <pre><code>Generate multiple choice questions on this: {paste material or give topic\n</code></pre> Create flashcards Prompt <pre><code>Create flashcards on this topic for me: {paste material or give topic}\n</code></pre> Improve text/explanation Prompt <pre><code>How can the following text/explanation about {topic} be improved?: {paste text}\n</code></pre> Mnemonics Prompt <pre><code>Help me remember the 5 most common facts/properties about {topic}\n</code></pre> Historical or factual events Prompt <pre><code>Help me memorize US History\n</code></pre> <p>Formulas and equations assistance</p> Step-by-step instructions Prompt <pre><code>Find the derivative of f(x) = 3x^3 + 2x^2 + 1\n</code></pre> Concepts clarification Prompt <pre><code>Clarify the concept for the equation: Find the derivative of f(x) = 3x^3 + 2x^2 + 1\n</code></pre> <p>Language learning</p> Vocabulary building Prompt <pre><code>What does 'aimer' mean in French and what is the antonym?\n</code></pre> Conversation practice Prompt <pre><code>Engage me in a conversation in French (I'm a beginner)\n</code></pre>","path":["Education","Tutoring"],"tags":[]},{"location":"tutoring/#table-online-ai-driven-educational-platforms","level":3,"title":"Table: Online, AI-driven Educational Platforms","text":"Platform Subject Areas Target Audience Pricing Key Features IXL Math, Language Arts, Science, Social Studies, Spanish Pre-K to 12<sup>th</sup> Grade Starts at $9.95/month (single subject), $19.95/month (all subjects) Personalized learning, adaptive questions, real-time diagnostics, progress tracking, awards, and certificates. Covers a vast range of skills and grade levels. Khan Academy Math, Science, Economics, Arts &amp; Humanities, Computing, Test Prep (SAT, LSAT, MCAT, etc.) K-12, College, Adults Free Comprehensive video lessons, practice exercises, personalized learning dashboard, progress tracking. Covers a wide array of subjects. Duolingo Languages All ages Free (with Duolingo Plus subscription for added features) Gamified language learning, bite-sized lessons, personalized practice, spaced repetition. Focuses on vocabulary, grammar, and pronunciation. Quizlet Various (User-Generated Content) All ages Free (with Quizlet Plus subscription for added features) Flashcards, study games, practice tests, and learning tools. Users can create their own study sets or use existing ones. EdX Various (University-Level Courses) Adults, Professionals Free to audit courses, paid certificates and degrees available Online courses from top universities and institutions worldwide. Offers professional certificates, MicroMasters programs, and online Master's degrees. Coursera Various (University-Level Courses) Adults, Professionals Free to audit courses, paid certificates and degrees available Similar to EdX, offering a vast catalog of online courses from leading universities and organizations. Provides specializations, professional certificates, and online degrees. Udemy Various (Skills-Based Courses) Adults, Professionals Courses priced individually (often discounted) Wide range of courses on various topics, including business, technology, personal development, and the arts. MasterClass Various (Expert-Led Courses) Adults $120/year (individual), $180/year (duo), $240/year (family) Video lessons taught by renowned experts in their respective fields, covering topics like writing, cooking, acting, music, and more. Codecademy Programming, Data Science, Web Development Teens, Adults Free (basic courses), Pro: $239.88/year or $39.99/month Interactive coding lessons, projects, quizzes, and skill paths. Focuses on practical, hands-on learning for in-demand tech skills. Brilliant Math, Science, Computer Science Teens, Adults $149/year or $24.99/month Interactive problem-solving courses, focusing on conceptual understanding. Google Classroom Various, can be used as a platform for any subject K-12, Higher Education Free for schools that use Google Workspace for Education Helps teachers create, distribute, and grade assignments in a paperless way. Integrates with other Google services. Kahoot Various, can be used to gamify any subject K-12, Higher Education, Corporate Training Free (basic), with paid plans for more features Game-based learning platform that makes it easy to create, share and play learning games or trivia quizzes in minutes. Grammarly AI writing tool that helps improve writing style, grammatical errors, and spelling. K-12, Higher Education, Professionals Free (basic), with paid plans","path":["Education","Tutoring"],"tags":[]},{"location":"vibe/","level":1,"title":"Vibe Coding","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>\"Vibe coding\" refers to using an LLM to generate and edit code directly within your IDE (e.g., VS Code). This approach allows for a more fluid and interactive coding experience, where the LLM acts as a collaborative partner.</p> Who coined the term 'vibe coding'? <p>The term \"vibe coding\" originated with a tweet by Andrej Karpathy in February 2025,</p> <p><p>There's a new kind of coding I call \"vibe coding\", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. I just mass chat, mass accept, skip to errors,…</p>— Andrej Karpathy (@karpathy) February 2, 2025 </p> <p>Allowing an LLM to execute code on your computer may be a violation of institutional security and privacy policy</p> <p>Desktop applications like Claude Desktop or OpenAI's ChatGPT Desktop give you the option to allow 'execution' of code on your computer (laptop or PC). </p> <p>You must understand the implications of giving these AI assistants the authority to execute code on your computer and access to the network it is running upon.</p> <p>Malicious code lives on the internet, and your Vibing AI assistant might install something bad while you're not paying attention</p> <p>Read more:  Vibe Check: False Packages A New LLM Security Risk (Note: This is a fictional link as per the example for demonstration).</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#available-platforms","level":2,"title":"Available Platforms","text":"Emoji Meaning VS Code GitHub CodeSpace Apple OS Windows Linux Command Line Interface Open Source Licensed API based","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#desktop-ides-and-standalone-editors","level":3,"title":"Desktop IDEs and Standalone Editors","text":"","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#claude-desktop","level":4,"title":"Claude Desktop","text":"<p>An easy-to-install desktop platform that connects to Anthropic's powerful LLM API, and allows you to connect to MCP servers.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#vs-code","level":4,"title":"VS Code","text":"<p>Microsoft's popular open-source code editor with extensive extension ecosystem, including numerous AI coding assistants (see VS Code Extensions section below).</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#cursor","level":4,"title":"Cursor","text":"<p>A popular standalone fork of VS Code, focused on integrating new models with stability and offering a flat-fee pricing model.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#positron","level":4,"title":"Positron","text":"<p>A next-generation data science IDE built on VS Code, developed by Posit (formerly RStudio), with native support for Python, R, and AI-assisted coding.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#firebase-idx","level":4,"title":"Firebase IDX","text":"<p>Google's cloud-based IDE (formerly Project IDX, now part of Firebase) with built-in AI assistance powered by Gemini, providing a VS Code-like editing experience.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#firebase-studio","level":4,"title":"Firebase Studio","text":"<p>Firebase's integrated development environment for building and deploying Firebase apps with AI-powered code generation and assistance.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#google-antigravity","level":4,"title":"Google Antigravity","text":"<p>Google's experimental AI-powered standalone IDE with advanced Gemini integration for next-generation development workflows.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#windsurf","level":4,"title":"Windsurf","text":"<p>Standalone editor offering similar agentic and inline features with tiered pricing and a \"just works\" usability orientation.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#vs-code-extensions","level":3,"title":"VS Code Extensions","text":"","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#github-copilot","level":4,"title":"GitHub Copilot","text":"<p>Integrated with VS Code and GitHub CodeSpaces, provides agentic coding with periodic performance fluctuations and tiered pricing.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#cline","level":4,"title":"Cline","text":"<p>VS Code extension that's open-source and model-agnostic, pioneering features like \"bring your own model\" (BYOM) and operating on a per-request billing structure.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#roo-code","level":4,"title":"Roo Code","text":"<p>VS Code extension derived from Cline, prioritizes rapid feature development and customization, serving users interested in experimental capabilities.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#claude-code","level":4,"title":"Claude Code","text":"<p>Official Anthropic VS Code extension providing AI pair programming with Claude 4.5 models, featuring multi-file editing, debugging, and terminal integration.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#gemini-code-assist","level":4,"title":"Gemini Code Assist","text":"<p>Google's VS Code extension powered by Gemini models, offering code completion, generation, and chat assistance with Google Cloud integration.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#command-line-interface-cli-tools","level":3,"title":"Command Line Interface (CLI) Tools","text":"","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#aider","level":4,"title":"Aider","text":"<p>A popular command-line tool for AI-driven coding, often used with local or remote LLMs.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#claude-code-cli","level":4,"title":"Claude Code CLI","text":"<p>Official Anthropic command-line interface for Claude, enabling AI-assisted development directly from the terminal with support for MCP servers.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#openai-codex-cli","level":4,"title":"OpenAI Codex CLI","text":"<p>Command-line access to OpenAI's Codex models, integrated with GitHub Copilot for terminal-based AI assistance.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#google-gemini-cli","level":4,"title":"Google Gemini CLI","text":"<p>Google's command-line interface for Gemini models, providing AI coding assistance and integration with Google Cloud services.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#opencodeai","level":4,"title":"OpenCode.ai","text":"<p>Open-source CLI tool supporting multiple AI models for code generation, analysis, and refactoring from the command line.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#browser-based-vibe-coding","level":3,"title":"Browser-based Vibe Coding","text":"","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#claude","level":4,"title":"Claude","text":"<p>Claude's web interface now includes Artifacts feature for interactive code execution, allowing you to write, run, and iterate on code directly in the browser with real-time preview.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#claude-code-for-web","level":4,"title":"Claude Code for Web","text":"<p>Browser-based version of Claude Code providing AI pair programming capabilities through the web, featuring multi-file editing, code generation, and debugging without requiring a desktop installation.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#chatgpt","level":4,"title":"ChatGPT","text":"<p>OpenAI's ChatGPT Plus and Team tiers include Code Interpreter (Advanced Data Analysis) for executing Python code, analyzing data, and generating visualizations directly in the browser.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#google-gemini","level":4,"title":"Google Gemini","text":"<p>Google Gemini's web interface features code execution capabilities, allowing you to run Python code and see results inline with AI-generated explanations.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#openwebui","level":4,"title":"OpenWebUI","text":"<p>Self-hostable, open-source web interface supporting multiple LLM providers (OpenAI, Anthropic, Ollama) with built-in code execution, function calling, and customizable workflows.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"vibe/#model-context-protocol-mcp","level":1,"title":"Model Context Protocol (MCP)","text":"<p> Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools. This ensures interoperability and allows developers to more easily swap out models or context sources without re-engineering their entire application.</p>","path":["Prompt Engineering","Vibe Coding"],"tags":[]},{"location":"tutorials/publichealth/casestudy/","level":1,"title":"Public Health","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#bias-and-data-quality","level":2,"title":"Bias and Data Quality","text":"","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#ethics-transparency-accountability","level":2,"title":"Ethics: Transparency &amp; Accountability","text":"","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#standardization","level":2,"title":"Standardization","text":"<p>The standardization of protocols and controls is critical for ensuring consistent, high-quality public health practices across different organizations and regions. </p> <p>AI Protocol Analysis and Harmonization</p> <p>AI can analyze multiple existing protocols to identify commonalities, differences, and best practices:</p> Example prompt <pre><code>Analyze different measles testing protocols from various health departments\nin Arizona, Texas, New Mexico, Sonora, and Chihuahua. \nIdentify:\n- Common required steps across all protocols\n- Key differences in methodology\n- Best practices that appear in multiple protocols\n- Potential gaps or missing elements\n- Recommendations for a standardized protocol\n</code></pre> <p>Natural Language Processing for Protocol Extraction</p> <p>AI can extract structured information from unstructured protocol documents:</p> <ul> <li>Convert narrative guidelines into step-by-step procedures</li> <li>Identify required equipment, materials, and personnel</li> <li>Extract critical values, thresholds, and decision points</li> <li>Create standardized terminology mappings</li> </ul> <p>Automated Protocol Validation</p> <p>AI systems can check protocols for: - Completeness (all necessary steps included) - Consistency (no contradictory instructions) - Compliance with regulations and standards - Evidence-based practice alignment</p>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#human-in-the-loop-hitl-approaches","level":3,"title":"Human-in-the-Loop (HITL) Approaches","text":"<p>Human-in-the-loop systems combine AI efficiency with human expertise to improve accuracy and reliability:</p> <p>Key HITL Components:</p> <ul> <li>Expert Annotation: Subject matter experts review and annotate AI-generated protocols</li> <li>Iterative Refinement: AI learns from expert corrections to improve future outputs</li> <li>Decision Points: Critical decisions require human approval before proceeding</li> <li>Quality Assurance: Random sampling and human verification of AI outputs</li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#key-infrastructure-requirements","level":3,"title":"Key Infrastructure Requirements","text":"<ul> <li>Scalability: Handle increasing protocol volumes and complexity</li> <li>Interoperability: Connect with existing health information systems</li> <li>Security: Protect sensitive health information</li> <li>Reliability: 99.9% uptime for critical health operations</li> <li>Traceability: Complete audit trails for regulatory compliance</li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#implementation-considerations","level":3,"title":"Implementation Considerations","text":"<ul> <li>Change Management: Training staff on new AI-assisted workflows</li> <li>Ethical Guidelines: Ensuring AI decisions are fair and unbiased</li> <li>Regulatory Compliance: Meeting local and federal health regulations</li> <li>Performance Monitoring: Tracking AI accuracy and human satisfaction</li> <li>Continuous Learning: Regular model updates based on new evidence</li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#best-practices-for-implementation","level":3,"title":"Best Practices for Implementation","text":"<ol> <li>Start Small: Pilot with non-critical protocols first</li> <li>Maintain Transparency: Document AI decision-making processes</li> <li>Preserve Expertise: AI augments, not replaces, human judgment</li> <li>Regular Audits: Systematic review of AI performance</li> <li>Stakeholder Engagement: Include all users in design and testing</li> <li>Continuous Training: Keep both AI models and humans updated</li> </ol> <p>Human-in-the-loop approaches that improve accuracy and reliability, combined with robust AI infrastructure, allow for more seamless integration into public health practices while maintaining the critical human oversight necessary for healthcare decision-making. </p>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#case-studies","level":2,"title":"Case Studies","text":"","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#awesome-lists","level":4,"title":"Awesome Lists","text":"<p>Maintained on GitHub and often feature the badge: , Awesome lists contain community-maintained lists of popular and widely used software, data, and code for almost everything on the internet.</p> <ul> <li> <p> Awesome Healthcare</p> </li> <li> <p> Awesome Healthcare Datasets</p> </li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#diagnostics","level":3,"title":"Diagnostics","text":"<p>AI has great promise for enhancing diagnostic capabilities, but have exhibited biases on race and ethnicity. There are calls to address these biases in big data and AI for health care by taking an open science approach</p> <p>List of FDA approved AI medical devices: https://www.datawrapper.de/_/IBGhg/</p> <p> </p> <p>Positive Examples</p> <p>High speed internet access via wired, broadband, or satellite allows clinicians to stream data to the cloud and larger AI resources and improved access to specialty care in Underserved and Rural Areas.</p> <p>Negative Examples:</p> <ul> <li>AI-enabled pulse oximeters overstate blood oxygen saturation in individuals with darker skin, exacerbating racial bias</li> </ul> <p>Readings:</p> <ul> <li> <p>https://www.medtechdive.com/news/fda-ai-medical-devices-growth/728975/</p> </li> <li> <p>https://nam.edu/perspectives/advancing-artificial-intelligence-in-health-settings-outside-the-hospital-and-clinic/</p> </li> <li> <p>https://www.nature.com/articles/s41746-018-0040-6</p> </li> <li> <p>https://www.digitaldiagnostics.com/products/eye-disease/lumineticscore/</p> </li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#disease-surveillance-prediction","level":3,"title":"Disease Surveillance &amp; Prediction","text":"<p>AI-powered predictions change the landscape of population-level public health surveillance. </p> <p>Machine learning (predictive AI) has been used for many years to analyze data and make predictions around disease spread and outbreak detection. </p> <p>AI-systems can quickly analyze electronic health records (EHRs), social media platforms, online search queries, environmental data, genomic sequences, wearable devices,  Of course. Here is the updated markdown table with public URLs for every example. Any examples for which I could not find a reliable, public URL have been removed.</p> Application Area AI Technique(s) Used Data Sources Leveraged Specific Examples/Platforms Key Outcomes/Impacts Early Outbreak Detection Machine Learning, NLP Social Media, News Reports, Airline Travel Data, Official Health Reports BlueDot, HealthMap Early warning for COVID-19 by detecting initial signals before official reports; faster public health response. Real-Time Monitoring Machine Learning, NLP EHRs, Lab Reports, Public Health Data, Free-text data CDC NLP analysis for vaccine safety Continuous tracking of disease spread and monitoring safety of vaccines by analyzing large volumes of free-text data. Epidemic Forecasting Machine Learning, Deep Learning Historical Disease Data, Climate Patterns, Population Mobility, Search Queries CDC FluSight, Dengue/Influenza models Improved prediction accuracy for flu seasons, dengue outbreaks; better preparedness. Identifying High-Risk Populations Machine Learning Demographic, Socioeconomic, Health Data, Aerial Imagery TowerScout Enables targeted interventions, such as identifying cooling towers from imagery to speed up response to Legionnaires' disease outbreaks. Pathogen Genomic Surveillance AI Algorithms, Machine Learning Genomic Sequences of Pathogens Nextstrain Rapid detection of new variants (e.g., SARS-CoV-2), understanding transmissibility/virulence changes. Syndromic Surveillance (Unconv.) NLP, Machine Learning, Image Analysis Online Search Queries, Social Media Posts, Wikipedia page views, Chest X-rays AI for TB detection from X-rays Early detection of community transmission before clinical reporting and improved speed and accuracy for TB surveillance. Antimicrobial Resistance (AMR) Tracking Predictive Analytics, ML Clinical Data, Epidemiological Data, Lab Results AI-driven AMR surveillance systems Improved detection of AMR trends, rapid pathogen ID and resistance profiling, guidance for stewardship. Vector-Borne Disease Prediction Machine Learning Environmental Data (temp, humidity, rainfall), Satellite Imagery, Historical Case Data AI models for Malaria prediction Prediction of high-risk areas for outbreaks, enabling targeted vector control measures. Resource Allocation Prediction Machine Learning Outbreak Data, Hospital Capacity Data, Supply Chain Information NHS A&amp;E demand forecasting tool Optimization of resource deployment during public health emergencies. Misinformation Monitoring NLP Social Media Content, Online News Project Heal, EPIWATCH Identification of false narratives that could impede public health responses, enabling counter-messaging. <p>Readings:</p> <ul> <li> <p>Zeng et al. (2021) Artificial intelligence–enabled public health surveillance—from local detection to global epidemic monitoring and control. Artificial Intelligence in Medicine Technical Basis and Clinical Applications</p> </li> <li> <p>Hattab, G. et al. (2025) The Way Forward to Embrace Artificial Intelligence in Public Health. American Journal of Public Health 115, 123_128</p> </li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#resource-allocation","level":3,"title":"Resource Allocation","text":"<p>Perhaps the most ethically fraught application of AI in health care is on resource allocation. Decisions made by algorithms for high-risk care have exhibited racial biases. </p> <p>Positive Examples:</p> <ul> <li>The UK's National Health Service (NHS) uses an AI-powered tool to forecast demand for emergency services, helping to optimize the allocation of staff, beds, and other resources to improve patient outcomes. (Read more)</li> </ul> <p>Negative Examples:</p> <ul> <li>Training data based on historical spending for health care on black vs white patients resulted in an algorithm systematically biased toward spending on more on white patients than on black patients, resulting in a perpetuation and exacerbation of the health disparity. </li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#clinical-decision-support","level":3,"title":"Clinical Decision Support","text":"<p>AI-powered tools can assist healthcare providers in making more informed decisions, but they must be used with caution as they can also perpetuate existing biases.</p> <p>Positive Examples:</p> <ul> <li>Oncology Screening: Development and validation of an autonomous artificial intelligence agent for clinical decision-making in oncology</li> <li>Diabetic Retinopathy Detection: AI systems like LumineticScore can analyze retinal images to detect diabetic retinopathy, a leading cause of blindness, enabling early intervention and treatment, particularly in areas with limited access to specialists.</li> <li>Drug Discovery: Language models like Google's TxGemma are being developed to accelerate drug discovery by understanding and predicting the properties of therapeutic compounds.</li> <li>Diagnostic Conversations: Research systems like Google's AMIE are exploring the potential for AI to conduct diagnostic conversations and improve medical reasoning. (Read more)</li> </ul> <p>Negative Examples:</p> <ul> <li>Skin Cancer Detection: AI models for detecting skin cancer have shown lower accuracy on darker skin tones, which can lead to missed or delayed diagnoses for patients from underrepresented racial and ethnic groups.</li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#mental-health","level":3,"title":"Mental Health","text":"<p>The application of AI in mental health presents both significant opportunities and serious risks, particularly concerning the well-being of vulnerable populations.</p> <p>Positive Examples:</p> <ul> <li>Increased Access to Care: AI-powered chatbots and virtual therapists can help mitigate shortages of mental health providers, especially in rural and underserved areas, by offering accessible, on-demand support. (Read more)</li> <li>Potential for Effective Treatment: Early research suggests that generative AI chatbots may become a valuable tool in mental health treatment, with some studies showing promising outcomes. (Read the study)</li> <li>Positive Mental Health: AI is being explored for applications in positive psychology, focusing on well-being and flourishing. (Read the review)</li> </ul> <p>Negative Examples:</p> <ul> <li>Unregulated and Unaccountable Care: The proliferation of unlicensed and unaccountable AI chatbots posing as therapists raises serious ethical concerns, as they may provide harmful advice or fail to respond appropriately in crisis situations. (Read more)</li> <li>Risk of Harm: Unregulated AI has been accused of contributing to negative mental health outcomes, including exacerbating distress, cyberbullying, and even being implicated in cases of suicide.</li> <li>Lack of Oversight: There is currently little regulatory oversight for AI therapy companies, creating a gap in ensuring the safety and effectiveness of these services. (Read more)</li> </ul>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/casestudy/#further-reading","level":2,"title":"Further Reading","text":"<p>WHO Guidance: Ethics and Governance of Artificial Intelligence for Health</p> <p>Focus Group on \"Artificial Intelligence for Health\" (FG-AI4H)</p>","path":["Tutorials","Public Health"],"tags":[]},{"location":"tutorials/publichealth/gis/","level":1,"title":"Vibe coding a Public Health Map","text":"<p>This work is licensed under a Creative Commons Attribution 4.0 International License.</p> <p>Setup</p> <p>Desktop LLM Apps</p> <p>Claude Desktop</p> <p>( Windows,  Mac OS)</p> <p>Connects automatically to Anthropic Claude. </p> <p> Claude Desktop https://claude.ai/download </p> <p>AnythingLLM Desktop</p> <p>( Windows,  Mac OS,  Linux)</p> <p> AnythingLLM https://anythingllm.com/desktop </p> <p>Integrated Development Environment (IDE) Desktops</p> <p> VS Code</p> <p>( Windows,  Mac OS,  Linux)</p> <p> https://code.visualstudio.com/download</p> <p>Positron</p> <p> https://positron.posit.co/ </p> <p>API Access</p> <p> https://console.anthropic.com/</p> <p>Cline ( VS Code Extension)  https://cline.bot/</p> <p>Optional:  QGIS https://qgis.org/download/</p> <p> QGISMCP</p> <p> https://github.com/jjsantos01/qgis_mcp</p>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#prompt-engineering-vibe-coding","level":2,"title":"Prompt Engineering &amp; Vibe Coding","text":"<p>The goal of this lab is to guide your LLM agent (Claude, Cline, etc.) through a reproducible workflow that turns open geospatial data into an interactive story map. Copy-and-paste the prompts below in order. Adjust ONLY the bracketed values (<code>&lt;…&gt;</code>) to match your environment.  </p>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#prerequisites-checklist","level":3,"title":"Prerequisites (checklist)","text":"✔︎ Requirement Notes Frontier-class LLM access (API or Desktop) Claude 4, GPT-4.5, Gemini 2.5 Pro, etc. IDE with Cline or Roo Code extension or Claude Desktop Enables local tool use &amp; file ops Filesystem MCP server running Gives the AI read/write access Git &amp; GitHub account (optional but recommended) For version control &amp; sharing","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-0-add-a-system-instruction-or-workspace-rules-file","level":3,"title":"Step 0 – Add a System Instruction or Workspace Rules file.","text":"<p>These are sometimes called an EigenPrompt -- because they come before any other prompts.</p> EigenPrompts <p>We are using Cline on VS Code, so we will create a unique Workspace Rules file, these are located in the <code>.clinerules</code> folder -- clicking on the :material-scales: icon will take you to Cline Rules </p> Copy/Paste <pre><code>**Eigenprompt: Rigorous Code Generation &amp; Automated Validation**\n\n**Objective:** Generate [code for a specific function/module/class | architectural outline] for [project/feature description] with a focus on correctness, testability, maintainability, and automated verification via Cline Workspace Rules.\n\n**I. Code Generation Specifications:**\n\n1. **Functionality:**  \n  - Clearly define input(s), output(s), and the intended behavior.\n\n2. **Language/Framework:**  \n  - Specify the programming language and version clearly (e.g., Python 3.10, JavaScript ES2022, Go 1.18).\n\n3. **Dependencies:**  \n  - Explicitly list external libraries or modules required.\n\n4. **Error Handling:**  \n  - Define expected errors explicitly with handling methods (exceptions, error codes, fallbacks).\n\n5. **Performance Constraints (Optional):**  \n  - Describe any important time or memory constraints clearly.\n\n6. **Code Style:**  \n  - Follow defined style guides (e.g., PEP 8, Google Java Style).  \n  - Clearly document non-obvious or complex logic concisely, specifying reasons (\"why\") and behavior (\"what\").\n\n**II. Testing &amp; Validation Requirements:**\n\n1. **Unit Tests:**  \n  - Specify testing framework explicitly (e.g., unittest, Jest, Mocha).  \n  - List and implement critical test cases clearly:\n    - Typical valid inputs.\n    - Edge cases.\n    - Invalid inputs and related error-handling tests.\n  - Indicate desired code coverage clearly [% of coverage as applicable].\n\n2. **Validation Criteria:**  \n  - Clearly describe measurable criteria for successful test results.  \n  - Specify validation datasets, criteria, or methods if needed.\n\n**III. Automated Execution, Validation, and Bug-Fixing Workflow (Cline Workspace Rules):**\n\n1. **Terminal Execution Validation:**\n  - After execution of generated code or tests via ChatGPT API in VS Code Terminal, automatically inspect the outputs.\n  - Verify explicitly that the commands have exited without errors or warnings.\n\n2. **Error &amp; Warning Inspection:**\n  - Check VS Code's \"Problems\" pane for reported errors, warnings, or alerts promptly after running code or tests.\n\n3. **Automated Re-examination on Errors:**\n  - In case of any detected terminal output issues or problems pane alerts:\n    - Automatically re-inspect the relevant code and identify root causes clearly.\n    - Promptly propose corrected or improved code, addressing identified issues directly.\n    - Re-run tests and terminal commands, verifying fixes iteratively until no critical issues persist.\n\n4. **Final Confirmation:**\n  - Explicitly confirm successful execution (no persistent errors or warnings) before finishing the task.\n\n**IV. Project Structure &amp; Documentation (Initialize/Update):**\n\n1. **`README.md`:**\n  - **Project Title:**\n  - **Description:** Succinct description.\n  - **Setup Instructions:** Clearly outlined installation and execution steps.\n  - **Usage:** Simple demonstration or examples.\n  - **Testing Instructions:** Exact commands to run provided unit tests.\n\n2. **`prompts/` directory:**\n  - Log initial eigenprompt clearly as `prompts/001_initial_eigenprompt.md`.\n  - Log ChatGPT API's full responses (code, documentation, README) as `prompts/001_response.md`.\n  - Future interactions follow sequential convention (e.g., `002_refinement_prompt.md`, `002_response.md`).\n\n**V. Output Format (Concise &amp; Complete):**\n\n- Clearly named source code files according to module criteria (e.g., `module_name.py`).\n- Clearly named unit test files aligned with testing framework (e.g., `test_module_name.py`).\n- Complete and concise README.md file content.\n- Confirmation that automated validation via Cline Workspace Rules has executed successfully or corrections documented explicitly.\n- Confirmation of structured prompt logging.\n\n---\n\n**Illustrative Usage Example:**\n\n**Objective:** Generate efficient Python code for calculating Fibonacci numbers with memoization, fully tested and automatically validated via Cline Workspace Rules.\n\n- **Code Specifications:**\n  - Input: non-negative integer `n`; Output: nth Fibonacci number.\n  - Use memoization for efficiency, with clear descriptive comments.\n  - Error Handling: Raise explicit `ValueError` on negative input.\n  - Python version: 3.10; Adhere strictly to PEP 8 style.\n\n- **Unit Testing:**\n  - Framework: `unittest`.\n  - Test cases: `fib(0)`→`0`, `fib(1)`→`1`, `fib(10)`→`55`, `fib(20)`→`6765`; negative inputs raise `ValueError`.\n\n- **Automated Validation (Cline Workflow):**\n  - Upon running tests in terminal through ChatGPT API integration with VS Code, check terminal output immediately.\n  - Automatically examine the \"Problems\" pane for errors or warnings.\n  - If issues detected, automatically re-inspect code, clearly identify and implement fixes, and iteratively rerun validation steps until no problems remain.\n\n- **Project Structure &amp; Logs:**\n  - Create README.md, `prompts/` structure and log prompts/responses precisely as described.\n\n- **Final Output:**\n  - Files: `fibonacci.py`, `test_fibonacci.py`, `README.md`.\n  - Explicit confirmation that code and tests execute without errors or warnings and validation is automated successfully.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-1-initialize-project-folders","level":3,"title":"Step 1 – Initialize project folders","text":"<pre><code>TASK\nCreate the following directory structure in the current repo  \n  data/  \n  map/  \n  code/  \n  prompts/\nAcknowledge when folders exist.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-2-download-unzip-snow-dataset","level":3,"title":"Step 2 – Download &amp; unzip “snow” dataset","text":"<pre><code>TASK\n1. Download https://geodacenter.github.io/data-and-lab/data/snow.zip into data/  \n2. Unzip it in place, then delete the original .zip  \n3. Write a brief summary of extracted files \n\nUse Python scripting; save the script as code/download_data.py\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-3-organize-geojson-layers","level":3,"title":"Step 3 – Organize GeoJSON layers","text":"<pre><code>TASK\nIn the unzipped snow dataset, locate every *.geojson file.  \nMove the .geojson files into the map/ folder\n\nIgnore all other file types.  \n\nConfirm moves as successful.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-4-summarize-accompanying-pdfs","level":3,"title":"Step 4 – Summarize accompanying PDFs","text":"<pre><code>TASK\nWithin data/snow/, there are several PDF documentation files.\n\n1. Extract their plain-text content and generate a markdown summary (≤ 200 words) of key variables &amp; metadata.  \n2. Save these markdown text as data/snow_docs_summary.md\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-5-build-a-storytelling-leaflet-map","level":3,"title":"Step 5 – Build a storytelling Leaflet map","text":"<pre><code>TASK\nUsing Leaflet HTML, CSS, and JavaScript, create  \n  map/snow_storymap.html\nRequirements:\n  • The HTML must scroll like a Story Map,\n  • Layers appear when scrolled to and disappear when they are scrolled past\n  • Summarized text explains the relevance and meaning of each data set\n  • Use chloropleth colors for presence or absence of observations, such as 'deaths' and 'deathdens' for deaths and death density\n  • add the death count to polygons but not point layers\n  • Run local python web server on a high random port (e.g., 51234) to avoid conflicts  \n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-6-iterate-for-aesthetics","level":3,"title":"Step 6 – Iterate for aesthetics","text":"<pre><code>TASK\nOpen map/snow_storymap.html and critique its look (colors, fonts, layout).  \nSuggest up to three improvements.  \nWait for user approval, then implement changes inside the same file.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-7-log-every-prompt","level":3,"title":"Step 7 – Log every prompt","text":"<pre><code>TASK\nCreate code/log_prompts.py that appends each user &amp; assistant message  \nfrom this session into prompts/session_&lt;timestamp&gt;.md  \nEnsure it runs automatically at the end of each assistant response.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-8-commit-push","level":3,"title":"Step 8 – Commit &amp; push","text":"<pre><code>TASK\nGit add all new/modified files  \nCommit with message \"Add snow GIS story-map lab\"  \nPush to &lt;your-GitHub-remote&gt;  \nReport the commit URL on success.\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#step-9-one-shot-prompt","level":3,"title":"Step 9 – One Shot Prompt","text":"<p>Now, try a new chat session and let's push everything through at once to see how it turns out:</p> <pre><code>The goal for this project is to create a story map that tells the story of 1850's the cholera outbreak in London. We will use HTML, JS, CSS, and Python for the code. \n\n\nFirst task,\n\n1. Download https://geodacenter.github.io/data-and-lab/data/snow.zip into a new folder called `data/`  \n2. Unzip the .zip file in place, then delete the .zip  \n3. Write a short summary in MarkDown of the steps to this in the `data/` folder.\n\nSecond task,\n\n4. In the unzipped dataset, locate every *.geojson file.  \n5. Move the .geojson files into a new `map/` folder. Ignore the data in the __MACOSX folder. Ignore all other file types.\n\nThird task,\n\n6. Summarize accompanying PDFs in the `data/` folder and save the summaries in a new MarkDown file.\n\nFinal task,\n\n6. Build a scrolling story telling map. Using Leaflet, HTML, CSS, and JavaScript, create a `map/snow_storymap.html` which will read the GeoJSON files we got earlier.\n\nRequirements:\n  • The HTML must scroll like a Story Map that is effective both on mobile and desktop\n  • the layers should appear when scrolled over and disappear when they are scrolled past\n  • Use the summarized text to explain the relevance and meaning of each data set in the context of the larger story\n  • Use chloropleth colors for presence or absence of observations, such as 'deaths' and 'deathdens' for deaths and death density\n  • add the death count to polygons as labels, but to the not point layers\n</code></pre>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]},{"location":"tutorials/publichealth/gis/#next-steps","level":3,"title":"Next Steps","text":"<p>• Modify the prompts to use QGISMCP and build the layers there.</p> <p>• Deploy the code and map via GitHub Pages.</p>","path":["Tutorials","Vibe coding a Public Health Map"],"tags":[]}]}